{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b483b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e68cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f81226169f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial settings\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4bada",
   "metadata": {},
   "source": [
    "## 1. Build the 2D RNN\n",
    "- tensorized RNN cell as in Hibat-Allah 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3588d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorizedGRU(nn.Module):\n",
    "    \"\"\" Custom GRU layer for 2D input \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.tanh    = torch.nn.Tanh()\n",
    "        \n",
    "          \n",
    "        # define all weights\n",
    "        w1      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W1 = nn.Parameter(w1)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        b1      = torch.empty(self.hidden_size)\n",
    "        self.b1 = nn.Parameter(b1)\n",
    "        \n",
    "        w2      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W2 = nn.Parameter(w2)  \n",
    "        b2      = torch.empty(self.hidden_size)\n",
    "        self.b2 = nn.Parameter(b2)\n",
    "        \n",
    "        w3      = torch.empty(2*self.hidden_size, self.hidden_size)\n",
    "        self.W3 = nn.Parameter(w3) \n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.W1, 1)\n",
    "        nn.init.xavier_uniform_(self.W2, 1)\n",
    "        nn.init.xavier_uniform_(self.W3, 1)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W1)\n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b1, -lim, lim)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W2) \n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b2, -lim, lim)\n",
    "   \n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        if len(inputs[0].size()) == 3:\n",
    "            inputs[0] = inputs[0][:,0,:]\n",
    "        if len(inputs[1].size()) == 3:\n",
    "            inputs[1] = inputs[1][:,0,:]\n",
    "\n",
    "        inputstate_mul = torch.einsum('ij,ik->ijk', torch.concat((states[0], states[1]), 1),torch.concat((inputs[0], inputs[1]),1))\n",
    "        # prepare input linear combination\n",
    "        state_mul1 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W1) # [batch_sz, num_units]\n",
    "        state_mul2 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W2) # [batch_sz, num_units]\n",
    "\n",
    "        u = self.sigmoid(state_mul2 + self.b2)\n",
    "        state_tilda = self.tanh(state_mul1 + self.b1) \n",
    "\n",
    "        new_state = u*state_tilda \n",
    "        new_state += (1.-u)*torch.einsum('ij,jk->ik', torch.concat((states[0], states[1]), 1), self.W3)\n",
    "        output = new_state\n",
    "        return output, new_state\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, system_size_x, system_size_y, hidden_dim, n_layers, sz_tot = None):\n",
    "        super(Model, self).__init__()\n",
    "        \"\"\"\n",
    "        Creates RNN consisting of GRU cells.\n",
    "        Inputs:\n",
    "            - input_size:  number of quantum numbers (i.e. 2 for spin-1/2 particles)\n",
    "            - system_size: length of each snapshot\n",
    "            - hidden_dim:  dimension of hidden states\n",
    "            - n_layers:    number of layers of the GRU\n",
    "        \"\"\"\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size  = input_size    # number of expected features in input data\n",
    "        self.output_size = input_size    # number of expected features in output data\n",
    "        self.N_x         = system_size_x # length of generated samples in x dir\n",
    "        self.N_y         = system_size_y # length of generated samples in x dir\n",
    "        self.hidden_dim  = hidden_dim    # number of features in the hidden state\n",
    "        self.n_layers    = n_layers      # number of stacked GRUs\n",
    "        self.sz_tot      = sz_tot        # total magnetization if u(1) symmetry is applied (default: None)\n",
    "        self.system_size = system_size_x*system_size_y\n",
    "        #Defining the layers\n",
    "        self.rnn  = TensorizedGRU(self.input_size, hidden_dim)   \n",
    "        self.lin1 = nn.Linear(hidden_dim, self.output_size)\n",
    "        self.lin2 = nn.Linear(hidden_dim, self.output_size)\n",
    "        #self.s    = torch.softmax(dim=0)\n",
    "        self.soft = nn.Softsign()\n",
    "        \n",
    "        self.get_num_parameters()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Passes the input through the network.\n",
    "        Inputs:\n",
    "            - x:      input state at t\n",
    "            - hidden: hidden state at t\n",
    "        Outputs:\n",
    "            - out:    output configuration at t+1\n",
    "            - hidden: hidden state at t+1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the dense layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generates the hidden state for a given batch size.\n",
    "        \"\"\"\n",
    "        # This method generates the first hidden state of zeros for the forward pass and passes it to the device.\n",
    "        # This is equivalent to a product state.\n",
    "        hidden = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float64).to(device)\n",
    "        return hidden\n",
    "    \n",
    "    def get_num_parameters(self):\n",
    "        \"\"\"\n",
    "        Calculates the number of parameters of the network. \"\"\"\n",
    "        p = 0\n",
    "        for param in list(self.parameters()):\n",
    "            if param.requires_grad:\n",
    "                p += param.numel()\n",
    "        print(\"Total number of parameters in the network: \"+str(p))\n",
    "        return p\n",
    "    \n",
    "    def _gen_samples(self, nx, ny, direction, inputs, hidden_inputs, numsamples):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        # samples are obtained by sampling from the amplitudes\n",
    "        sample = torch.multinomial(ampl, 1) \n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample, 2).double()\n",
    "        \n",
    "        return sample[:,0], sigma, ampl, torch.mul(torch.pi,phase), hidden\n",
    "    \n",
    "    \n",
    "    def sample(self, num_samples):\n",
    "        \"\"\"\n",
    "        Generates num_samples samples from the network and returns the samples,\n",
    "        their log probabilities and phases.\n",
    "        \"\"\"\n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma       = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y): # add a padding for the inputs and hidden states\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "                \n",
    "        samples     = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    samples[nx][ny], sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_samples(nx, ny, direction, inputs, hidden_inputs, num_samples)\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "                    ohs[nx][ny] = sigma\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    samples[nx][ny], sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_samples(nx, ny, direction, inputs, hidden_inputs, num_samples)\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    \n",
    "        samples = torch.stack([torch.stack(s, axis=1) for s in samples], axis=1) #.reshape((num_samples, self.N_x, self.N_y))\n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return samples, log_probs_ampl, phase\n",
    "    \n",
    "    def _gen_probs(self, nx, ny, direction, sample, inputs, hidden_inputs):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample.reshape((sample.size()[0],1)), 2).double()\n",
    "        \n",
    "        return sigma, ampl, torch.mul(torch.pi,phase), hidden\n",
    "    \n",
    "    def log_probabilities(self, samples):\n",
    "        \"\"\"\n",
    "        Calculates the log probability and the phase of each item in samples.\n",
    "        \"\"\"\n",
    "        # reshape samples\n",
    "        num_samples = samples.size()[0]\n",
    "        samples = samples.clone().detach()\n",
    "        samples = [[samples[:,nx,ny] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        \n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma  = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y):\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_probs(nx, ny, direction, samples[nx][ny], inputs, hidden_inputs)\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_probs(nx, ny, direction, samples[nx][ny], inputs, hidden_inputs)\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return log_probs_ampl, phase\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9067d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n",
      "Model(\n",
      "  (rnn): TensorizedGRU(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (lin1): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (lin2): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (soft): Softsign()\n",
      ")\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[-1.7199e-01, -3.5822e-02, -8.7693e-02, -4.8696e-02],\n",
      "         [-1.6129e-01,  7.3265e-02, -1.6366e-01, -1.1634e-02],\n",
      "         [ 6.3465e-02, -6.1541e-02,  1.0360e-01,  2.3027e-02],\n",
      "         ...,\n",
      "         [-1.5881e-01, -1.8020e-01,  1.2630e-03, -7.0050e-02],\n",
      "         [-4.5944e-02, -2.5674e-02,  1.7266e-01,  1.7306e-01],\n",
      "         [-1.7070e-02, -5.4824e-02,  8.8665e-02, -1.4569e-02]],\n",
      "\n",
      "        [[-1.7372e-01,  5.9513e-02,  1.7479e-01, -1.4472e-01],\n",
      "         [-3.9431e-02,  3.9594e-02, -1.4867e-01, -1.5631e-01],\n",
      "         [ 1.3630e-01, -6.4649e-02,  1.0650e-01,  1.6322e-02],\n",
      "         ...,\n",
      "         [-1.6735e-01, -1.7476e-01,  6.1941e-02, -1.7032e-01],\n",
      "         [-1.4962e-01,  9.2836e-02,  8.8627e-02, -1.6637e-01],\n",
      "         [ 1.3138e-01, -3.5501e-02,  1.3555e-01, -1.0714e-01]],\n",
      "\n",
      "        [[-1.7360e-01, -1.2103e-01, -2.8304e-02, -1.8234e-01],\n",
      "         [-1.2440e-02, -9.1120e-02, -4.2495e-02, -2.5958e-05],\n",
      "         [ 1.0247e-02, -1.7859e-01,  9.3912e-02, -1.1190e-01],\n",
      "         ...,\n",
      "         [-1.0870e-01,  3.6932e-03, -1.2927e-01,  1.1593e-01],\n",
      "         [ 3.5962e-02, -7.9079e-02, -1.0580e-01,  5.9807e-02],\n",
      "         [-4.3705e-02,  3.4882e-02,  1.7154e-02,  2.2710e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3190e-01,  1.1240e-01,  8.4346e-03,  1.7572e-01],\n",
      "         [-1.2268e-01, -1.2576e-01, -6.4630e-02,  1.2988e-01],\n",
      "         [-6.6618e-02,  2.5709e-02,  1.7046e-03, -5.8663e-02],\n",
      "         ...,\n",
      "         [-4.4588e-02, -1.5783e-01, -7.9890e-02,  8.1010e-02],\n",
      "         [ 7.1141e-02,  1.6322e-01, -3.8186e-02, -1.5473e-01],\n",
      "         [ 9.8033e-02, -6.2471e-02, -5.2853e-02,  8.6244e-02]],\n",
      "\n",
      "        [[ 1.8201e-01,  1.5615e-01,  3.6258e-02, -3.5220e-02],\n",
      "         [ 3.9209e-02, -5.0871e-02,  1.3006e-01,  4.2899e-02],\n",
      "         [ 1.1628e-01, -6.1487e-03,  2.2902e-02,  1.2185e-01],\n",
      "         ...,\n",
      "         [ 1.7750e-01,  6.9046e-02, -8.0330e-02, -1.4540e-01],\n",
      "         [ 1.1026e-01, -8.6783e-02, -1.4622e-01,  2.5653e-02],\n",
      "         [ 9.3090e-02, -4.0571e-02,  1.8826e-02, -8.0237e-02]],\n",
      "\n",
      "        [[ 1.4036e-01,  1.6707e-01,  1.1918e-01, -1.7653e-01],\n",
      "         [-1.6678e-01,  1.0137e-01,  1.5823e-01,  9.7492e-02],\n",
      "         [ 1.8204e-02, -3.6382e-02, -1.3704e-01, -2.5481e-02],\n",
      "         ...,\n",
      "         [-2.8230e-02,  2.8949e-02, -1.6668e-02, -1.1877e-01],\n",
      "         [ 7.0326e-02, -1.4754e-01, -3.1509e-02,  1.7204e-01],\n",
      "         [-2.5610e-03, -1.1823e-02,  8.3749e-02,  1.6846e-01]]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([-0.1219, -0.0427,  0.0218, -0.0743, -0.0585,  0.0061, -0.0943,  0.0472,\n",
      "         0.0495, -0.0247, -0.0327,  0.0307,  0.0171,  0.1300, -0.0761],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0724, -0.0560,  0.1232, -0.0118],\n",
      "         [ 0.0227,  0.1083, -0.0262,  0.0706],\n",
      "         [-0.0109,  0.0938,  0.1310,  0.0390],\n",
      "         ...,\n",
      "         [ 0.0137, -0.0604,  0.1180,  0.0703],\n",
      "         [-0.0650, -0.1499,  0.1134, -0.0838],\n",
      "         [ 0.0731, -0.1741, -0.1674,  0.1067]],\n",
      "\n",
      "        [[-0.0587,  0.1584, -0.0129,  0.1263],\n",
      "         [-0.0394,  0.1638, -0.1437, -0.0632],\n",
      "         [-0.0185, -0.1540, -0.0194, -0.1323],\n",
      "         ...,\n",
      "         [ 0.1758, -0.0431,  0.0525, -0.1704],\n",
      "         [ 0.0195,  0.0091,  0.1535,  0.1213],\n",
      "         [-0.1230,  0.0493,  0.1378,  0.1165]],\n",
      "\n",
      "        [[-0.1419,  0.1754,  0.0293,  0.1148],\n",
      "         [ 0.0139,  0.0475,  0.1357,  0.0234],\n",
      "         [ 0.1093,  0.1279,  0.1077,  0.0954],\n",
      "         ...,\n",
      "         [ 0.1039,  0.1141, -0.0692,  0.1075],\n",
      "         [ 0.0043, -0.1182, -0.0031,  0.1617],\n",
      "         [ 0.1204,  0.1491, -0.0274,  0.1418]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0611,  0.0253, -0.0736, -0.0362],\n",
      "         [ 0.1102,  0.1173,  0.0402, -0.0635],\n",
      "         [-0.1520, -0.0196,  0.1640, -0.0079],\n",
      "         ...,\n",
      "         [ 0.1525,  0.1671, -0.0999,  0.0486],\n",
      "         [ 0.0056, -0.0815,  0.0169, -0.1315],\n",
      "         [ 0.0483, -0.1179, -0.0170,  0.0497]],\n",
      "\n",
      "        [[ 0.0012,  0.1152,  0.0230,  0.0602],\n",
      "         [-0.1663, -0.0015, -0.0624, -0.1434],\n",
      "         [-0.1662,  0.1340, -0.1691,  0.1080],\n",
      "         ...,\n",
      "         [-0.0121,  0.0161, -0.1669, -0.0757],\n",
      "         [ 0.1296, -0.0594, -0.0064,  0.1457],\n",
      "         [-0.1486,  0.1763,  0.0316, -0.0779]],\n",
      "\n",
      "        [[ 0.0771, -0.0164, -0.0289,  0.0812],\n",
      "         [ 0.1107,  0.1139, -0.0314, -0.1162],\n",
      "         [-0.1252, -0.0471, -0.0552, -0.1177],\n",
      "         ...,\n",
      "         [ 0.0246,  0.1495, -0.0982,  0.1129],\n",
      "         [-0.0226, -0.1525, -0.1056, -0.0031],\n",
      "         [ 0.1695, -0.1504,  0.1628, -0.1785]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([ 0.1717, -0.1072,  0.1000,  0.0280,  0.0760,  0.0281,  0.1279,  0.1031,\n",
      "        -0.0683,  0.1476, -0.1349, -0.1734, -0.0046, -0.1239, -0.1622],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([30, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.1729, -0.1688,  0.3463,  0.2684, -0.0520, -0.1640,  0.3423,  0.0916,\n",
      "         -0.1845, -0.1042,  0.1588, -0.0630,  0.1996, -0.1587,  0.1978],\n",
      "        [ 0.2706, -0.2907,  0.0646, -0.2977,  0.0400, -0.2909, -0.2889, -0.2925,\n",
      "         -0.1277,  0.1009,  0.2176,  0.1560, -0.1581, -0.2184,  0.1542],\n",
      "        [ 0.0913, -0.0564, -0.3121,  0.3086, -0.2124, -0.3513, -0.0274, -0.0799,\n",
      "         -0.2974,  0.0165,  0.3249,  0.2049,  0.1935, -0.0166, -0.2617],\n",
      "        [-0.1282, -0.0765,  0.0057, -0.2986,  0.2761,  0.2345, -0.1831,  0.2049,\n",
      "          0.0043,  0.0974,  0.2011,  0.0678,  0.3015, -0.1947,  0.0758],\n",
      "        [-0.2701,  0.1567, -0.1061,  0.2820, -0.0357, -0.3633,  0.0303, -0.0742,\n",
      "         -0.1673, -0.1090, -0.3612, -0.1582, -0.0148, -0.3175, -0.2845],\n",
      "        [-0.2002,  0.0474, -0.1350, -0.1806, -0.0896,  0.3634, -0.0929, -0.2344,\n",
      "         -0.2894,  0.0433, -0.2056,  0.1782, -0.1488,  0.0638, -0.3562],\n",
      "        [-0.0291,  0.1945,  0.1144, -0.0677,  0.2330,  0.0647,  0.2401, -0.2118,\n",
      "         -0.3069,  0.0373,  0.2876,  0.1551,  0.2342, -0.3411,  0.0845],\n",
      "        [ 0.1717,  0.3591, -0.0962, -0.3042, -0.2444, -0.1019,  0.3551, -0.1513,\n",
      "         -0.0040, -0.2075,  0.0718, -0.0472,  0.1025, -0.2640,  0.0773],\n",
      "        [-0.3075,  0.1993,  0.3247, -0.0886,  0.3639, -0.0092, -0.2929, -0.0671,\n",
      "          0.2167,  0.2691,  0.1086, -0.1671,  0.2318, -0.2763,  0.3441],\n",
      "        [-0.2586,  0.3581,  0.2887,  0.1700, -0.2222, -0.0186,  0.2447,  0.2127,\n",
      "          0.3647,  0.1927,  0.3275, -0.0045, -0.2488, -0.0923, -0.0985],\n",
      "        [ 0.0391,  0.1867,  0.3244,  0.2184, -0.1113,  0.0633, -0.0553,  0.0913,\n",
      "         -0.3338,  0.0259, -0.2746,  0.3296, -0.0121,  0.0407,  0.2012],\n",
      "        [ 0.3586, -0.0255,  0.1392, -0.3130,  0.2768,  0.3534,  0.1141, -0.2486,\n",
      "          0.2593, -0.1737, -0.3635, -0.3372, -0.2545, -0.1742,  0.1870],\n",
      "        [-0.3424,  0.0182,  0.1503,  0.3254, -0.1681,  0.2175, -0.1055,  0.2954,\n",
      "         -0.1320,  0.2302,  0.2442,  0.1609, -0.0747,  0.0544,  0.1978],\n",
      "        [-0.2311, -0.0819,  0.2924, -0.2006,  0.2579, -0.3123,  0.0399,  0.1533,\n",
      "          0.0151,  0.2040,  0.0320, -0.0667, -0.1494, -0.1717,  0.1448],\n",
      "        [-0.2771,  0.0797, -0.2292, -0.1030,  0.0412,  0.2440,  0.1083, -0.3232,\n",
      "          0.0562, -0.2253, -0.1713, -0.2133,  0.1100,  0.0071, -0.1748],\n",
      "        [-0.3438, -0.1927, -0.0689, -0.2184,  0.2139,  0.0815,  0.2241,  0.2843,\n",
      "         -0.2227,  0.1800,  0.2635,  0.1982,  0.1261, -0.0670,  0.3441],\n",
      "        [-0.0731,  0.3104,  0.2925,  0.0230, -0.3169, -0.3446,  0.3477, -0.1234,\n",
      "         -0.1189,  0.0276, -0.2418,  0.0571, -0.0538,  0.1177, -0.1872],\n",
      "        [-0.2856, -0.1173,  0.2382,  0.1963,  0.1934, -0.3405,  0.3599,  0.3139,\n",
      "         -0.2562, -0.2565, -0.2583, -0.0795, -0.2896,  0.2798, -0.3469],\n",
      "        [-0.2814, -0.0659, -0.2159,  0.2826,  0.0510, -0.3581, -0.2990, -0.0207,\n",
      "         -0.1686,  0.1585, -0.1703,  0.3370, -0.0100,  0.1706,  0.0677],\n",
      "        [-0.1873, -0.3133, -0.3038, -0.0213, -0.3410, -0.1740,  0.3180, -0.0715,\n",
      "          0.0086,  0.3170,  0.2405, -0.3310, -0.2583, -0.3391,  0.1068],\n",
      "        [-0.1218, -0.2752, -0.2886, -0.2740,  0.0477,  0.1406, -0.2726,  0.1226,\n",
      "          0.1656,  0.2981,  0.3360,  0.1853, -0.0073,  0.3101,  0.2091],\n",
      "        [ 0.3350,  0.0165,  0.1113,  0.2938, -0.0584,  0.0479,  0.2615, -0.2960,\n",
      "          0.1334, -0.2696,  0.1795,  0.3587, -0.1860,  0.1216, -0.2121],\n",
      "        [-0.3373, -0.2505, -0.0328,  0.2570, -0.2843, -0.0100, -0.1423,  0.1343,\n",
      "          0.1767,  0.2347, -0.0674, -0.3083,  0.1075, -0.2002, -0.1650],\n",
      "        [-0.1464,  0.3502,  0.0156,  0.3601, -0.0947, -0.1201,  0.3646, -0.3426,\n",
      "          0.2160, -0.2127, -0.3393,  0.0843,  0.0341,  0.1905,  0.0307],\n",
      "        [-0.3164, -0.2478, -0.0354, -0.0505, -0.3258, -0.3555,  0.1001, -0.0595,\n",
      "         -0.0742, -0.3153, -0.2309,  0.1232,  0.2026,  0.0254,  0.0241],\n",
      "        [ 0.3175, -0.3573, -0.0375, -0.3050, -0.0743,  0.2146, -0.1152, -0.0129,\n",
      "          0.0514,  0.3061, -0.2123, -0.1140,  0.1986,  0.2406, -0.1695],\n",
      "        [ 0.2366,  0.0007, -0.1518,  0.2750,  0.0817,  0.1501, -0.1611,  0.1178,\n",
      "         -0.2420, -0.0269,  0.1361,  0.1203, -0.1558, -0.3589,  0.3107],\n",
      "        [ 0.3499,  0.0055, -0.1345,  0.2935,  0.2233,  0.0732,  0.2708, -0.1036,\n",
      "         -0.1418, -0.3095,  0.0284,  0.0652,  0.2566,  0.0380,  0.2364],\n",
      "        [-0.2233,  0.3612,  0.3208,  0.1678, -0.0212, -0.3346,  0.0034,  0.3388,\n",
      "          0.0422, -0.0565,  0.2813,  0.2915, -0.3055,  0.0617,  0.1220],\n",
      "        [ 0.2743,  0.0566,  0.0107, -0.2302, -0.0611,  0.1178,  0.0851, -0.1133,\n",
      "         -0.0015, -0.2039, -0.3508,  0.1302, -0.0402,  0.0451, -0.2503]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.0594,  0.0502, -0.0261,  0.0123,  0.2562,  0.1595,  0.2099,  0.0258,\n",
      "         -0.1823, -0.0050,  0.1007, -0.1532,  0.1507,  0.2158,  0.1344],\n",
      "        [ 0.0181,  0.0155,  0.2545, -0.2116, -0.2443,  0.0388, -0.0316, -0.0591,\n",
      "         -0.2338, -0.1019,  0.0586,  0.0869,  0.0483, -0.0307,  0.0706]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([0.1784, 0.1938], dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.0603, -0.0465, -0.0751,  0.0927, -0.0998,  0.0308, -0.2548, -0.2045,\n",
      "         -0.1716, -0.0766,  0.1910, -0.0513,  0.2276, -0.1954,  0.1400],\n",
      "        [ 0.2399,  0.1470,  0.0422,  0.0139, -0.1958, -0.0762,  0.0494, -0.0499,\n",
      "         -0.1182,  0.0682, -0.0658, -0.0627, -0.0439,  0.2302, -0.1862]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([-0.1017, -0.2248], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "Nx = 3\n",
    "Ny = 3\n",
    "hiddendim  = 15\n",
    "numsamples = 10\n",
    "\n",
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=2, system_size_x=Nx, system_size_y = Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=0)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "model = model.double()\n",
    "for p in list(model.parameters()):\n",
    "    print(p.size())\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44615675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([439, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the sampling method\n",
    "samples, log_probs, phase = model.sample(1000)\n",
    "\n",
    "samples = torch.unique(samples, dim=0)\n",
    "print(samples.size())\n",
    "\n",
    "2**(Nx*Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4221f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([439])\n",
      "torch.Size([439])\n",
      "tensor(0.8589+0.j, dtype=torch.complex128, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test the probability method\n",
    "log_probs, phases = model.log_probabilities(samples)\n",
    "print(log_probs.size())\n",
    "print(phases.size())\n",
    "print(torch.sum(torch.mul(torch.exp(0.5*log_probs+1j*phases),torch.exp(0.5*log_probs+1j*phases).conj())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb03b4c",
   "metadata": {},
   "source": [
    "### 2. Calculate the matrix elements (here 2D XXZ model)\n",
    "\n",
    "$$ E_{\\theta}^{loc}(x) = \\frac{<x|H|\\psi_\\theta>}{<x|\\psi_\\theta>} = H_{diag}(x)+H_{offd}(x)\\frac{<x^{\\prime}|\\psi_\\theta>}{<x|\\psi_\\theta>} $$\n",
    "with $\\hat{H}_{offd}|x^{\\prime}>=H_{offd}(x)|x^{\\prime}>$ and ${<x|\\psi_\\theta>}$ given by the square root of the exponential of model.log_probabilities(x) defined above.\n",
    "\n",
    "- for $J_p = 0$ and $J_z = 1$: $E_{loc} = H_{diag}(x) = 0.25*J_z*systemsize$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f77b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZ1D_MatrixElements(Jp, Jz, samples, length):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    \"\"\"\n",
    "\n",
    "    N = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples, length))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for i in range(length): \n",
    "        values  = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        valuesT[values==2] = +1 #If both spins are up\n",
    "        valuesT[values==0] = +1 #If both spins are down\n",
    "        valuesT[values==1] = -1 #If they are opposite\n",
    "        diag_matrixelements[:,i] = valuesT.reshape((numsamples))*Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, length))\n",
    "    xprime = []\n",
    "    for i in range(length): \n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        #flip the spins\n",
    "        new_samples             = samples.clone()\n",
    "        new_samples[:,(i+1)%N]  = samples[:,i]\n",
    "        new_samples[:,i]        = samples[:,(i+1)%N]\n",
    "        valuesT[values==2]      = 0 #If both spins are up\n",
    "        valuesT[values==0]      = 0 #If both spins are down\n",
    "        valuesT[values==1]      = 1 #If they are opposite\n",
    "        offd_matrixelements[:,i] = valuesT.reshape((numsamples))*Jp*0.5\n",
    "        xprime.append(new_samples)\n",
    "    return diag_matrixelements, offd_matrixelements, torch.stack(xprime, axis=0)\n",
    "\n",
    "def XXZ1D_Eloc(Jp, Jz, samples, RNN, boundaries):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    N          = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length = N\n",
    "    else:\n",
    "        length = N-1\n",
    "    \n",
    "    queue_samples       = torch.zeros((length+1, numsamples, N, 1), dtype = torch.int32) \n",
    "    log_probs           = np.zeros((length+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ1D_MatrixElements(Jp, Jz, samples, length)\n",
    "    diag_me = torch.sum(diag_me, axis=1)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    queue_samples[0] = samples\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    #off-diagonal elements\n",
    "    \n",
    "    offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "    queue_samples[1:] = new_samples\n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(length+1)*numsamples, N, 1])\n",
    "    log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "    log_probs_reshaped = torch.reshape(log_probs, (length+1,numsamples)).to(torch.complex64)\n",
    "    phases_reshaped = torch.reshape(phases, (length+1,numsamples))\n",
    "    for i in range(1,length+1):\n",
    "        tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:])\n",
    "        tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "        Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    return Eloc\n",
    "    \n",
    "def XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - samples: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - length_x: system length in x dir\n",
    "    - length_y: system length in y dir\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "\n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for n in range(numsamples):\n",
    "        for i in range(Nx): \n",
    "            for j in range(Ny):\n",
    "                if i != length_x:\n",
    "                    if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "                if j != length_y:\n",
    "                    if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, (Nx*Ny*2-(Nx+Ny))))\n",
    "    xprime = torch.zeros((Nx*Ny*2-(Nx+Ny),numsamples, Nx, Ny))\n",
    "    if Jp!=0:\n",
    "        for n in range(numsamples):\n",
    "            num = 0\n",
    "            for i in range(Nx): \n",
    "                for j in range(Ny):\n",
    "                    new_sample = samples[n].clone()\n",
    "                    if i != length_x:\n",
    "                        if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                            new_sample[(i+1)%Nx,j]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,(i+1)%Nx, j]\n",
    "                            offd_matrixelements[n,num] = Jp*0.5\n",
    "                            xprime[num,n]              = new_sample\n",
    "                            num +=1\n",
    "                    if j != length_y:\n",
    "                        if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                            new_sample[i,(j+1)%Ny]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,i,(j+1)%Ny]\n",
    "                            offd_matrixelements[n,num] = Jp*0.5\n",
    "                            xprime[num,n]              = new_sample\n",
    "                            num +=1  \n",
    "    return diag_matrixelements, offd_matrixelements, xprime\n",
    "\n",
    "\n",
    "def XXZ2D_Eloc(Jp, Jz, samples, RNN, boundaries, symmetry):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - RNN: RNN model\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    elif \"open\":\n",
    "        length_x = Nx-1\n",
    "        length_y = Ny-1\n",
    "    else:\n",
    "        raise \"Boundary \"+boundaries+\" not implemented\"\n",
    "    length = Nx*Ny*2-(Nx+Ny)\n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    \n",
    "    # pass all samples together through the network\n",
    "    if symmetry!= None:\n",
    "        symmetric_samples = get_symmetric_samples(samples, symmetry)\n",
    "        queue_samples = torch.zeros(((length+1+1), numsamples, Nx, Ny), dtype = torch.int32) \n",
    "        queue_samples[length+1] = symmetric_samples\n",
    "    else:\n",
    "        queue_samples = torch.zeros(((length+1), numsamples, Nx, Ny), dtype = torch.int32) \n",
    "    \n",
    "    queue_samples[0] = samples\n",
    "    queue_samples[1:length+1] = new_samples\n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [queue_samples.size()[0]*numsamples, Nx, Ny])\n",
    "    log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "    log_probs_reshaped = torch.reshape(log_probs, (queue_samples.size()[0],numsamples)).to(torch.complex64)\n",
    "    phases_reshaped = torch.reshape(phases, (queue_samples.size()[0],numsamples))\n",
    "    if Jp != 0: #off-diagonal elements\n",
    "        for i in range(1,(length+1)):\n",
    "            tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:]).to(torch.complex64)\n",
    "            tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "            Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    if symmetry != None:\n",
    "        return Eloc, symmetric_samples, log_probs_reshaped[length+1], phases_reshaped[length+1]\n",
    "    else:\n",
    "        return Eloc\n",
    "\n",
    "def get_symmetric_samples(samples, symmetry):\n",
    "    if symmetry == \"C4\":\n",
    "        symmetric_samples = torch.zeros((samples.size()[0],samples.size()[1], samples.size()[2]), dtype = torch.int32) \n",
    "        l = int(samples.size()[0]/3)\n",
    "        symmetric_samples[:l] = torch.rot90(samples[:l],1, [1,2])\n",
    "        symmetric_samples[l:2*l] = torch.rot90(samples[l:2*l],2, [1,2])\n",
    "        symmetric_samples[2*l:] = torch.rot90(samples[2*l:],1, [1,2])\n",
    "    return symmetric_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cdfd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 0],\n",
      "         [1, 0, 0],\n",
      "         [0, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [1, 1, 0],\n",
      "         [0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [0, 0, 1],\n",
      "         [1, 1, 0]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [1, 1, 1],\n",
      "         [0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 1],\n",
      "         [0, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [1, 0, 1],\n",
      "         [0, 1, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [0, 1, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [1, 1, 0],\n",
      "         [1, 1, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [0, 1, 1],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [0, 1, 0],\n",
      "         [0, 1, 1]]])\n",
      "tensor([[[0, 0, 1],\n",
      "         [1, 0, 1],\n",
      "         [1, 1, 0]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [1, 0, 1],\n",
      "         [0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 0]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0],\n",
      "         [1, 0, 1],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[1, 0, 1],\n",
      "         [1, 1, 1],\n",
      "         [1, 0, 0]]], dtype=torch.int32)\n",
      "-------\n",
      "tensor([[0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 0]])\n",
      "tensor([[0, 1, 0],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 0]], dtype=torch.int32)\n",
      "tensor(4.4968+0.0184j, grad_fn=<SelectBackward0>)\n",
      "0.0018577676673359942\n",
      "(0.0018947675+0j)\n",
      "tensor([0.0020, 0.0021, 0.0020, 0.0022, 0.0022, 0.0019, 0.0019, 0.0020, 0.0021,\n",
      "        0.0021], dtype=torch.float64, grad_fn=<ExpBackward0>)\n",
      "tensor([0.0020+0.j, 0.0021+0.j, 0.0020+0.j, 0.0021+0.j, 0.0022+0.j, 0.0019+0.j, 0.0019+0.j,\n",
      "        0.0020+0.j, 0.0021+0.j, 0.0021+0.j], grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#simple tests\n",
    "Jp = 1\n",
    "Jz = 0\n",
    "boundaries = \"open\"\n",
    "\n",
    "samples, log_probs, phase = model.sample(10)\n",
    "print(samples[:10])\n",
    "i = np.argmin(torch.exp(log_probs).detach().numpy())\n",
    "\n",
    "local_energy, sym_samples, sym_probs, sym_phases = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries, \"C4\")\n",
    "print(sym_samples)\n",
    "print(\"-------\")\n",
    "print(samples[i])\n",
    "print(sym_samples[i])\n",
    "print(local_energy[i])\n",
    "print(torch.exp(log_probs).detach().numpy()[i])\n",
    "print(torch.exp(sym_probs).detach().numpy()[i])\n",
    "print(torch.exp(log_probs[:10]))\n",
    "print(torch.exp(sym_probs[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f79c8c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5aa38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(4321)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c872de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "Jp         = 1\n",
    "Jz         = 1\n",
    "Nx         = 4\n",
    "Ny         = 4\n",
    "bounds     = \"open\"\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs   = 3000\n",
    "lr         = 0.03\n",
    "hidden_dim = int(Nx*Ny/2)\n",
    "\n",
    "\n",
    "model = Model(input_size=2, system_size_x=Nx,system_size_y=Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=None)\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer and cost function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def cost_fct(samples, model, Jp, Jz, log_probs, phases, boundaries, sz_tot=None, symmetry=None):\n",
    "    if symmetry != None:\n",
    "        Eloc, sym_samples, sym_log_probs, sym_phases = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries, symmetry)\n",
    "    else:\n",
    "        Eloc = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries, symmetry)\n",
    "    log_psi = (0.5*log_probs+1j*phases)\n",
    "    eloc_sum = (Eloc).mean(axis=0)\n",
    "    e_loc_corr = (Eloc - eloc_sum).detach()\n",
    "    if sz_tot != None:\n",
    "        e_loc_corr += (get_sz_(samples).detach()-sz_tot*torch.ones((samples.size()[0])))**2 \n",
    "    if symmetry != None:\n",
    "        e_loc_corr += (torch.exp(sym_log_probs)-torch.exp(log_probs))**2\n",
    "    cost = 2 * torch.real((torch.conj(log_psi) * e_loc_corr.to(torch.complex128))).mean(axis=0)\n",
    "    return Eloc, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observables that can be evaluated during the training or afterwards\n",
    "def get_length(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    else:\n",
    "        length_x = Nx-1\n",
    "        length_y = Ny-1\n",
    "    return Nx, Ny, length_x, length_y\n",
    "\n",
    "\n",
    "def get_szsz(samples, log_probs, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    szsz_x = torch.zeros((samples.size()[0], length_x, length_y+1))\n",
    "    szsz_y = torch.zeros((samples.size()[0], length_x+1, length_y))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    for j in range(Ny):\n",
    "        for i in range(Nx):\n",
    "            if i != length_x:\n",
    "                szsz_x[:,i,j] = s[:,i,j]*s[:,(i+1)%Nx,j]\n",
    "            if j != length_y:\n",
    "                szsz_y[:,i,j] += s[:,i,j]*s[:,i,(j+1)%Ny]\n",
    "    return [torch.mean(szsz_x, axis=0).detach().numpy()*1/4, torch.mean(szsz_y, axis=0).detach().numpy()*1/4]\n",
    "\n",
    "def get_sxsx(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sxsx_x = torch.zeros((samples.size()[0], length_x, length_y+1))\n",
    "    sxsx_y = torch.zeros((samples.size()[0], length_x+1, length_y))\n",
    "    for j in range(Ny):\n",
    "        for i in range(Nx):\n",
    "            if i != length_x:\n",
    "                d = [1,0]\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                sxsx_x[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases)))\n",
    "            if j != length_y:\n",
    "                d = [0,1]\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                sxsx_y[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases)))\n",
    "    return [torch.mean(sxsx_x, axis=0).detach().numpy()*1/4, torch.mean(sxsx_y, axis=0).detach().numpy()*1/4]\n",
    "\n",
    "def get_sysy(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sysy_x = torch.zeros((samples.size()[0], length_x, length_y+1))\n",
    "    sysy_y = torch.zeros((samples.size()[0], length_x+1, length_y))\n",
    "    for j in range(Ny):\n",
    "        for i in range(Nx):\n",
    "            if i != length_x:\n",
    "                d = [1,0]\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                s1 = s1.to(torch.complex64)\n",
    "                s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "                s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 1] = -1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 0] = 1j\n",
    "                sysy_x[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]*s1[:,(i+d[0])%Nx,(j+d[1])%Ny])\n",
    "            if j != length_y:\n",
    "                d = [0,1]\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                s1 = s1.to(torch.complex64)\n",
    "                s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "                s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 1] = -1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 0] = 1j\n",
    "                sysy_y[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]*s1[:,(i+d[0])%Nx,(j+d[1])%Ny])\n",
    "\n",
    "    return [torch.mean(sysy_x, axis=0).detach().numpy()*1/4, torch.mean(sysy_y, axis=0).detach().numpy()*1/4]\n",
    "\n",
    "def get_sz_(samples):\n",
    "    # used in the cost function, no averaging here!\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.sum(sz, axis=2), axis=1) *1/2 \n",
    "\n",
    "def get_sz(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.mean(sz, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sx(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sx = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            sx[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))\n",
    "    return torch.sum(torch.mean(sx, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sy(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sy = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            s1 = s1.to(torch.complex64)\n",
    "            s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "            s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "            sy[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]\n",
    "    return torch.sum(torch.mean(sy, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "\n",
    "def flip_neighbor_spins(samples, i,j, direction, Nx, Ny):\n",
    "    s = samples.clone().detach()\n",
    "    N = s.size()[1]\n",
    "    s[:,i,j][samples[:,i,j] == 0]   = 1\n",
    "    s[:,i,j][samples[:,i,j] == 1]   = 0\n",
    "    s[:,(i+direction[0])%Nx,(j+direction[1])%Ny][samples[:,(i+direction[0])%Nx,(j+direction[1])%Ny] == 0] = 1\n",
    "    s[:,(i+direction[0])%Nx,(j+direction[1])%Ny][samples[:,(i+direction[0])%Nx,(j+direction[1])%Ny] == 1] = 0\n",
    "    return s\n",
    "\n",
    "def flip_spin(samples, i,j):\n",
    "    s = samples.clone().detach()\n",
    "    s[:,i,j][samples[:,i,j] == 0] = 1\n",
    "    s[:,i,j][samples[:,i,j] == 1] = 0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f579eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_62902/1887564198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mElocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Clears existing gradients from previous epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_62902/962338838.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mampl_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mohs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_62902/962338838.py\u001b[0m in \u001b[0;36m_gen_samples\u001b[0;34m(self, nx, ny, direction, inputs, hidden_inputs, numsamples)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# samples are obtained by sampling from the amplitudes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mampl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m# one hot encode the current sigma to pass it into the GRU at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# the next time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "n_samples = 200\n",
    "sym = \"C4\"\n",
    "Elocs = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    samples, log_probs, phases = model.sample(n_samples)\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    \n",
    "    Eloc, cost = cost_fct(samples, model, Jp, Jz, log_probs, phases, bounds, sz_tot=0, symmetry=sym)\n",
    "    cost.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    optimizer.zero_grad()\n",
    "    sx = get_sx(samples, log_probs, phases)\n",
    "    sy = get_sy(samples, log_probs, phases)\n",
    "    sz = get_sz(samples)\n",
    "    if epoch >= 1/3*n_epochs and sym == None:\n",
    "        print(\"Use spatial symmetry from now on.\")\n",
    "        sym = \"C4\"\n",
    "    Elocs = (Eloc).mean(axis=0)\n",
    "    if epoch%10 == 0 or epoch == 1:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.8f}\".format(cost)+\", mean(E): {:.8f}\".format((Eloc).mean(axis=0))+\", var(E): {:.8f}\".format((Eloc).var(axis=0))+\", Sx: {:.4f}\".format(sx)+\", Sy: {:.4f}\".format(sy)+\", Sz: {:.4f}\".format(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399d598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples, log_probs, phases = model.sample(10000)\n",
    "print(torch.reshape(samples, (10000,Nx, Ny))[:10])\n",
    "#print(log_probs[:50])\n",
    "#print(torch.exp(0.5*log_probs)[:50]*torch.exp(1j*phases)[:50])\n",
    "print(\"max\")\n",
    "print(samples[np.argmax(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(max(torch.exp(0.5*log_probs).detach().numpy()))\n",
    "print(\"min\")\n",
    "print(samples[np.argmin(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(min(torch.exp(0.5*log_probs).detach().numpy()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181edff",
   "metadata": {},
   "source": [
    "### 3. Evaluate Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53af738",
   "metadata": {},
   "source": [
    "This is what we can test:\n",
    "- For the Heisenberg model:The average magnetization in all directions should vanish.\n",
    "- The correlator in all directions should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae440a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the nearest neighbor spin correlators\n",
    "samples, log_probs, phases = model.sample(1000)\n",
    "szsz = get_szsz(samples, log_probs, bounds)\n",
    "print(szsz)\n",
    "sxsx = get_sxsx(samples, log_probs, phases, bounds)\n",
    "print(sxsx)\n",
    "sysy = get_sysy(samples, log_probs, phases, bounds)\n",
    "print(sysy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sx, sy and sz\n",
    "sz = get_sz(samples)\n",
    "print(sz)\n",
    "sx = get_sx(samples, log_probs, phases)\n",
    "print(sx)\n",
    "sy = get_sy(samples, log_probs, phases)\n",
    "print(sy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d95f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, boundaries, folder):\n",
    "    torch.save(model.state_dict(), folder+\"model_params.pt\")\n",
    "    # calculate the nearest neighbor spin correlators\n",
    "    samples, log_probs, phases = model.sample(1000)\n",
    "    szsz = np.array(get_szsz(samples, log_probs, boundaries))\n",
    "    np.save(folder+\"szsz.npy\", szsz)\n",
    "    sxsx = np.array(get_sxsx(samples, log_probs, phases, boundaries))\n",
    "    np.save(folder+\"sxsx.npy\", sxsx)\n",
    "    sysy = np.array(get_sysy(samples, log_probs, phases, boundaries))\n",
    "    np.save(folder+\"sysy.npy\", sysy)\n",
    "\n",
    "fol = str(Nx)+\"x\"+str(Ny)+\"_qubits/Jp=\"+str(float(Jp))+\"Jz=\"+str(float(Jz))+\"/\"\n",
    "save(model, bounds, fol)\n",
    "np.save(fol+\"/Eloc.npy\", np.array(Elocs.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model can then be load again by using\n",
    "#model = Model(input_size=2, system_size=systemsize, hidden_dim=hiddendim, n_layers=1)\n",
    "fol = str(Nx)+\"x\"+str(Ny)+\"_qubits/Jp=\"+str(float(Jp))+\"Jz=\"+str(float(Jz))+\"/\"\n",
    "model.load_state_dict(torch.load(fol+\"model_params.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba26767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
