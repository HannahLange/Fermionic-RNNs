{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b483b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e68cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa4510c7a10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial settings\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4bada",
   "metadata": {},
   "source": [
    "## 1. Build the 2D RNN\n",
    "- tensorized RNN cell as in Hibat-Allah 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3588d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorizedGRU(nn.Module):\n",
    "    \"\"\" Custom GRU layer for 2D input \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.tanh    = torch.nn.Tanh()\n",
    "        \n",
    "          \n",
    "        # define all weights\n",
    "        w1      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W1 = nn.Parameter(w1)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        b1      = torch.empty(self.hidden_size)\n",
    "        self.b1 = nn.Parameter(b1)\n",
    "        \n",
    "        w2      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W2 = nn.Parameter(w2)  \n",
    "        b2      = torch.empty(self.hidden_size)\n",
    "        self.b2 = nn.Parameter(b2)\n",
    "        \n",
    "        w3      = torch.empty(2*self.hidden_size, self.hidden_size)\n",
    "        self.W3 = nn.Parameter(w3) \n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.W1, 1)\n",
    "        nn.init.xavier_uniform_(self.W2, 1)\n",
    "        nn.init.xavier_uniform_(self.W3, 1)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W1)\n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b1, -lim, lim)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W2) \n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b2, -lim, lim)\n",
    "   \n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        if len(inputs[0].size()) == 3:\n",
    "            inputs[0] = inputs[0][:,0,:]\n",
    "        if len(inputs[1].size()) == 3:\n",
    "            inputs[1] = inputs[1][:,0,:]\n",
    "\n",
    "        inputstate_mul = torch.einsum('ij,ik->ijk', torch.concat((states[0], states[1]), 1),torch.concat((inputs[0], inputs[1]),1))\n",
    "        # prepare input linear combination\n",
    "        state_mul1 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W1) # [batch_sz, num_units]\n",
    "        state_mul2 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W2) # [batch_sz, num_units]\n",
    "\n",
    "        u = self.sigmoid(state_mul2 + self.b2)\n",
    "        state_tilda = self.tanh(state_mul1 + self.b1) \n",
    "\n",
    "        new_state = u*state_tilda \n",
    "        new_state += (1.-u)*torch.einsum('ij,jk->ik', torch.concat((states[0], states[1]), 1), self.W3)\n",
    "        output = new_state\n",
    "        return output, new_state\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, system_size_x, system_size_y, hidden_dim, n_layers, sz_tot = None):\n",
    "        super(Model, self).__init__()\n",
    "        \"\"\"\n",
    "        Creates RNN consisting of GRU cells.\n",
    "        Inputs:\n",
    "            - input_size:  number of quantum numbers (i.e. 2 for spin-1/2 particles)\n",
    "            - system_size: length of each snapshot\n",
    "            - hidden_dim:  dimension of hidden states\n",
    "            - n_layers:    number of layers of the GRU\n",
    "        \"\"\"\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size  = input_size    # number of expected features in input data\n",
    "        self.output_size = input_size    # number of expected features in output data\n",
    "        self.N_x         = system_size_x # length of generated samples in x dir\n",
    "        self.N_y         = system_size_y # length of generated samples in x dir\n",
    "        self.hidden_dim  = hidden_dim    # number of features in the hidden state\n",
    "        self.n_layers    = n_layers      # number of stacked GRUs\n",
    "        self.sz_tot      = sz_tot        # total magnetization if u(1) symmetry is applied (default: None)\n",
    "        self.system_size = system_size_x*system_size_y\n",
    "        #Defining the layers\n",
    "        self.rnn  = TensorizedGRU(self.input_size, hidden_dim)   \n",
    "        self.lin1 = nn.Linear(hidden_dim, self.output_size)\n",
    "        self.lin2 = nn.Linear(hidden_dim, self.output_size)\n",
    "        #self.s    = torch.softmax(dim=0)\n",
    "        self.soft = nn.Softsign()\n",
    "        \n",
    "        self.get_num_parameters()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Passes the input through the network.\n",
    "        Inputs:\n",
    "            - x:      input state at t\n",
    "            - hidden: hidden state at t\n",
    "        Outputs:\n",
    "            - out:    output configuration at t+1\n",
    "            - hidden: hidden state at t+1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the dense layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generates the hidden state for a given batch size.\n",
    "        \"\"\"\n",
    "        # This method generates the first hidden state of zeros for the forward pass and passes it to the device.\n",
    "        # This is equivalent to a product state.\n",
    "        hidden = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float64).to(device)\n",
    "        return hidden\n",
    "    \n",
    "    def get_num_parameters(self):\n",
    "        \"\"\"\n",
    "        Calculates the number of parameters of the network. \"\"\"\n",
    "        p = 0\n",
    "        for param in list(self.parameters()):\n",
    "            if param.requires_grad:\n",
    "                p += param.numel()\n",
    "        print(\"Total number of parameters in the network: \"+str(p))\n",
    "        return p\n",
    "    \n",
    "    def enforce_sz_total(self, samples, amplitudes):\n",
    "        bl = (self.system_size//2)*torch.ones((samples.size()[0],1))\n",
    "        s_dn = samples.clone().detach()\n",
    "        s_dn[samples == 0] = -1\n",
    "        s_dn[samples == 1] = 0\n",
    "        num_up  = torch.sum(samples, axis=1)\n",
    "        num_dn  = - torch.sum(s_dn, axis=1)\n",
    "\n",
    "        ampl_up = torch.heaviside(bl-num_up, torch.tensor([0.]))\n",
    "        ampl_dn = torch.heaviside(bl-num_dn, torch.tensor([0.]))\n",
    "        \n",
    "        ampl = amplitudes * torch.stack([ampl_dn, ampl_up], axis=1)[:,:,0]\n",
    "        ampl = torch.nn.functional.normalize(ampl, p=2, eps = 1e-30)\n",
    "        return ampl\n",
    "    \n",
    "    def _gen_samples(self, nx, ny, direction, samples, ampl_probs, phase_probs, ohs, inputs, hidden_inputs, numsamples):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        phase_probs[nx][ny] = torch.mul(torch.pi,phase)\n",
    "        # samples are obtained by sampling from the amplitudes\n",
    "        \"\"\"\n",
    "        if self.sz_tot != None and i>=self.system_size/2:\n",
    "            ampl = self.enforce_sz_total(torch.stack(samples, axis=1), ampl)\n",
    "        \"\"\"\n",
    "        ampl_probs[nx][ny] = ampl\n",
    "        sample = torch.multinomial(ampl, 1)\n",
    "        samples[nx][ny] = sample[:,0]\n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample, 2).double()\n",
    "        ohs[nx][ny] = sigma\n",
    "        inputs[str(nx)+str(ny)] = sigma\n",
    "        \n",
    "        return samples, inputs, ampl_probs, phase_probs, ohs\n",
    "    \n",
    "    \n",
    "    def sample(self, num_samples):\n",
    "        \"\"\"\n",
    "        Generates num_samples samples from the network and returns the samples,\n",
    "        their log probabilities and phases.\n",
    "        \"\"\"\n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma       = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y): # add a padding for the inputs and hidden states\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "                \n",
    "        samples     = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    samples, inputs, ampl_probs, phase_probs, ohs = self._gen_samples(nx, ny, direction, samples, ampl_probs, phase_probs, ohs, inputs, hidden_inputs, num_samples)\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    samples, inputs, ampl_probs, phase_probs, ohs = self._gen_samples(nx, ny, direction, samples, ampl_probs, phase_probs, ohs, inputs, hidden_inputs, num_samples)\n",
    "\n",
    "        samples = torch.stack([torch.stack(s, axis=1) for s in samples], axis=1) #.reshape((num_samples, self.N_x, self.N_y))\n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return samples, log_probs_ampl, phase\n",
    "    \n",
    "    def _gen_probs(self, nx, ny, direction, sample, ampl_probs, phase_probs, inputs, hidden_inputs, ohs):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        phase_probs[nx][ny] = torch.mul(torch.pi,phase)\n",
    "        # samples are obtained by sampling from the amplitudes\n",
    "        \"\"\"\n",
    "        if self.sz_tot != None and i>=self.system_size/2:\n",
    "            ampl = self.enforce_sz_total(torch.stack(samples, axis=1), ampl)\n",
    "        \"\"\"\n",
    "        ampl_probs[nx][ny] = ampl\n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample.reshape((sample.size()[0],1)), 2).double()\n",
    "        ohs[nx][ny] = sigma\n",
    "        inputs[str(nx)+str(ny)] = sigma\n",
    "        \n",
    "        return inputs, ampl_probs, phase_probs, ohs\n",
    "    \n",
    "    def log_probabilities(self, samples):\n",
    "        \"\"\"\n",
    "        Calculates the log probability and the phase of each item in samples.\n",
    "        \"\"\"\n",
    "        # reshape samples\n",
    "        num_samples = samples.size()[0]\n",
    "        samples = samples.clone().detach()\n",
    "        samples = [[samples[:,nx,ny] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        \n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma       = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y):\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    inputs, ampl_probs, phase_probs, ohs = self._gen_probs(nx, ny, direction, samples[nx][ny], ampl_probs, phase_probs, inputs, hidden_inputs, ohs)\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    inputs, ampl_probs, phase_probs, ohs = self._gen_probs(nx, ny, direction, samples[nx][ny], ampl_probs, phase_probs, inputs, hidden_inputs, ohs)\n",
    "                    \n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return log_probs_ampl, phase\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9067d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n",
      "Model(\n",
      "  (rnn): TensorizedGRU(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (lin1): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (lin2): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (soft): Softsign()\n",
      ")\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1703, -0.1422,  0.1806, -0.0350],\n",
      "         [-0.1722,  0.0154, -0.1178, -0.1032],\n",
      "         [-0.0439, -0.1444,  0.0637,  0.0879],\n",
      "         ...,\n",
      "         [-0.1684,  0.1757, -0.1358,  0.0560],\n",
      "         [-0.0774, -0.0889, -0.1779,  0.1703],\n",
      "         [-0.0153,  0.0052,  0.0654, -0.1404]],\n",
      "\n",
      "        [[ 0.0452,  0.1021, -0.1616,  0.0148],\n",
      "         [-0.1241,  0.0633, -0.1624, -0.0490],\n",
      "         [ 0.1464, -0.1803,  0.0510,  0.1438],\n",
      "         ...,\n",
      "         [ 0.0605, -0.1124,  0.0911,  0.1560],\n",
      "         [-0.1663,  0.0049, -0.0602,  0.1737],\n",
      "         [ 0.0603, -0.1727, -0.1437, -0.0890]],\n",
      "\n",
      "        [[-0.1537,  0.0747,  0.0464,  0.0915],\n",
      "         [-0.1132, -0.0562, -0.1248,  0.1478],\n",
      "         [ 0.0727, -0.0739,  0.0546,  0.0353],\n",
      "         ...,\n",
      "         [-0.0478,  0.0822, -0.1533, -0.1770],\n",
      "         [ 0.1253, -0.0480,  0.0277, -0.0864],\n",
      "         [-0.1568,  0.0088,  0.0700, -0.1737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1103, -0.1021,  0.1532,  0.0921],\n",
      "         [ 0.1039, -0.1763, -0.1633,  0.1519],\n",
      "         [ 0.0733, -0.1681, -0.1597,  0.1486],\n",
      "         ...,\n",
      "         [ 0.0580,  0.1695,  0.1317,  0.0771],\n",
      "         [-0.1353, -0.0376,  0.1422, -0.0468],\n",
      "         [-0.0016, -0.1405, -0.1618,  0.1479]],\n",
      "\n",
      "        [[ 0.1169, -0.1617,  0.0685, -0.0210],\n",
      "         [-0.0263,  0.0644, -0.0467,  0.0759],\n",
      "         [-0.0167, -0.0705,  0.1730, -0.0632],\n",
      "         ...,\n",
      "         [-0.1670, -0.0427, -0.0248, -0.1710],\n",
      "         [ 0.1034, -0.0679,  0.0742, -0.0667],\n",
      "         [ 0.0154,  0.0455, -0.0955,  0.0332]],\n",
      "\n",
      "        [[-0.0500, -0.0850,  0.1173,  0.1722],\n",
      "         [-0.0502, -0.1065,  0.0347, -0.1281],\n",
      "         [ 0.0268,  0.0941, -0.1627, -0.0356],\n",
      "         ...,\n",
      "         [-0.0951, -0.1574, -0.0337,  0.0851],\n",
      "         [ 0.0242,  0.1265, -0.1134, -0.0070],\n",
      "         [ 0.0312, -0.1216,  0.0470,  0.0993]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([ 0.0494, -0.0217,  0.0165,  0.1258,  0.1538,  0.0231,  0.0256,  0.1435,\n",
      "         0.1815,  0.0489, -0.1290, -0.1693, -0.0263,  0.1423, -0.1330],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1595,  0.1557, -0.0610, -0.0033],\n",
      "         [ 0.0863,  0.0207,  0.1161,  0.1690],\n",
      "         [ 0.1523, -0.1483, -0.0713,  0.0243],\n",
      "         ...,\n",
      "         [-0.1029, -0.0727,  0.1789,  0.1652],\n",
      "         [-0.0051, -0.0084, -0.1006, -0.1287],\n",
      "         [ 0.1376,  0.1155, -0.0561, -0.1648]],\n",
      "\n",
      "        [[ 0.0851, -0.1116,  0.1760, -0.1388],\n",
      "         [ 0.1752,  0.0949,  0.1084,  0.1131],\n",
      "         [-0.1127, -0.1811, -0.1444,  0.1391],\n",
      "         ...,\n",
      "         [ 0.0932, -0.0805,  0.0254, -0.0085],\n",
      "         [-0.1644,  0.0457,  0.1136,  0.1694],\n",
      "         [ 0.0340, -0.0629, -0.1619,  0.0811]],\n",
      "\n",
      "        [[ 0.0422,  0.0330,  0.1639,  0.0998],\n",
      "         [ 0.1806,  0.1385, -0.0339,  0.0535],\n",
      "         [-0.0758, -0.0008,  0.0818,  0.1637],\n",
      "         ...,\n",
      "         [-0.1479, -0.1641, -0.0953, -0.0537],\n",
      "         [-0.1719,  0.0363,  0.1647,  0.0806],\n",
      "         [ 0.1321, -0.0333, -0.0818, -0.0551]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1144, -0.0254,  0.0517,  0.0325],\n",
      "         [-0.0914,  0.1109,  0.0905, -0.0315],\n",
      "         [ 0.0556,  0.1656,  0.1495,  0.0004],\n",
      "         ...,\n",
      "         [-0.0833,  0.0516, -0.1372, -0.0705],\n",
      "         [-0.1501, -0.1345,  0.1018,  0.0156],\n",
      "         [ 0.1311,  0.0798,  0.0701, -0.0289]],\n",
      "\n",
      "        [[-0.0858, -0.1339, -0.1660,  0.0471],\n",
      "         [-0.1433, -0.1080, -0.0384,  0.0889],\n",
      "         [ 0.0872, -0.0634, -0.0020, -0.1104],\n",
      "         ...,\n",
      "         [-0.0080,  0.0725,  0.1443, -0.0400],\n",
      "         [ 0.1337,  0.0024,  0.1270,  0.1260],\n",
      "         [-0.1516,  0.1577, -0.0067, -0.1239]],\n",
      "\n",
      "        [[ 0.0575, -0.0348,  0.0239,  0.0365],\n",
      "         [ 0.1048,  0.0917,  0.1050,  0.0314],\n",
      "         [-0.0412, -0.1742, -0.1620, -0.1129],\n",
      "         ...,\n",
      "         [ 0.1270,  0.0724,  0.0857,  0.0612],\n",
      "         [ 0.0171,  0.0900,  0.0913, -0.1470],\n",
      "         [-0.1475,  0.1387,  0.1800, -0.1673]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([ 0.1051,  0.0344,  0.1560,  0.0685, -0.1818,  0.0472,  0.0490, -0.0348,\n",
      "         0.0657,  0.0566,  0.1604,  0.1023,  0.0344, -0.0720,  0.1564],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([30, 15])\n",
      "Parameter containing:\n",
      "tensor([[-3.0281e-01, -1.4798e-02, -3.2300e-01,  2.5038e-01,  3.1090e-01,\n",
      "          3.6266e-02, -7.5901e-02,  2.8571e-01,  1.2384e-01,  2.1046e-01,\n",
      "         -4.1070e-02, -1.5628e-01, -2.1538e-01,  2.3169e-01,  3.5890e-01],\n",
      "        [-1.9228e-01, -7.6943e-02,  1.0268e-01, -2.6686e-01,  3.6307e-01,\n",
      "         -3.5062e-02, -3.0738e-01,  2.8543e-02,  1.0159e-01, -9.5173e-02,\n",
      "          2.8157e-01, -3.1623e-01, -2.9945e-01, -3.5827e-01, -2.3407e-01],\n",
      "        [-3.1025e-01, -1.8277e-02,  2.8056e-01,  1.8055e-02, -7.7972e-02,\n",
      "          2.7048e-01,  2.9117e-01, -3.2150e-01,  1.9801e-01,  3.5754e-01,\n",
      "          5.6867e-02,  1.6276e-01,  3.1343e-02, -1.6597e-01,  1.0301e-01],\n",
      "        [-8.4647e-02,  1.6164e-01,  3.0177e-01,  2.7913e-01,  3.6317e-02,\n",
      "          2.2876e-01, -7.0046e-02, -5.9274e-02,  3.2510e-01,  2.6464e-01,\n",
      "          2.7016e-02,  3.5084e-01, -1.3850e-02, -2.2440e-01,  2.7786e-01],\n",
      "        [ 4.5116e-02, -3.0249e-01,  8.2921e-02,  2.5824e-01,  2.0133e-01,\n",
      "          2.8922e-02,  2.5774e-01,  2.4927e-01,  2.7811e-01,  6.1080e-02,\n",
      "          1.7690e-01, -2.7554e-01, -2.2312e-02,  9.0703e-02,  2.4778e-01],\n",
      "        [-1.0180e-01, -6.4682e-02,  2.9609e-01, -3.5487e-01,  2.4378e-01,\n",
      "          3.1687e-01,  2.8820e-01,  1.6415e-01,  1.9387e-01, -3.2977e-02,\n",
      "         -1.4491e-01, -2.7191e-01,  3.6065e-01, -2.2939e-02,  1.7442e-01],\n",
      "        [ 3.1913e-01,  2.4607e-01, -8.1752e-02,  2.9078e-01, -2.0841e-01,\n",
      "         -5.3176e-02,  3.1870e-01, -1.3201e-01,  2.4834e-02, -2.9738e-02,\n",
      "         -1.8113e-01, -2.0226e-01,  1.0229e-01, -2.4687e-01,  8.1026e-02],\n",
      "        [-3.3714e-01,  2.1119e-01, -6.9569e-02,  2.2014e-01, -3.0889e-01,\n",
      "          2.2326e-01, -1.4612e-01, -3.1557e-02,  1.1547e-01, -2.3972e-01,\n",
      "          2.9585e-01,  2.4898e-02,  1.4267e-01,  3.3352e-01,  1.0278e-01],\n",
      "        [ 2.3897e-01,  3.0495e-01,  2.8405e-01,  1.7337e-01,  6.6094e-02,\n",
      "         -1.0167e-01, -3.2857e-01,  8.6347e-02,  1.0799e-02,  4.5231e-02,\n",
      "          5.5759e-02,  2.1091e-01,  2.9762e-01,  1.9842e-01,  2.1091e-02],\n",
      "        [-3.6269e-01, -2.7121e-01,  1.4484e-01,  1.1838e-01, -2.2573e-01,\n",
      "          2.4013e-01,  1.7810e-01,  3.1697e-01,  2.1017e-01,  3.4223e-02,\n",
      "         -2.9304e-01,  1.0801e-01,  2.7800e-01, -1.2870e-01, -1.5255e-01],\n",
      "        [-3.4221e-01, -1.6687e-02,  2.4859e-01,  2.7028e-01,  2.0667e-01,\n",
      "          8.3557e-02, -3.3919e-01,  8.3153e-02,  5.7314e-02,  1.8947e-01,\n",
      "          3.5490e-01,  2.9458e-01, -2.0551e-01, -2.1155e-01, -3.2843e-01],\n",
      "        [-4.5063e-02,  1.4856e-01, -2.7988e-01, -1.9384e-01, -1.0033e-01,\n",
      "          2.5922e-01, -9.4843e-02,  1.2205e-01,  1.4864e-01,  1.8380e-01,\n",
      "          2.0598e-01, -1.4280e-02,  3.2882e-01,  1.3545e-01,  1.1863e-01],\n",
      "        [-1.4226e-01,  3.9243e-02, -3.1570e-01, -3.0971e-01,  3.2563e-01,\n",
      "          3.2199e-01,  2.0726e-01,  3.6561e-02, -1.9027e-01,  9.2154e-02,\n",
      "          2.0619e-01,  2.0190e-01,  3.5232e-01, -3.5897e-01,  2.6462e-02],\n",
      "        [-1.2379e-01, -2.1701e-01, -6.8729e-02, -4.1285e-02,  2.2054e-01,\n",
      "          3.6349e-01,  2.8440e-01, -1.7151e-01, -9.9230e-03,  1.8020e-01,\n",
      "         -1.1196e-01, -6.4266e-02, -1.1342e-01, -1.4217e-01, -1.8602e-01],\n",
      "        [ 9.6675e-02,  1.8382e-01,  3.0349e-01,  2.3656e-01, -3.6316e-01,\n",
      "          9.2072e-02,  1.2360e-01, -1.4485e-01, -3.0003e-01, -2.0590e-01,\n",
      "         -1.5803e-01,  2.7673e-02,  1.1976e-01, -3.0871e-01, -2.6481e-01],\n",
      "        [ 5.5693e-02, -2.0820e-01,  3.0873e-01,  1.3682e-01, -3.2849e-01,\n",
      "         -4.9457e-02, -2.7346e-01,  2.9363e-01,  1.9170e-01, -3.0616e-01,\n",
      "         -3.3800e-01,  1.4505e-01, -1.5820e-01, -1.9184e-01, -3.5365e-01],\n",
      "        [ 1.0256e-01, -5.1234e-03, -2.6148e-01, -4.0945e-03, -2.9055e-01,\n",
      "          1.2165e-01,  7.7957e-02,  3.3817e-01, -2.8373e-01,  2.7998e-01,\n",
      "         -1.6193e-01,  6.2300e-03, -2.0972e-01,  1.4350e-01, -3.1503e-01],\n",
      "        [-2.1980e-01, -2.6398e-01, -1.4324e-01,  3.4532e-01, -2.1191e-01,\n",
      "         -1.8761e-02,  8.0627e-02,  1.6558e-01, -1.5942e-01,  3.3300e-02,\n",
      "         -7.0476e-02, -4.8154e-02,  1.2384e-01, -2.2648e-02, -3.4602e-01],\n",
      "        [-3.2143e-01,  9.7684e-02, -3.3168e-01, -4.4450e-02,  1.9918e-02,\n",
      "         -1.9031e-01, -3.5466e-01, -2.4913e-01, -8.6750e-02,  1.5546e-01,\n",
      "          3.1929e-01, -2.8136e-01, -1.7402e-01, -3.4551e-01, -1.3703e-01],\n",
      "        [ 2.4517e-01,  3.3048e-01,  2.4102e-01, -2.5723e-01, -2.7999e-01,\n",
      "         -3.5461e-01,  3.0446e-01, -1.5989e-01, -9.7264e-02,  1.7244e-01,\n",
      "         -1.6058e-02, -3.4686e-01, -8.5511e-02,  1.0477e-01,  3.0260e-01],\n",
      "        [-3.5619e-01,  1.0956e-01,  2.8493e-01, -7.7566e-02, -2.0915e-01,\n",
      "         -1.9618e-01,  3.1020e-01,  2.6115e-01, -2.1629e-01,  5.1230e-05,\n",
      "          1.9543e-01,  5.3123e-02,  2.9590e-01,  2.6532e-01,  2.8823e-01],\n",
      "        [-1.3185e-02, -3.6162e-01, -3.2870e-01, -2.0261e-01,  3.1973e-01,\n",
      "         -3.0232e-01,  2.8023e-01, -1.3701e-01, -1.3101e-01,  1.0906e-01,\n",
      "          3.4736e-01,  6.7218e-02,  9.2073e-02,  9.7630e-02,  1.6701e-01],\n",
      "        [-1.5362e-01,  5.9030e-02,  8.1510e-03, -1.3309e-01,  2.1081e-01,\n",
      "         -2.0585e-01,  1.6120e-04, -3.5910e-01, -1.4534e-02, -3.8286e-02,\n",
      "          3.3666e-01,  7.3134e-02, -1.6723e-01,  2.3372e-01,  3.1462e-01],\n",
      "        [ 1.3191e-01, -1.0911e-01,  1.0300e-01, -2.6300e-02,  6.4437e-02,\n",
      "         -1.1911e-01, -1.1159e-01,  1.8171e-02, -3.4544e-01, -2.5460e-01,\n",
      "          2.1710e-01, -8.4192e-02, -1.8833e-01,  1.0948e-01, -1.5809e-01],\n",
      "        [ 3.6500e-01, -6.0414e-02,  1.8777e-01, -2.9461e-01, -2.6187e-01,\n",
      "         -3.3530e-01, -2.4869e-01,  1.6381e-01, -4.7187e-02, -1.5570e-01,\n",
      "          9.8112e-03, -1.8618e-01,  1.5652e-01,  3.5547e-02,  2.3742e-01],\n",
      "        [-1.4287e-02,  1.9476e-01, -1.9127e-01,  4.5825e-02, -7.7656e-04,\n",
      "          9.9954e-02,  3.0683e-01,  3.2966e-01, -5.4837e-02, -2.7975e-01,\n",
      "         -2.8019e-02,  1.9948e-01,  2.9717e-01, -1.6392e-01,  2.7290e-01],\n",
      "        [-1.7732e-01,  1.8281e-01, -2.2715e-01,  1.8681e-01, -1.9555e-02,\n",
      "         -2.1147e-01, -1.1116e-01, -3.3086e-01,  1.0471e-01, -3.9363e-02,\n",
      "          3.5616e-01, -3.4661e-02, -1.0401e-02,  2.5416e-02,  1.9617e-01],\n",
      "        [ 2.6382e-01,  3.5930e-01, -1.9164e-01, -5.0357e-02,  5.4778e-02,\n",
      "         -4.8209e-02, -2.6914e-01,  3.4386e-01,  1.1583e-01,  1.3968e-01,\n",
      "         -2.5150e-01,  1.6977e-01,  6.4737e-02,  5.5797e-02, -3.5544e-01],\n",
      "        [-2.5378e-01, -2.4945e-01, -5.7125e-02, -1.5815e-01,  2.9373e-01,\n",
      "         -2.4319e-01,  3.5100e-01,  2.3277e-01, -3.3284e-01,  3.3310e-01,\n",
      "         -3.1982e-01,  3.5826e-01, -5.3742e-02, -1.5527e-02, -4.3049e-02],\n",
      "        [ 3.3088e-01,  2.5498e-01, -3.5469e-01,  2.4041e-01,  1.5231e-01,\n",
      "         -3.0715e-01,  1.3499e-01, -8.9320e-02, -2.7970e-01, -2.9812e-02,\n",
      "         -3.0234e-01, -9.9984e-02,  2.9651e-01, -2.3909e-01,  3.3125e-02]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0319,  0.1543,  0.1486, -0.1001, -0.0041,  0.0616,  0.0857,  0.0883,\n",
      "          0.2001, -0.1282, -0.2383,  0.0150,  0.2219,  0.2423, -0.1296],\n",
      "        [ 0.1329,  0.0658,  0.1206,  0.1596,  0.0940, -0.2505,  0.2176,  0.1622,\n",
      "         -0.0826, -0.2372,  0.0737,  0.0713,  0.2436,  0.0762,  0.0103]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([ 0.2055, -0.1062], dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.0244,  0.0508,  0.0049, -0.0902,  0.1486,  0.0256, -0.1395,  0.0605,\n",
      "         -0.2437,  0.0301, -0.0111, -0.1819, -0.0741,  0.2283,  0.1142],\n",
      "        [-0.2112,  0.0449, -0.0022,  0.2118,  0.1376,  0.0201, -0.0369, -0.1223,\n",
      "         -0.2565,  0.0543, -0.0156,  0.1143, -0.0852, -0.0129,  0.1853]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([ 0.0356, -0.0664], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "Nx = 2\n",
    "Ny = 3\n",
    "hiddendim  = 15\n",
    "numsamples = 10\n",
    "\n",
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=2, system_size_x=Nx, system_size_y = Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=0)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "model = model.double()\n",
    "for p in list(model.parameters()):\n",
    "    print(p.size())\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "44615675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the sampling method\n",
    "samples, log_probs, phase = model.sample(numsamples)\n",
    "\n",
    "#samples = torch.unique(samples, dim=0)\n",
    "print(samples.size())\n",
    "\n",
    "2**(Nx*Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4221f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 2])\n",
      "torch.Size([10, 6, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "multiply() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/162410470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test the probability method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/2803621386.py\u001b[0m in \u001b[0;36mlog_probabilities\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mampl_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mampl_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mohs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mohs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_probs_ampl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: multiply() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "# test the probability method\n",
    "log_probs, phases = model.log_probabilities(samples)\n",
    "print(log_probs.size())\n",
    "print(phases.size())\n",
    "print(torch.sum(torch.mul(torch.exp(0.5*log_probs+1j*phases),torch.exp(0.5*log_probs+1j*phases).conj())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb03b4c",
   "metadata": {},
   "source": [
    "### 2. Calculate the matrix elements (here 2D XXZ model)\n",
    "\n",
    "$$ E_{\\theta}^{loc}(x) = \\frac{<x|H|\\psi_\\theta>}{<x|\\psi_\\theta>} = H_{diag}(x)+H_{offd}(x)\\frac{<x^{\\prime}|\\psi_\\theta>}{<x|\\psi_\\theta>} $$\n",
    "with $\\hat{H}_{offd}|x^{\\prime}>=H_{offd}(x)|x^{\\prime}>$ and ${<x|\\psi_\\theta>}$ given by the square root of the exponential of model.log_probabilities(x) defined above.\n",
    "\n",
    "- for $J_p = 0$ and $J_z = 1$: $E_{loc} = H_{diag}(x) = 0.25*J_z*systemsize$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b9f77b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZ1D_MatrixElements(Jp, Jz, samples, length):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    \"\"\"\n",
    "\n",
    "    N = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples, length))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for i in range(length): \n",
    "        values  = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        valuesT[values==2] = +1 #If both spins are up\n",
    "        valuesT[values==0] = +1 #If both spins are down\n",
    "        valuesT[values==1] = -1 #If they are opposite\n",
    "        diag_matrixelements[:,i] = valuesT.reshape((numsamples))*Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, length))\n",
    "    xprime = []\n",
    "    for i in range(length): \n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        #flip the spins\n",
    "        new_samples             = samples.clone()\n",
    "        new_samples[:,(i+1)%N]  = samples[:,i]\n",
    "        new_samples[:,i]        = samples[:,(i+1)%N]\n",
    "        valuesT[values==2]      = 0 #If both spins are up\n",
    "        valuesT[values==0]      = 0 #If both spins are down\n",
    "        valuesT[values==1]      = 1 #If they are opposite\n",
    "        offd_matrixelements[:,i] = valuesT.reshape((numsamples))*Jp*0.5\n",
    "        xprime.append(new_samples)\n",
    "    return diag_matrixelements, offd_matrixelements, torch.stack(xprime, axis=0)\n",
    "\n",
    "def XXZ1D_Eloc(Jp, Jz, samples, RNN, boundaries):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    N          = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length = N\n",
    "    else:\n",
    "        length = N-1\n",
    "    \n",
    "    queue_samples       = torch.zeros((length+1, numsamples, N, 1), dtype = torch.int32) \n",
    "    log_probs           = np.zeros((length+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ1D_MatrixElements(Jp, Jz, samples, length)\n",
    "    diag_me = torch.sum(diag_me, axis=1)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    queue_samples[0] = samples\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    #off-diagonal elements\n",
    "    \n",
    "    offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "    queue_samples[1:] = new_samples\n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(length+1)*numsamples, N, 1])\n",
    "    log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "    log_probs_reshaped = torch.reshape(log_probs, (length+1,numsamples)).to(torch.complex64)\n",
    "    phases_reshaped = torch.reshape(phases, (length+1,numsamples))\n",
    "    for i in range(1,length+1):\n",
    "        tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:])\n",
    "        tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "        Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    return Eloc\n",
    "    \n",
    "def XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - samples: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - length_x: system length in x dir\n",
    "    - length_y: system length in y dir\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for n in range(numsamples):\n",
    "        for i in range(Nx): \n",
    "            for j in range(Ny):\n",
    "                if i != length_x:\n",
    "                    if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "                if j != length_y:\n",
    "                    if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, length_x*length_y))\n",
    "    xprime = torch.zeros((length_x*length_y, numsamples, Nx, Ny))\n",
    "    if Jp!=0:\n",
    "        for n in range(numsamples):\n",
    "            num = 0\n",
    "            for i in range(length_x): \n",
    "                for j in range(length_y):\n",
    "                    new_sample = samples[n].clone()\n",
    "                    if i != length_x:\n",
    "                        if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                            new_sample[(i+1)%Nx,j]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,(i+1)%Nx, j]\n",
    "                            offd_matrixelements[:,i] += Jp*0.5\n",
    "                    if j != length_y:\n",
    "                        if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                            new_sample[i,(j+1)%Ny]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,i,(j+1)%Ny]\n",
    "                            offd_matrixelements[:,i] += Jp*0.5\n",
    "                    xprime[num,n]=new_sample\n",
    "                    num +=1\n",
    "\n",
    "    return diag_matrixelements, offd_matrixelements, xprime\n",
    "\n",
    "\n",
    "def XXZ2D_Eloc(Jp, Jz, samples, RNN, boundaries):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - RNN: RNN model\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    elif \"open\":\n",
    "        length_x = Nx-1\n",
    "        length_y = Ny-1\n",
    "    else:\n",
    "        raise \"Boundary \"+boundaries+\" not implemented\"\n",
    "    \n",
    "    queue_samples       = torch.zeros((length_x*length_y+1, numsamples, Nx, Ny), dtype = torch.int32) \n",
    "    log_probs           = np.zeros((length_x*length_y+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    queue_samples[0] = samples\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    #off-diagonal elements\n",
    "    if Jp != 0:\n",
    "        offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "        queue_samples[1:] = new_samples\n",
    "        queue_samples_reshaped = np.reshape(queue_samples, [(length_x*length_y+1)*numsamples, Nx, Ny])\n",
    "        log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "        log_probs_reshaped = torch.reshape(log_probs, (length_x*length_y+1,numsamples)).to(torch.complex64)\n",
    "        phases_reshaped = torch.reshape(phases, (length_x*length_y+1,numsamples))\n",
    "        for i in range(1,length_x*length_y+1):\n",
    "            tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:])\n",
    "            tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "            Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    return Eloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "32cdfd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0],\n",
      "         [0, 1, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0],\n",
      "         [0, 1, 1]],\n",
      "\n",
      "        [[1, 0, 1],\n",
      "         [0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [0, 0, 0]]])\n",
      "-------\n",
      "tensor([-0.7500+0.j, -0.7500+0.j, -0.2500+0.j, -0.2500+0.j, -0.2500+0.j,  0.7500+0.j,\n",
      "         0.2500+0.j,  0.2500+0.j,  0.2500+0.j,  0.7500+0.j])\n",
      "tensor([-3.8767, -4.6837, -4.2802, -4.2802, -4.2802, -5.0872, -3.8767, -3.8767,\n",
      "        -3.4731, -3.4731], dtype=torch.float64, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#simple tests\n",
    "Jp = 0\n",
    "Jz = 1\n",
    "boundaries = \"open\"\n",
    "\n",
    "samples, log_probs, phase = model.sample(10)\n",
    "print(samples)\n",
    "print(\"-------\")\n",
    "local_energy = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries)\n",
    "print(local_energy)\n",
    "print(log_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f79c8c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e5aa38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(4321)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c872de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n",
      "Parameter containing:\n",
      "tensor([[[-0.1367,  0.0138,  0.0571, -0.1692],\n",
      "         [ 0.0306,  0.0737, -0.0706,  0.1643],\n",
      "         [-0.0248, -0.0750,  0.0371, -0.1183],\n",
      "         ...,\n",
      "         [ 0.0760, -0.0711, -0.0587, -0.0538],\n",
      "         [ 0.1391, -0.1777,  0.0149, -0.0733],\n",
      "         [-0.1404,  0.0321,  0.1779,  0.0143]],\n",
      "\n",
      "        [[ 0.1446, -0.0336, -0.0944, -0.0903],\n",
      "         [ 0.0108, -0.0543,  0.1593,  0.0984],\n",
      "         [ 0.1563, -0.1320, -0.1747,  0.0104],\n",
      "         ...,\n",
      "         [ 0.0383, -0.0763, -0.1472, -0.1576],\n",
      "         [-0.0558,  0.1043,  0.0582, -0.0716],\n",
      "         [ 0.0757, -0.0898,  0.0358, -0.0542]],\n",
      "\n",
      "        [[-0.0375,  0.1046, -0.1556,  0.0105],\n",
      "         [ 0.0627,  0.1695, -0.0756,  0.0478],\n",
      "         [ 0.0056,  0.0846, -0.1062, -0.0127],\n",
      "         ...,\n",
      "         [-0.0443, -0.1198, -0.1217, -0.0106],\n",
      "         [-0.1195,  0.1703,  0.0054,  0.0803],\n",
      "         [-0.1724,  0.0757,  0.1819, -0.0092]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0913, -0.1651, -0.1577, -0.1045],\n",
      "         [ 0.0470, -0.1417,  0.0338,  0.0803],\n",
      "         [-0.0943, -0.0377, -0.0429,  0.0394],\n",
      "         ...,\n",
      "         [-0.1426,  0.0569, -0.1823,  0.1204],\n",
      "         [-0.0117, -0.1252,  0.0592,  0.1056],\n",
      "         [ 0.0591,  0.1728, -0.1809,  0.1346]],\n",
      "\n",
      "        [[ 0.1499,  0.0747,  0.0731, -0.1627],\n",
      "         [-0.1790,  0.1221, -0.0193, -0.0021],\n",
      "         [-0.1057,  0.1647, -0.0776,  0.0484],\n",
      "         ...,\n",
      "         [-0.0528, -0.1575, -0.1501,  0.1256],\n",
      "         [-0.0322, -0.1713, -0.0188, -0.0107],\n",
      "         [ 0.0756,  0.0614, -0.0332,  0.0369]],\n",
      "\n",
      "        [[ 0.0252, -0.1553,  0.1584, -0.0905],\n",
      "         [-0.0014, -0.0612,  0.0309,  0.0764],\n",
      "         [-0.0781,  0.0229, -0.1282, -0.1255],\n",
      "         ...,\n",
      "         [ 0.0847, -0.0455,  0.0784, -0.1439],\n",
      "         [ 0.1674, -0.0739, -0.0191,  0.0094],\n",
      "         [-0.0414,  0.0507,  0.0830, -0.0446]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0448, -0.1059, -0.1318, -0.1476, -0.1288, -0.0244,  0.0997, -0.1277,\n",
      "         0.0168, -0.0671, -0.0155,  0.1614,  0.1713,  0.0241,  0.1052],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0980,  0.0485, -0.1067, -0.1456],\n",
      "         [-0.1781, -0.0096,  0.1582, -0.1000],\n",
      "         [-0.0145,  0.0702,  0.1143, -0.0617],\n",
      "         ...,\n",
      "         [-0.0919, -0.0140,  0.0418,  0.0217],\n",
      "         [-0.1375, -0.0532,  0.0874,  0.0278],\n",
      "         [ 0.1653, -0.1486,  0.1336, -0.0606]],\n",
      "\n",
      "        [[ 0.1031, -0.1543, -0.1258,  0.0891],\n",
      "         [ 0.0179,  0.0159, -0.1544, -0.1369],\n",
      "         [ 0.0973,  0.1498,  0.0339,  0.1180],\n",
      "         ...,\n",
      "         [ 0.0026,  0.0492, -0.1426,  0.1311],\n",
      "         [-0.0787, -0.1798, -0.0611, -0.1659],\n",
      "         [-0.1465, -0.0563,  0.1341,  0.1393]],\n",
      "\n",
      "        [[-0.1587, -0.0758,  0.0062, -0.1815],\n",
      "         [-0.1709, -0.0592, -0.1822, -0.1127],\n",
      "         [ 0.0781, -0.0507, -0.0898,  0.1356],\n",
      "         ...,\n",
      "         [ 0.1217,  0.0998,  0.1568, -0.0807],\n",
      "         [ 0.1019, -0.0510,  0.0049, -0.0727],\n",
      "         [-0.1791, -0.0916,  0.1634, -0.0249]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1670,  0.1198, -0.1809, -0.0908],\n",
      "         [-0.1344, -0.1816, -0.0566, -0.0115],\n",
      "         [-0.1023, -0.1777,  0.1640, -0.0099],\n",
      "         ...,\n",
      "         [-0.0626,  0.1381,  0.0728,  0.1613],\n",
      "         [ 0.0190, -0.0215,  0.1699, -0.1761],\n",
      "         [ 0.0790,  0.1295, -0.0011, -0.0720]],\n",
      "\n",
      "        [[-0.1331,  0.0318,  0.0028, -0.1454],\n",
      "         [-0.1334, -0.0703,  0.0114, -0.0658],\n",
      "         [ 0.1822, -0.1539, -0.0356,  0.1139],\n",
      "         ...,\n",
      "         [ 0.0701,  0.1071, -0.0276, -0.1475],\n",
      "         [ 0.0100, -0.0720, -0.0766,  0.1595],\n",
      "         [-0.0196, -0.1821, -0.1664, -0.1734]],\n",
      "\n",
      "        [[-0.0260,  0.0700, -0.0174, -0.0826],\n",
      "         [-0.1482,  0.0628,  0.0860, -0.1655],\n",
      "         [-0.0107, -0.1730,  0.0174,  0.0215],\n",
      "         ...,\n",
      "         [-0.0761,  0.0149,  0.1286,  0.0429],\n",
      "         [-0.0915, -0.1636,  0.1710, -0.0526],\n",
      "         [-0.0495, -0.0592,  0.1746,  0.0710]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1482, -0.1308,  0.0072,  0.1020, -0.0102, -0.1799,  0.0698,  0.0335,\n",
      "        -0.0326, -0.1211,  0.1039, -0.0699, -0.1056,  0.1033,  0.1396],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1511, -0.2099, -0.1617, -0.1789,  0.3425,  0.1572,  0.1636,  0.0010,\n",
      "         -0.0211,  0.1380,  0.0111,  0.3170, -0.1265,  0.0400,  0.3485],\n",
      "        [-0.1834,  0.3263, -0.3158,  0.2850,  0.0092,  0.1879,  0.1367, -0.2628,\n",
      "         -0.2867, -0.3539, -0.2656,  0.1933, -0.1872,  0.1097,  0.0842],\n",
      "        [-0.0707,  0.3364, -0.0747, -0.2330, -0.2480, -0.2224, -0.0516,  0.2663,\n",
      "          0.1441,  0.0076, -0.3433, -0.0850,  0.0888, -0.2047, -0.0473],\n",
      "        [ 0.2993,  0.2480, -0.0660, -0.2707, -0.0215, -0.2126, -0.2769,  0.3417,\n",
      "         -0.3012,  0.0741,  0.0366,  0.2594, -0.3620, -0.1810,  0.1863],\n",
      "        [ 0.3577,  0.0238,  0.1631, -0.1504, -0.0828,  0.2781, -0.2819,  0.2663,\n",
      "          0.1089,  0.0024, -0.0821,  0.2404, -0.2664, -0.2753, -0.1887],\n",
      "        [-0.2850, -0.1258,  0.3275,  0.2391,  0.3301, -0.2996,  0.2013,  0.1293,\n",
      "          0.0758,  0.1865,  0.1534, -0.2948,  0.0423, -0.2753, -0.2449],\n",
      "        [-0.1229, -0.3056,  0.2896, -0.0048, -0.3019, -0.0318,  0.3272, -0.2441,\n",
      "          0.3283,  0.3442, -0.2034, -0.1375,  0.3498,  0.3433,  0.2513],\n",
      "        [ 0.2378,  0.3643, -0.1802,  0.1490,  0.0954,  0.0691, -0.2999,  0.1616,\n",
      "          0.2352, -0.3477, -0.1909, -0.3296,  0.2401,  0.0315, -0.3131],\n",
      "        [ 0.1223,  0.0746,  0.2283, -0.0788,  0.2681, -0.1414,  0.1095, -0.2256,\n",
      "         -0.2652, -0.1355, -0.2481,  0.0270,  0.2873,  0.2609, -0.1677],\n",
      "        [ 0.2576, -0.0210,  0.2364, -0.3618,  0.3124,  0.2873,  0.3483, -0.0958,\n",
      "          0.1591,  0.0861, -0.3252, -0.1769,  0.0787,  0.0970,  0.2693],\n",
      "        [ 0.1784,  0.1364,  0.0183, -0.3101,  0.2514,  0.3226, -0.1576, -0.1516,\n",
      "         -0.1523,  0.2542,  0.2906,  0.1512, -0.2929,  0.2393, -0.2436],\n",
      "        [-0.0695, -0.3262,  0.3427, -0.0633, -0.0373,  0.0671, -0.1912, -0.2312,\n",
      "          0.2081, -0.0582, -0.1722, -0.1358,  0.1140,  0.1742, -0.0685],\n",
      "        [ 0.0723,  0.0848, -0.2301, -0.0996,  0.1237,  0.2111,  0.2661, -0.1167,\n",
      "          0.3550,  0.0252,  0.1088,  0.1408,  0.0127, -0.1891, -0.1385],\n",
      "        [-0.2992, -0.1732, -0.0990, -0.3212,  0.1701, -0.0929, -0.0126,  0.0931,\n",
      "         -0.0885,  0.2285,  0.1793,  0.2397, -0.1819,  0.2492, -0.1756],\n",
      "        [ 0.3558, -0.1397, -0.2805, -0.3604,  0.2083, -0.2788,  0.2386,  0.0333,\n",
      "          0.0115, -0.3179,  0.0641,  0.2531,  0.2147,  0.1034,  0.2405],\n",
      "        [-0.0827,  0.0419, -0.3484,  0.2489,  0.1823, -0.0747, -0.1673,  0.1477,\n",
      "          0.2774, -0.1458,  0.2805, -0.1561, -0.2838, -0.3420, -0.0673],\n",
      "        [-0.1519, -0.2829,  0.1667,  0.2498,  0.2893, -0.0879, -0.3527,  0.1451,\n",
      "         -0.1230, -0.1834,  0.0082, -0.0292,  0.2793,  0.0172,  0.1767],\n",
      "        [ 0.2077, -0.3035,  0.0650,  0.2478, -0.2848,  0.2201,  0.2738, -0.2579,\n",
      "         -0.0511, -0.2180,  0.1340,  0.1040,  0.0170, -0.0005,  0.3120],\n",
      "        [-0.3619, -0.2135,  0.0876, -0.3551, -0.2183,  0.1453,  0.2902, -0.3039,\n",
      "         -0.2594,  0.1529,  0.2856,  0.3051, -0.0093, -0.1621, -0.0714],\n",
      "        [ 0.2042,  0.1288, -0.3144,  0.2113,  0.0801,  0.2026, -0.0921,  0.3253,\n",
      "         -0.2999,  0.3167,  0.0561,  0.1970,  0.0792, -0.2506, -0.1528],\n",
      "        [ 0.2011, -0.0693,  0.0215, -0.1689,  0.0899,  0.3395,  0.3601, -0.1232,\n",
      "          0.1844,  0.3202,  0.1717,  0.0520,  0.3647, -0.2558, -0.1312],\n",
      "        [ 0.1283, -0.2551,  0.3100, -0.3373, -0.1801, -0.0265,  0.0840,  0.3639,\n",
      "          0.1947,  0.0887, -0.3367, -0.0435, -0.1395,  0.0382,  0.0792],\n",
      "        [-0.1089,  0.0984, -0.1593,  0.2285, -0.1016,  0.1226,  0.1435,  0.1759,\n",
      "          0.2688,  0.2352, -0.1568, -0.0677,  0.2069,  0.1463, -0.3042],\n",
      "        [ 0.3322, -0.0148, -0.2058,  0.2823,  0.0077,  0.2904,  0.0018, -0.2157,\n",
      "         -0.2814,  0.2386,  0.0887, -0.1891, -0.2530, -0.0971, -0.0964],\n",
      "        [-0.2775,  0.3610, -0.2511, -0.1018, -0.1332,  0.1388, -0.1419, -0.2246,\n",
      "         -0.1145, -0.3490,  0.1400,  0.0553, -0.0491, -0.1760, -0.3383],\n",
      "        [-0.2804,  0.1006,  0.3543,  0.0067,  0.0692,  0.2046,  0.2076,  0.2420,\n",
      "          0.3090, -0.3105,  0.0426, -0.3513, -0.1244, -0.3041,  0.1897],\n",
      "        [ 0.0992, -0.0551,  0.3638,  0.2401, -0.1394, -0.3242,  0.2661,  0.2696,\n",
      "         -0.1921,  0.0503, -0.2484,  0.1533, -0.1329,  0.0085,  0.2193],\n",
      "        [-0.3479, -0.3109, -0.1214,  0.0160,  0.1092, -0.0278, -0.3182,  0.1275,\n",
      "         -0.2745,  0.3620, -0.0210,  0.0010,  0.2745, -0.1330, -0.1740],\n",
      "        [ 0.0134,  0.0807, -0.2061,  0.0436, -0.1359,  0.2187, -0.1352, -0.2693,\n",
      "          0.0649,  0.1929, -0.2259,  0.1084,  0.2535,  0.3435,  0.0320],\n",
      "        [-0.0671, -0.2002,  0.1674, -0.3463, -0.0642,  0.0596, -0.3181, -0.2644,\n",
      "          0.0055,  0.3399, -0.0287,  0.1752,  0.1099, -0.0683,  0.1340]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0648, -0.1752, -0.0761, -0.0865,  0.2271,  0.0584,  0.1647, -0.1453,\n",
      "          0.1265,  0.1248, -0.1200, -0.1921,  0.1838, -0.1761,  0.1322],\n",
      "        [-0.1584,  0.1665,  0.2278, -0.0493, -0.0998, -0.1944, -0.1206, -0.2295,\n",
      "          0.2234, -0.0416,  0.0629,  0.1006, -0.1204, -0.1213,  0.1777]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1257, -0.2559], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0885,  0.1861, -0.2360, -0.0150,  0.1862, -0.0119,  0.1239,  0.0648,\n",
      "          0.2199, -0.0956,  0.1475,  0.1432,  0.1814, -0.0076,  0.0133],\n",
      "        [ 0.1771,  0.0800,  0.1394, -0.0080, -0.0136, -0.2509,  0.1228,  0.1783,\n",
      "         -0.1262, -0.1483, -0.2279,  0.1058, -0.0996,  0.1362, -0.1922]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0336, -0.1961], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "Jp         = 0\n",
    "Jz         = 1\n",
    "Nx         = 2\n",
    "Ny         = 2\n",
    "bounds     = \"open\"\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs   = 3000\n",
    "lr         = 0.01\n",
    "hidden_dim = 10\n",
    "\n",
    "folder = \"with_total_sz_cost/\"\n",
    "\n",
    "model = Model(input_size=2, system_size_x=Nx,system_size_y=Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=None)\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "for p in list(model.parameters()):\n",
    "    print(p)\n",
    "\n",
    "\n",
    "# Optimizer and cost function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def cost_fct(samples, model, Jp, Jz, log_probs, phases, boundaries, sz_tot=None):\n",
    "    Eloc = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries)\n",
    "    log_psi = (0.5*log_probs+1j*phases)\n",
    "    eloc_sum = (Eloc).mean(axis=0)\n",
    "    e_loc_corr = (Eloc - eloc_sum).detach()\n",
    "    if sz_tot != None:\n",
    "        e_loc_corr += (get_sz_(samples).detach()-sz_tot*torch.ones((samples.size()[0])))**2\n",
    "    cost = 2 * torch.real((torch.conj(log_psi) * e_loc_corr.to(torch.complex128))).mean(axis=0)\n",
    "    return Eloc, cost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# observables that can be evaluated during the training or afterwards\n",
    "def get_length(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    else:\n",
    "        length_x = Nx-1\n",
    "        length_y = N-1\n",
    "    return Nx, Ny, length_x, length_y\n",
    "\n",
    "\n",
    "def get_szsz(samples, log_probs, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    szsz = torch.zeros((samples.size()[0], length_x, length_y))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            szsz[:,i,j] = s[:,i,j]*s[:,(i+1)%Nx,j]\n",
    "            szsz[:,i,j] += s[:,i,j]*s[:,i,(j+1)%Ny]\n",
    "    return torch.mean(szsz, axis=0)*1/4\n",
    "\n",
    "def get_sxsx(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sxsx = torch.zeros((samples.size()[0], length))\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            s1 = flip_neighbor_spins(samples, i)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            sxsx[:,i] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))\n",
    "    return torch.mean(sxsx, axis=0)*1/4\n",
    "\n",
    "def get_sysy(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sysy = torch.zeros((samples.size()[0], length))\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            s1 = flip_neighbor_spins(samples, i)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            s1 = s1.to(torch.complex64)\n",
    "            s1[:,i,0][s1[:,i,0] == 1] = -1j\n",
    "            s1[:,i,0][s1[:,i,0] == 0] = 1j\n",
    "            s1[:,(i+1)%N,0][s1[:,(i+1)%N,0] == 1] = -1j\n",
    "            s1[:,(i+1)%N,0][s1[:,(i+1)%N,0] == 0] = 1j\n",
    "            sysy[:,i] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,0]*s1[:,(i+1)%N,0]\n",
    "    return torch.mean(sysy, axis=0)*1/4\n",
    "\n",
    "def get_sz_(samples):\n",
    "    # used in the cost function, no averaging here!\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.sum(sz, axis=2), axis=1) *1/2 \n",
    "\n",
    "def get_sz(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.mean(sz, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sx(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sx = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            sx[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))\n",
    "    return torch.sum(torch.mean(sx, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sy(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sy = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            s1 = s1.to(torch.complex64)\n",
    "            s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "            s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "            sy[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]\n",
    "    return torch.sum(torch.mean(sy, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "\n",
    "def flip_neighbor_spins(samples, i):\n",
    "    s = samples.clone().detach()\n",
    "    N = s.size()[1]\n",
    "    s[:,i,:][samples[:,i,:] == 0]   = 1\n",
    "    s[:,i,:][samples[:,i,:] == 1]   = 0\n",
    "    s[:,(i+1)%N,:][samples[:,(i+1)%N,:] == 0] = 1\n",
    "    s[:,(i+1)%N,:][samples[:,(i+1)%N,:] == 1] = 0\n",
    "    return s\n",
    "\n",
    "def flip_spin(samples, i,j):\n",
    "    s = samples.clone().detach()\n",
    "    s[:,i,j][samples[:,i,j] == 0] = 1\n",
    "    s[:,i,j][samples[:,i,j] == 1] = 0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "02f579eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3000............. Loss: 0.01201052, mean(E): 0.04750000+0.00000000j, var(E): 0.23583333, Sx: 0.4324, Sy: -0.2490, Sz: -0.0375\n",
      "Epoch: 10/3000............. Loss: 0.00792063, mean(E): -0.03000000+0.00000000j, var(E): 0.30486214, Sx: 0.4311, Sy: -0.2513, Sz: 0.0325\n",
      "Epoch: 20/3000............. Loss: 0.00071837, mean(E): 0.00250000+0.00000000j, var(E): 0.23307644, Sx: 0.4340, Sy: -0.2482, Sz: -0.0087\n",
      "Epoch: 30/3000............. Loss: 0.00065769, mean(E): -0.03000000+0.00000000j, var(E): 0.24972431, Sx: 0.4389, Sy: -0.2392, Sz: 0.0125\n",
      "Epoch: 40/3000............. Loss: 0.00144179, mean(E): 0.03750000+0.00000000j, var(E): 0.22666040, Sx: 0.4404, Sy: -0.2365, Sz: 0.0125\n",
      "Epoch: 50/3000............. Loss: -0.00036632, mean(E): -0.02000000+0.00000000j, var(E): 0.22015038, Sx: 0.4396, Sy: -0.2382, Sz: 0.0013\n",
      "Epoch: 60/3000............. Loss: 0.00277937, mean(E): 0.02250000+0.00000000j, var(E): 0.28270051, Sx: 0.4423, Sy: -0.2328, Sz: 0.0138\n",
      "Epoch: 70/3000............. Loss: -0.00068448, mean(E): -0.03750000+0.00000000j, var(E): 0.24671052, Sx: 0.4431, Sy: -0.2316, Sz: 0.0063\n",
      "Epoch: 80/3000............. Loss: -0.00000000, mean(E): -0.03500000+0.00000000j, var(E): 0.24438596, Sx: 0.4424, Sy: -0.2330, Sz: 0.0000\n",
      "Epoch: 90/3000............. Loss: -0.00112614, mean(E): -0.01500000+0.00000000j, var(E): 0.21030076, Sx: 0.4410, Sy: -0.2352, Sz: -0.0150\n",
      "Epoch: 100/3000............. Loss: -0.00000377, mean(E): 0.03250000+0.00000000j, var(E): 0.19192356, Sx: 0.4444, Sy: -0.2292, Sz: 0.0344\n",
      "Epoch: 110/3000............. Loss: 0.00266141, mean(E): -0.01000000+0.00000000j, var(E): 0.26556391, Sx: 0.4463, Sy: -0.2251, Sz: 0.0125\n",
      "Epoch: 120/3000............. Loss: -0.00104773, mean(E): 0.05750000+0.00000000j, var(E): 0.25483084, Sx: 0.4445, Sy: -0.2293, Sz: 0.0125\n",
      "Epoch: 130/3000............. Loss: 0.00013653, mean(E): -0.00750000+0.00000000j, var(E): 0.23302631, Sx: 0.4466, Sy: -0.2256, Sz: 0.0125\n",
      "Epoch: 140/3000............. Loss: 0.00467422, mean(E): 0.01500000+0.00000000j, var(E): 0.27045113, Sx: 0.4513, Sy: -0.2137, Sz: 0.0256\n",
      "Epoch: 150/3000............. Loss: 0.00029079, mean(E): 0.02250000+0.00000000j, var(E): 0.25262532, Sx: 0.4513, Sy: -0.2152, Sz: 0.0094\n",
      "Epoch: 160/3000............. Loss: -0.00056330, mean(E): -0.02250000+0.00000000j, var(E): 0.24761279, Sx: 0.4509, Sy: -0.2164, Sz: 0.0062\n",
      "Epoch: 170/3000............. Loss: -0.00000513, mean(E): 0.02750000+0.00000000j, var(E): 0.23232456, Sx: 0.4541, Sy: -0.2092, Sz: -0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/4195673636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mElocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/4096841237.py\u001b[0m in \u001b[0;36mget_sy\u001b[0;34m(samples, log_probs, phases)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflip_spin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mlog_probs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/1660997060.py\u001b[0m in \u001b[0;36mlog_probabilities\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_x\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mampl_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mampl_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mampl_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mampl_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.reshape((num_samples, self.N_x*self.N_y, 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/1660997060.py\u001b[0m in \u001b[0;36m_gen_probs\u001b[0;34m(self, nx, ny, direction, sample, ampl_probs, phase_probs, inputs, hidden_inputs, ohs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mfull_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mhidden\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;31m# the amplitude is given by a linear layer with a softmax activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mampl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/1660997060.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Passing in the input and hidden state into the model and obtaining outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Reshaping the outputs such that it can be fit into the dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_4927/1660997060.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate_tilda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mnew_state\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ij,jk->ik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 400\n",
    "Elocs = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    samples, log_probs, phases = model.sample(n_samples)\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    \n",
    "    Eloc, cost = cost_fct(samples, model, Jp, Jz, log_probs, phases, bounds, sz_tot=None)\n",
    "    cost.backward(retain_graph=True) # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    optimizer.zero_grad()\n",
    "    sx = get_sx(samples, log_probs, phases)\n",
    "    sy = get_sy(samples, log_probs, phases)\n",
    "    sz = get_sz(samples)\n",
    "    Elocs = (Eloc).mean(axis=0)\n",
    "    if epoch%10 == 0 or epoch == 1:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.8f}\".format(cost)+\", mean(E): {:.8f}\".format((Eloc).mean(axis=0))+\", var(E): {:.8f}\".format((Eloc).var(axis=0))+\", Sx: {:.4f}\".format(sx)+\", Sy: {:.4f}\".format(sy)+\", Sz: {:.4f}\".format(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399d598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples, log_probs, phases = model.sample(10000)\n",
    "print(torch.reshape(samples, (10000,Nx, Ny))[:10])\n",
    "print(log_probs[:50])\n",
    "print(torch.exp(0.5*log_probs)[:50]*torch.exp(1j*phases)[:50])\n",
    "print(\"max\")\n",
    "print(samples[np.argmax(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(max(torch.exp(0.5*log_probs).detach().numpy()))\n",
    "print(\"min\")\n",
    "print(samples[np.argmin(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(min(torch.exp(0.5*log_probs).detach().numpy()))\n",
    "\n",
    "for p in list(model.parameters()):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181edff",
   "metadata": {},
   "source": [
    "### 3. Evaluate Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53af738",
   "metadata": {},
   "source": [
    "This is what we can test:\n",
    "- For the Heisenberg model:The average magnetization in all directions should vanish.\n",
    "- The correlator in all directions should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae440a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the nearest neighbor spin correlators\n",
    "samples, log_probs, phases = model.sample(1000)\n",
    "szsz = get_szsz(samples, log_probs, bounds)\n",
    "print(szsz)\n",
    "sxsx = get_sxsx(samples, log_probs, phases, bounds)\n",
    "print(sxsx)\n",
    "sysy = get_sysy(samples, log_probs, phases, bounds)\n",
    "print(sysy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sx, sy and sz\n",
    "sz = get_sz(samples)\n",
    "print(sz)\n",
    "sx = get_sx(samples, log_probs, phases)\n",
    "print(sx)\n",
    "sy = get_sy(samples, log_probs, phases)\n",
    "print(sy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d95f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, boundaries, folder):\n",
    "    torch.save(model.state_dict(), folder+\"model_params.pt\")\n",
    "    # calculate the nearest neighbor spin correlators\n",
    "    samples, log_probs, phases = model.sample(1000)\n",
    "    szsz = get_szsz(samples, log_probs, boundaries).detach().numpy()\n",
    "    np.save(folder+\"szsz.npy\", szsz)\n",
    "    sxsx = get_sxsx(samples, log_probs, phases, boundaries).detach().numpy()\n",
    "    np.save(folder+\"sxsx.npy\", sxsx)\n",
    "    sysy = get_sysy(samples, log_probs, phases, boundaries).detach().numpy()\n",
    "    np.save(folder+\"sysy.npy\", sysy)\n",
    "\n",
    "save(model, bounds, \"with_total_sz=0/Delta=0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model can then be load again by using\n",
    "#model = Model(input_size=2, system_size=systemsize, hidden_dim=hiddendim, n_layers=1)\n",
    "#model.load_state_dict(torch.load(\"model_params.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba26767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
