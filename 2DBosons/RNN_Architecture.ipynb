{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b483b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e68cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8cf027fa10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial settings\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4bada",
   "metadata": {},
   "source": [
    "## 1. Build the 2D RNN\n",
    "- tensorized RNN cell as in Hibat-Allah 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3588d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorizedGRU(nn.Module):\n",
    "    \"\"\" Custom GRU layer for 2D input \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.tanh    = torch.nn.Tanh()\n",
    "        \n",
    "          \n",
    "        # define all weights\n",
    "        w1      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W1 = nn.Parameter(w1)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        b1      = torch.empty(self.hidden_size)\n",
    "        self.b1 = nn.Parameter(b1)\n",
    "        \n",
    "        w2      = torch.empty(self.hidden_size, 2*self.hidden_size, 2*self.input_size)\n",
    "        self.W2 = nn.Parameter(w2)  \n",
    "        b2      = torch.empty(self.hidden_size)\n",
    "        self.b2 = nn.Parameter(b2)\n",
    "        \n",
    "        w3      = torch.empty(2*self.hidden_size, self.hidden_size)\n",
    "        self.W3 = nn.Parameter(w3) \n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.W1, 1)\n",
    "        nn.init.xavier_uniform_(self.W2, 1)\n",
    "        nn.init.xavier_uniform_(self.W3, 1)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W1)\n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b1, -lim, lim)\n",
    "        fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(self.W2) \n",
    "        lim = np.sqrt(3.0 / (0.5*(fan_in+fan_out)))\n",
    "        nn.init.uniform_(self.b2, -lim, lim)\n",
    "   \n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        if len(inputs[0].size()) == 3:\n",
    "            inputs[0] = inputs[0][:,0,:]\n",
    "        if len(inputs[1].size()) == 3:\n",
    "            inputs[1] = inputs[1][:,0,:]\n",
    "\n",
    "        inputstate_mul = torch.einsum('ij,ik->ijk', torch.concat((states[0], states[1]), 1),torch.concat((inputs[0], inputs[1]),1))\n",
    "        # prepare input linear combination\n",
    "        state_mul1 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W1) # [batch_sz, num_units]\n",
    "        state_mul2 = torch.einsum('ijk,ljk->il', inputstate_mul, self.W2) # [batch_sz, num_units]\n",
    "\n",
    "        u = self.sigmoid(state_mul2 + self.b2)\n",
    "        state_tilda = self.tanh(state_mul1 + self.b1) \n",
    "\n",
    "        new_state = u*state_tilda \n",
    "        new_state += (1.-u)*torch.einsum('ij,jk->ik', torch.concat((states[0], states[1]), 1), self.W3)\n",
    "        output = new_state\n",
    "        return output, new_state\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, system_size_x, system_size_y, hidden_dim, n_layers, sz_tot = None):\n",
    "        super(Model, self).__init__()\n",
    "        \"\"\"\n",
    "        Creates RNN consisting of GRU cells.\n",
    "        Inputs:\n",
    "            - input_size:  number of quantum numbers (i.e. 2 for spin-1/2 particles)\n",
    "            - system_size: length of each snapshot\n",
    "            - hidden_dim:  dimension of hidden states\n",
    "            - n_layers:    number of layers of the GRU\n",
    "        \"\"\"\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size  = input_size    # number of expected features in input data\n",
    "        self.output_size = input_size    # number of expected features in output data\n",
    "        self.N_x         = system_size_x # length of generated samples in x dir\n",
    "        self.N_y         = system_size_y # length of generated samples in x dir\n",
    "        self.hidden_dim  = hidden_dim    # number of features in the hidden state\n",
    "        self.n_layers    = n_layers      # number of stacked GRUs\n",
    "        self.sz_tot      = sz_tot        # total magnetization if u(1) symmetry is applied (default: None)\n",
    "        self.system_size = system_size_x*system_size_y\n",
    "        #Defining the layers\n",
    "        self.rnn  = TensorizedGRU(self.input_size, hidden_dim)   \n",
    "        self.lin1 = nn.Linear(hidden_dim, self.output_size)\n",
    "        self.lin2 = nn.Linear(hidden_dim, self.output_size)\n",
    "        #self.s    = torch.softmax(dim=0)\n",
    "        self.soft = nn.Softsign()\n",
    "        \n",
    "        self.get_num_parameters()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Passes the input through the network.\n",
    "        Inputs:\n",
    "            - x:      input state at t\n",
    "            - hidden: hidden state at t\n",
    "        Outputs:\n",
    "            - out:    output configuration at t+1\n",
    "            - hidden: hidden state at t+1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the dense layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generates the hidden state for a given batch size.\n",
    "        \"\"\"\n",
    "        # This method generates the first hidden state of zeros for the forward pass and passes it to the device.\n",
    "        # This is equivalent to a product state.\n",
    "        hidden = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float64).to(device)\n",
    "        return hidden\n",
    "    \n",
    "    def get_num_parameters(self):\n",
    "        \"\"\"\n",
    "        Calculates the number of parameters of the network. \"\"\"\n",
    "        p = 0\n",
    "        for param in list(self.parameters()):\n",
    "            if param.requires_grad:\n",
    "                p += param.numel()\n",
    "        print(\"Total number of parameters in the network: \"+str(p))\n",
    "        return p\n",
    "    \n",
    "    def _gen_samples(self, nx, ny, direction, inputs, hidden_inputs, numsamples):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        # samples are obtained by sampling from the amplitudes\n",
    "        sample = torch.multinomial(ampl, 1) \n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample, 2).double()\n",
    "        \n",
    "        return sample[:,0], sigma, ampl, torch.mul(torch.pi,phase), hidden\n",
    "    \n",
    "    \n",
    "    def sample(self, num_samples):\n",
    "        \"\"\"\n",
    "        Generates num_samples samples from the network and returns the samples,\n",
    "        their log probabilities and phases.\n",
    "        \"\"\"\n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma       = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y): # add a padding for the inputs and hidden states\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "                \n",
    "        samples     = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    samples[nx][ny], sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_samples(nx, ny, direction, inputs, hidden_inputs, num_samples)\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "                    ohs[nx][ny] = sigma\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    samples[nx][ny], sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_samples(nx, ny, direction, inputs, hidden_inputs, num_samples)\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    \n",
    "        samples = torch.stack([torch.stack(s, axis=1) for s in samples], axis=1) #.reshape((num_samples, self.N_x, self.N_y))\n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return samples, log_probs_ampl, phase\n",
    "    \n",
    "    def _gen_probs(self, nx, ny, direction, sample, inputs, hidden_inputs):\n",
    "        # pass the hidden unit and sigma into the GRU cell at t=i \n",
    "        # and get the output y (will be used for calculating the \n",
    "        # probability) and the next hidden state\n",
    "        full_sigma = [inputs[str(nx+direction[0])+str(ny)],inputs[str(nx)+str(ny+direction[1])]]\n",
    "        hidden     = [hidden_inputs[str(nx+direction[0])+str(ny)],hidden_inputs[str(nx)+str(ny+direction[1])]]\n",
    "        y, hidden  = self.forward(full_sigma, hidden)\n",
    "        # the amplitude is given by a linear layer with a softmax activation\n",
    "        ampl = self.lin1(y)\n",
    "        ampl = torch.softmax(ampl,dim=1) # amplitude, all elements in a row sum to 1\n",
    "        # the phase is given by a linear layer with a softsign activation\n",
    "        phase = self.lin2(y)\n",
    "        phase = self.soft(phase) \n",
    "        # one hot encode the current sigma to pass it into the GRU at\n",
    "        # the next time step\n",
    "        sigma = nn.functional.one_hot(sample.reshape((sample.size()[0],1)), 2).double()\n",
    "        \n",
    "        return sigma, ampl, torch.mul(torch.pi,phase), hidden\n",
    "    \n",
    "    def log_probabilities(self, samples):\n",
    "        \"\"\"\n",
    "        Calculates the log probability and the phase of each item in samples.\n",
    "        \"\"\"\n",
    "        # reshape samples\n",
    "        num_samples = samples.size()[0]\n",
    "        samples = samples.clone().detach()\n",
    "        samples = [[samples[:,nx,ny] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        \n",
    "        # generate a first input of zeros (sigma and hidden states) to the first GRU cell at t=0\n",
    "        sigma  = torch.zeros((num_samples,2), dtype=torch.float64).to(device)\n",
    "        inputs = {}\n",
    "        hidden_inputs = {}\n",
    "        for ny in range(-1, self.N_y):\n",
    "            for nx in range(-1, self.N_x+1):\n",
    "                inputs[str(nx)+str(ny)] = sigma\n",
    "                hidden_inputs[str(nx)+str(ny)] = self.init_hidden(num_samples)\n",
    "\n",
    "        ampl_probs  = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        phase_probs = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        ohs         = [[[] for ny in range(self.N_y)] for nx in range(self.N_x)]\n",
    "        for ny in range(self.N_y):\n",
    "            if ny % 2 == 0: #go from left to right\n",
    "                for nx in range(self.N_x):\n",
    "                    direction = [-1,-1]\n",
    "                    sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_probs(nx, ny, direction, samples[nx][ny], inputs, hidden_inputs)\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "            else: #go from right to left\n",
    "                for nx in range(self.N_x-1, -1, -1):\n",
    "                    direction = [1,-1]\n",
    "                    sigma, ampl_probs[nx][ny], phase_probs[nx][ny], hidden_inputs[str(nx)+str(ny)] = self._gen_probs(nx, ny, direction, samples[nx][ny], inputs, hidden_inputs)\n",
    "                    ohs[nx][ny] = sigma\n",
    "                    inputs[str(nx)+str(ny)] = sigma\n",
    "        ampl_probs = torch.cat([torch.stack(a, axis=1) for a in ampl_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        phase_probs = torch.cat([torch.stack(p, axis=1) for p in phase_probs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        ohs = torch.cat([torch.cat(o, axis=1) for o in ohs], axis=1) #.reshape((num_samples, self.N_x*self.N_y, 2))\n",
    "        # calculate the wavefunction and split it into amplitude and phase\n",
    "        log_probs_ampl = torch.sum(torch.log(torch.sum(torch.torch.multiply(ampl_probs,ohs), axis =2)), axis=1)\n",
    "        phase = torch.sum((torch.sum(torch.torch.multiply(phase_probs,ohs), axis =2)), axis=1)\n",
    "        return log_probs_ampl, phase\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9067d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n",
      "Model(\n",
      "  (rnn): TensorizedGRU(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (lin1): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (lin2): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (soft): Softsign()\n",
      ")\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[-1.7199e-01, -3.5822e-02, -8.7693e-02, -4.8696e-02],\n",
      "         [-1.6129e-01,  7.3265e-02, -1.6366e-01, -1.1634e-02],\n",
      "         [ 6.3465e-02, -6.1541e-02,  1.0360e-01,  2.3027e-02],\n",
      "         ...,\n",
      "         [-1.5881e-01, -1.8020e-01,  1.2630e-03, -7.0050e-02],\n",
      "         [-4.5944e-02, -2.5674e-02,  1.7266e-01,  1.7306e-01],\n",
      "         [-1.7070e-02, -5.4824e-02,  8.8665e-02, -1.4569e-02]],\n",
      "\n",
      "        [[-1.7372e-01,  5.9513e-02,  1.7479e-01, -1.4472e-01],\n",
      "         [-3.9431e-02,  3.9594e-02, -1.4867e-01, -1.5631e-01],\n",
      "         [ 1.3630e-01, -6.4649e-02,  1.0650e-01,  1.6322e-02],\n",
      "         ...,\n",
      "         [-1.6735e-01, -1.7476e-01,  6.1941e-02, -1.7032e-01],\n",
      "         [-1.4962e-01,  9.2836e-02,  8.8627e-02, -1.6637e-01],\n",
      "         [ 1.3138e-01, -3.5501e-02,  1.3555e-01, -1.0714e-01]],\n",
      "\n",
      "        [[-1.7360e-01, -1.2103e-01, -2.8304e-02, -1.8234e-01],\n",
      "         [-1.2440e-02, -9.1120e-02, -4.2495e-02, -2.5958e-05],\n",
      "         [ 1.0247e-02, -1.7859e-01,  9.3912e-02, -1.1190e-01],\n",
      "         ...,\n",
      "         [-1.0870e-01,  3.6932e-03, -1.2927e-01,  1.1593e-01],\n",
      "         [ 3.5962e-02, -7.9079e-02, -1.0580e-01,  5.9807e-02],\n",
      "         [-4.3705e-02,  3.4882e-02,  1.7154e-02,  2.2710e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3190e-01,  1.1240e-01,  8.4346e-03,  1.7572e-01],\n",
      "         [-1.2268e-01, -1.2576e-01, -6.4630e-02,  1.2988e-01],\n",
      "         [-6.6618e-02,  2.5709e-02,  1.7046e-03, -5.8663e-02],\n",
      "         ...,\n",
      "         [-4.4588e-02, -1.5783e-01, -7.9890e-02,  8.1010e-02],\n",
      "         [ 7.1141e-02,  1.6322e-01, -3.8186e-02, -1.5473e-01],\n",
      "         [ 9.8033e-02, -6.2471e-02, -5.2853e-02,  8.6244e-02]],\n",
      "\n",
      "        [[ 1.8201e-01,  1.5615e-01,  3.6258e-02, -3.5220e-02],\n",
      "         [ 3.9209e-02, -5.0871e-02,  1.3006e-01,  4.2899e-02],\n",
      "         [ 1.1628e-01, -6.1487e-03,  2.2902e-02,  1.2185e-01],\n",
      "         ...,\n",
      "         [ 1.7750e-01,  6.9046e-02, -8.0330e-02, -1.4540e-01],\n",
      "         [ 1.1026e-01, -8.6783e-02, -1.4622e-01,  2.5653e-02],\n",
      "         [ 9.3090e-02, -4.0571e-02,  1.8826e-02, -8.0237e-02]],\n",
      "\n",
      "        [[ 1.4036e-01,  1.6707e-01,  1.1918e-01, -1.7653e-01],\n",
      "         [-1.6678e-01,  1.0137e-01,  1.5823e-01,  9.7492e-02],\n",
      "         [ 1.8204e-02, -3.6382e-02, -1.3704e-01, -2.5481e-02],\n",
      "         ...,\n",
      "         [-2.8230e-02,  2.8949e-02, -1.6668e-02, -1.1877e-01],\n",
      "         [ 7.0326e-02, -1.4754e-01, -3.1509e-02,  1.7204e-01],\n",
      "         [-2.5610e-03, -1.1823e-02,  8.3749e-02,  1.6846e-01]]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([-0.1219, -0.0427,  0.0218, -0.0743, -0.0585,  0.0061, -0.0943,  0.0472,\n",
      "         0.0495, -0.0247, -0.0327,  0.0307,  0.0171,  0.1300, -0.0761],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([15, 30, 4])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0724, -0.0560,  0.1232, -0.0118],\n",
      "         [ 0.0227,  0.1083, -0.0262,  0.0706],\n",
      "         [-0.0109,  0.0938,  0.1310,  0.0390],\n",
      "         ...,\n",
      "         [ 0.0137, -0.0604,  0.1180,  0.0703],\n",
      "         [-0.0650, -0.1499,  0.1134, -0.0838],\n",
      "         [ 0.0731, -0.1741, -0.1674,  0.1067]],\n",
      "\n",
      "        [[-0.0587,  0.1584, -0.0129,  0.1263],\n",
      "         [-0.0394,  0.1638, -0.1437, -0.0632],\n",
      "         [-0.0185, -0.1540, -0.0194, -0.1323],\n",
      "         ...,\n",
      "         [ 0.1758, -0.0431,  0.0525, -0.1704],\n",
      "         [ 0.0195,  0.0091,  0.1535,  0.1213],\n",
      "         [-0.1230,  0.0493,  0.1378,  0.1165]],\n",
      "\n",
      "        [[-0.1419,  0.1754,  0.0293,  0.1148],\n",
      "         [ 0.0139,  0.0475,  0.1357,  0.0234],\n",
      "         [ 0.1093,  0.1279,  0.1077,  0.0954],\n",
      "         ...,\n",
      "         [ 0.1039,  0.1141, -0.0692,  0.1075],\n",
      "         [ 0.0043, -0.1182, -0.0031,  0.1617],\n",
      "         [ 0.1204,  0.1491, -0.0274,  0.1418]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0611,  0.0253, -0.0736, -0.0362],\n",
      "         [ 0.1102,  0.1173,  0.0402, -0.0635],\n",
      "         [-0.1520, -0.0196,  0.1640, -0.0079],\n",
      "         ...,\n",
      "         [ 0.1525,  0.1671, -0.0999,  0.0486],\n",
      "         [ 0.0056, -0.0815,  0.0169, -0.1315],\n",
      "         [ 0.0483, -0.1179, -0.0170,  0.0497]],\n",
      "\n",
      "        [[ 0.0012,  0.1152,  0.0230,  0.0602],\n",
      "         [-0.1663, -0.0015, -0.0624, -0.1434],\n",
      "         [-0.1662,  0.1340, -0.1691,  0.1080],\n",
      "         ...,\n",
      "         [-0.0121,  0.0161, -0.1669, -0.0757],\n",
      "         [ 0.1296, -0.0594, -0.0064,  0.1457],\n",
      "         [-0.1486,  0.1763,  0.0316, -0.0779]],\n",
      "\n",
      "        [[ 0.0771, -0.0164, -0.0289,  0.0812],\n",
      "         [ 0.1107,  0.1139, -0.0314, -0.1162],\n",
      "         [-0.1252, -0.0471, -0.0552, -0.1177],\n",
      "         ...,\n",
      "         [ 0.0246,  0.1495, -0.0982,  0.1129],\n",
      "         [-0.0226, -0.1525, -0.1056, -0.0031],\n",
      "         [ 0.1695, -0.1504,  0.1628, -0.1785]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "torch.Size([15])\n",
      "Parameter containing:\n",
      "tensor([ 0.1717, -0.1072,  0.1000,  0.0280,  0.0760,  0.0281,  0.1279,  0.1031,\n",
      "        -0.0683,  0.1476, -0.1349, -0.1734, -0.0046, -0.1239, -0.1622],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([30, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.1729, -0.1688,  0.3463,  0.2684, -0.0520, -0.1640,  0.3423,  0.0916,\n",
      "         -0.1845, -0.1042,  0.1588, -0.0630,  0.1996, -0.1587,  0.1978],\n",
      "        [ 0.2706, -0.2907,  0.0646, -0.2977,  0.0400, -0.2909, -0.2889, -0.2925,\n",
      "         -0.1277,  0.1009,  0.2176,  0.1560, -0.1581, -0.2184,  0.1542],\n",
      "        [ 0.0913, -0.0564, -0.3121,  0.3086, -0.2124, -0.3513, -0.0274, -0.0799,\n",
      "         -0.2974,  0.0165,  0.3249,  0.2049,  0.1935, -0.0166, -0.2617],\n",
      "        [-0.1282, -0.0765,  0.0057, -0.2986,  0.2761,  0.2345, -0.1831,  0.2049,\n",
      "          0.0043,  0.0974,  0.2011,  0.0678,  0.3015, -0.1947,  0.0758],\n",
      "        [-0.2701,  0.1567, -0.1061,  0.2820, -0.0357, -0.3633,  0.0303, -0.0742,\n",
      "         -0.1673, -0.1090, -0.3612, -0.1582, -0.0148, -0.3175, -0.2845],\n",
      "        [-0.2002,  0.0474, -0.1350, -0.1806, -0.0896,  0.3634, -0.0929, -0.2344,\n",
      "         -0.2894,  0.0433, -0.2056,  0.1782, -0.1488,  0.0638, -0.3562],\n",
      "        [-0.0291,  0.1945,  0.1144, -0.0677,  0.2330,  0.0647,  0.2401, -0.2118,\n",
      "         -0.3069,  0.0373,  0.2876,  0.1551,  0.2342, -0.3411,  0.0845],\n",
      "        [ 0.1717,  0.3591, -0.0962, -0.3042, -0.2444, -0.1019,  0.3551, -0.1513,\n",
      "         -0.0040, -0.2075,  0.0718, -0.0472,  0.1025, -0.2640,  0.0773],\n",
      "        [-0.3075,  0.1993,  0.3247, -0.0886,  0.3639, -0.0092, -0.2929, -0.0671,\n",
      "          0.2167,  0.2691,  0.1086, -0.1671,  0.2318, -0.2763,  0.3441],\n",
      "        [-0.2586,  0.3581,  0.2887,  0.1700, -0.2222, -0.0186,  0.2447,  0.2127,\n",
      "          0.3647,  0.1927,  0.3275, -0.0045, -0.2488, -0.0923, -0.0985],\n",
      "        [ 0.0391,  0.1867,  0.3244,  0.2184, -0.1113,  0.0633, -0.0553,  0.0913,\n",
      "         -0.3338,  0.0259, -0.2746,  0.3296, -0.0121,  0.0407,  0.2012],\n",
      "        [ 0.3586, -0.0255,  0.1392, -0.3130,  0.2768,  0.3534,  0.1141, -0.2486,\n",
      "          0.2593, -0.1737, -0.3635, -0.3372, -0.2545, -0.1742,  0.1870],\n",
      "        [-0.3424,  0.0182,  0.1503,  0.3254, -0.1681,  0.2175, -0.1055,  0.2954,\n",
      "         -0.1320,  0.2302,  0.2442,  0.1609, -0.0747,  0.0544,  0.1978],\n",
      "        [-0.2311, -0.0819,  0.2924, -0.2006,  0.2579, -0.3123,  0.0399,  0.1533,\n",
      "          0.0151,  0.2040,  0.0320, -0.0667, -0.1494, -0.1717,  0.1448],\n",
      "        [-0.2771,  0.0797, -0.2292, -0.1030,  0.0412,  0.2440,  0.1083, -0.3232,\n",
      "          0.0562, -0.2253, -0.1713, -0.2133,  0.1100,  0.0071, -0.1748],\n",
      "        [-0.3438, -0.1927, -0.0689, -0.2184,  0.2139,  0.0815,  0.2241,  0.2843,\n",
      "         -0.2227,  0.1800,  0.2635,  0.1982,  0.1261, -0.0670,  0.3441],\n",
      "        [-0.0731,  0.3104,  0.2925,  0.0230, -0.3169, -0.3446,  0.3477, -0.1234,\n",
      "         -0.1189,  0.0276, -0.2418,  0.0571, -0.0538,  0.1177, -0.1872],\n",
      "        [-0.2856, -0.1173,  0.2382,  0.1963,  0.1934, -0.3405,  0.3599,  0.3139,\n",
      "         -0.2562, -0.2565, -0.2583, -0.0795, -0.2896,  0.2798, -0.3469],\n",
      "        [-0.2814, -0.0659, -0.2159,  0.2826,  0.0510, -0.3581, -0.2990, -0.0207,\n",
      "         -0.1686,  0.1585, -0.1703,  0.3370, -0.0100,  0.1706,  0.0677],\n",
      "        [-0.1873, -0.3133, -0.3038, -0.0213, -0.3410, -0.1740,  0.3180, -0.0715,\n",
      "          0.0086,  0.3170,  0.2405, -0.3310, -0.2583, -0.3391,  0.1068],\n",
      "        [-0.1218, -0.2752, -0.2886, -0.2740,  0.0477,  0.1406, -0.2726,  0.1226,\n",
      "          0.1656,  0.2981,  0.3360,  0.1853, -0.0073,  0.3101,  0.2091],\n",
      "        [ 0.3350,  0.0165,  0.1113,  0.2938, -0.0584,  0.0479,  0.2615, -0.2960,\n",
      "          0.1334, -0.2696,  0.1795,  0.3587, -0.1860,  0.1216, -0.2121],\n",
      "        [-0.3373, -0.2505, -0.0328,  0.2570, -0.2843, -0.0100, -0.1423,  0.1343,\n",
      "          0.1767,  0.2347, -0.0674, -0.3083,  0.1075, -0.2002, -0.1650],\n",
      "        [-0.1464,  0.3502,  0.0156,  0.3601, -0.0947, -0.1201,  0.3646, -0.3426,\n",
      "          0.2160, -0.2127, -0.3393,  0.0843,  0.0341,  0.1905,  0.0307],\n",
      "        [-0.3164, -0.2478, -0.0354, -0.0505, -0.3258, -0.3555,  0.1001, -0.0595,\n",
      "         -0.0742, -0.3153, -0.2309,  0.1232,  0.2026,  0.0254,  0.0241],\n",
      "        [ 0.3175, -0.3573, -0.0375, -0.3050, -0.0743,  0.2146, -0.1152, -0.0129,\n",
      "          0.0514,  0.3061, -0.2123, -0.1140,  0.1986,  0.2406, -0.1695],\n",
      "        [ 0.2366,  0.0007, -0.1518,  0.2750,  0.0817,  0.1501, -0.1611,  0.1178,\n",
      "         -0.2420, -0.0269,  0.1361,  0.1203, -0.1558, -0.3589,  0.3107],\n",
      "        [ 0.3499,  0.0055, -0.1345,  0.2935,  0.2233,  0.0732,  0.2708, -0.1036,\n",
      "         -0.1418, -0.3095,  0.0284,  0.0652,  0.2566,  0.0380,  0.2364],\n",
      "        [-0.2233,  0.3612,  0.3208,  0.1678, -0.0212, -0.3346,  0.0034,  0.3388,\n",
      "          0.0422, -0.0565,  0.2813,  0.2915, -0.3055,  0.0617,  0.1220],\n",
      "        [ 0.2743,  0.0566,  0.0107, -0.2302, -0.0611,  0.1178,  0.0851, -0.1133,\n",
      "         -0.0015, -0.2039, -0.3508,  0.1302, -0.0402,  0.0451, -0.2503]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.0594,  0.0502, -0.0261,  0.0123,  0.2562,  0.1595,  0.2099,  0.0258,\n",
      "         -0.1823, -0.0050,  0.1007, -0.1532,  0.1507,  0.2158,  0.1344],\n",
      "        [ 0.0181,  0.0155,  0.2545, -0.2116, -0.2443,  0.0388, -0.0316, -0.0591,\n",
      "         -0.2338, -0.1019,  0.0586,  0.0869,  0.0483, -0.0307,  0.0706]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([0.1784, 0.1938], dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2, 15])\n",
      "Parameter containing:\n",
      "tensor([[-0.0603, -0.0465, -0.0751,  0.0927, -0.0998,  0.0308, -0.2548, -0.2045,\n",
      "         -0.1716, -0.0766,  0.1910, -0.0513,  0.2276, -0.1954,  0.1400],\n",
      "        [ 0.2399,  0.1470,  0.0422,  0.0139, -0.1958, -0.0762,  0.0494, -0.0499,\n",
      "         -0.1182,  0.0682, -0.0658, -0.0627, -0.0439,  0.2302, -0.1862]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([2])\n",
      "Parameter containing:\n",
      "tensor([-0.1017, -0.2248], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "Nx = 2\n",
    "Ny = 2\n",
    "hiddendim  = 15\n",
    "numsamples = 10\n",
    "\n",
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=2, system_size_x=Nx, system_size_y = Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=0)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "model = model.double()\n",
    "for p in list(model.parameters()):\n",
    "    print(p.size())\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44615675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the sampling method\n",
    "samples, log_probs, phase = model.sample(1000)\n",
    "\n",
    "samples = torch.unique(samples, dim=0)\n",
    "print(samples.size())\n",
    "\n",
    "2**(Nx*Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4221f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "tensor(1.0000+0.j, dtype=torch.complex128, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test the probability method\n",
    "log_probs, phases = model.log_probabilities(samples)\n",
    "print(log_probs.size())\n",
    "print(phases.size())\n",
    "print(torch.sum(torch.mul(torch.exp(0.5*log_probs+1j*phases),torch.exp(0.5*log_probs+1j*phases).conj())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb03b4c",
   "metadata": {},
   "source": [
    "### 2. Calculate the matrix elements (here 2D XXZ model)\n",
    "\n",
    "$$ E_{\\theta}^{loc}(x) = \\frac{<x|H|\\psi_\\theta>}{<x|\\psi_\\theta>} = H_{diag}(x)+H_{offd}(x)\\frac{<x^{\\prime}|\\psi_\\theta>}{<x|\\psi_\\theta>} $$\n",
    "with $\\hat{H}_{offd}|x^{\\prime}>=H_{offd}(x)|x^{\\prime}>$ and ${<x|\\psi_\\theta>}$ given by the square root of the exponential of model.log_probabilities(x) defined above.\n",
    "\n",
    "- for $J_p = 0$ and $J_z = 1$: $E_{loc} = H_{diag}(x) = 0.25*J_z*systemsize$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f77b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZ1D_MatrixElements(Jp, Jz, samples, length):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    \"\"\"\n",
    "\n",
    "    N = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples, length))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for i in range(length): \n",
    "        values  = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        valuesT[values==2] = +1 #If both spins are up\n",
    "        valuesT[values==0] = +1 #If both spins are down\n",
    "        valuesT[values==1] = -1 #If they are opposite\n",
    "        diag_matrixelements[:,i] = valuesT.reshape((numsamples))*Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, length))\n",
    "    xprime = []\n",
    "    for i in range(length): \n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = values.clone()\n",
    "        #flip the spins\n",
    "        new_samples             = samples.clone()\n",
    "        new_samples[:,(i+1)%N]  = samples[:,i]\n",
    "        new_samples[:,i]        = samples[:,(i+1)%N]\n",
    "        valuesT[values==2]      = 0 #If both spins are up\n",
    "        valuesT[values==0]      = 0 #If both spins are down\n",
    "        valuesT[values==1]      = 1 #If they are opposite\n",
    "        offd_matrixelements[:,i] = valuesT.reshape((numsamples))*Jp*0.5\n",
    "        xprime.append(new_samples)\n",
    "    return diag_matrixelements, offd_matrixelements, torch.stack(xprime, axis=0)\n",
    "\n",
    "def XXZ1D_Eloc(Jp, Jz, samples, RNN, boundaries):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    N          = samples.size()[1]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length = N\n",
    "    else:\n",
    "        length = N-1\n",
    "    \n",
    "    queue_samples       = torch.zeros((length+1, numsamples, N, 1), dtype = torch.int32) \n",
    "    log_probs           = np.zeros((length+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ1D_MatrixElements(Jp, Jz, samples, length)\n",
    "    diag_me = torch.sum(diag_me, axis=1)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    queue_samples[0] = samples\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    #off-diagonal elements\n",
    "    \n",
    "    offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "    queue_samples[1:] = new_samples\n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(length+1)*numsamples, N, 1])\n",
    "    log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "    log_probs_reshaped = torch.reshape(log_probs, (length+1,numsamples)).to(torch.complex64)\n",
    "    phases_reshaped = torch.reshape(phases, (length+1,numsamples))\n",
    "    for i in range(1,length+1):\n",
    "        tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:])\n",
    "        tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "        Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    return Eloc\n",
    "    \n",
    "def XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - samples: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - length_x: system length in x dir\n",
    "    - length_y: system length in y dir\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = torch.zeros((numsamples))\n",
    "    #diagonal elements from the SzSz term \n",
    "    for n in range(numsamples):\n",
    "        for i in range(Nx): \n",
    "            for j in range(Ny):\n",
    "                if i != length_x:\n",
    "                    if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "                if j != length_y:\n",
    "                    if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                        diag_matrixelements[n] += -Jz*0.25\n",
    "                    else:\n",
    "                        diag_matrixelements[n] += Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements from the S+S- terms\n",
    "    offd_matrixelements = torch.zeros((numsamples, length_x*length_y*2))\n",
    "    xprime = torch.zeros((length_x*length_y*2, numsamples, Nx, Ny))\n",
    "    if Jp!=0:\n",
    "        for n in range(numsamples):\n",
    "            num = 0\n",
    "            for i in range(length_x): \n",
    "                for j in range(length_y):\n",
    "                    new_sample = samples[n].clone()\n",
    "                    if i != length_x:\n",
    "                        if samples[n,i,j] != samples[n,(i+1)%Nx,j]:\n",
    "                            new_sample[(i+1)%Nx,j]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,(i+1)%Nx, j]\n",
    "                            offd_matrixelements[n,num] += Jp*0.5\n",
    "                            xprime[num,n]=new_sample\n",
    "                            num +=1\n",
    "                    if j != length_y:\n",
    "                        if samples[n,i,j] != samples[n,i,(j+1)%Ny]:\n",
    "                            new_sample[i,(j+1)%Ny]   = samples[n,i,j]\n",
    "                            new_sample[i,j]          = samples[n,i,(j+1)%Ny]\n",
    "                            offd_matrixelements[n,num] += Jp*0.5\n",
    "                            xprime[num,n]=new_sample\n",
    "                            num +=1\n",
    "                    \n",
    "    return diag_matrixelements, offd_matrixelements, xprime\n",
    "\n",
    "\n",
    "def XXZ2D_Eloc(Jp, Jz, samples, RNN, boundaries):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 2D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    - RNN: RNN model\n",
    "    - boundaries: str, open or periodic\n",
    "    \"\"\"\n",
    "\n",
    "    Nx         = samples.size()[1]\n",
    "    Ny         = samples.size()[2]\n",
    "    numsamples = samples.size()[0]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    elif \"open\":\n",
    "        length_x = Nx-1\n",
    "        length_y = Ny-1\n",
    "    else:\n",
    "        raise \"Boundary \"+boundaries+\" not implemented\"\n",
    "    \n",
    "    queue_samples       = torch.zeros((length_x*length_y*2+1, numsamples, Nx, Ny), dtype = torch.int32) \n",
    "    log_probs           = np.zeros((length_x*length_y*2+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #matrix elements\n",
    "    diag_me, offd_me, new_samples = XXZ2D_MatrixElements(Jp, Jz, samples, length_x, length_y)\n",
    "    offd_me = offd_me.to(torch.complex64)\n",
    "    # diagonal elements\n",
    "    queue_samples[0] = samples\n",
    "    Eloc = diag_me.to(torch.complex64)\n",
    "    #off-diagonal elements\n",
    "    if Jp != 0:\n",
    "        offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "        queue_samples[1:] = new_samples\n",
    "        queue_samples_reshaped = np.reshape(queue_samples, [(length_x*length_y*2+1)*numsamples, Nx, Ny])\n",
    "        log_probs, phases = model.log_probabilities(queue_samples_reshaped.to(torch.int64))\n",
    "        log_probs_reshaped = torch.reshape(log_probs, (length_x*length_y*2+1,numsamples)).to(torch.complex64)\n",
    "        phases_reshaped = torch.reshape(phases, (length_x*length_y*2+1,numsamples))\n",
    "        for i in range(1,length_x*length_y*2+1):\n",
    "            tot_log_probs = 0.5*(log_probs_reshaped[i,:]-log_probs_reshaped[0,:])\n",
    "            tot_log_probs += 1j*(phases_reshaped[i,:]-phases_reshaped[0,:])\n",
    "            Eloc += offd_me[:,i-1]*(torch.exp(tot_log_probs))\n",
    "    return Eloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32cdfd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [0, 0, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [0, 1, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [1, 1, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [1, 0, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1],\n",
      "         [1, 1, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [0, 0, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[1, 0, 1],\n",
      "         [0, 1, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0],\n",
      "         [0, 0, 0],\n",
      "         [1, 0, 0]]])\n",
      "-------\n",
      "tensor([-0.3813-0.0345j, -1.4499+0.0267j, -0.4516+0.0013j,  2.3735+0.0187j,\n",
      "        -1.4499+0.0267j,  0.0762+0.0663j, -1.5102+0.0840j, -0.3739-0.0235j,\n",
      "        -4.0164-0.0311j, -0.4516+0.0013j], grad_fn=<AddBackward0>)\n",
      "tensor([-3.1093, -2.1320, -2.1251, -7.9958, -2.1320, -4.0673, -3.3062, -2.9953,\n",
      "        -2.6132, -2.1251], dtype=torch.float64, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#simple tests\n",
    "Jp = 1\n",
    "Jz = 1\n",
    "boundaries = \"open\"\n",
    "\n",
    "samples, log_probs, phase = model.sample(10)\n",
    "print(samples)\n",
    "print(\"-------\")\n",
    "local_energy = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries)\n",
    "print(local_energy)\n",
    "print(log_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f79c8c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e5aa38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(4321)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c872de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 4144\n",
      "Parameter containing:\n",
      "tensor([[[ 1.0566e-01, -6.0767e-05,  1.1456e-01,  1.0755e-01],\n",
      "         [-2.9062e-03, -1.0438e-01,  6.9534e-02,  1.6747e-01],\n",
      "         [ 2.3354e-03,  2.1005e-02,  1.3408e-01,  1.4956e-01],\n",
      "         ...,\n",
      "         [ 1.3772e-01,  1.4667e-01,  1.4424e-02,  1.8132e-01],\n",
      "         [ 4.1480e-02, -8.9484e-02,  1.7379e-01, -5.9462e-02],\n",
      "         [ 1.1433e-01,  1.4143e-01, -1.7633e-01, -3.1094e-02]],\n",
      "\n",
      "        [[-1.3762e-01,  9.8594e-02, -3.6308e-02,  1.6726e-01],\n",
      "         [-1.6004e-01,  1.1517e-02,  8.8071e-02,  6.3117e-03],\n",
      "         [ 1.4016e-01, -5.8708e-02,  1.4204e-01, -1.2518e-01],\n",
      "         ...,\n",
      "         [-1.5076e-01,  5.6153e-02, -1.0839e-01,  6.6478e-02],\n",
      "         [-1.3062e-01, -1.0684e-01,  1.2778e-01,  1.6356e-01],\n",
      "         [ 1.1809e-01, -1.0066e-01,  1.3641e-01,  9.7207e-03]],\n",
      "\n",
      "        [[ 3.0131e-02, -3.5614e-02, -1.3568e-01, -1.5696e-01],\n",
      "         [-5.2084e-02,  1.2624e-01, -7.4834e-02, -1.9129e-02],\n",
      "         [-1.4492e-01, -1.2326e-01, -2.6145e-02, -5.7940e-02],\n",
      "         ...,\n",
      "         [ 5.5555e-02,  3.7185e-02, -7.9722e-02, -1.7889e-01],\n",
      "         [ 6.1649e-02, -1.3210e-01, -2.0724e-02,  1.6316e-01],\n",
      "         [-1.0142e-01,  3.5675e-02,  4.1704e-03, -1.0315e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.2139e-02, -6.4009e-02, -5.1086e-02,  2.6586e-02],\n",
      "         [ 4.3092e-02,  1.0260e-01,  8.2446e-02, -1.7135e-01],\n",
      "         [ 1.2294e-01, -1.3377e-02,  6.3766e-02,  3.1282e-02],\n",
      "         ...,\n",
      "         [-1.1188e-02, -5.1377e-02, -4.1208e-02, -3.7997e-02],\n",
      "         [-1.3945e-01, -1.1495e-01,  1.0521e-01, -1.1618e-01],\n",
      "         [ 1.4188e-01,  1.5451e-02, -9.2649e-03,  1.5109e-01]],\n",
      "\n",
      "        [[ 6.4966e-02, -1.6256e-01,  1.8953e-04,  1.7995e-01],\n",
      "         [-1.1682e-01,  1.5814e-01, -1.5011e-01, -1.2198e-02],\n",
      "         [ 7.3547e-02, -8.1903e-02,  5.7590e-02,  1.8227e-01],\n",
      "         ...,\n",
      "         [-7.9558e-02,  1.6976e-01, -1.2199e-01, -1.3960e-01],\n",
      "         [ 9.4369e-02,  1.7150e-01,  1.4595e-01,  7.6468e-02],\n",
      "         [-1.0406e-02, -1.6875e-01, -9.2845e-02, -1.7112e-01]],\n",
      "\n",
      "        [[ 4.2852e-02,  1.4550e-02,  1.7755e-01,  2.7614e-02],\n",
      "         [-9.4421e-02,  3.2386e-02, -7.3758e-02,  2.1267e-02],\n",
      "         [-1.3982e-01,  1.6579e-01,  4.7187e-02, -1.2447e-01],\n",
      "         ...,\n",
      "         [ 5.0529e-02, -2.5812e-02, -1.0772e-01,  9.5536e-02],\n",
      "         [ 1.2653e-01, -1.3859e-01,  1.4688e-01, -9.5928e-02],\n",
      "         [ 1.1738e-01,  3.8684e-03,  7.8619e-02,  3.7011e-02]]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1599, -0.1537,  0.1223, -0.0012, -0.1778, -0.0693,  0.1378, -0.0426,\n",
      "         0.0989,  0.1487, -0.1757, -0.1563, -0.0184,  0.0699,  0.0502],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1023,  0.0143,  0.0065, -0.0935],\n",
      "         [-0.0518, -0.0831, -0.1443,  0.1124],\n",
      "         [-0.0077,  0.0364, -0.1632,  0.0391],\n",
      "         ...,\n",
      "         [-0.1771, -0.1133, -0.0295,  0.0116],\n",
      "         [-0.1008,  0.0192, -0.0952,  0.0056],\n",
      "         [ 0.1640,  0.1347,  0.0275,  0.0349]],\n",
      "\n",
      "        [[ 0.0711, -0.1316,  0.0260,  0.1664],\n",
      "         [-0.0919, -0.1489,  0.1379, -0.0495],\n",
      "         [-0.0556, -0.0139, -0.1132,  0.1445],\n",
      "         ...,\n",
      "         [-0.1454,  0.0516,  0.1623,  0.0214],\n",
      "         [ 0.0041, -0.1443, -0.0420,  0.0369],\n",
      "         [ 0.0315,  0.0992, -0.1638, -0.1438]],\n",
      "\n",
      "        [[-0.1689,  0.0590,  0.0108, -0.1792],\n",
      "         [-0.0180, -0.1275,  0.1077,  0.1141],\n",
      "         [-0.1036,  0.0322, -0.1591, -0.1683],\n",
      "         ...,\n",
      "         [-0.0089, -0.0924,  0.1346,  0.0926],\n",
      "         [-0.1556,  0.0611, -0.1186,  0.0336],\n",
      "         [ 0.1584, -0.1205,  0.1078,  0.1824]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0327,  0.0339, -0.1327,  0.0654],\n",
      "         [ 0.0746,  0.0016,  0.0949, -0.0310],\n",
      "         [ 0.0949, -0.1168,  0.0995, -0.1554],\n",
      "         ...,\n",
      "         [ 0.0208,  0.0623,  0.0143,  0.1463],\n",
      "         [-0.0270,  0.0819,  0.0010, -0.0543],\n",
      "         [-0.0476,  0.1346,  0.1563,  0.0797]],\n",
      "\n",
      "        [[-0.0695, -0.1741,  0.1052, -0.1109],\n",
      "         [-0.1336, -0.1592,  0.0572, -0.0358],\n",
      "         [ 0.1757, -0.0715,  0.0976,  0.0259],\n",
      "         ...,\n",
      "         [ 0.0920, -0.0917,  0.0214, -0.0341],\n",
      "         [ 0.1541, -0.0381,  0.1119, -0.0105],\n",
      "         [-0.1136,  0.0689, -0.0948, -0.1088]],\n",
      "\n",
      "        [[ 0.1101, -0.1263,  0.1391,  0.0669],\n",
      "         [-0.1269, -0.1667,  0.1561, -0.1493],\n",
      "         [-0.0971,  0.1511,  0.1107, -0.0296],\n",
      "         ...,\n",
      "         [ 0.0957,  0.0395, -0.0083,  0.1008],\n",
      "         [ 0.1389, -0.0976,  0.0332,  0.0152],\n",
      "         [-0.1612, -0.0291, -0.0822,  0.1087]]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1610,  0.0308,  0.1382,  0.1805,  0.1584,  0.0145, -0.0395,  0.0922,\n",
      "        -0.0255, -0.0055, -0.0732, -0.1415, -0.1297, -0.1181, -0.0642],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0082,  0.2027, -0.1976,  0.0790, -0.0937, -0.1167,  0.0084,\n",
      "         -0.0932,  0.0961,  0.1724, -0.2082,  0.3052, -0.1054,  0.1808],\n",
      "        [-0.1960,  0.0948,  0.2388,  0.1354, -0.2181,  0.2197,  0.1422, -0.1673,\n",
      "          0.3583,  0.3309,  0.1872, -0.0607, -0.1674, -0.0791, -0.1016],\n",
      "        [ 0.0599, -0.1208,  0.1529,  0.1324,  0.3335, -0.1423,  0.3612,  0.1663,\n",
      "         -0.1462,  0.1220,  0.1076,  0.2958,  0.2796, -0.0494, -0.0886],\n",
      "        [ 0.1653, -0.1481,  0.2169, -0.0592, -0.0428, -0.1604, -0.2326,  0.0819,\n",
      "          0.0407,  0.2194, -0.0367, -0.3029,  0.3412,  0.0545, -0.2781],\n",
      "        [-0.0715, -0.1902,  0.2008, -0.2359,  0.0709,  0.0498,  0.3320, -0.0966,\n",
      "         -0.1678, -0.2693,  0.1431,  0.2235, -0.2982, -0.1667,  0.0266],\n",
      "        [-0.2354, -0.3029, -0.0362,  0.3636,  0.3051,  0.0488,  0.3481, -0.0892,\n",
      "          0.1429, -0.0179, -0.3083, -0.1600, -0.2723, -0.1758, -0.1262],\n",
      "        [ 0.1752, -0.2266,  0.1714,  0.3096,  0.1412, -0.3103,  0.0244, -0.3200,\n",
      "          0.0379,  0.0761, -0.2853, -0.1335,  0.3123,  0.2101,  0.0324],\n",
      "        [ 0.1117,  0.0923, -0.0674,  0.1096,  0.1913, -0.0539,  0.2529,  0.3339,\n",
      "         -0.1790, -0.1378,  0.0489, -0.0091,  0.2524, -0.2874, -0.3503],\n",
      "        [ 0.1963, -0.1917, -0.1762, -0.3438,  0.3298, -0.1895,  0.0070, -0.1052,\n",
      "         -0.2790,  0.0424, -0.3308, -0.1095, -0.1978,  0.1965, -0.3497],\n",
      "        [-0.2157,  0.1227, -0.3208,  0.1452, -0.0278,  0.0323, -0.2079, -0.3044,\n",
      "          0.2599, -0.2310, -0.3023,  0.2046, -0.0621,  0.0374,  0.0260],\n",
      "        [ 0.3592, -0.2216, -0.2878, -0.2666,  0.2635,  0.1342,  0.3505, -0.3247,\n",
      "         -0.0685, -0.1499,  0.1593, -0.2016, -0.2129,  0.1358, -0.0744],\n",
      "        [ 0.2174, -0.1234, -0.2032,  0.1669,  0.0855,  0.2616, -0.0330,  0.0088,\n",
      "         -0.3495, -0.2801, -0.0832,  0.1496, -0.2844,  0.1914,  0.1570],\n",
      "        [-0.2079,  0.2566,  0.0200, -0.0037, -0.1121,  0.3496, -0.2180,  0.2209,\n",
      "          0.2288,  0.3074,  0.3424,  0.3399,  0.2297, -0.3487,  0.1395],\n",
      "        [-0.3329,  0.0743, -0.3173,  0.3490,  0.0713,  0.0563,  0.1187, -0.2476,\n",
      "          0.3446, -0.1458, -0.0648,  0.2353, -0.0961,  0.0192, -0.1872],\n",
      "        [-0.0734,  0.0669, -0.2603, -0.2322,  0.3585, -0.0778,  0.3344,  0.3539,\n",
      "         -0.0573,  0.2143,  0.2066, -0.3291, -0.0669, -0.3646,  0.1478],\n",
      "        [ 0.2367, -0.0906, -0.1017,  0.3487,  0.3611,  0.0352, -0.3619,  0.2168,\n",
      "          0.3014,  0.0126, -0.3176,  0.1695, -0.0720,  0.2490, -0.0183],\n",
      "        [ 0.3473, -0.3429,  0.0661,  0.2258,  0.3582,  0.3342, -0.2070,  0.0936,\n",
      "         -0.2181,  0.1833,  0.1802,  0.1482, -0.0503,  0.2092, -0.0907],\n",
      "        [-0.1158,  0.0388, -0.2850,  0.1758, -0.0226, -0.2705, -0.1540,  0.1844,\n",
      "         -0.3262, -0.2548,  0.1674, -0.2505,  0.1396,  0.3389,  0.2953],\n",
      "        [-0.2935,  0.0144, -0.1986,  0.2279, -0.2695,  0.3480, -0.1823, -0.1391,\n",
      "          0.2790,  0.0652, -0.0246, -0.2931, -0.3539,  0.2171, -0.1433],\n",
      "        [-0.3038, -0.0795,  0.1455,  0.1449, -0.3390, -0.0288,  0.1104, -0.1844,\n",
      "          0.0673, -0.1843,  0.2245,  0.1728,  0.3081,  0.0654,  0.2847],\n",
      "        [-0.1247,  0.0921, -0.2357, -0.3634, -0.1078,  0.3355, -0.0543,  0.3427,\n",
      "         -0.2839, -0.2120,  0.1379,  0.3263, -0.3405,  0.2910,  0.1476],\n",
      "        [ 0.1964, -0.1144,  0.1841,  0.3270, -0.2587,  0.2221, -0.1767,  0.1497,\n",
      "         -0.1094, -0.2498, -0.1607, -0.3378,  0.0762, -0.2347,  0.1707],\n",
      "        [ 0.2568,  0.1979,  0.1323,  0.1502, -0.0527, -0.0288, -0.0951, -0.1862,\n",
      "         -0.3046, -0.2542, -0.1740,  0.1010,  0.3594,  0.0153,  0.2010],\n",
      "        [ 0.3026, -0.1597,  0.0294,  0.0429,  0.1928, -0.0663, -0.0216,  0.3551,\n",
      "         -0.3098, -0.1289,  0.3095, -0.1017, -0.0182, -0.0294, -0.0773],\n",
      "        [-0.0844,  0.0382,  0.3172, -0.2998,  0.0397, -0.2614, -0.2691,  0.3272,\n",
      "         -0.0436,  0.0149,  0.2336,  0.3238,  0.3627,  0.2861, -0.1048],\n",
      "        [-0.2913,  0.1569, -0.2664, -0.1022,  0.2608, -0.1133, -0.0076, -0.0589,\n",
      "         -0.3477, -0.0933, -0.2812, -0.0909, -0.2572,  0.3218,  0.3360],\n",
      "        [ 0.1736,  0.1909,  0.0123, -0.2167,  0.2492, -0.3426,  0.1225,  0.0289,\n",
      "         -0.0330, -0.3013,  0.2022,  0.2401,  0.1351,  0.3604,  0.2290],\n",
      "        [-0.3126,  0.1685,  0.1787,  0.1920, -0.3560, -0.0537,  0.1691, -0.1425,\n",
      "          0.3075,  0.2015, -0.0642, -0.2211,  0.3286, -0.0358,  0.2445],\n",
      "        [ 0.1899,  0.0438, -0.0061, -0.3508,  0.0366,  0.1919, -0.0858,  0.2384,\n",
      "         -0.1486,  0.3140,  0.2112,  0.3632,  0.1835, -0.0900,  0.1085],\n",
      "        [-0.2881,  0.1925,  0.0862,  0.3150, -0.1211,  0.1686, -0.0858, -0.0971,\n",
      "         -0.2734,  0.3126, -0.1947, -0.1185, -0.1953,  0.1514, -0.3040]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1629,  0.2177,  0.0509,  0.1378,  0.1493,  0.1408,  0.2358, -0.0274,\n",
      "         -0.0171,  0.1069, -0.1635,  0.1270,  0.0610,  0.1345, -0.0658],\n",
      "        [ 0.0472, -0.1476, -0.0506,  0.0004,  0.2533,  0.2014, -0.1102, -0.2262,\n",
      "         -0.1558,  0.1240, -0.2505, -0.1799, -0.0632,  0.0088, -0.0008]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1989,  0.0602], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2215, -0.1371, -0.0955, -0.0236, -0.1216, -0.0552, -0.1766,  0.1541,\n",
      "         -0.1003, -0.1228,  0.0088, -0.2036,  0.2029, -0.1853, -0.2215],\n",
      "        [ 0.0025, -0.0251, -0.0106, -0.0841,  0.1219,  0.2153, -0.1818,  0.0384,\n",
      "         -0.0244, -0.0138,  0.0765, -0.1513,  0.1180,  0.2376, -0.0197]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1611, -0.0905], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "Jp         = 1\n",
    "Jz         = 1\n",
    "Nx         = 4\n",
    "Ny         = 4\n",
    "bounds     = \"open\"\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs   = 3000\n",
    "lr         = 0.01\n",
    "hidden_dim = 10\n",
    "\n",
    "folder = \"with_total_sz_cost/\"\n",
    "\n",
    "model = Model(input_size=2, system_size_x=Nx,system_size_y=Ny, hidden_dim=hiddendim, n_layers=1, sz_tot=None)\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "for p in list(model.parameters()):\n",
    "    print(p)\n",
    "\n",
    "\n",
    "# Optimizer and cost function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def cost_fct(samples, model, Jp, Jz, log_probs, phases, boundaries, sz_tot=0):\n",
    "    Eloc = XXZ2D_Eloc(Jp, Jz, samples, model, boundaries)\n",
    "    log_psi = (0.5*log_probs+1j*phases)\n",
    "    eloc_sum = (Eloc).mean(axis=0)\n",
    "    e_loc_corr = (Eloc - eloc_sum).detach()\n",
    "    if sz_tot != None:\n",
    "        e_loc_corr += (get_sz_(samples).detach()-sz_tot*torch.ones((samples.size()[0])))**2\n",
    "    cost = 2 * torch.real((torch.conj(log_psi) * e_loc_corr.to(torch.complex128))).mean(axis=0)\n",
    "    return Eloc, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "994860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observables that can be evaluated during the training or afterwards\n",
    "def get_length(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    if boundaries == \"periodic\":\n",
    "        length_x = Nx\n",
    "        length_y = Ny\n",
    "    else:\n",
    "        length_x = Nx-1\n",
    "        length_y = Ny-1\n",
    "    return Nx, Ny, length_x, length_y\n",
    "\n",
    "\n",
    "def get_szsz(samples, log_probs, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    szsz = torch.zeros((samples.size()[0], length_x, length_y))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            szsz[:,i,j] = s[:,i,j]*s[:,(i+1)%Nx,j]\n",
    "            szsz[:,i,j] += s[:,i,j]*s[:,i,(j+1)%Ny]\n",
    "    return torch.mean(szsz, axis=0)*1/4\n",
    "\n",
    "def get_sxsx(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sxsx = torch.zeros((samples.size()[0], length_x, length_y))\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            for d in [[1,0], [0,1]]:\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                sxsx[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases)))\n",
    "    return torch.mean(sxsx, axis=0)*1/4\n",
    "\n",
    "def get_sysy(samples, log_probs, phases, boundaries):\n",
    "    Nx, Ny, length_x, length_y = get_length(samples)\n",
    "    sysy = torch.zeros((samples.size()[0], length_x, length_y))\n",
    "    for i in range(length_x):\n",
    "        for j in range(length_y):\n",
    "            for d in [[1,0], [0,1]]:\n",
    "                s1 = flip_neighbor_spins(samples, i, j, d, Nx, Ny)\n",
    "                log_probs1, phases1 = model.log_probabilities(s1)\n",
    "                s1 = s1.to(torch.complex64)\n",
    "                s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "                s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 1] = -1j\n",
    "                s1[:,(i+d[0])%Nx,(j+d[1])%Ny][s1[:,(i+d[0])%Nx,(j+d[1])%Ny] == 0] = 1j\n",
    "                sysy[:,i,j] += torch.real(torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]*s1[:,(i+d[0])%Nx,(j+d[0])%Ny])\n",
    "    return torch.mean(sysy, axis=0)*1/4\n",
    "\n",
    "def get_sz_(samples):\n",
    "    # used in the cost function, no averaging here!\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.sum(sz, axis=2), axis=1) *1/2 \n",
    "\n",
    "def get_sz(samples):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sz = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    s = samples.clone().detach() \n",
    "    s[samples == 0] = -1\n",
    "    sz = s.to(torch.float64)\n",
    "    return torch.sum(torch.mean(sz, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sx(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sx = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            sx[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))\n",
    "    return torch.sum(torch.mean(sx, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "def get_sy(samples, log_probs, phases):\n",
    "    Nx = samples.size()[1]\n",
    "    Ny = samples.size()[2]\n",
    "    sy = torch.zeros((samples.size()[0], Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            s1 = flip_spin(samples, i,j)\n",
    "            log_probs1, phases1 = model.log_probabilities(s1)\n",
    "            s1 = s1.to(torch.complex64)\n",
    "            s1[:,i,j][s1[:,i,j] == 1] = -1j\n",
    "            s1[:,i,j][s1[:,i,j] == 0] = 1j\n",
    "            sy[:,i,j] = torch.exp(0.5*(log_probs1-log_probs))*torch.exp(1j*(phases1-phases))*s1[:,i,j]\n",
    "    return torch.sum(torch.mean(sy, axis=0)*1/2) / (Nx*Ny)\n",
    "\n",
    "\n",
    "def flip_neighbor_spins(samples, i,j, direction, Nx, Ny):\n",
    "    s = samples.clone().detach()\n",
    "    N = s.size()[1]\n",
    "    s[:,i,j][samples[:,i,j] == 0]   = 1\n",
    "    s[:,i,j][samples[:,i,j] == 1]   = 0\n",
    "    s[:,(i+direction[0])%Nx,(j+direction[1])%Ny][samples[:,(i+direction[0])%Nx,(j+direction[1])%Ny] == 0] = 1\n",
    "    s[:,(i+direction[0])%Nx,(j+direction[1])%Ny][samples[:,(i+direction[0])%Nx,(j+direction[1])%Ny] == 1] = 0\n",
    "    return s\n",
    "\n",
    "def flip_spin(samples, i,j):\n",
    "    s = samples.clone().detach()\n",
    "    s[:,i,j][samples[:,i,j] == 0] = 1\n",
    "    s[:,i,j][samples[:,i,j] == 1] = 0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02f579eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3000............. Loss: -0.02638908, mean(E): 4.42814159-0.02440443j, var(E): 0.48367098, Sx: 0.2016, Sy: -0.0412, Sz: 0.0706\n",
      "Epoch: 10/3000............. Loss: -2.48190373, mean(E): -1.60675430+0.01123549j, var(E): 4.36623240, Sx: -0.0215, Sy: 0.0085, Sz: -0.0216\n",
      "Epoch: 20/3000............. Loss: -2.15646090, mean(E): -4.88775921-0.02380471j, var(E): 2.98553753, Sx: 0.0054, Sy: 0.0126, Sz: 0.0069\n",
      "Epoch: 30/3000............. Loss: -0.98382990, mean(E): -5.43676949+0.01438079j, var(E): 0.56575602, Sx: 0.0118, Sy: 0.0281, Sz: 0.0000\n",
      "Epoch: 40/3000............. Loss: -0.28635922, mean(E): -5.80788994+0.00139284j, var(E): 0.35168815, Sx: 0.0004, Sy: -0.0001, Sz: -0.0059\n",
      "Epoch: 50/3000............. Loss: 0.20062722, mean(E): -5.83531189-0.00301035j, var(E): 0.28871056, Sx: -0.0024, Sy: -0.0012, Sz: -0.0044\n",
      "Epoch: 60/3000............. Loss: 0.01855647, mean(E): -5.86335611-0.00344591j, var(E): 0.28627756, Sx: -0.0009, Sy: -0.0034, Sz: 0.0028\n",
      "Epoch: 70/3000............. Loss: 0.19335628, mean(E): -5.98989487+0.00472823j, var(E): 0.30685928, Sx: 0.0017, Sy: -0.0025, Sz: -0.0016\n",
      "Epoch: 80/3000............. Loss: -0.09607826, mean(E): -5.96374655-0.00046308j, var(E): 0.06928475, Sx: 0.0020, Sy: -0.0022, Sz: -0.0009\n",
      "Epoch: 90/3000............. Loss: 0.34051756, mean(E): -5.98024750+0.01404949j, var(E): 0.38394636, Sx: 0.0056, Sy: -0.0049, Sz: 0.0012\n",
      "Epoch: 100/3000............. Loss: -0.11079568, mean(E): -5.99023342+0.00145161j, var(E): 0.21011409, Sx: 0.0034, Sy: -0.0084, Sz: -0.0009\n",
      "Epoch: 110/3000............. Loss: -0.00342040, mean(E): -6.03014755-0.00161690j, var(E): 0.33196291, Sx: -0.0013, Sy: -0.0087, Sz: 0.0013\n",
      "Epoch: 120/3000............. Loss: -0.15926707, mean(E): -5.97774315+0.00389762j, var(E): 0.06255767, Sx: -0.0036, Sy: -0.0104, Sz: 0.0022\n",
      "Epoch: 130/3000............. Loss: 0.43706808, mean(E): -6.08883429+0.00554799j, var(E): 0.31756279, Sx: -0.0002, Sy: -0.0066, Sz: -0.0019\n",
      "Epoch: 140/3000............. Loss: -0.12705161, mean(E): -6.00840950+0.00597545j, var(E): 0.15627681, Sx: -0.0027, Sy: -0.0105, Sz: -0.0022\n",
      "Epoch: 150/3000............. Loss: 0.24196373, mean(E): -6.09709120+0.00280408j, var(E): 0.21058939, Sx: -0.0005, Sy: -0.0064, Sz: -0.0016\n",
      "Epoch: 160/3000............. Loss: 0.19102021, mean(E): -6.09094667+0.00578311j, var(E): 0.16779095, Sx: -0.0021, Sy: -0.0080, Sz: -0.0003\n",
      "Epoch: 170/3000............. Loss: -0.20756530, mean(E): -6.11396503-0.00807037j, var(E): 0.10177516, Sx: 0.0002, Sy: -0.0084, Sz: -0.0022\n",
      "Epoch: 180/3000............. Loss: -0.08308764, mean(E): -6.08035040+0.00553771j, var(E): 0.10115651, Sx: -0.0083, Sy: -0.0103, Sz: -0.0022\n",
      "Epoch: 190/3000............. Loss: -0.19949087, mean(E): -6.09648561+0.00870204j, var(E): 0.08235252, Sx: -0.0092, Sy: -0.0076, Sz: 0.0006\n",
      "Epoch: 200/3000............. Loss: -0.33601558, mean(E): -6.14649534+0.01772015j, var(E): 0.05726954, Sx: -0.0133, Sy: 0.0153, Sz: -0.0006\n",
      "Epoch: 210/3000............. Loss: -0.11351010, mean(E): -6.16887474-0.00176727j, var(E): 0.04408469, Sx: -0.0059, Sy: -0.0057, Sz: -0.0012\n",
      "Epoch: 220/3000............. Loss: -0.06878012, mean(E): -6.21793032+0.00567362j, var(E): 0.15451387, Sx: -0.0036, Sy: -0.0053, Sz: 0.0006\n",
      "Epoch: 230/3000............. Loss: 0.02738008, mean(E): -6.20896816-0.00229988j, var(E): 0.05455574, Sx: -0.0038, Sy: -0.0032, Sz: -0.0006\n",
      "Epoch: 240/3000............. Loss: -0.02711249, mean(E): -6.22576475-0.00127840j, var(E): 0.02772340, Sx: -0.0020, Sy: -0.0027, Sz: 0.0003\n",
      "Epoch: 250/3000............. Loss: -0.00642449, mean(E): -6.22398615+0.00290629j, var(E): 0.07169854, Sx: -0.0019, Sy: -0.0025, Sz: 0.0003\n",
      "Epoch: 260/3000............. Loss: -0.08324393, mean(E): -6.23836565-0.00077322j, var(E): 0.03557710, Sx: -0.0033, Sy: -0.0032, Sz: -0.0006\n",
      "Epoch: 270/3000............. Loss: -0.04830554, mean(E): -6.24422169-0.00172304j, var(E): 0.01767009, Sx: 0.0007, Sy: -0.0024, Sz: 0.0003\n",
      "Epoch: 280/3000............. Loss: 0.45624995, mean(E): -6.23315191+0.00079042j, var(E): 0.03840342, Sx: 0.0025, Sy: -0.0037, Sz: 0.0006\n",
      "Epoch: 290/3000............. Loss: 0.25273594, mean(E): -6.25792217-0.00269760j, var(E): 0.02760679, Sx: -0.0007, Sy: -0.0008, Sz: 0.0000\n",
      "Epoch: 300/3000............. Loss: -4.70647647, mean(E): -6.04553938+0.20594428j, var(E): 18.11021423, Sx: -0.0006, Sy: -0.0006, Sz: -0.0000\n",
      "Epoch: 310/3000............. Loss: -0.85195915, mean(E): -6.20432281-0.00111054j, var(E): 0.14508149, Sx: 0.0005, Sy: -0.0010, Sz: 0.0000\n",
      "Epoch: 320/3000............. Loss: 0.26105423, mean(E): -6.25261354+0.00548060j, var(E): 0.03178412, Sx: -0.0017, Sy: -0.0028, Sz: -0.0003\n",
      "Epoch: 330/3000............. Loss: 0.28266371, mean(E): -6.24118233-0.00244791j, var(E): 0.00591357, Sx: 0.0003, Sy: -0.0005, Sz: 0.0000\n",
      "Epoch: 340/3000............. Loss: 0.03748031, mean(E): -6.25446081-0.00204063j, var(E): 0.00923699, Sx: 0.0002, Sy: -0.0004, Sz: -0.0000\n",
      "Epoch: 350/3000............. Loss: -0.05036709, mean(E): -6.24579096+0.00310185j, var(E): 0.00206138, Sx: 0.0002, Sy: -0.0005, Sz: -0.0000\n",
      "Epoch: 360/3000............. Loss: -0.01798991, mean(E): -6.24959326+0.00186310j, var(E): 0.00165729, Sx: 0.0001, Sy: -0.0005, Sz: 0.0000\n",
      "Epoch: 370/3000............. Loss: -0.00508925, mean(E): -6.25016689+0.00146931j, var(E): 0.00059527, Sx: 0.0001, Sy: -0.0004, Sz: 0.0000\n",
      "Epoch: 380/3000............. Loss: 0.01180640, mean(E): -6.25438690-0.00014446j, var(E): 0.00106946, Sx: 0.0001, Sy: -0.0005, Sz: 0.0000\n",
      "Epoch: 390/3000............. Loss: -0.35356209, mean(E): -6.25248337-0.00660194j, var(E): 0.00356048, Sx: 0.0002, Sy: -0.0005, Sz: 0.0000\n",
      "Epoch: 400/3000............. Loss: -0.10723592, mean(E): -6.24835491-0.00008596j, var(E): 0.02169413, Sx: 0.0014, Sy: -0.0045, Sz: -0.0003\n",
      "Epoch: 410/3000............. Loss: 0.06572399, mean(E): -6.25457764+0.00041582j, var(E): 0.00109770, Sx: 0.0001, Sy: -0.0003, Sz: 0.0000\n",
      "Epoch: 420/3000............. Loss: -0.20113188, mean(E): -6.23325968-0.00067785j, var(E): 0.07095952, Sx: 0.0001, Sy: -0.0003, Sz: 0.0006\n",
      "Epoch: 430/3000............. Loss: 0.01564692, mean(E): -6.25241852+0.00005019j, var(E): 0.00077409, Sx: 0.0001, Sy: -0.0003, Sz: 0.0000\n",
      "Epoch: 440/3000............. Loss: 0.00748581, mean(E): -6.25341797-0.00005507j, var(E): 0.00030683, Sx: 0.0002, Sy: -0.0003, Sz: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/664810285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Clears existing gradients from previous epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mEloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz_tot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does backpropagation and calculates gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Updates the weights accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/3412640866.py\u001b[0m in \u001b[0;36mcost_fct\u001b[0;34m(samples, model, Jp, Jz, log_probs, phases, boundaries, sz_tot)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz_tot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mEloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXXZ2D_Eloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlog_psi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0meloc_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/1918376898.py\u001b[0m in \u001b[0;36mXXZ2D_Eloc\u001b[0;34m(Jp, Jz, samples, RNN, boundaries)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mqueue_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mqueue_samples_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_samples_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mlog_probs_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlength_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mphases_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlength_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/962338838.py\u001b[0m in \u001b[0;36mlog_probabilities\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_x\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                     \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mampl_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0mohs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/962338838.py\u001b[0m in \u001b[0;36m_gen_probs\u001b[0;34m(self, nx, ny, direction, sample, inputs, hidden_inputs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mfull_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mhidden\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;31m# the amplitude is given by a linear layer with a softmax activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mampl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/962338838.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Passing in the input and hidden state into the model and obtaining outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Reshaping the outputs such that it can be fit into the dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/962338838.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# prepare input linear combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mstate_mul1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijk,ljk->il'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputstate_mul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_sz, num_units]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mstate_mul2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijk,ljk->il'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputstate_mul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_sz, num_units]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_mul2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 200\n",
    "Elocs = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    samples, log_probs, phases = model.sample(n_samples)\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    \n",
    "    Eloc, cost = cost_fct(samples, model, Jp, Jz, log_probs, phases, bounds, sz_tot=None)\n",
    "    cost.backward(retain_graph=True) # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    optimizer.zero_grad()\n",
    "    sx = get_sx(samples, log_probs, phases)\n",
    "    sy = get_sy(samples, log_probs, phases)\n",
    "    sz = get_sz(samples)\n",
    "    Elocs = (Eloc).mean(axis=0)\n",
    "    if epoch%10 == 0 or epoch == 1:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.8f}\".format(cost)+\", mean(E): {:.8f}\".format((Eloc).mean(axis=0))+\", var(E): {:.8f}\".format((Eloc).var(axis=0))+\", Sx: {:.4f}\".format(sx)+\", Sy: {:.4f}\".format(sy)+\", Sz: {:.4f}\".format(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5399d598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0],\n",
      "         [1, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0]],\n",
      "\n",
      "        [[1, 0, 1, 0],\n",
      "         [0, 1, 0, 1],\n",
      "         [1, 0, 1, 0],\n",
      "         [0, 1, 0, 1]]])\n",
      "max\n",
      "tensor([[1, 0, 1, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 1, 0, 1]])\n",
      "0.6854771791257822\n",
      "min\n",
      "tensor([[0, 1, 0, 1],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 0, 1, 0]])\n",
      "0.0025263580706203492\n"
     ]
    }
   ],
   "source": [
    "samples, log_probs, phases = model.sample(10000)\n",
    "print(torch.reshape(samples, (10000,Nx, Ny))[:10])\n",
    "#print(log_probs[:50])\n",
    "#print(torch.exp(0.5*log_probs)[:50]*torch.exp(1j*phases)[:50])\n",
    "print(\"max\")\n",
    "print(samples[np.argmax(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(max(torch.exp(0.5*log_probs).detach().numpy()))\n",
    "print(\"min\")\n",
    "print(samples[np.argmin(torch.exp(0.5*log_probs).detach().numpy())])\n",
    "print(min(torch.exp(0.5*log_probs).detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181edff",
   "metadata": {},
   "source": [
    "### 3. Evaluate Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53af738",
   "metadata": {},
   "source": [
    "This is what we can test:\n",
    "- For the Heisenberg model:The average magnetization in all directions should vanish.\n",
    "- The correlator in all directions should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae440a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4350, -0.5000, -0.5000],\n",
      "        [-0.3960, -0.5000, -0.5000],\n",
      "        [-0.4480, -0.5000, -0.5000]])\n",
      "tensor([[-1.3036e-01,  2.3703e-19,  5.0937e-35],\n",
      "        [-1.0723e-01,  4.3039e-06,  3.6025e-14],\n",
      "        [-3.0751e-04, -1.3146e-08,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "tensor([[-1.9814e-04, -2.3703e-19,  0.0000e+00],\n",
      "        [ 9.7889e-04,  1.3668e-25, -1.4199e-14],\n",
      "        [ 7.4662e-05, -1.5608e-07,  0.0000e+00]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate the nearest neighbor spin correlators\n",
    "samples, log_probs, phases = model.sample(1000)\n",
    "szsz = get_szsz(samples, log_probs, bounds)\n",
    "print(szsz)\n",
    "sxsx = get_sxsx(samples, log_probs, phases, bounds)\n",
    "print(sxsx)\n",
    "sysy = get_sysy(samples, log_probs, phases, bounds)\n",
    "print(sysy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0cf907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0008, dtype=torch.float64)\n",
      "tensor(-0.0034, grad_fn=<DivBackward0>)\n",
      "tensor(0.0033, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate sx, sy and sz\n",
    "sz = get_sz(samples)\n",
    "print(sz)\n",
    "sx = get_sx(samples, log_probs, phases)\n",
    "print(sx)\n",
    "sy = get_sy(samples, log_probs, phases)\n",
    "print(sy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3d95f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'with_total_sz=0/Delta=0/model_params.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/1612693109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"sysy.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msysy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with_total_sz=0/Delta=0/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_9277/1612693109.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, boundaries, folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"model_params.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# calculate the nearest neighbor spin correlators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mszsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_szsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'with_total_sz=0/Delta=0/model_params.pt'"
     ]
    }
   ],
   "source": [
    "def save(model, boundaries, folder):\n",
    "    torch.save(model.state_dict(), folder+\"model_params.pt\")\n",
    "    # calculate the nearest neighbor spin correlators\n",
    "    samples, log_probs, phases = model.sample(1000)\n",
    "    szsz = get_szsz(samples, log_probs, boundaries).detach().numpy()\n",
    "    np.save(folder+\"szsz.npy\", szsz)\n",
    "    sxsx = get_sxsx(samples, log_probs, phases, boundaries).detach().numpy()\n",
    "    np.save(folder+\"sxsx.npy\", sxsx)\n",
    "    sysy = get_sysy(samples, log_probs, phases, boundaries).detach().numpy()\n",
    "    np.save(folder+\"sysy.npy\", sysy)\n",
    "\n",
    "save(model, bounds, \"with_total_sz=0/Delta=0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model can then be load again by using\n",
    "#model = Model(input_size=2, system_size=systemsize, hidden_dim=hiddendim, n_layers=1)\n",
    "#model.load_state_dict(torch.load(\"model_params.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba26767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
