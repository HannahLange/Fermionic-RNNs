{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1c5e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061fd75",
   "metadata": {},
   "source": [
    "### 1. Setup the Wavefunction architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "302d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNwavefunction(object):\n",
    "    def __init__(self,systemsize,cell=tf.compat.v1.nn.rnn_cell.GRUCell,activation=tf.nn.relu,units=[15]):\n",
    "        \"\"\" \n",
    "            RNN wave function architecture\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters:\n",
    "            \n",
    "            systemsize:  int, number of sites\n",
    "            cell:        a tensorflow RNN \n",
    "            units:       list of int, each entry defines the number of hidden units for each RNN building block        \n",
    "        \"\"\"\n",
    "        self.graph       = tf.Graph()\n",
    "        self.scope       = 'RNNwavefunction' #Label of our wavefunction\n",
    "        self.N           = systemsize\n",
    "        \n",
    "        with self.graph.as_default(): #everything inside will belong to self.graph\n",
    "            with tf.compat.v1.variable_scope(self.scope): #make sure that this will be asigned to \"RNNwavefunction\" \n",
    "                tf.compat.v1.set_random_seed(1234)\n",
    "                self.rnn = tf.compat.v1.nn.rnn_cell.MultiRNNCell([cell(units[n],activation=activation,name='GRU_{0}'.format(n)) for n in range(len(units))])\n",
    "                print(self.rnn)\n",
    "                # define the dense layer\n",
    "                self.dense = tf.compat.v1.layers.Dense(2,activation=tf.nn.softmax,name='wf_dense')\n",
    "                \n",
    "    def sample(self,numsamples,inputdim):\n",
    "        \"\"\"\n",
    "            generate samples from a probability distribution parametrized by a recurrent network\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            numsamples:      int, number of samples to be produced\n",
    "            inputdim:        int, hilbert space dimension\n",
    "    \n",
    "            ------------------------------------------------------------------------\n",
    "            Returns:         a tuple (samples,log-probs)\n",
    "             \n",
    "            samples:         tf.Tensor of shape (numsamples,systemsize), the samples in integer encoding \n",
    "        \"\"\" \n",
    "        self.inputdim   = inputdim\n",
    "        self.numsamples = numsamples\n",
    "        self.outputdim  = inputdim\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            with tf.compat.v1.variable_scope(self.scope):\n",
    "                samples = []\n",
    "                one_hot_samples = []\n",
    "                probs = []\n",
    "                # define inputs for the RNN \n",
    "                inputs     = np.zeros((self.numsamples,self.inputdim))\n",
    "                inputs     = tf.constant(dtype=tf.float32,value=inputs,shape=[self.numsamples,self.inputdim])\n",
    "                # initialize the states tensors with zero (first hidden states)\n",
    "                rnn_state  = self.rnn.zero_state(self.numsamples,dtype=tf.float32)\n",
    "                \n",
    "                for n in range(0,self.N):\n",
    "                    #compute the next hidden state of the RNN\n",
    "                    rnn_output, rnn_state = self.rnn(inputs, rnn_state)\n",
    "                    print(rnn_output)\n",
    "                    #apply the Softmax layer\n",
    "                    output = self.dense(rnn_output)\n",
    "                    probs.append(output)\n",
    "                    #sample from the probability\n",
    "                    temp   = tf.reshape(tf.random.categorical(tf.compat.v1.log(output),num_samples=1),[-1,]) \n",
    "                    samples.append(temp)\n",
    "                    inputs = tf.one_hot(temp,depth=self.outputdim)\n",
    "                    one_hot_samples.append(inputs)\n",
    "\n",
    "            self.samples    = tf.stack(values=samples,axis=1)\n",
    "            temp            = tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "            one_hot_samples = tf.transpose(tf.stack(values=one_hot_samples,axis=2),perm=[0,2,1])\n",
    "            self.log_probs  = tf.reduce_sum(tf.compat.v1.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)            \n",
    "            print(self.log_probs)\n",
    "            return self.samples, self.log_probs\n",
    "        \n",
    "        \n",
    "    \n",
    "    def log_probability(self,samples,inputdim):\n",
    "        \"\"\"\n",
    "            calculate the log-probabilities of samples\n",
    "            ------------------------------------------------------------------------\n",
    "            Parameters: \n",
    "            \n",
    "            samples:         tf.Tensor, a tf.placeholder of shape (number of samples,system-size) \n",
    "                             containing the input samples in integer encoding\n",
    "            inputdim:        int, dimension of the input space\n",
    "                      \n",
    "            ------------------------------------------------------------------------         \n",
    "            Returns: \n",
    "            log-probs        tf.Tensor of shape (number of samples,), the log-probability of each sample         \n",
    "            \"\"\"\n",
    "        \n",
    "        self.inputdim   = inputdim\n",
    "        self.outputim   = inputdim\n",
    "        self.numsamples = numsamples\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "\n",
    "            with tf.compat.v1.variable_scope(self.scope):         \n",
    "                probs      = []\n",
    "                \n",
    "                # define inputs for the RNN \n",
    "                inputs     = np.zeros((self.numsamples,self.inputdim)).astype(np.float32)\n",
    "                inputs     = tf.constant(dtype=tf.float32,value=inputs,shape=[self.numsamples,self.inputdim])\n",
    "                # initialize the states tensors with zero (first hidden states)\n",
    "                rnn_state  = self.rnn.zero_state(self.numsamples,dtype=tf.float32)\n",
    "                \n",
    "                for n in range(0,self.N):\n",
    "                    #compute the next hidden state of the RNN\n",
    "                    rnn_output, rnn_state = self.rnn(inputs, rnn_state)\n",
    "                    #apply the Softmax layer\n",
    "                    output = self.dense(rnn_output)\n",
    "                    #sample from the probability\n",
    "                    probs.append(output)\n",
    "                    inputs = tf.reshape(tf.one_hot(tf.reshape(tf.slice(samples,begin=[np.int32(0),np.int32(n)],size=[np.int32(-1),np.int32(1)]),shape=[self.numsamples]),depth=self.outputdim),shape=[self.numsamples,self.inputdim])\n",
    "        \n",
    "\n",
    "            temp            = tf.transpose(tf.stack(values=probs,axis=2),perm=[0,2,1])\n",
    "            one_hot_samples = tf.one_hot(samples,depth=self.inputdim)\n",
    "            self.log_probs  = tf.reduce_sum(tf.compat.v1.log(tf.reduce_sum(tf.multiply(temp,one_hot_samples),axis=2)),axis=1)            \n",
    "            \n",
    "            return self.log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79a775",
   "metadata": {},
   "source": [
    "#### Initialization and first tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b33acaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f9821fb3450>\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_1:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_2:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_3:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_4:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_5:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_6:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_7:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_8:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"RNNwavefunction_1/RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/add_9:0\", shape=(5, 15), dtype=float32)\n",
      "Tensor(\"Sum_1:0\", shape=(5,), dtype=float32)\n",
      "(<tf.Tensor 'stack:0' shape=(5, 10) dtype=int64>, <tf.Tensor 'Sum_1:0' shape=(5,) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "units=[15] #list containing the number of hidden units for each layer of the networks\n",
    "\n",
    "N          = 10\n",
    "input_dim  = 2\n",
    "numsamples = 5 #only for initialization; later I'll use a much larger value (see below)\n",
    "\n",
    "\n",
    "wf         = RNNwavefunction(N,units=units) #contains the graph with the RNNs\n",
    "samples    = wf.sample(numsamples,input_dim) #call this function once to create the dense layers\n",
    "print(samples)\n",
    "with wf.graph.as_default(): #now initialize everything \n",
    "    #placeholder for inputs and learning rate\n",
    "    inputs       = tf.compat.v1.placeholder(dtype=tf.int32,shape=[numsamples,N]) \n",
    "    learningrate = tf.compat.v1.placeholder(dtype=tf.float32,shape=[])\n",
    "    probs        = wf.log_probability(inputs,input_dim)\n",
    "    optimizer    = tf.compat.v1.train.AdamOptimizer(learning_rate=learningrate)\n",
    "    init         = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c444ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 0 1 0 0 1 0 0]\n",
      " [0 0 0 1 1 1 1 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 1 1]]\n",
      "[-7.2338486 -6.595579  -6.75748   -7.067438  -7.1174088]\n"
     ]
    }
   ],
   "source": [
    "#Start the session\n",
    "sess = tf.compat.v1.Session(graph=wf.graph)\n",
    "sess.run(init)\n",
    "generated_samples, generated_probs = sess.run(samples)  \n",
    "print(generated_samples)\n",
    "print(generated_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6113fca",
   "metadata": {},
   "source": [
    "#### Parameters of the RNN wave function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51b9c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/gates/kernel:0\n",
      "RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/gates/bias:0\n",
      "RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/candidate/kernel:0\n",
      "RNNwavefunction/multi_rnn_cell/cell_0/GRU_0/candidate/bias:0\n",
      "RNNwavefunction/wf_dense/kernel:0\n",
      "RNNwavefunction/wf_dense/bias:0\n",
      "The number of variational parameters of the pRNN wavefunction is 870\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count the number of parameters\n",
    "with wf.graph.as_default():\n",
    "    variables_names = [v.name for v in tf.compat.v1.trainable_variables()]\n",
    "    sum = 0\n",
    "    for v in variables_names:\n",
    "        print(v)\n",
    "        value = sess.run(v)\n",
    "        sum += len(value)\n",
    "    print('The number of variational parameters of the pRNN wavefunction is {0}'.format(sum))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b22cc",
   "metadata": {},
   "source": [
    "### 2. Calculate the matrix elements (here 1D TFIM)\n",
    "\n",
    "$$ E_{\\theta}^{loc}(x) = \\frac{<x|H|\\psi_\\theta>}{<x|\\psi_\\theta>} = H_{diag}(x)+H_{offd}(x)\\frac{<x^{\\prime}|\\psi_\\theta>}{<x|\\psi_\\theta>} $$\n",
    "with $\\hat{H}_{offd}|x^{\\prime}>=H_{offd}(x)|x^{\\prime}>$ and ${<x|\\psi_\\theta>}$ given by the square root of the exponential of rnn.log_probability(x) defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99a7ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XXZ1D_MatrixElements(Jp, Jz, samples):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    \"\"\"\n",
    "    \n",
    "    N = samples.shape[1]\n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_matrixelements = np.zeros((numsamples), dtype = np.float64)\n",
    "    for i in range(N): #diagonal elements from the SzSz term\n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = np.copy(values)\n",
    "        valuesT[values==2] = +1 #If both spins are up\n",
    "        valuesT[values==0] = +1 #If both spins are down\n",
    "        valuesT[values==1] = -1 #If they are opposite\n",
    "\n",
    "        diag_matrixelements += valuesT*Jz*0.25\n",
    "    \n",
    "    #off-diagonal elements\n",
    "    offd_matrixelements = np.zeros((numsamples), dtype = np.float64)\n",
    "    for i in range(N): \n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = np.copy(values)\n",
    "        #flip the spins\n",
    "        new_samples = samples.copy()\n",
    "        new_samples[:,i+1] = samples[:,i]\n",
    "        new_samples[:,i]   = samples[:,i+1]\n",
    "        valuesT[values==2] = 0 #If both spins are up\n",
    "        valuesT[values==0] = 0 #If both spins are down\n",
    "        valuesT[values==1] = 1 #If they are opposite\n",
    "\n",
    "        offd_matrixelements += valuesT*Jp*0.5\n",
    "    return matrixelements\n",
    "\n",
    "def XXZ1D_Eloc(Jp, Jz, samples, RNN):\n",
    "    \"\"\" \n",
    "    Calculate the local energies of 1D XXZ model given a set of set of samples.\n",
    "    Returns: The local energies that correspond to the input samples.\n",
    "    Inputs:\n",
    "    - sample: (num_samples, N)\n",
    "    - Jp: float\n",
    "    - Jz: float\n",
    "    \"\"\"\n",
    "    N          = samples.shape[1]\n",
    "    numsamples = samples.shape[0]\n",
    "    with RNN.graph.as_default():\n",
    "        samples_placeholder = tf.compat.v1.placeholder(dtype=tf.int32,shape=(None,N))\n",
    "        log_probs_tensor    = wf.log_probability(samples_placeholder,inputdim=2)\n",
    "\n",
    "    queue_samples       = np.zeros((N+1, numsamples, N), dtype = np.int32) \n",
    "    log_probs           = np.zeros((N+1)*numsamples, dtype=np.float64) \n",
    "    \n",
    "    #diagonal elements\n",
    "    diag_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "    for i in range(N): #diagonal elements from the SzSz term\n",
    "        values             = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT            = np.copy(values)\n",
    "        valuesT[values==2] = +1 #If both spins are up\n",
    "        valuesT[values==0] = +1 #If both spins are down\n",
    "        valuesT[values==1] = -1 #If they are opposite\n",
    "\n",
    "        diag_matrixelements = valuesT*Jz*0.25\n",
    "        Eloc = diag_matrixelements\n",
    "    queue_samples[0] = samples\n",
    "    \n",
    "    #off-diagonal elements\n",
    "    offd_Eloc = np.zeros((numsamples), dtype = np.float64)\n",
    "    for i in range(N): \n",
    "        values = samples[:,i]+samples[:,(i+1)%N]\n",
    "        valuesT = np.copy(values)\n",
    "        #flip the spins\n",
    "        new_samples = samples.copy()\n",
    "        new_samples[:,(i+1)%N] = samples[:,i]\n",
    "        new_samples[:,i]   = samples[:,(i+1)%N]\n",
    "        valuesT[values==2] = 0 #If both spins are up\n",
    "        valuesT[values==0] = 0 #If both spins are down\n",
    "        valuesT[values==1] = 1 #If they are opposite\n",
    "\n",
    "        offd_matrixelements = valuesT*Jp*0.5\n",
    "        queue_samples[i+1] = new_samples\n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(N+1)*numsamples, N])\n",
    "    log_probs = sess.run(log_probs_tensor)\n",
    "    log_probs_reshaped = np.reshape(log_probs, [N+1,numsamples])\n",
    "    Eloc += offd_matrixelements.dot(np.exp(0.5*log_probs_reshaped[1:,:]-0.5*log_probs_reshaped[0,:]))\n",
    "    \n",
    "    return Eloc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "66ce25ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[0, 0, 1, ..., 0, 1, 1],\n       [0, 0, 0, ..., 1, 0, 0],\n       [0, 1, 1, ..., 0, 1, 1],\n       ...,\n       [1, 1, 1, ..., 0, 1, 0],\n       [1, 0, 0, ..., 1, 1, 0],\n       [0, 1, 0, ..., 0, 0, 0]], dtype=int32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3610\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3698\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[0;32m-> 3699\u001b[0;31m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   3700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_911/3097000269.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXXZ1D_Eloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kj/w16m6_q14ln6kd7tkfk1s0780000gp/T/ipykernel_911/1649025779.py\u001b[0m in \u001b[0;36mXXZ1D_Eloc\u001b[0;34m(Jp, Jz, samples, RNN)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mqueue_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mqueue_samples_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_samples_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mlog_probs_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mEloc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moffd_matrixelements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_probs_reshaped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_probs_reshaped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1165\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \"\"\"\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML_environment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    308\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    310\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[0, 0, 1, ..., 0, 1, 1],\n       [0, 0, 0, ..., 1, 0, 0],\n       [0, 1, 1, ..., 0, 1, 1],\n       ...,\n       [1, 1, 1, ..., 0, 1, 0],\n       [1, 0, 0, ..., 1, 1, 0],\n       [0, 1, 0, ..., 0, 0, 0]], dtype=int32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "XXZ1D_Eloc(1, 0, generated_samples, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76fc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
