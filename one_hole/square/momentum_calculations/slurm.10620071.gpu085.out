1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, U=1.0, t=1.0, density=0.9375, Nx=4, Ny=4, kx=0.5, ky=0.0, bounds=1, boundsx=0, boundsy=0, load_model=1, sym=0.0, antisym=0.0, hd=70)
4 4 0.9375 15
4x4_qubits/periodic/Jp=1.0Jz=1.0t=1.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
check if ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=1.0den=0.94/model_params_h=70_no_antisym.pt exists.
load ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=1.0den=0.94/model_params_h=70_no_antisym.pt
0.38738890003699744
tensor(0.0917, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 1/ 1000/ t/epoch=1.63............. Loss: -0.30596507, mean(E): -18.39791287-0.02886361j, var(E): 0.21545661, Px: -0.49822359-0.31795320j, Py: 0.48661944-0.24592683j
0.7679877704607115
tensor(0.1906, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.1420305438263911
tensor(0.2785, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.5097392678375618
tensor(0.3739, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.8713248970311833
tensor(0.4435, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.226988019620549
tensor(0.5376, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.5769195257663693
tensor(0.6139, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.9213012228502677
tensor(0.7711, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.260306402715595
tensor(0.7962, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.594100365306269
tensor(0.8313, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 10/ 1000/ t/epoch=0.58............. Loss: 1.21214202, mean(E): -18.43150810-0.01232757j, var(E): 0.18836041, Px: 0.47984939-0.45012444j, Py: 0.48051296-0.26537928j
3.9228409026646283
tensor(0.9564, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.246678746835807
tensor(1.0301, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.565757984861144
tensor(1.1422, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.880216443720544
tensor(1.1642, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.190186047797844
tensor(1.1296, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.495793151189666
tensor(1.3411, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.797158846952756
tensor(1.4660, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.094399255184058
tensor(1.4868, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.387625791648664
tensor(1.5314, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.676945418510874
tensor(1.6280, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 20/ 1000/ t/epoch=0.58............. Loss: 1.04518790, mean(E): -18.43778050+0.01650547j, var(E): 0.21262438, Px: -0.48990032-0.22050583j, Py: 0.49368617-0.22358861j
6.962460878580353
tensor(0.6666, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.244270914357112
tensor(2.2793, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.522470473044028
tensor(1.8126, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.797150898591837
tensor(2.1152, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.068400111748744
tensor(1.9778, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.336302779002585
tensor(2.0742, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.600940471227823
tensor(1.8110, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.862391812781173
tensor(2.1835, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.1207326217277
tensor(2.1733, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.376036041823156
tensor(2.2884, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 30/ 1000/ t/epoch=0.58............. Loss: 2.21087156, mean(E): -18.38886417+0.03375651j, var(E): 0.29083502, Px: -0.47290306-0.32669293j, Py: 0.49328519-0.26861649j
9.628372666827284
tensor(2.1095, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.877810657676827
tensor(1.9592, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.124415853004676
tensor(2.2183, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.368251873453593
tensor(2.5015, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.60938022019789
tensor(3.1632, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.847860368054851
tensor(2.4693, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.08374985353844
tensor(2.1773, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.317104358181536
tensor(2.5944, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.547977787428454
tensor(2.4682, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.776422345377446
tensor(2.8378, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 40/ 1000/ t/epoch=0.58............. Loss: 2.00499385, mean(E): -18.36848461-0.00673913j, var(E): 0.49168910, Px: 0.49326428-0.30349183j, Py: -0.49084146-0.26140556j
12.002488605632383
tensor(2.4869, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.226225578504188
tensor(2.4994, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.44768077478538
tensor(2.8559, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.66690026630532
tensor(3.0062, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.883928743459228
tensor(2.9035, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.09880956989063
tensor(2.3004, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.311584834494663
tensor(3.2275, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.522295400898127
tensor(2.9483, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.730980954561906
tensor(0.9602, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.937680047641447
tensor(3.4781, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 50/ 1000/ t/epoch=0.58............. Loss: 2.75972916, mean(E): -18.29356276-0.00700463j, var(E): 0.59562556, Px: -0.45906107-0.44621085j, Py: -0.49786398-0.32008191j
14.142430141732243
tensor(3.4603, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.345267648618742
tensor(2.1126, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.546227969137712
tensor(3.0311, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.745345530259621
tensor(2.3459, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.942653820485333
tensor(3.1292, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.138185423649087
tensor(2.5224, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.33197205121308
tensor(1.7400, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.524044573133757
tensor(2.0154, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.71443304737489
tensor(1.9746, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.903166748138078
tensor(3.1751, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 60/ 1000/ t/epoch=0.58............. Loss: 0.45879120, mean(E): -18.18520901-0.00586078j, var(E): 0.81244576, Px: 0.48938467-0.42826512j, Py: 0.44670017-0.39163881j
16.09027419287695
tensor(1.4847, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.27578316815741
tensor(2.4522, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.459720754422552
tensor(3.4646, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.64211334971758
tensor(1.5494, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.822986692426475
tensor(3.9506, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.002365883069658
tensor(0.0640, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.18027540520859
tensor(2.5694, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.356739145500995
tensor(0.2011, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.531780412947718
tensor(0.8984, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.705421957370042
tensor(2.1542, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 70/ 1000/ t/epoch=0.58............. Loss: -0.46692828, mean(E): -18.09138642-0.07882151j, var(E): 1.24632624, Px: -0.36549204-0.38871903j, Py: -0.32183427-0.49876834j
17.87768598715408
tensor(1.7182, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.0485941862968
tensor(1.7466, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.21816773078654
tensor(2.1569, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.386427304348825
tensor(0.3894, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.553393113586814
tensor(1.3914, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.71908490254411
tensor(0.0919, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.883521966716156
tensor(0.9051, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.046723166535095
tensor(2.2164, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.208706940351668
tensor(3.8890, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.36949131693647
tensor(0.2346, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 80/ 1000/ t/epoch=0.59............. Loss: -2.84849923, mean(E): -18.04738885-0.11265405j, var(E): 1.18222746, Px: 0.49518612-0.29569944j, Py: 0.10996002-0.47266408j
19.529093927521764
tensor(0.6637, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.68753201740402
tensor(1.8314, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.844822457126188
tensor(0.1364, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.000981753257925
tensor(0.2710, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.1560260587909
tensor(0.3996, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.309971183165644
tensor(0.4508, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.462832601945486
tensor(0.4356, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.614625466152326
tensor(0.3209, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.765364611278375
tensor(0.0220, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.915064565987272
tensor(0.2928, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 90/ 1000/ t/epoch=0.59............. Loss: -2.65488328, mean(E): -17.79545062-0.16434121j, var(E): 2.34774384, Px: 0.40785840-0.31810156j, Py: -0.07423091-0.42430979j
21.063739560517327
tensor(0.0685, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.211403534798993
tensor(0.1610, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.358070146298278
tensor(0.4113, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.50375277759696
tensor(0.1711, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.648464543720287
tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.792218299222064
tensor(1.1511, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.935026645036814
tensor(0.2524, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.07690193510804
tensor(1.4799, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.217856282801378
tensor(0.0787, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.35790156711096
tensor(1.6461, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 100/ 1000/ t/epoch=0.59............. Loss: -2.50146777, mean(E): -17.76489887+0.03701811j, var(E): 2.44720965, Px: -0.42777452-0.36319647j, Py: 0.26155151-0.46209777j
22.497049438666885
tensor(0.0202, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.63531132555145
tensor(1.0076, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.772698438931407
tensor(0.5051, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.909221778513135
tensor(0.8724, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.04489213782739
tensor(0.0976, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.17972010935001
tensor(0.4197, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.313716089464602
tensor(0.4413, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.44689028327306
tensor(0.1656, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.57925270925948
tensor(1.8442, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.710813203812762
tensor(2.0938, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 110/ 1000/ t/epoch=0.59............. Loss: -1.88854597, mean(E): -17.89853216-0.06577251j, var(E): 1.59978023, Px: 0.20442909-0.47566276j, Py: 0.03069298-0.43411864j
23.841581425613036
tensor(0.0265, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.971566859886824
tensor(0.1347, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.100778822535585
tensor(0.1157, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.229226464142144
tensor(0.4638, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.356918773859324
tensor(0.2056, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.48386458318493
tensor(0.1176, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.610072569626983
tensor(0.0977, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.735551260263136
tensor(2.9640, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.860309035197727
tensor(0.1226, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.98435413092019
tensor(0.2085, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 120/ 1000/ t/epoch=0.59............. Loss: -2.23879549, mean(E): -17.85921360-0.04317040j, var(E): 1.65843043, Px: 0.43635279-0.35586820j, Py: -0.06553992-0.50426906j
25.107694643568035
tensor(0.0370, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.23033853209769
tensor(0.0756, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.352293621366286
tensor(0.2575, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.47356760512743
tensor(0.2400, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.59416804894372
tensor(0.1284, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.71410239301889
tensor(0.0471, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.833377954952148
tensor(0.2286, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.95200193241723
tensor(0.1749, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.069981405768782
tensor(0.2818, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.18732334057822
tensor(0.1623, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 130/ 1000/ t/epoch=0.6............. Loss: -0.92999149, mean(E): -17.89830405+0.06802375j, var(E): 2.02795010, Px: 0.44173869-0.29264555j, Py: 0.05293817-0.38382716j
26.304034590101498
tensor(0.8325, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.420121897680872
tensor(0.0336, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.53559189908285
tensor(0.2637, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.65045112477427
tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.764706002138528
tensor(5.5490, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.878362857633757
tensor(0.3117, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.99142791889491
tensor(0.0178, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.103907316781278
tensor(0.1643, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.215807087371363
tensor(0.1198, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.327133173906553
tensor(0.0808, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 140/ 1000/ t/epoch=0.59............. Loss: 1.30192270, mean(E): -17.95283327-0.06154546j, var(E): 1.56541108, Px: 0.44765634-0.31098687j, Py: 0.01477479-0.38067061j
27.437891428685212
tensor(0.1284, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.548087614908805
tensor(0.0264, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.65772740848127
tensor(0.1627, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.76681639976334
tensor(0.0334, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.875360095282897
tensor(0.1311, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.983363919402883
tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.090833215947875
tensor(0.0224, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.197773249790643
tensor(1.1866, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.304189208399794
tensor(0.3746, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.41008620334975
tensor(0.0429, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 150/ 1000/ t/epoch=0.6............. Loss: -1.27172482, mean(E): -17.92775073+0.04583667j, var(E): 2.00420510, Px: 0.46309721-0.39131278j, Py: -0.01223871-0.49393332j
28.515469271793993
tensor(0.1017, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.620343377902792
tensor(0.5203, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.72471341426638
tensor(6.6427, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.82858420326454
tensor(0.1552, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.93196049840362
tensor(0.0891, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.034846985621837
tensor(0.1256, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.137248284563853
tensor(0.1209, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.23916894982539
tensor(0.2625, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.340613472168798
tensor(0.1325, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.441586279710364
tensor(0.3972, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 160/ 1000/ t/epoch=0.6............. Loss: 0.78151130, mean(E): -18.02176936+0.03725199j, var(E): 1.83532318, Px: -0.48846399-0.22939619j, Py: 0.11557308-0.31526964j
29.542091739080135
tensor(0.0261, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.64213415655501
tensor(0.1878, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.7417177791659
tensor(0.0925, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.840846795779523
tensor(0.6547, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.939525338155754
tensor(0.8061, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.037757481980904
tensor(0.1153, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.135547247877874
tensor(0.0269, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.232898602393547
tensor(0.3717, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.32981545896426
tensor(0.3339, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.42630167885971
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 170/ 1000/ t/epoch=0.6............. Loss: 1.05579026, mean(E): -17.90016842-0.05638213j, var(E): 1.90884599, Px: 0.49986202-0.31131256j, Py: 0.00329272-0.38400735j
30.522361072106058
tensor(0.0078, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.61799739838872
tensor(0.0237, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.713214367935258
tensor(0.5964, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.80801564237915
tensor(0.1507, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.902404835604635
tensor(0.1344, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.996385514573404
tensor(0.0268, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.08996120013338
tensor(0.1530, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.183135367810234
tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.275911448581876
tensor(0.1563, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.368292829636633
tensor(0.1571, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 180/ 1000/ t/epoch=0.6............. Loss: 1.02416413, mean(E): -17.82116432+0.03160857j, var(E): 2.07894344, Px: 0.43986901-0.32079890j, Py: -0.03730072-0.37806084j
31.46028285511519
tensor(0.5752, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.551884826837018
tensor(0.6130, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.643102005011496
tensor(0.1759, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.73393760893411
tensor(0.2354, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.82439481766827
tensor(0.0185, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
31.914476770712845
tensor(0.0170, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.00418656865602
tensor(0.0795, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.09352727381564
tensor(0.1355, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.182501910866456
tensor(1.5664, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.27111346745459
tensor(0.0118, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 190/ 1000/ t/epoch=0.6............. Loss: 0.89318468, mean(E): -17.93128518-0.00867869j, var(E): 1.66080580, Px: 0.49659142-0.34983683j, Py: 0.01885028-0.35435800j
32.359364894799484
tensor(0.3791, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.447259108283625
tensor(0.0735, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.534798988030545
tensor(0.2327, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.62198737947101
tensor(0.0403, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.70882709389802
tensor(0.2611, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.795320909010755
tensor(1.3623, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.8814715694476
tensor(0.2556, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
32.96728178730885
tensor(0.0732, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.05275424266894
tensor(0.0709, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.1378915840787
tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 200/ 1000/ t/epoch=0.6............. Loss: 0.19688814, mean(E): -17.93931699-0.08818718j, var(E): 1.42891974, Px: -0.49469941-0.19828423j, Py: 0.00866769-0.35772207j
33.222696429057876
tensor(0.0118, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.30717136457792
tensor(0.2217, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.39131894753556
tensor(0.5240, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.47514170521716
tensor(0.1782, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.55864213575416
tensor(0.7116, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.641822708569855
tensor(0.1090, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.72468586481751
tensor(0.1254, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.80723401781031
tensor(1.5068, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.88946955344306
tensor(0.2397, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
33.97139483060594
tensor(0.6372, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 210/ 1000/ t/epoch=0.6............. Loss: 2.36082550, mean(E): -18.07888647+0.02060548j, var(E): 1.61972736, Px: -0.48716840-0.28205761j, Py: 0.13635369-0.33025417j
34.05301218159059
tensor(0.4279, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.134323912488405
tensor(0.0070, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.215332303581576
tensor(0.4374, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.29603960972677
tensor(0.1120, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.37644806073172
tensor(0.0170, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.45655986172489
tensor(0.3167, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.53637719351835
tensor(0.0430, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.61590221296393
tensor(0.6742, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.695137053303036
tensor(0.3215, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.77408382450987
tensor(0.0419, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 220/ 1000/ t/epoch=0.6............. Loss: 0.62527290, mean(E): -18.00059588-0.06890270j, var(E): 1.47342847, Px: 0.49722131-0.24172408j, Py: 0.03459850-0.35414958j
34.85274461362872
tensor(0.2016, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
34.931121485104896
tensor(0.1038, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.00921648110989
tensor(0.0850, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.087031621860625
tensor(0.4205, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.164568905933066
tensor(2.3373, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.24183031057019
tensor(0.0085, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.31881779198451
tensor(0.3057, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.3955332856553
tensor(0.1477, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.47197870662055
tensor(2.5501, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.54815594976379
tensor(0.0117, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 230/ 1000/ t/epoch=0.61............. Loss: -0.27845669, mean(E): -18.00629868+0.12656630j, var(E): 2.12395673, Px: 0.49214314-0.26129147j, Py: 0.01634768-0.21403661j
35.62406689009593
tensor(0.0449, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.6997133830322
tensor(0.1086, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.7750972646642
tensor(0.0749, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.85022035202735
tensor(0.0246, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.925084443363716
tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
35.999691318380194
tensor(0.3502, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.07404273850246
tensor(0.0313, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.148140447124476
tensor(0.0458, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.22198616985373
tensor(1.1782, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.29558161475241
tensor(0.4339, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 240/ 1000/ t/epoch=0.61............. Loss: 1.21873960, mean(E): -17.96970043+0.00127501j, var(E): 2.22881433, Px: -0.41012630-0.42731225j, Py: 0.06226598-0.30758548j
36.368928472574446
tensor(0.2169, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.44202841699857
tensor(0.0587, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.51488310485748
tensor(0.5356, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.58749417636317
tensor(0.2332, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.659863255328474
tensor(0.4610, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.73199194938498
tensor(0.1162, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.803881850197286
tensor(0.1739, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.87553453367381
tensor(0.1008, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
36.94695156017398
tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.01813447471219
tensor(0.1647, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 250/ 1000/ t/epoch=0.6............. Loss: 0.18369189, mean(E): -17.98504534-0.03564665j, var(E): 1.76081179, Px: -0.46892464-0.42245301j, Py: -0.05902154-0.33280181j
37.089084807158336
tensor(0.0520, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.159804072435065
tensor(0.0171, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.23029377071194
tensor(0.0180, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.3005553875963
tensor(0.0066, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.37059039432116
tensor(0.0515, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.440400247930114
tensor(0.4334, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.50998639145911
tensor(0.2015, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.57935025411551
tensor(0.2218, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.648493251454205
tensor(0.0237, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.717416785550945
tensor(0.1645, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 260/ 1000/ t/epoch=0.6............. Loss: 0.50833024, mean(E): -17.88573977-0.04790220j, var(E): 1.65272270, Px: 0.44375597-0.31510508j, Py: -0.03462938-0.31947979j
37.786122245172905
tensor(0.3188, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.85461100594663
tensor(0.0922, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.92288443052328
tensor(0.1883, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
37.99094386874131
tensor(0.0615, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.05879065778657
tensor(0.3474, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.12642612234999
tensor(0.1353, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.19385157478274
tensor(0.0915, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.261068315249034
tensor(0.3339, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.328077631876546
tensor(0.4759, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
38.39488080090454
tensor(0.6887, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
