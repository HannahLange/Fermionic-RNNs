1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, U=1.0, t=3.0, density=0.9375, Nx=4, Ny=4, kx=0.5, ky=0.5, bounds=1, boundsx=0, boundsy=0, load_model=1, sym=0.0, antisym=0.0, hd=70)
4 4 0.9375 15
4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
check if ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/model_params_h=70_no_antisym.pt exists.
load ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/model_params_h=70_no_antisym.pt
0.38738890003699744
tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 1/ 1000/ t/epoch=1.72............. Loss: -0.78881873, mean(E): -23.49478709-0.01631020j, var(E): 1.48612750, Px: 0.47372651-0.15762375j, Py: 0.48187776-0.26532204j
0.7679877704607115
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.1420305438263911
tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.5097392678375618
tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.8713248970311833
tensor(0.0132, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.226988019620549
tensor(7.3832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)
2.5769195257663693
tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.9213012228502677
tensor(0.0126, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.260306402715595
tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.594100365306269
tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 10/ 1000/ t/epoch=0.6............. Loss: 0.48259279, mean(E): -23.53712500+0.00995732j, var(E): 1.60600732, Px: 0.49480003-0.12432563j, Py: 0.48842674-0.25736813j
3.9228409026646283
tensor(0.0168, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.246678746835807
tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.565757984861144
tensor(0.0133, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.880216443720544
tensor(0.0486, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.190186047797844
tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.495793151189666
tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.797158846952756
tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.094399255184058
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.387625791648664
tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.676945418510874
tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 20/ 1000/ t/epoch=0.6............. Loss: -0.10671803, mean(E): -23.40454386-0.02121259j, var(E): 2.54342990, Px: 0.49804482-0.13247967j, Py: 0.48955508-0.26796293j
6.962460878580353
tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.244270914357112
tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.522470473044028
tensor(0.0100, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.797150898591837
tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.068400111748744
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.336302779002585
tensor(0.0090, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.600940471227823
tensor(0.0306, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.862391812781173
tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.1207326217277
tensor(0.0041, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.376036041823156
tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 30/ 1000/ t/epoch=0.6............. Loss: 0.01591381, mean(E): -23.51599283-0.00738061j, var(E): 1.36660819, Px: 0.48854827-0.14039719j, Py: -0.49022942-0.23386400j
9.628372666827284
tensor(0.0067, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.877810657676827
tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.124415853004676
tensor(0.0433, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.368251873453593
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.60938022019789
tensor(0.0294, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.847860368054851
tensor(0.0063, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.08374985353844
tensor(0.0107, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.317104358181536
tensor(0.0595, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.547977787428454
tensor(0.0880, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.776422345377446
tensor(9.3273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)
Epoch: 40/ 1000/ t/epoch=0.59............. Loss: 0.12832461, mean(E): -23.52616385-0.00608274j, var(E): 2.04357173, Px: 0.49789181-0.14578063j, Py: 0.49813563-0.22346825j
12.002488605632383
tensor(0.0037, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.226225578504188
tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.44768077478538
tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.66690026630532
tensor(0.0076, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.883928743459228
tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.09880956989063
tensor(0.0323, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.311584834494663
tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.522295400898127
tensor(0.0224, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.730980954561906
tensor(0.0215, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.937680047641447
tensor(0.0487, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 50/ 1000/ t/epoch=0.6............. Loss: -0.56474913, mean(E): -23.59768150-0.00415720j, var(E): 1.98302913, Px: 0.45888507-0.18628080j, Py: 0.45752160-0.25491588j
14.142430141732243
tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.345267648618742
tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.546227969137712
tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.745345530259621
tensor(0.0067, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.942653820485333
tensor(0.0190, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.138185423649087
tensor(0.0117, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.33197205121308
tensor(7.2176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)
15.524044573133757
tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.71443304737489
tensor(0.0313, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.903166748138078
tensor(0.0197, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 60/ 1000/ t/epoch=0.59............. Loss: 0.24842168, mean(E): -23.60152156-0.03346798j, var(E): 1.98897443, Px: 0.46860431-0.15352195j, Py: 0.48399846-0.24371031j
16.09027419287695
tensor(0.0068, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.27578316815741
tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.459720754422552
tensor(0.0259, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.64211334971758
tensor(0.0426, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.822986692426475
tensor(0.0239, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.002365883069658
tensor(0.0185, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.18027540520859
tensor(0.0163, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.356739145500995
tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.531780412947718
tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.705421957370042
tensor(0.0279, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 70/ 1000/ t/epoch=0.6............. Loss: 1.03823222, mean(E): -23.59417802-0.00922395j, var(E): 4.07293157, Px: -0.47414301-0.13372417j, Py: 0.46990514-0.26455281j
17.87768598715408
tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.0485941862968
tensor(0.0244, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.21816773078654
tensor(0.0129, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.386427304348825
tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.553393113586814
tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.71908490254411
tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.883521966716156
tensor(0.0189, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.046723166535095
tensor(0.0958, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.208706940351668
tensor(0.0037, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.36949131693647
tensor(0.0333, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 80/ 1000/ t/epoch=0.59............. Loss: -0.14871972, mean(E): -23.51568926-0.04301962j, var(E): 1.84248485, Px: -0.49823823-0.16931781j, Py: -0.45858132-0.25941285j
19.529093927521764
tensor(0.0136, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.68753201740402
tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.844822457126188
tensor(0.0102, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.000981753257925
tensor(0.0593, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.1560260587909
tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.309971183165644
tensor(0.0156, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.462832601945486
tensor(0.0154, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.614625466152326
tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.765364611278375
tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.915064565987272
tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 90/ 1000/ t/epoch=0.6............. Loss: -0.41604381, mean(E): -23.45463341-0.05332892j, var(E): 1.36633389, Px: 0.49427224-0.15801210j, Py: -0.49044372-0.19414246j
21.063739560517327
tensor(0.0698, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.211403534798993
tensor(0.0204, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.358070146298278
tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.50375277759696
tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.648464543720287
tensor(0.0325, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.792218299222064
tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.935026645036814
tensor(0.0304, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.07690193510804
tensor(0.0609, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.217856282801378
tensor(0.0111, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.35790156711096
tensor(0.0188, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 100/ 1000/ t/epoch=0.6............. Loss: -0.55390853, mean(E): -23.68505969-0.03827896j, var(E): 3.36275400, Px: -0.48260062-0.18037729j, Py: 0.47678623-0.18389137j
22.497049438666885
tensor(0.0086, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.63531132555145
tensor(0.0191, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.772698438931407
tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.909221778513135
tensor(0.0980, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.04489213782739
tensor(0.0081, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.17972010935001
tensor(0.0104, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
