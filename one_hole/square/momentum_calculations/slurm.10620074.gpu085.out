1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, U=1.0, t=3.0, density=0.9375, Nx=4, Ny=4, kx=0.0, ky=0.5, bounds=1, boundsx=0, boundsy=0, load_model=1, sym=0.0, antisym=0.0, hd=70)
4 4 0.9375 15
4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
check if ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/model_params_h=70_no_antisym.pt exists.
load ../4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/model_params_h=70_no_antisym.pt
0.38738890003699744
tensor(0.0871, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 1/ 1000/ t/epoch=1.65............. Loss: -0.70214957, mean(E): -23.49478709-0.01631020j, var(E): 1.48612750, Px: 0.47372651-0.15762375j, Py: 0.48187776-0.26532204j
0.7679877704607115
tensor(0.1821, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.1420305438263911
tensor(0.2739, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.5097392678375618
tensor(0.3668, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
1.8713248970311833
tensor(0.4612, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.226988019620549
tensor(0.5542, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.5769195257663693
tensor(0.6428, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
2.9213012228502677
tensor(0.6914, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.260306402715595
tensor(0.7107, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
3.594100365306269
tensor(0.8862, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 10/ 1000/ t/epoch=0.6............. Loss: 1.58489426, mean(E): -23.54198816+0.00240970j, var(E): 1.62333396, Px: 0.49627585-0.12894690j, Py: 0.48357722-0.26565726j
3.9228409026646283
tensor(0.8267, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.246678746835807
tensor(1.0295, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.565757984861144
tensor(1.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
4.880216443720544
tensor(1.2086, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.190186047797844
tensor(1.2078, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.495793151189666
tensor(1.3737, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
5.797158846952756
tensor(1.2460, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.094399255184058
tensor(1.5115, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.387625791648664
tensor(1.3953, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
6.676945418510874
tensor(1.6566, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 20/ 1000/ t/epoch=0.59............. Loss: 1.78975237, mean(E): -23.40481887-0.01803197j, var(E): 2.56478306, Px: 0.49795263-0.14313123j, Py: 0.48746285-0.26487546j
6.962460878580353
tensor(1.5920, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.244270914357112
tensor(1.7438, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.522470473044028
tensor(1.7642, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
7.797150898591837
tensor(1.9172, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.068400111748744
tensor(2.0053, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.336302779002585
tensor(1.8595, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.600940471227823
tensor(1.7344, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
8.862391812781173
tensor(1.9494, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.1207326217277
tensor(1.9831, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.376036041823156
tensor(2.1838, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 30/ 1000/ t/epoch=0.59............. Loss: 2.76450612, mean(E): -23.39970266-0.00439431j, var(E): 1.37795096, Px: 0.48259359-0.16211954j, Py: 0.49656689-0.21739461j
9.628372666827284
tensor(2.2244, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
9.877810657676827
tensor(2.4117, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.124415853004676
tensor(2.2260, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.368251873453593
tensor(2.5906, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.60938022019789
tensor(2.4295, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
10.847860368054851
tensor(2.4623, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.08374985353844
tensor(2.6371, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.317104358181536
tensor(2.8528, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.547977787428454
tensor(2.6718, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
11.776422345377446
tensor(2.9122, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 40/ 1000/ t/epoch=0.59............. Loss: 4.09138302, mean(E): -23.42617240+0.01637751j, var(E): 1.86017236, Px: -0.49710521-0.20040560j, Py: 0.48666342-0.22978946j
12.002488605632383
tensor(2.5916, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.226225578504188
tensor(2.9190, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.44768077478538
tensor(2.9268, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.66690026630532
tensor(2.5828, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
12.883928743459228
tensor(2.7689, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.09880956989063
tensor(2.5841, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.311584834494663
tensor(2.9513, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.522295400898127
tensor(2.8568, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.730980954561906
tensor(3.0033, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
13.937680047641447
tensor(2.0514, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 50/ 1000/ t/epoch=0.6............. Loss: 4.30956098, mean(E): -23.54630399+0.07215109j, var(E): 1.77776571, Px: 0.38107903-0.29439317j, Py: 0.45566095-0.23384382j
14.142430141732243
tensor(2.7290, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.345267648618742
tensor(2.2729, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.546227969137712
tensor(2.9539, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.745345530259621
tensor(3.5611, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
14.942653820485333
tensor(1.8273, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.138185423649087
tensor(2.3389, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.33197205121308
tensor(2.0014, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.524044573133757
tensor(0.0253, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.71443304737489
tensor(0.1436, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
15.903166748138078
tensor(0.0780, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 60/ 1000/ t/epoch=0.6............. Loss: 4.60931722, mean(E): -23.07039205-0.03145600j, var(E): 4.08870548, Px: 0.06742309-0.27038536j, Py: 0.48108867-0.25209640j
16.09027419287695
tensor(0.0155, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.27578316815741
tensor(0.0170, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.459720754422552
tensor(0.0669, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.64211334971758
tensor(0.0521, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
16.822986692426475
tensor(0.0799, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.002365883069658
tensor(0.0669, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.18027540520859
tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.356739145500995
tensor(0.1155, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.531780412947718
tensor(0.0314, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
17.705421957370042
tensor(0.0578, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 70/ 1000/ t/epoch=0.59............. Loss: 4.81213184, mean(E): -22.64043203+0.19628244j, var(E): 8.10070010, Px: -0.05569733-0.21775734j, Py: 0.48732644-0.30310988j
17.87768598715408
tensor(0.0189, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.0485941862968
tensor(0.1204, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.21816773078654
tensor(0.0348, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.386427304348825
tensor(0.0161, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.553393113586814
tensor(0.0610, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.71908490254411
tensor(0.0100, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
18.883521966716156
tensor(0.0561, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.046723166535095
tensor(0.1126, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.208706940351668
tensor(0.0483, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.36949131693647
tensor(0.0389, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 80/ 1000/ t/epoch=0.59............. Loss: 4.72119840, mean(E): -22.98266675+0.05948823j, var(E): 4.48709196, Px: 0.00619108-0.20381353j, Py: -0.45563350-0.29442227j
19.529093927521764
tensor(0.0322, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.68753201740402
tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
19.844822457126188
tensor(0.0647, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.000981753257925
tensor(6.7837e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)
20.1560260587909
tensor(0.1257, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.309971183165644
tensor(0.0280, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.462832601945486
tensor(0.0137, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.614625466152326
tensor(0.0290, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.765364611278375
tensor(0.0196, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
20.915064565987272
tensor(0.0159, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 90/ 1000/ t/epoch=0.59............. Loss: 3.84724333, mean(E): -23.08620288-0.16349795j, var(E): 2.80751829, Px: 0.00845733-0.27926635j, Py: -0.47372144-0.24605109j
21.063739560517327
tensor(0.2819, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.211403534798993
tensor(0.0573, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.358070146298278
tensor(0.9861, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.50375277759696
tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.648464543720287
tensor(0.4767, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.792218299222064
tensor(0.0117, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
21.935026645036814
tensor(0.0324, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.07690193510804
tensor(0.0348, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.217856282801378
tensor(0.0336, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.35790156711096
tensor(0.0132, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 100/ 1000/ t/epoch=0.6............. Loss: 4.00455086, mean(E): -23.22125451-0.04810269j, var(E): 4.56860042, Px: -0.00368332-0.16891281j, Py: 0.47602544-0.19649571j
22.497049438666885
tensor(0.0920, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.63531132555145
tensor(0.0961, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.772698438931407
tensor(0.0298, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
22.909221778513135
tensor(0.0777, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.04489213782739
tensor(0.0566, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.17972010935001
tensor(0.0405, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.313716089464602
tensor(0.0587, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.44689028327306
tensor(0.0238, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.57925270925948
tensor(0.0330, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.710813203812762
tensor(0.0678, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 110/ 1000/ t/epoch=0.59............. Loss: 5.56173990, mean(E): -23.00362946-0.15720617j, var(E): 4.22485311, Px: 0.03971130-0.23570316j, Py: -0.46419322-0.21904431j
23.841581425613036
tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
23.971566859886824
tensor(0.0190, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.100778822535585
tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.229226464142144
tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.356918773859324
tensor(0.0532, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.48386458318493
tensor(0.0246, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.610072569626983
tensor(0.2113, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.735551260263136
tensor(0.0103, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.860309035197727
tensor(0.0396, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
24.98435413092019
tensor(0.1213, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 120/ 1000/ t/epoch=0.59............. Loss: 5.39876668, mean(E): -22.98404837+0.07954308j, var(E): 4.84203618, Px: -0.03770062-0.20372403j, Py: -0.44138771-0.25997984j
25.107694643568035
tensor(0.0125, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.23033853209769
tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.352293621366286
tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.47356760512743
tensor(0.1288, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.59416804894372
tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.71410239301889
tensor(0.0236, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.833377954952148
tensor(0.0539, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
25.95200193241723
tensor(0.0114, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.069981405768782
tensor(0.0122, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.18732334057822
tensor(0.1437, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 130/ 1000/ t/epoch=0.59............. Loss: 4.00067235, mean(E): -23.00505090-0.05167541j, var(E): 7.60685037, Px: 0.05426576-0.22541225j, Py: -0.44956127-0.38012228j
26.304034590101498
tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.420121897680872
tensor(0.0737, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.53559189908285
tensor(0.0101, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.65045112477427
tensor(0.1539, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.764706002138528
tensor(0.0140, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.878362857633757
tensor(0.2155, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
26.99142791889491
tensor(0.1951, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.103907316781278
tensor(0.1946, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.215807087371363
tensor(0.0913, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.327133173906553
tensor(0.0407, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 140/ 1000/ t/epoch=0.6............. Loss: 4.39842966, mean(E): -23.07792462+0.02506729j, var(E): 3.09679596, Px: -0.03039204-0.21894944j, Py: 0.47624791-0.29304808j
27.437891428685212
tensor(0.2484, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.548087614908805
tensor(0.0216, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.65772740848127
tensor(0.0998, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.76681639976334
tensor(0.0838, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.875360095282897
tensor(0.1637, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
27.983363919402883
tensor(0.0283, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.090833215947875
tensor(0.0119, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.197773249790643
tensor(0.2789, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.304189208399794
tensor(0.0938, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.41008620334975
tensor(0.0280, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 150/ 1000/ t/epoch=0.6............. Loss: 3.06017083, mean(E): -23.19736851-0.03743739j, var(E): 2.60666864, Px: 0.01664127-0.27260371j, Py: -0.47335137-0.21755300j
28.515469271793993
tensor(0.1502, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.620343377902792
tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.72471341426638
tensor(0.2478, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.82858420326454
tensor(0.2999, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
28.93196049840362
tensor(0.1038, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.034846985621837
tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.137248284563853
tensor(0.0911, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.23916894982539
tensor(0.2147, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.340613472168798
tensor(0.1017, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.441586279710364
tensor(0.1565, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
Epoch: 160/ 1000/ t/epoch=0.6............. Loss: 3.59091051, mean(E): -23.19857481+0.16350155j, var(E): 4.42902725, Px: 0.07272799-0.28280204j, Py: 0.49504461-0.20970662j
29.542091739080135
tensor(0.5985, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.64213415655501
tensor(0.6890, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.7417177791659
tensor(0.0730, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.840846795779523
tensor(0.3096, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
29.939525338155754
tensor(0.0700, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.037757481980904
tensor(0.2126, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
30.135547247877874
tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)
