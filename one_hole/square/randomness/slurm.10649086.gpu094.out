1.13.1+cu117
Namespace(Jp=0.0, Jz=1.0, U=1.0, t=3.0, density=0.9375, Nx=4, Ny=4, bounds=1, boundsx=0, boundsy=0, load_model=0, sym=0.0, antisym=0.0, hd=70, seed=1237)
GPU is available
4x4_qubits/periodic/Jp=0.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
tensor(10.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=3.79............. Loss: 4.18021457, mean(E): -15.55002044+0.00142724j, var(E): 20.17649864
0.0
tensor(10.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=1.16............. Loss: 4.77105701, mean(E): -15.84742943-0.00129722j, var(E): 20.79703387
0.0
tensor(11.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=1.16............. Loss: 4.76857280, mean(E): -17.06108934+0.06054774j, var(E): 23.73122210
0.0
tensor(11.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=1.16............. Loss: 3.37292359, mean(E): -17.71421128-0.00341818j, var(E): 26.82255369
0.0
tensor(11.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=1.16............. Loss: 2.74242407, mean(E): -18.93436071-0.00897295j, var(E): 17.83322474
0.0
tensor(12.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=1.17............. Loss: 0.86175817, mean(E): -19.16368922+0.00676219j, var(E): 12.58006339
0.0
tensor(12.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=1.16............. Loss: 0.73733475, mean(E): -19.42207929+0.05377314j, var(E): 11.48670899
0.0
tensor(12.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=1.16............. Loss: 0.99978664, mean(E): -19.71273318-0.00180012j, var(E): 8.59366308
0.0
tensor(12.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=1.16............. Loss: 1.37903364, mean(E): -19.71285275-0.08379583j, var(E): 9.48452556
0.0
tensor(12.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=1.16............. Loss: 1.48145199, mean(E): -20.25059055+0.04211321j, var(E): 9.23458674
0.0
tensor(12.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=1.17............. Loss: 1.59074399, mean(E): -20.59639131+0.05695726j, var(E): 11.93298848
0.0
tensor(12.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=1.17............. Loss: 0.06359960, mean(E): -20.14027081+0.04342517j, var(E): 7.23751268
0.0
tensor(12.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=1.17............. Loss: 0.13396890, mean(E): -20.03784281-0.01770614j, var(E): 6.61969640
0.0
tensor(13.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=1.17............. Loss: 0.62565200, mean(E): -20.40694499-0.00395546j, var(E): 8.78003098
0.0
tensor(13.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=1.18............. Loss: -0.10641623, mean(E): -20.64427314+0.01156368j, var(E): 5.90488950
0.0
tensor(13.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=1.18............. Loss: 0.16679256, mean(E): -20.63041076+0.05767936j, var(E): 7.93101362
0.0
tensor(13.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=1.18............. Loss: 0.10558484, mean(E): -20.76778711+0.03199671j, var(E): 5.88806659
0.0
tensor(13.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=1.18............. Loss: 0.15890327, mean(E): -20.21527884-0.00695224j, var(E): 4.62282687
0.0
tensor(13.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=1.18............. Loss: 0.32715745, mean(E): -20.74742308+0.07835949j, var(E): 5.05768607
0.0
tensor(13.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=1.18............. Loss: 0.31434074, mean(E): -20.83487122+0.06316769j, var(E): 6.49018448
0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=1.18............. Loss: 1.51757476, mean(E): -20.96504812+0.01512066j, var(E): 7.69541444
0.0
tensor(13.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=1.18............. Loss: 1.06888574, mean(E): -21.01768283-0.04986444j, var(E): 8.44536433
0.0
tensor(13.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=1.18............. Loss: 0.06626990, mean(E): -20.83651514-0.03859961j, var(E): 4.85230020
0.0
tensor(13.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=1.19............. Loss: 0.50280376, mean(E): -21.06832635+0.05843438j, var(E): 3.69644568
0.0
tensor(13.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=1.19............. Loss: -0.23957534, mean(E): -20.81768296-0.01313247j, var(E): 4.55138551
0.0
tensor(13.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=1.18............. Loss: 0.08535645, mean(E): -21.22238317-0.05323564j, var(E): 3.67541808
0.0
tensor(13.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=1.18............. Loss: -0.36494275, mean(E): -20.98777460+0.00147780j, var(E): 3.75245271
0.0
tensor(14.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=1.18............. Loss: -0.27032590, mean(E): -21.09958896-0.01648154j, var(E): 5.97245362
0.0
tensor(14.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=1.18............. Loss: -1.00808333, mean(E): -20.78433642-0.00908013j, var(E): 4.84662206
0.0
tensor(14.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=1.18............. Loss: -0.07615520, mean(E): -20.90032344-0.00422260j, var(E): 4.36755237
0.0
tensor(14.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=1.19............. Loss: 0.38636101, mean(E): -21.18543738+0.00644395j, var(E): 4.65217816
0.0
tensor(14.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=1.18............. Loss: 1.09400166, mean(E): -21.29875952+0.01992437j, var(E): 4.10035319
0.0
tensor(14.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=1.18............. Loss: 0.43105834, mean(E): -21.24762300-0.02862200j, var(E): 3.86316097
0.0
tensor(14.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=1.19............. Loss: -0.13910375, mean(E): -21.16376056-0.00070955j, var(E): 5.54103427
0.0
tensor(14.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=1.18............. Loss: -1.04675669, mean(E): -21.05851464+0.02328365j, var(E): 4.53541863
0.0
tensor(14.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=1.19............. Loss: -0.11772373, mean(E): -21.37150003-0.00190253j, var(E): 3.13056915
0.0
tensor(14.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=1.19............. Loss: 0.72686046, mean(E): -21.42129466+0.00741490j, var(E): 3.77063138
0.0
tensor(14.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=1.18............. Loss: 0.19081122, mean(E): -21.19300965-0.01345916j, var(E): 3.45781563
0.0
tensor(14.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=1.19............. Loss: -0.14587531, mean(E): -21.29849371+0.00346818j, var(E): 3.05434583
0.0
tensor(14.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=1.18............. Loss: -0.74477562, mean(E): -21.30337840+0.01323336j, var(E): 2.55347102
0.0
tensor(14.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=1.18............. Loss: -0.21524193, mean(E): -21.23466575-0.02150454j, var(E): 3.24166712
0.0
tensor(14.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=1.18............. Loss: -0.15053040, mean(E): -21.23636879+0.02767474j, var(E): 3.14567619
0.0
tensor(14.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=1.19............. Loss: -0.01209707, mean(E): -21.33928151-0.02051782j, var(E): 2.15945993
0.0
tensor(15.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=1.18............. Loss: 0.62476108, mean(E): -21.36546890+0.06937837j, var(E): 2.41182532
0.0
tensor(15.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=1.19............. Loss: -0.16286721, mean(E): -21.36137108-0.00941946j, var(E): 3.01111780
0.0
tensor(15.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=1.18............. Loss: -0.48377667, mean(E): -21.22265560+0.02072301j, var(E): 2.41167808
0.0
tensor(15.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=1.18............. Loss: 0.63788908, mean(E): -21.35181399+0.00935984j, var(E): 6.41802056
0.0
tensor(15.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=1.19............. Loss: -0.26779133, mean(E): -21.45567804-0.03979556j, var(E): 2.00713223
0.0
tensor(15.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=1.19............. Loss: -0.00633736, mean(E): -21.34179072-0.01440375j, var(E): 3.42871494
0.0
tensor(15.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=1.19............. Loss: 0.90565823, mean(E): -21.51058567-0.02422514j, var(E): 3.55963731
0.0
tensor(15.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=1.18............. Loss: 0.37472659, mean(E): -21.48708355-0.03681076j, var(E): 2.19173268
0.0
tensor(15.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=1.19............. Loss: -0.26292573, mean(E): -21.44971795+0.00644963j, var(E): 1.72866696
0.0
tensor(15.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=1.18............. Loss: -0.11930788, mean(E): -21.41290834-0.01156751j, var(E): 2.32950877
0.0
tensor(15.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=1.18............. Loss: 0.55708316, mean(E): -21.53816308+0.00363138j, var(E): 2.32878892
0.0
tensor(15.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=1.18............. Loss: -0.74098330, mean(E): -21.31838862+0.01585218j, var(E): 2.97348187
0.0
tensor(15.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=1.19............. Loss: 0.56080053, mean(E): -21.42484159-0.00081583j, var(E): 2.43332638
0.0
tensor(15.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=1.19............. Loss: 0.55377409, mean(E): -21.31322639+0.00171234j, var(E): 3.31991230
0.0
tensor(15.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=1.18............. Loss: 0.44778864, mean(E): -21.45643155-0.02599569j, var(E): 3.02230246
0.0
tensor(15.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=1.18............. Loss: -0.33548063, mean(E): -21.47693890+0.01267040j, var(E): 1.71537825
0.0
tensor(15.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=1.19............. Loss: -0.08068444, mean(E): -21.40868500-0.00401319j, var(E): 2.47411100
0.0
tensor(15.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=1.19............. Loss: 0.25948625, mean(E): -21.61487595-0.02311580j, var(E): 1.41412610
0.0
tensor(15.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=1.18............. Loss: 0.52811145, mean(E): -21.52076984+0.02361684j, var(E): 2.38927110
0.0
tensor(15.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=1.19............. Loss: -0.09530141, mean(E): -21.42342145-0.00574507j, var(E): 1.92407386
0.0
tensor(15.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=1.19............. Loss: -0.48940213, mean(E): -21.45380542+0.01045486j, var(E): 1.63167693
0.0
tensor(15.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=1.19............. Loss: 0.29640941, mean(E): -21.50988282+0.01671878j, var(E): 2.03769015
0.0
tensor(15.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=1.19............. Loss: -0.42161730, mean(E): -21.46260210+0.04475546j, var(E): 1.75919247
0.0
tensor(15.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=1.19............. Loss: -0.03886905, mean(E): -21.44335047+0.02255752j, var(E): 2.37666538
0.0
tensor(15.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=1.19............. Loss: 0.73550085, mean(E): -21.53255992-0.05885005j, var(E): 3.97733672
0.0
tensor(15.8966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=1.19............. Loss: -0.53557099, mean(E): -21.48363930-0.01100861j, var(E): 1.40081503
0.0
tensor(15.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=1.19............. Loss: 0.05391082, mean(E): -21.47326151+0.01101845j, var(E): 1.97692878
0.0
tensor(15.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=1.19............. Loss: 0.07469201, mean(E): -21.44876628+0.03873806j, var(E): 3.07161232
0.0
tensor(16.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=1.19............. Loss: -0.95554478, mean(E): -21.41403263-0.01000702j, var(E): 2.35803944
0.0
tensor(16.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=1.19............. Loss: -0.08295810, mean(E): -21.37611845+0.03169362j, var(E): 2.24294204
0.0
tensor(16.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=1.19............. Loss: 0.44074020, mean(E): -21.54629742-0.02307559j, var(E): 2.21673886
0.0
tensor(16.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=1.18............. Loss: -0.29307519, mean(E): -21.52346471-0.00880176j, var(E): 1.06973834
0.0
tensor(16.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=1.19............. Loss: -0.21762279, mean(E): -21.48449830+0.02011516j, var(E): 2.97312750
0.0
tensor(16.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=1.19............. Loss: 0.75138057, mean(E): -21.55870390+0.03136651j, var(E): 5.87329778
0.0
tensor(16.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=1.19............. Loss: 0.49504801, mean(E): -21.53941031+0.01664102j, var(E): 1.44332800
0.0
tensor(16.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=1.19............. Loss: -0.31264630, mean(E): -21.41476331+0.01326452j, var(E): 1.75597512
0.0
tensor(16.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=1.18............. Loss: -0.37174812, mean(E): -21.55849403-0.00301196j, var(E): 1.57348516
0.0
tensor(16.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=1.19............. Loss: -0.16940170, mean(E): -21.50262454+0.00340640j, var(E): 1.25750210
0.0
tensor(16.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=1.19............. Loss: -0.87148369, mean(E): -21.32927039+0.01647255j, var(E): 2.15975927
0.0
tensor(16.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=1.19............. Loss: 0.64262653, mean(E): -21.72456211+0.00268949j, var(E): 1.56225331
0.0
tensor(16.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=1.18............. Loss: -0.16224912, mean(E): -21.47910084-0.02103400j, var(E): 1.11586560
0.0
tensor(16.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=1.18............. Loss: -0.32095005, mean(E): -21.50558729+0.02552257j, var(E): 1.28028724
0.0
tensor(16.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=1.19............. Loss: -0.54865397, mean(E): -21.36324568-0.02382053j, var(E): 2.03310563
0.0
tensor(16.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=1.19............. Loss: -0.58131605, mean(E): -21.36924472-0.00126167j, var(E): 1.61040359
0.0
tensor(16.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=1.18............. Loss: -0.41469483, mean(E): -21.40820023+0.02688664j, var(E): 1.86278444
0.0
tensor(16.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=1.19............. Loss: -0.49600097, mean(E): -21.36986303+0.00549699j, var(E): 1.37950065
0.0
tensor(16.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=1.19............. Loss: 0.03299643, mean(E): -21.46447351+0.01321265j, var(E): 1.42069051
0.0
tensor(16.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=1.19............. Loss: 0.27154656, mean(E): -21.63215878+0.05042254j, var(E): 1.64227372
0.0
tensor(16.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=1.18............. Loss: 0.13595048, mean(E): -21.55066271-0.02908763j, var(E): 1.94550198
0.0
tensor(16.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=1.19............. Loss: -1.12627876, mean(E): -21.36566122-0.01131393j, var(E): 1.44831515
0.0
tensor(16.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=1.18............. Loss: 0.30213521, mean(E): -21.61641938-0.00172891j, var(E): 1.68988769
0.0
tensor(16.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=1.18............. Loss: 0.21939514, mean(E): -21.61981464+0.00872244j, var(E): 1.00137205
0.0
tensor(16.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=1.18............. Loss: -0.48774700, mean(E): -21.47363301+0.00074367j, var(E): 2.79504248
0.0
tensor(16.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=1.19............. Loss: 0.46667821, mean(E): -21.68634751+0.00937696j, var(E): 1.09564239
0.0
tensor(16.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=1.18............. Loss: -0.84802336, mean(E): -21.27201035+0.00712741j, var(E): 1.77734113
0.0
tensor(16.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=1.19............. Loss: 0.66730788, mean(E): -21.59672815-0.02053498j, var(E): 1.53093573
0.0
tensor(16.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=1.18............. Loss: -0.96606118, mean(E): -21.40965774+0.00050520j, var(E): 1.45584807
0.0
tensor(16.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=1.19............. Loss: 0.08847618, mean(E): -21.57484636-0.01151972j, var(E): 1.67840377
-0.0
tensor(16.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=1.18............. Loss: 0.29882581, mean(E): -21.58654362-0.03030316j, var(E): 3.88708953
-0.0
tensor(16.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=1.19............. Loss: 1.07477613, mean(E): -21.79118895-0.00155739j, var(E): 2.04927431
-0.0
tensor(16.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=1.18............. Loss: -0.96104889, mean(E): -21.36404859-0.04437057j, var(E): 2.10615474
-0.0
tensor(16.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=1.18............. Loss: -0.53169409, mean(E): -21.50620132+0.01550623j, var(E): 1.41767401
-0.0
tensor(17.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=1.19............. Loss: -0.06210235, mean(E): -21.55661102+0.00308195j, var(E): 1.21561709
-0.0
tensor(17.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=1.19............. Loss: -0.59973863, mean(E): -21.44271412-0.01603755j, var(E): 1.16010851
-0.0
tensor(17.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=1.18............. Loss: 1.10129650, mean(E): -21.69195033-0.01698372j, var(E): 1.69642956
-0.0
tensor(17.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=1.19............. Loss: -0.45718605, mean(E): -21.48210016-0.03309444j, var(E): 1.58861866
-0.0
tensor(17.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=1.19............. Loss: 0.56138573, mean(E): -21.65099760-0.00536664j, var(E): 2.58487516
-0.0
tensor(17.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=1.19............. Loss: -0.47885561, mean(E): -21.50266443-0.01032171j, var(E): 1.73852468
-0.0
tensor(17.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=1.19............. Loss: -0.77322928, mean(E): -21.48970500+0.03147036j, var(E): 1.50188448
-0.0
tensor(17.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=1.19............. Loss: 0.03455510, mean(E): -21.61738477-0.00995107j, var(E): 0.97046829
-0.0
tensor(17.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=1.19............. Loss: 0.05176038, mean(E): -21.53052775-0.00839453j, var(E): 1.51327044
-0.0
tensor(17.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=1.19............. Loss: -0.01027999, mean(E): -21.63128044+0.01015991j, var(E): 1.33341977
-0.0
tensor(17.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=1.19............. Loss: 0.09534967, mean(E): -21.57796875-0.01088716j, var(E): 1.48748865
-0.0
tensor(17.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=1.19............. Loss: 1.57144951, mean(E): -21.68738887+0.00399812j, var(E): 2.74794595
-0.0
tensor(17.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=1.18............. Loss: 0.36338706, mean(E): -21.64995513+0.00604447j, var(E): 1.60025088
-0.0
tensor(17.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=1.19............. Loss: -0.48992233, mean(E): -21.56088820+0.01848899j, var(E): 1.53506797
-0.0
tensor(17.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=1.19............. Loss: 0.51067653, mean(E): -21.64629904-0.01821299j, var(E): 1.32147693
-0.0
tensor(17.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=1.19............. Loss: -0.20172548, mean(E): -21.62236532+0.00194887j, var(E): 1.56848267
-0.0
tensor(17.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=1.19............. Loss: -0.65002496, mean(E): -21.50457832+0.00669282j, var(E): 1.67432029
-0.0
tensor(17.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=1.19............. Loss: -0.08111986, mean(E): -21.59027134-0.01867520j, var(E): 1.31796147
-0.0
tensor(17.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=1.18............. Loss: -0.04944425, mean(E): -21.54552103+0.02680258j, var(E): 1.44797876
-0.0
tensor(17.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=1.19............. Loss: 0.49609411, mean(E): -21.71814034-0.00353872j, var(E): 1.27844665
-0.0
tensor(17.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=1.18............. Loss: -0.41912529, mean(E): -21.46270801-0.00767402j, var(E): 1.48743056
-0.0
tensor(17.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=1.19............. Loss: -0.33002076, mean(E): -21.43041126+0.00187789j, var(E): 1.70056552
-0.0
tensor(17.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=1.18............. Loss: 0.23822461, mean(E): -21.66716568+0.00286077j, var(E): 1.17209160
-0.0
tensor(17.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=1.18............. Loss: 0.80399851, mean(E): -21.76292720+0.02250449j, var(E): 2.09472681
-0.0
tensor(17.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=1.18............. Loss: 0.25270404, mean(E): -21.59233517-0.00227562j, var(E): 1.34606312
-0.0
tensor(17.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=1.19............. Loss: -0.05607718, mean(E): -21.44814936+0.02984484j, var(E): 2.00754095
-0.0
tensor(17.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=1.19............. Loss: -0.03673643, mean(E): -21.54195166-0.00419942j, var(E): 1.80525505
-0.0
tensor(17.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=1.19............. Loss: -0.68221922, mean(E): -21.45716484-0.02085857j, var(E): 2.11045379
-0.0
tensor(17.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=1.18............. Loss: -0.43561910, mean(E): -21.58135369-0.00912471j, var(E): 1.44333156
-0.0
tensor(17.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=1.19............. Loss: 0.58269176, mean(E): -21.67824491+0.01845510j, var(E): 3.27681925
-0.0
tensor(17.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=1.18............. Loss: -0.15811767, mean(E): -21.47888862-0.02268949j, var(E): 1.37078380
-0.0
tensor(17.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=1.18............. Loss: -0.15702291, mean(E): -21.52228327+0.00340131j, var(E): 1.55903955
-0.0
tensor(17.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=1.18............. Loss: 0.38202881, mean(E): -21.53632440-0.02235491j, var(E): 0.91204552
-0.0
tensor(17.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=1.18............. Loss: 1.75511348, mean(E): -21.71294609-0.01977578j, var(E): 3.04473745
-0.0
tensor(17.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=1.18............. Loss: 0.35576338, mean(E): -21.64964978+0.03168891j, var(E): 1.50659386
-0.0
tensor(18.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=1.18............. Loss: -0.11859037, mean(E): -21.45715182-0.00642630j, var(E): 1.34763180
-0.0
tensor(18.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=1.18............. Loss: 0.48636078, mean(E): -21.68072229-0.00338685j, var(E): 1.75444672
-0.0
tensor(18.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=1.18............. Loss: -0.15800545, mean(E): -21.45484029+0.02562943j, var(E): 1.20653531
-0.0
tensor(18.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=1.18............. Loss: -0.40735127, mean(E): -21.45402776+0.00987981j, var(E): 1.53810157
-0.0
tensor(18.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=1.18............. Loss: -0.13380374, mean(E): -21.61169260-0.02090158j, var(E): 1.63136064
-0.0
tensor(18.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=1.18............. Loss: -0.08598270, mean(E): -21.58875959+0.02276971j, var(E): 0.85312898
-0.0
tensor(18.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=1.18............. Loss: 0.51496842, mean(E): -21.69220248+0.02160145j, var(E): 0.75759801
-0.0
tensor(18.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=1.18............. Loss: 0.11643778, mean(E): -21.70829273-0.03623721j, var(E): 0.94919193
-0.0
tensor(18.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=1.18............. Loss: 0.64900439, mean(E): -21.66825293-0.01242077j, var(E): 3.03791376
-0.0
tensor(18.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=1.18............. Loss: -0.81840284, mean(E): -21.55119743-0.01790212j, var(E): 1.57766797
-0.0
tensor(18.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=1.18............. Loss: -0.91152051, mean(E): -21.46275372-0.00537533j, var(E): 1.65805334
-0.0
tensor(18.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=1.18............. Loss: -0.27078074, mean(E): -21.49820950-0.00647555j, var(E): 0.96184132
-0.0
tensor(18.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=1.19............. Loss: -0.65994909, mean(E): -21.43085972-0.00170823j, var(E): 0.99668640
-0.0
tensor(18.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=1.19............. Loss: -0.20921046, mean(E): -21.55967019+0.00618152j, var(E): 0.81879857
-0.0
tensor(18.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=1.18............. Loss: -0.17940139, mean(E): -21.54155482-0.01314223j, var(E): 0.89464432
-0.0
tensor(18.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=1.18............. Loss: 0.00856067, mean(E): -21.66124737+0.00173820j, var(E): 0.81314644
-0.0
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=1.19............. Loss: -0.42667836, mean(E): -21.59508976+0.02146667j, var(E): 1.41953855
-0.0
tensor(18.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=1.18............. Loss: 0.51000203, mean(E): -21.72923365-0.02380431j, var(E): 1.46392891
-0.0
tensor(18.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=1.18............. Loss: 0.39219933, mean(E): -21.66939737+0.00684539j, var(E): 1.22077261
-0.0
tensor(18.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=1.19............. Loss: 0.33764653, mean(E): -21.61068899-0.00080815j, var(E): 2.13235013
-0.0
tensor(18.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=1.19............. Loss: 0.17363344, mean(E): -21.75376993-0.04360163j, var(E): 1.27257515
-0.0
tensor(18.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=1.18............. Loss: 0.38751111, mean(E): -21.73472927-0.02552262j, var(E): 1.34046919
-0.0
tensor(18.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=1.19............. Loss: -0.41139002, mean(E): -21.62489988-0.00893833j, var(E): 0.86955437
-0.0
tensor(18.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=1.18............. Loss: 0.11488667, mean(E): -21.62588902-0.00318396j, var(E): 1.08727435
-0.0
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=1.18............. Loss: -0.67749355, mean(E): -21.47656032+0.01844579j, var(E): 1.23335466
-0.0
tensor(18.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=1.18............. Loss: 0.22932362, mean(E): -21.60814870+0.01044409j, var(E): 0.96950654
-0.0
tensor(18.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=1.18............. Loss: 0.48867478, mean(E): -21.70345807-0.01760225j, var(E): 1.21709272
-0.0
tensor(18.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=1.18............. Loss: 0.13062151, mean(E): -21.68735264+0.00667705j, var(E): 1.01764474
-0.0
tensor(18.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=1.18............. Loss: -0.03783417, mean(E): -21.63057602-0.01152071j, var(E): 1.00773718
-0.0
tensor(18.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=1.18............. Loss: -0.95771944, mean(E): -21.42719359-0.01246755j, var(E): 1.25953673
-0.0
tensor(18.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=1.19............. Loss: -0.10494177, mean(E): -21.59220663-0.02750284j, var(E): 0.96021320
-0.0
tensor(18.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=1.19............. Loss: 0.32310834, mean(E): -21.61760804-0.00043943j, var(E): 0.94434016
-0.0
tensor(18.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=1.18............. Loss: 0.14026347, mean(E): -21.70950462-0.00865135j, var(E): 0.90930077
-0.0
tensor(18.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=1.19............. Loss: -0.04940395, mean(E): -21.68599853-0.02769618j, var(E): 1.38829397
-0.0
tensor(18.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=1.19............. Loss: 0.87485689, mean(E): -21.76958065+0.01830315j, var(E): 1.85570425
-0.0
tensor(18.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=1.19............. Loss: -0.38427682, mean(E): -21.53632417+0.00482571j, var(E): 1.07155175
-0.0
tensor(18.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=1.19............. Loss: 0.14217856, mean(E): -21.70661907-0.01908277j, var(E): 0.89589873
-0.0
tensor(18.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=1.19............. Loss: -0.07272805, mean(E): -21.67071972+0.01242891j, var(E): 0.75903329
-0.0
tensor(18.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=1.19............. Loss: -0.13937094, mean(E): -21.49097147-0.02803059j, var(E): 1.31535901
-0.0
tensor(18.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=1.19............. Loss: -0.06945308, mean(E): -21.62030092-0.01656677j, var(E): 1.08722947
-0.0
tensor(18.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=1.19............. Loss: 0.20029674, mean(E): -21.64235649-0.02913799j, var(E): 0.96302089
-0.0
tensor(18.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=1.18............. Loss: -0.05592507, mean(E): -21.65293868+0.00194111j, var(E): 1.78232096
-0.0
tensor(18.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=1.19............. Loss: 0.31510817, mean(E): -21.55048048-0.00254175j, var(E): 1.30396049
-0.0
tensor(18.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=1.19............. Loss: -0.02902932, mean(E): -21.58243082+0.00290265j, var(E): 0.88970150
-0.0
tensor(18.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=1.18............. Loss: -0.28241376, mean(E): -21.56533233-0.03440000j, var(E): 1.38837808
-0.0
tensor(19.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=1.19............. Loss: -0.02619306, mean(E): -21.59511719-0.00279954j, var(E): 0.97517872
-0.0
tensor(19.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=1.18............. Loss: 0.25630672, mean(E): -21.67971755-0.00501625j, var(E): 1.41831800
-0.0
tensor(19.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=1.19............. Loss: 1.10082651, mean(E): -21.76706273+0.00758377j, var(E): 2.67677673
-0.0
tensor(19.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=1.18............. Loss: 0.27884506, mean(E): -21.72083001+0.01433107j, var(E): 1.26162592
-0.0
tensor(19.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=1.19............. Loss: -0.27645527, mean(E): -21.58238485+0.01471436j, var(E): 1.14602810
-0.0
tensor(19.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=1.19............. Loss: 0.16133807, mean(E): -21.61773667+0.00170458j, var(E): 2.04354058
-0.0
tensor(19.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=1.18............. Loss: -0.13118920, mean(E): -21.64291230-0.01295900j, var(E): 1.06913784
-0.0
tensor(19.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=1.19............. Loss: -0.04413017, mean(E): -21.61434411-0.01231918j, var(E): 0.76494689
-0.0
tensor(19.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=1.18............. Loss: -0.02381906, mean(E): -21.68247518+0.00152828j, var(E): 1.37834385
-0.0
tensor(19.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=1.19............. Loss: -0.08624310, mean(E): -21.58564104-0.02373023j, var(E): 0.60777538
-0.0
tensor(19.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=1.19............. Loss: -0.75229459, mean(E): -21.53267726-0.00278074j, var(E): 1.71902270
-0.0
tensor(19.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=1.19............. Loss: -0.29993804, mean(E): -21.50116302-0.01575828j, var(E): 1.35259323
-0.0
tensor(19.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=1.19............. Loss: -0.02287716, mean(E): -21.67607894+0.02540674j, var(E): 0.99484083
-0.0
tensor(19.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=1.19............. Loss: 0.08698904, mean(E): -21.66398416-0.03735839j, var(E): 1.38793778
-0.0
tensor(19.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=1.19............. Loss: 0.08538959, mean(E): -21.56587297+0.01094470j, var(E): 0.86524467
-0.0
tensor(19.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=1.19............. Loss: 0.49456602, mean(E): -21.74526497+0.01316304j, var(E): 0.99512601
-0.0
tensor(19.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=1.19............. Loss: 0.95837079, mean(E): -21.83581147-0.02516169j, var(E): 2.01382172
-0.0
tensor(19.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=1.19............. Loss: 0.20667130, mean(E): -21.75158135-0.00501027j, var(E): 2.15081230
-0.0
tensor(19.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=1.19............. Loss: -0.14731297, mean(E): -21.58135529+0.00401480j, var(E): 1.24783810
-0.0
tensor(19.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=1.19............. Loss: -0.45828095, mean(E): -21.59723611+0.00506997j, var(E): 1.17722580
-0.0
tensor(19.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=1.19............. Loss: 0.05608975, mean(E): -21.63598337+0.00436691j, var(E): 0.88417766
-0.0
tensor(19.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=1.19............. Loss: 0.42852124, mean(E): -21.64341679+0.01303025j, var(E): 1.42877326
-0.0
tensor(19.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=1.19............. Loss: 0.02257712, mean(E): -21.61243503+0.01313428j, var(E): 1.77761833
-0.0
tensor(19.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=1.19............. Loss: 0.63961413, mean(E): -21.65053579-0.01990868j, var(E): 1.44527544
-0.0
tensor(19.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=1.18............. Loss: -0.32845254, mean(E): -21.64810332-0.01236240j, var(E): 1.42428656
-0.0
tensor(19.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=1.19............. Loss: 0.11333666, mean(E): -21.62287592+0.00238656j, var(E): 0.81686188
-0.0
tensor(19.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=1.19............. Loss: -0.25253242, mean(E): -21.61015346+0.01022826j, var(E): 1.69566012
-0.0
tensor(19.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=1.19............. Loss: 0.06688177, mean(E): -21.70959836-0.00759323j, var(E): 0.96522106
-0.0
tensor(19.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=1.19............. Loss: 0.28351239, mean(E): -21.76124204+0.00527155j, var(E): 1.46673834
-0.0
tensor(19.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=1.19............. Loss: -0.69717173, mean(E): -21.53623422-0.01454113j, var(E): 1.41383881
-0.0
tensor(19.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=1.19............. Loss: 0.40892335, mean(E): -21.70126873+0.00380874j, var(E): 2.01093691
-0.0
tensor(19.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=1.18............. Loss: 0.23791432, mean(E): -21.72082277+0.00821643j, var(E): 1.25287473
-0.0
tensor(19.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=1.19............. Loss: -0.86739103, mean(E): -21.48860666-0.00013198j, var(E): 0.90000352
-0.0
tensor(19.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=1.18............. Loss: -1.03527916, mean(E): -21.51036144-0.00467113j, var(E): 1.53094068
-0.0
tensor(19.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=1.19............. Loss: -0.14542815, mean(E): -21.68169082+0.01580291j, var(E): 1.18214559
-0.0
tensor(19.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=1.19............. Loss: 0.57582768, mean(E): -21.59205237-0.01064096j, var(E): 2.41609667
-0.0
tensor(19.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=1.19............. Loss: 0.21444985, mean(E): -21.65772650+0.00286419j, var(E): 0.77021810
-0.0
tensor(19.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=1.19............. Loss: 0.45814908, mean(E): -21.74397222+0.00266336j, var(E): 1.32241341
-0.0
tensor(19.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=1.19............. Loss: -0.40894523, mean(E): -21.49524742-0.02095975j, var(E): 1.44175327
-0.0
tensor(19.8439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=1.19............. Loss: 0.81626408, mean(E): -21.71535880+0.01960408j, var(E): 2.43244336
-0.0
tensor(19.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=1.19............. Loss: -0.16678091, mean(E): -21.62419644+0.00411148j, var(E): 1.25344431
-0.0
tensor(19.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=1.18............. Loss: -0.43223093, mean(E): -21.55988187-0.01857683j, var(E): 0.94453965
-0.0
tensor(19.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=1.19............. Loss: -0.46189459, mean(E): -21.52799958+0.01989683j, var(E): 0.76941842
-0.0
tensor(19.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=1.19............. Loss: -0.43872237, mean(E): -21.59227512+0.01554908j, var(E): 0.76701765
-0.0
tensor(19.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=1.18............. Loss: -0.20408516, mean(E): -21.66837318+0.00032457j, var(E): 0.84907432
-0.0
tensor(19.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=1.19............. Loss: -0.14833332, mean(E): -21.62218371-0.01720660j, var(E): 1.55994847
-0.0
tensor(19.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=1.19............. Loss: -0.27630819, mean(E): -21.60247689-0.02108241j, var(E): 0.91897705
-0.0
tensor(19.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=1.18............. Loss: 0.11445112, mean(E): -21.64116983-0.00154563j, var(E): 0.96737929
-0.0
tensor(19.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=1.19............. Loss: -0.15703193, mean(E): -21.67462829-0.00999809j, var(E): 0.87656987
-0.0
tensor(19.9884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=1.18............. Loss: -0.24487103, mean(E): -21.64239015-0.01388672j, var(E): 0.77238768
-0.0
tensor(20.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=1.18............. Loss: 0.35205814, mean(E): -21.74852899+0.00535515j, var(E): 1.03340192
-0.0
tensor(20.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=1.19............. Loss: -0.13944807, mean(E): -21.67297545+0.00839192j, var(E): 0.56148891
-0.0
tensor(20.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=1.19............. Loss: 0.39223774, mean(E): -21.80422837+0.01863932j, var(E): 0.87211453
-0.0
tensor(20.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=1.18............. Loss: -0.12022005, mean(E): -21.62146818-0.01106266j, var(E): 0.60472331
-0.0
tensor(20.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=1.19............. Loss: -0.07297272, mean(E): -21.68164473+0.00060444j, var(E): 0.52331771
-0.0
tensor(20.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=1.19............. Loss: 0.18453062, mean(E): -21.70967827+0.02630518j, var(E): 1.16548559
-0.0
tensor(20.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=1.19............. Loss: -0.39405325, mean(E): -21.61127018-0.01296221j, var(E): 0.85813675
-0.0
tensor(20.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=1.19............. Loss: 0.00957246, mean(E): -21.71970387+0.00218591j, var(E): 0.97486408
-0.0
tensor(20.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=1.19............. Loss: 0.06820600, mean(E): -21.69158569+0.00962729j, var(E): 0.94314077
-0.0
tensor(20.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=1.19............. Loss: -0.13356992, mean(E): -21.68741779-0.00523637j, var(E): 0.64240188
-0.0
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=1.18............. Loss: 0.19737100, mean(E): -21.75284162+0.01144938j, var(E): 0.88747685
-0.0
tensor(20.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=1.19............. Loss: 0.01894082, mean(E): -21.66279574+0.00793140j, var(E): 0.38751215
-0.0
tensor(20.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=1.19............. Loss: -0.48938973, mean(E): -21.58778298+0.00381585j, var(E): 1.21331905
-0.0
tensor(20.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=1.19............. Loss: 0.01445697, mean(E): -21.70523250-0.01230127j, var(E): 0.77345731
-0.0
tensor(20.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=1.19............. Loss: 0.34620396, mean(E): -21.64298562-0.01704201j, var(E): 1.27672325
-0.0
tensor(20.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=1.19............. Loss: -0.39469579, mean(E): -21.57804330-0.00909781j, var(E): 1.02417608
-0.0
tensor(20.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=1.19............. Loss: -0.37719190, mean(E): -21.52219178-0.00928674j, var(E): 0.92806180
-0.0
tensor(20.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=1.19............. Loss: 0.00208760, mean(E): -21.69895320+0.01731374j, var(E): 0.48305682
-0.0
tensor(20.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=1.19............. Loss: 0.01761849, mean(E): -21.53643428+0.00391279j, var(E): 1.68960314
-0.0
tensor(20.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=1.19............. Loss: -0.16113228, mean(E): -21.60492215-0.02137951j, var(E): 1.20902032
-0.0
tensor(20.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=1.18............. Loss: -0.33490810, mean(E): -21.69030262+0.00205100j, var(E): 1.24143639
-0.0
tensor(20.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=1.18............. Loss: -0.28830914, mean(E): -21.67742140+0.01632300j, var(E): 0.76310152
-0.0
tensor(20.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=1.18............. Loss: -0.24907351, mean(E): -21.54860556+0.01029722j, var(E): 1.48014829
-0.0
tensor(20.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=1.18............. Loss: 0.27124805, mean(E): -21.71657489+0.00301222j, var(E): 1.44512444
-0.0
tensor(20.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=1.19............. Loss: 0.53218270, mean(E): -21.84661200-0.00570094j, var(E): 1.22430115
-0.0
tensor(20.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=1.19............. Loss: -0.02378569, mean(E): -21.63876151-0.00297186j, var(E): 1.04755481
-0.0
tensor(20.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=1.19............. Loss: -0.75805721, mean(E): -21.51545665-0.01765940j, var(E): 1.06468437
-0.0
tensor(20.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=1.19............. Loss: 0.25980881, mean(E): -21.73070691+0.01910742j, var(E): 1.07789944
-0.0
tensor(20.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=1.19............. Loss: 0.51516081, mean(E): -21.76696920+0.00742883j, var(E): 0.85822235
-0.0
tensor(20.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=1.18............. Loss: -0.56045205, mean(E): -21.55077022-0.01912261j, var(E): 1.04422625
-0.0
tensor(20.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=1.18............. Loss: 0.08134434, mean(E): -21.70185782-0.00134482j, var(E): 1.32918613
-0.0
tensor(20.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=1.19............. Loss: 0.37284414, mean(E): -21.66578184+0.00197254j, var(E): 1.24076583
-0.0
tensor(20.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=1.19............. Loss: 0.33327897, mean(E): -21.73071895-0.00347421j, var(E): 0.86581107
-0.0
tensor(20.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=1.19............. Loss: -0.29286363, mean(E): -21.65197119+0.00737141j, var(E): 1.62737571
-0.0
tensor(20.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=1.19............. Loss: 0.16373593, mean(E): -21.68068660-0.01624841j, var(E): 1.22017177
-0.0
tensor(20.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=1.18............. Loss: -0.22681884, mean(E): -21.67278541-0.00635559j, var(E): 0.76281579
-0.0
tensor(20.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=1.19............. Loss: 0.39304559, mean(E): -21.74303202+0.00912858j, var(E): 1.53663674
-0.0
tensor(20.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=1.19............. Loss: -0.78156092, mean(E): -21.55805685-0.00921065j, var(E): 0.86632028
-0.0
tensor(20.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=1.19............. Loss: -0.16563340, mean(E): -21.66890037-0.02811935j, var(E): 1.20447278
-0.0
tensor(20.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=1.18............. Loss: 0.53876714, mean(E): -21.71063414+0.00456567j, var(E): 2.10709851
-0.0
tensor(20.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=1.18............. Loss: -0.31300424, mean(E): -21.56552564-0.00674336j, var(E): 1.13263463
-0.0
tensor(20.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=1.19............. Loss: 0.09067204, mean(E): -21.65478032-0.00426459j, var(E): 1.29281320
-0.0
tensor(20.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=1.19............. Loss: -0.10167765, mean(E): -21.64833677-0.00853054j, var(E): 0.65993101
-0.0
tensor(20.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=1.19............. Loss: -0.28980570, mean(E): -21.59377387+0.00368594j, var(E): 0.95011748
-0.0
tensor(20.9262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=1.19............. Loss: -0.45834100, mean(E): -21.65398703+0.01887702j, var(E): 1.18826798
-0.0
tensor(20.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=1.18............. Loss: 0.58283060, mean(E): -21.77216592+0.02726200j, var(E): 1.08148845
-0.0
tensor(20.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=1.18............. Loss: -0.30718888, mean(E): -21.64051709+0.00251086j, var(E): 0.71817726
-0.0
tensor(20.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=1.18............. Loss: -0.29746827, mean(E): -21.60418331-0.00288301j, var(E): 0.54272294
-0.0
tensor(20.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=1.19............. Loss: 0.29534311, mean(E): -21.76208880-0.00343371j, var(E): 0.80404521
-0.0
tensor(20.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=1.19............. Loss: -0.06672124, mean(E): -21.68225563-0.00214055j, var(E): 0.67746218
-0.0
tensor(20.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=1.18............. Loss: -0.12598125, mean(E): -21.72824289-0.01289551j, var(E): 0.72237504
-0.0
tensor(21.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=1.19............. Loss: -0.11645922, mean(E): -21.57545739-0.00537154j, var(E): 0.57897876
-0.0
tensor(21.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=1.19............. Loss: 0.10302660, mean(E): -21.71698665-0.00269480j, var(E): 1.07104997
-0.0
tensor(21.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=1.18............. Loss: -0.17224946, mean(E): -21.56288515+0.00839314j, var(E): 1.26932812
-0.0
tensor(21.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=1.19............. Loss: -0.13984461, mean(E): -21.64622618-0.00230617j, var(E): 0.46144212
-0.0
tensor(21.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=1.18............. Loss: -0.22371199, mean(E): -21.69670961-0.00700242j, var(E): 1.00424705
-0.0
tensor(21.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=1.18............. Loss: -0.32224108, mean(E): -21.66028621-0.00653455j, var(E): 0.49300391
-0.0
tensor(21.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=1.19............. Loss: -0.15843313, mean(E): -21.66303910+0.01329540j, var(E): 0.57643291
-0.0
tensor(21.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=1.19............. Loss: -0.42039850, mean(E): -21.66205757-0.00451552j, var(E): 0.89209618
-0.0
tensor(21.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=1.19............. Loss: -0.27633575, mean(E): -21.63174367+0.02292926j, var(E): 0.95061752
-0.0
tensor(21.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=1.19............. Loss: 0.44161359, mean(E): -21.79101670+0.01961835j, var(E): 0.82708534
-0.0
tensor(21.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=1.19............. Loss: 0.71857935, mean(E): -21.76858491+0.01921110j, var(E): 0.98251520
-0.0
tensor(21.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=1.19............. Loss: -0.50897976, mean(E): -21.52671939+0.01166280j, var(E): 1.06803225
-0.0
tensor(21.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=1.19............. Loss: 0.00040293, mean(E): -21.66895884-0.00299501j, var(E): 1.38730253
-0.0
tensor(21.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=1.19............. Loss: -0.07032057, mean(E): -21.68405818-0.01051948j, var(E): 1.35139756
-0.0
tensor(21.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=1.19............. Loss: -0.76472468, mean(E): -21.65296609-0.02545860j, var(E): 1.07594049
-0.0
tensor(21.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=1.18............. Loss: 0.08309979, mean(E): -21.68816250-0.03002235j, var(E): 0.69178399
-0.0
tensor(21.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=1.19............. Loss: -0.13568062, mean(E): -21.61513919-0.00165625j, var(E): 0.60582796
-0.0
tensor(21.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=1.19............. Loss: -0.01398148, mean(E): -21.65322281+0.00695168j, var(E): 0.74183633
-0.0
tensor(21.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=1.19............. Loss: 0.15950203, mean(E): -21.69417015+0.01848988j, var(E): 0.88595249
-0.0
tensor(21.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=1.19............. Loss: 0.03981576, mean(E): -21.71962930+0.01121081j, var(E): 0.57448228
-0.0
tensor(21.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=1.19............. Loss: -0.27871888, mean(E): -21.59689708-0.00387914j, var(E): 0.94419829
-0.0
tensor(21.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=1.19............. Loss: -0.01349977, mean(E): -21.66869226+0.01436844j, var(E): 0.93305380
-0.0
tensor(21.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=1.19............. Loss: -0.18488505, mean(E): -21.60543733-0.00213781j, var(E): 1.47513698
-0.0
tensor(21.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=1.19............. Loss: -0.34520520, mean(E): -21.62379322+0.01977416j, var(E): 1.23039582
-0.0
tensor(21.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=1.19............. Loss: -0.35751265, mean(E): -21.58662257-0.00105862j, var(E): 0.76901716
-0.0
tensor(21.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=1.18............. Loss: 0.52690728, mean(E): -21.79915365+0.02371027j, var(E): 0.75626453
-0.0
tensor(21.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=1.19............. Loss: 0.24594507, mean(E): -21.68077536-0.00496520j, var(E): 1.51577316
-0.0
tensor(21.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=1.19............. Loss: -0.50893413, mean(E): -21.65293100-0.00835235j, var(E): 1.16789873
-0.0
tensor(21.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=1.18............. Loss: -0.28299393, mean(E): -21.66648649-0.00313980j, var(E): 0.88752586
-0.0
tensor(21.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=1.18............. Loss: -0.18621030, mean(E): -21.58647881-0.00037068j, var(E): 0.61356207
-0.0
tensor(21.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=1.19............. Loss: 0.00907188, mean(E): -21.72833768-0.01115320j, var(E): 0.77909554
-0.0
tensor(21.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=1.19............. Loss: 0.08175435, mean(E): -21.70304894-0.00467605j, var(E): 0.65872067
-0.0
tensor(21.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=1.19............. Loss: 0.45409495, mean(E): -21.71020837-0.00999235j, var(E): 0.70125149
-0.0
tensor(21.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=1.19............. Loss: -0.18232236, mean(E): -21.65022276+0.00267524j, var(E): 1.30645882
-0.0
tensor(21.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=1.19............. Loss: -0.45230924, mean(E): -21.64224517+0.01037698j, var(E): 0.94912689
-0.0
tensor(21.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=1.19............. Loss: -0.00539263, mean(E): -21.68888722-0.00056890j, var(E): 0.75896135
-0.0
tensor(21.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=1.19............. Loss: 0.06898007, mean(E): -21.72921727-0.02160285j, var(E): 0.63737424
-0.0
tensor(21.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=1.19............. Loss: -0.41150984, mean(E): -21.63257246+0.00429680j, var(E): 1.00419748
-0.0
tensor(21.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=1.19............. Loss: 0.03171130, mean(E): -21.63877949-0.00597096j, var(E): 0.96666461
-0.0
tensor(21.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=1.18............. Loss: 0.27802032, mean(E): -21.68069175+0.00666665j, var(E): 0.46326472
-0.0
tensor(21.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=1.19............. Loss: -0.02229138, mean(E): -21.65182485+0.01752153j, var(E): 0.57794143
-0.0
tensor(21.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=1.19............. Loss: 1.04103830, mean(E): -21.83110917-0.00734002j, var(E): 2.45320864
-0.0
tensor(21.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=1.18............. Loss: -1.03303172, mean(E): -21.52654071-0.01032667j, var(E): 1.39252179
-0.0
tensor(21.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=1.19............. Loss: -0.31291978, mean(E): -21.57617345-0.00330710j, var(E): 0.68166083
-0.0
tensor(21.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=1.18............. Loss: 0.41110059, mean(E): -21.74226371-0.01721504j, var(E): 1.35894881
-0.0
tensor(21.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=1.19............. Loss: -0.01607968, mean(E): -21.66917482-0.00404525j, var(E): 1.58281364
-0.0
tensor(21.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=1.18............. Loss: -0.37188017, mean(E): -21.65528502+0.00056802j, var(E): 0.59286775
-0.0
tensor(21.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=1.18............. Loss: -0.96625726, mean(E): -21.46892600-0.01852784j, var(E): 1.22147468
-0.0
tensor(21.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=1.18............. Loss: 0.79791752, mean(E): -21.79359217+0.00771212j, var(E): 1.48722270
-0.0
tensor(21.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=1.18............. Loss: -0.71441731, mean(E): -21.66419568+0.00926480j, var(E): 1.19268594
-0.0
tensor(21.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=1.18............. Loss: -0.21230031, mean(E): -21.63947574-0.00123148j, var(E): 0.90081902
-0.0
tensor(21.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=1.18............. Loss: -0.17995099, mean(E): -21.68033180+0.01539199j, var(E): 0.69304220
-0.0
tensor(21.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=1.18............. Loss: -0.45951589, mean(E): -21.58536778+0.01078651j, var(E): 1.29475524
-0.0
tensor(21.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=1.19............. Loss: 0.24201790, mean(E): -21.73426506+0.00226329j, var(E): 0.99129191
-0.0
tensor(21.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=1.18............. Loss: -0.35396443, mean(E): -21.54827706+0.00589088j, var(E): 0.98476956
-0.0
tensor(21.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=1.18............. Loss: -0.04749914, mean(E): -21.68809213+0.00406542j, var(E): 0.79857196
-0.0
tensor(21.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=1.18............. Loss: -0.43505368, mean(E): -21.58883665+0.00413463j, var(E): 1.56310887
-0.0
tensor(21.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=1.18............. Loss: -0.10229735, mean(E): -21.65914347-0.00107719j, var(E): 1.42247838
-0.0
tensor(21.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=1.18............. Loss: -0.42645225, mean(E): -21.66177893+0.00485472j, var(E): 0.66684217
-0.0
tensor(21.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=1.19............. Loss: -0.17122098, mean(E): -21.74202466-0.01090810j, var(E): 0.44581888
-0.0
tensor(22.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=1.18............. Loss: 0.82276197, mean(E): -21.81407898+0.00858458j, var(E): 2.14379752
-0.0
tensor(22.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=1.18............. Loss: -0.38699401, mean(E): -21.51904717+0.01455031j, var(E): 1.31180502
-0.0
tensor(22.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=1.19............. Loss: -0.13049000, mean(E): -21.64301766+0.00756398j, var(E): 1.06930114
-0.0
tensor(22.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=1.18............. Loss: 0.67111515, mean(E): -21.80282196+0.01300348j, var(E): 1.16194778
-0.0
tensor(22.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=1.19............. Loss: -0.16865287, mean(E): -21.69562052-0.02203981j, var(E): 0.79349076
-0.0
tensor(22.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=1.19............. Loss: -0.21593864, mean(E): -21.74159955-0.00063868j, var(E): 1.20501090
-0.0
tensor(22.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=1.18............. Loss: -0.24348615, mean(E): -21.71424088-0.00553215j, var(E): 0.67178158
-0.0
tensor(22.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=1.19............. Loss: -0.66590885, mean(E): -21.53323596+0.01225689j, var(E): 1.05137487
-0.0
tensor(22.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=1.18............. Loss: -0.33563846, mean(E): -21.76268687+0.00877887j, var(E): 0.99401760
-0.0
tensor(22.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=1.19............. Loss: 0.53039808, mean(E): -21.73456171+0.00714942j, var(E): 1.16256026
-0.0
tensor(22.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=1.19............. Loss: -0.25457254, mean(E): -21.64453806+0.00071769j, var(E): 0.70170615
-0.0
tensor(22.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=1.19............. Loss: -0.64506878, mean(E): -21.56358710+0.01685940j, var(E): 0.76454944
-0.0
tensor(22.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=1.19............. Loss: -0.14125457, mean(E): -21.67306558-0.00433210j, var(E): 1.09566570
-0.0
tensor(22.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=1.19............. Loss: -0.07925701, mean(E): -21.67172074+0.00350583j, var(E): 0.97206937
-0.0
tensor(22.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=1.19............. Loss: -0.30339170, mean(E): -21.67256682-0.00458359j, var(E): 1.04479508
-0.0
tensor(22.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=1.19............. Loss: 0.42438620, mean(E): -21.73883287-0.00399810j, var(E): 1.03276876
-0.0
tensor(22.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=1.18............. Loss: -0.03596564, mean(E): -21.68503684+0.00958283j, var(E): 0.46548407
-0.0
tensor(22.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=1.18............. Loss: -0.04028056, mean(E): -21.65978042-0.00602752j, var(E): 0.56067616
-0.0
tensor(22.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=1.19............. Loss: -0.29192540, mean(E): -21.65185234+0.00705431j, var(E): 0.78203134
-0.0
tensor(22.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=1.19............. Loss: 0.01598753, mean(E): -21.68322964+0.00195322j, var(E): 0.53033862
-0.0
tensor(22.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=1.19............. Loss: -0.02918227, mean(E): -21.60817830+0.00123043j, var(E): 0.80979920
-0.0
tensor(22.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=1.19............. Loss: 0.07024673, mean(E): -21.66298662-0.00469865j, var(E): 0.68995208
-0.0
tensor(22.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=1.18............. Loss: 1.08358078, mean(E): -21.77240900+0.01175828j, var(E): 2.70972494
-0.0
tensor(22.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=1.19............. Loss: -0.54813468, mean(E): -21.58050577-0.01282863j, var(E): 0.79706514
-0.0
tensor(22.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=1.19............. Loss: 0.19833027, mean(E): -21.68870701+0.02015530j, var(E): 1.06118135
-0.0
tensor(22.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=1.19............. Loss: 0.09804081, mean(E): -21.72865184-0.00758230j, var(E): 0.51536429
-0.0
tensor(22.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=1.18............. Loss: 0.57217165, mean(E): -21.76256670+0.00657675j, var(E): 0.86193234
-0.0
tensor(22.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=1.19............. Loss: -0.46258400, mean(E): -21.58498628-0.01898449j, var(E): 0.58169591
-0.0
tensor(22.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=1.19............. Loss: -0.10277356, mean(E): -21.64597657+0.00051654j, var(E): 0.75823119
-0.0
tensor(22.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=1.19............. Loss: 0.64520429, mean(E): -21.82127178-0.00291321j, var(E): 1.12708474
-0.0
tensor(22.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=1.19............. Loss: -0.09041567, mean(E): -21.60730566-0.00108546j, var(E): 0.49264718
-0.0
tensor(22.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=1.19............. Loss: 0.21660904, mean(E): -21.76509165-0.00356688j, var(E): 0.67865900
-0.0
tensor(22.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=1.19............. Loss: -0.15212548, mean(E): -21.68597089-0.00384508j, var(E): 0.80394600
-0.0
tensor(22.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=1.18............. Loss: -0.57210186, mean(E): -21.62581313+0.00669039j, var(E): 0.91281374
-0.0
tensor(22.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=1.18............. Loss: -0.50578645, mean(E): -21.62259804+0.00304328j, var(E): 0.99223093
-0.0
tensor(22.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=1.19............. Loss: -0.03858014, mean(E): -21.73298715+0.00132259j, var(E): 0.66696801
-0.0
tensor(22.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=1.19............. Loss: -0.17144791, mean(E): -21.66664169-0.00750170j, var(E): 0.59211183
-0.0
tensor(22.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=1.18............. Loss: -0.63211614, mean(E): -21.66756486-0.00215369j, var(E): 0.75153837
-0.0
tensor(22.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=1.19............. Loss: -0.04811606, mean(E): -21.69287694-0.01359273j, var(E): 0.63462414
-0.0
tensor(22.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=1.19............. Loss: -0.33325871, mean(E): -21.67268329+0.01201896j, var(E): 0.72594789
-0.0
tensor(22.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=1.19............. Loss: -0.50847710, mean(E): -21.61844894-0.00336908j, var(E): 1.03544348
-0.0
tensor(22.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=1.18............. Loss: 0.30512595, mean(E): -21.79716915+0.02221045j, var(E): 0.74595478
-0.0
tensor(22.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=1.18............. Loss: 0.17088244, mean(E): -21.82023356-0.00399914j, var(E): 0.45595812
-0.0
tensor(22.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=1.18............. Loss: -0.64005828, mean(E): -21.60103189+0.00166991j, var(E): 0.56441806
-0.0
tensor(22.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=1.18............. Loss: -0.21943002, mean(E): -21.71287854+0.00539380j, var(E): 0.52220411
-0.0
tensor(22.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=1.18............. Loss: 0.23424583, mean(E): -21.76661962-0.00340155j, var(E): 0.28032708
-0.0
tensor(22.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=1.19............. Loss: -0.38165448, mean(E): -21.63401730+0.01277800j, var(E): 1.21028089
-0.0
tensor(22.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=1.19............. Loss: -0.17238651, mean(E): -21.69641957-0.00342447j, var(E): 1.20232542
-0.0
tensor(22.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=1.19............. Loss: -0.14927262, mean(E): -21.74897370-0.01422670j, var(E): 0.71369125
-0.0
tensor(22.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=1.19............. Loss: -0.12831463, mean(E): -21.69876826-0.00628566j, var(E): 0.86907786
-0.0
tensor(22.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=1.18............. Loss: -0.02677616, mean(E): -21.64754662+0.00046586j, var(E): 0.93893516
-0.0
tensor(22.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=1.19............. Loss: 0.63731484, mean(E): -21.77249478+0.01709428j, var(E): 0.84878266
-0.0
tensor(22.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=1.19............. Loss: 0.02848388, mean(E): -21.65426103+0.00084440j, var(E): 0.91613201
-0.0
tensor(22.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=1.18............. Loss: 0.24549785, mean(E): -21.72097491-0.01531454j, var(E): 0.34011326
-0.0
tensor(22.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=1.19............. Loss: 0.03333404, mean(E): -21.61819587+0.00007299j, var(E): 0.50404915
-0.0
tensor(22.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=1.18............. Loss: 0.09364443, mean(E): -21.75624652+0.00874617j, var(E): 0.90172644
-0.0
tensor(22.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=1.18............. Loss: -0.28387245, mean(E): -21.65065025-0.00334070j, var(E): 0.51833082
-0.0
tensor(22.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=1.19............. Loss: 0.17339830, mean(E): -21.78876839-0.00363143j, var(E): 0.68343778
-0.0
tensor(22.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=1.18............. Loss: -0.42289175, mean(E): -21.68684878+0.00470678j, var(E): 1.06194996
-0.0
tensor(22.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=1.19............. Loss: -0.35785713, mean(E): -21.66762843+0.00476348j, var(E): 1.11754347
-0.0
tensor(22.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=1.19............. Loss: -0.55155944, mean(E): -21.61148850+0.00453313j, var(E): 0.71735560
-0.0
tensor(23.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=1.19............. Loss: 0.39734469, mean(E): -21.77850572+0.00428921j, var(E): 1.34667495
-0.0
tensor(23.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=1.19............. Loss: -0.06792659, mean(E): -21.71107994-0.00332050j, var(E): 1.37497037
-0.0
tensor(23.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=1.19............. Loss: 0.02921498, mean(E): -21.57480497+0.01039322j, var(E): 1.00635758
-0.0
tensor(23.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=1.18............. Loss: -0.42231761, mean(E): -21.59349704-0.00566958j, var(E): 0.64203534
-0.0
tensor(23.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=1.18............. Loss: -0.10795691, mean(E): -21.64686114+0.01414238j, var(E): 0.66440037
-0.0
tensor(23.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=1.18............. Loss: 0.10749480, mean(E): -21.62789209+0.01820488j, var(E): 0.78823656
-0.0
tensor(23.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=1.19............. Loss: -0.16765305, mean(E): -21.64510496+0.00913604j, var(E): 0.62032125
-0.0
tensor(23.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=1.19............. Loss: 0.30704880, mean(E): -21.73420206+0.00440806j, var(E): 0.84320239
-0.0
tensor(23.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=1.19............. Loss: -0.31493809, mean(E): -21.69070562+0.00230048j, var(E): 0.96208147
-0.0
tensor(23.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=1.19............. Loss: 0.31812904, mean(E): -21.68967622-0.00624918j, var(E): 0.44729764
-0.0
tensor(23.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=1.18............. Loss: -0.26808517, mean(E): -21.61553387-0.00068579j, var(E): 0.62212404
-0.0
tensor(23.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=1.19............. Loss: 0.01216413, mean(E): -21.76748129+0.00054301j, var(E): 0.55758442
-0.0
tensor(23.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=1.19............. Loss: 0.22330971, mean(E): -21.74755326+0.00142543j, var(E): 0.78700697
-0.0
tensor(23.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=1.19............. Loss: -0.04771342, mean(E): -21.68682372-0.00466779j, var(E): 0.82656140
-0.0
tensor(23.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=1.18............. Loss: -0.37277078, mean(E): -21.63831825+0.00938099j, var(E): 0.58199486
-0.0
tensor(23.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=1.18............. Loss: 0.04351334, mean(E): -21.73042505+0.00360919j, var(E): 0.66155744
-0.0
tensor(23.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=1.19............. Loss: 0.05576685, mean(E): -21.75175695+0.00311347j, var(E): 0.96303951
-0.0
tensor(23.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=1.18............. Loss: 0.22624994, mean(E): -21.70894459-0.00068967j, var(E): 0.58067617
-0.0
tensor(23.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=1.18............. Loss: 0.09016563, mean(E): -21.74273806+0.00127217j, var(E): 0.94688561
-0.0
tensor(23.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=1.18............. Loss: -0.19932403, mean(E): -21.70899981+0.00873942j, var(E): 0.79752150
-0.0
tensor(23.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=1.19............. Loss: -0.21875833, mean(E): -21.69666567+0.01065974j, var(E): 0.56699809
-0.0
tensor(23.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=1.19............. Loss: -0.40303291, mean(E): -21.68113598+0.01104358j, var(E): 1.07587504
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=1.18............. Loss: -0.28582134, mean(E): -21.65462452-0.00202086j, var(E): 0.67445531
-0.0
tensor(23.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=1.19............. Loss: 0.03120664, mean(E): -21.74165104-0.00316536j, var(E): 0.93584998
-0.0
tensor(23.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=1.18............. Loss: 0.87464720, mean(E): -21.87644827-0.00451999j, var(E): 1.20982821
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=1.19............. Loss: 0.09567052, mean(E): -21.70078864-0.00324427j, var(E): 0.73414945
-0.0
tensor(23.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=1.19............. Loss: -0.24079445, mean(E): -21.66995859+0.00706957j, var(E): 0.97200545
-0.0
tensor(23.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=1.18............. Loss: 0.11767787, mean(E): -21.67057473-0.01728391j, var(E): 1.03082670
-0.0
tensor(23.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=1.19............. Loss: 0.06727909, mean(E): -21.77061666-0.00022857j, var(E): 1.02067618
-0.0
tensor(23.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=1.18............. Loss: 0.14144448, mean(E): -21.76223839+0.00907579j, var(E): 0.69099817
-0.0
tensor(23.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=1.19............. Loss: 0.02882306, mean(E): -21.67529024-0.00117458j, var(E): 0.48468145
-0.0
tensor(23.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=1.19............. Loss: -0.03077508, mean(E): -21.76129621-0.01515849j, var(E): 0.60880014
-0.0
tensor(23.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=1.19............. Loss: 0.89894878, mean(E): -21.81730675+0.00488940j, var(E): 1.00644150
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=1.19............. Loss: 0.28036810, mean(E): -21.78953694+0.00457758j, var(E): 1.62098595
-0.0
tensor(23.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=1.19............. Loss: -0.14410582, mean(E): -21.61250538-0.00337203j, var(E): 1.01334107
-0.0
tensor(23.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=1.19............. Loss: -0.20544406, mean(E): -21.64127890-0.00909199j, var(E): 1.19585187
-0.0
tensor(23.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=1.19............. Loss: 0.00094197, mean(E): -21.67836417-0.00651333j, var(E): 0.82413968
-0.0
tensor(23.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=1.19............. Loss: 0.51919112, mean(E): -21.75365347+0.00177361j, var(E): 1.12574956
-0.0
tensor(23.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=1.19............. Loss: -0.05274526, mean(E): -21.65357649-0.00141189j, var(E): 0.58484905
-0.0
tensor(23.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=1.19............. Loss: 0.05556608, mean(E): -21.69919763+0.00781160j, var(E): 0.53218756
-0.0
tensor(23.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=1.19............. Loss: -0.30949822, mean(E): -21.68354541-0.00035504j, var(E): 0.73814257
-0.0
tensor(23.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=1.19............. Loss: -0.11201013, mean(E): -21.71320163-0.00679863j, var(E): 0.95653585
-0.0
tensor(23.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=1.18............. Loss: -0.34706111, mean(E): -21.67264782+0.00483820j, var(E): 0.72424387
-0.0
tensor(23.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=1.19............. Loss: -0.12237515, mean(E): -21.71187761-0.00475137j, var(E): 1.06312415
-0.0
tensor(23.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=1.18............. Loss: -0.02278326, mean(E): -21.70001461+0.00538395j, var(E): 0.58058865
-0.0
tensor(23.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=1.19............. Loss: 0.08817626, mean(E): -21.71240765-0.00296437j, var(E): 0.72000236
-0.0
tensor(23.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=1.18............. Loss: -0.04964621, mean(E): -21.67473957-0.00112024j, var(E): 0.67232840
-0.0
tensor(23.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=1.18............. Loss: 0.03480234, mean(E): -21.69548262-0.01114012j, var(E): 1.08435211
-0.0
tensor(23.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=1.19............. Loss: -0.02888861, mean(E): -21.69009390-0.00427752j, var(E): 0.43556479
-0.0
tensor(23.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=1.19............. Loss: -0.41076050, mean(E): -21.58298401+0.00397704j, var(E): 1.03387756
-0.0
tensor(23.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=1.19............. Loss: 0.22680928, mean(E): -21.75178654-0.00061018j, var(E): 0.59573723
-0.0
tensor(23.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=1.18............. Loss: 0.19400948, mean(E): -21.72810453-0.00438985j, var(E): 0.55201227
-0.0
tensor(23.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=1.18............. Loss: 0.33009916, mean(E): -21.72997121-0.00107304j, var(E): 1.38106847
-0.0
tensor(23.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=1.19............. Loss: 0.43944582, mean(E): -21.78635357+0.00832702j, var(E): 0.66672925
-0.0
tensor(23.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=1.19............. Loss: -0.23768914, mean(E): -21.70638776+0.00127230j, var(E): 0.52461909
-0.0
tensor(23.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=1.19............. Loss: -0.12431392, mean(E): -21.64727433+0.00409635j, var(E): 0.51890543
-0.0
tensor(23.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=1.19............. Loss: -0.08490368, mean(E): -21.69874934+0.00244229j, var(E): 0.56852939
-0.0
tensor(23.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=1.18............. Loss: 0.15047828, mean(E): -21.74174362-0.00063612j, var(E): 0.68926218
-0.0
tensor(23.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=1.19............. Loss: 0.18474538, mean(E): -21.70156386-0.01083197j, var(E): 0.61364691
-0.0
tensor(23.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=1.18............. Loss: 0.30446291, mean(E): -21.73463635+0.01568547j, var(E): 0.99802257
-0.0
tensor(23.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=1.19............. Loss: 0.00700219, mean(E): -21.65966228+0.00093377j, var(E): 0.44020625
-0.0
tensor(23.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=1.19............. Loss: -0.06503239, mean(E): -21.72690632-0.01602086j, var(E): 0.92007697
-0.0
tensor(23.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=1.19............. Loss: -0.16961906, mean(E): -21.74106196-0.00866886j, var(E): 1.14496373
-0.0
tensor(23.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=1.18............. Loss: -0.07903215, mean(E): -21.71846459-0.00543319j, var(E): 0.52624524
-0.0
tensor(23.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=1.19............. Loss: -0.36252962, mean(E): -21.70407494-0.00086869j, var(E): 0.55226015
-0.0
tensor(23.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=1.19............. Loss: 0.00708455, mean(E): -21.72550352-0.00455590j, var(E): 0.49848151
-0.0
tensor(23.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=1.19............. Loss: -0.31056925, mean(E): -21.69034727+0.00027919j, var(E): 1.33928479
-0.0
tensor(23.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=1.19............. Loss: 0.39631360, mean(E): -21.85383101-0.00204791j, var(E): 0.51372724
-0.0
tensor(23.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=1.19............. Loss: -0.30609653, mean(E): -21.72251251-0.00056589j, var(E): 0.91766506
-0.0
tensor(23.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=1.19............. Loss: 0.12386713, mean(E): -21.71355151+0.00574024j, var(E): 0.64614314
-0.0
tensor(24.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=1.19............. Loss: -0.42001887, mean(E): -21.68249064+0.00461979j, var(E): 0.84429080
-0.0
tensor(24.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=1.18............. Loss: -0.13538306, mean(E): -21.66937012+0.00778152j, var(E): 0.59043893
-0.0
tensor(24.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=1.18............. Loss: -0.87003955, mean(E): -21.59329319-0.00546109j, var(E): 0.85907008
-0.0
tensor(24.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=1.18............. Loss: 0.18553148, mean(E): -21.78267886+0.00828492j, var(E): 0.76171831
-0.0
tensor(24.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=1.19............. Loss: 0.09860940, mean(E): -21.79081134+0.00615912j, var(E): 0.55038493
-0.0
tensor(24.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=1.18............. Loss: -0.20592422, mean(E): -21.66121867+0.01274811j, var(E): 1.44999440
-0.0
tensor(24.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=1.18............. Loss: 0.21953535, mean(E): -21.78133506+0.01315515j, var(E): 0.57684874
-0.0
tensor(24.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=1.19............. Loss: 0.59641242, mean(E): -21.78664942-0.00214913j, var(E): 0.81871628
-0.0
tensor(24.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=1.19............. Loss: -0.10664238, mean(E): -21.67253445-0.00179036j, var(E): 0.61704864
-0.0
tensor(24.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=1.18............. Loss: 0.05767954, mean(E): -21.69737531+0.00658597j, var(E): 0.42854259
-0.0
tensor(24.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=1.18............. Loss: 0.11155104, mean(E): -21.68419783-0.00250599j, var(E): 0.45997078
-0.0
tensor(24.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=1.18............. Loss: 0.39505507, mean(E): -21.79438876+0.00483812j, var(E): 0.84202912
-0.0
tensor(24.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=1.18............. Loss: 0.06595077, mean(E): -21.74463561-0.01114030j, var(E): 0.31354184
-0.0
tensor(24.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=1.18............. Loss: 0.42833359, mean(E): -21.80113135+0.00922610j, var(E): 0.50475085
-0.0
tensor(24.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=1.19............. Loss: 0.40860346, mean(E): -21.71744665+0.00617629j, var(E): 0.57237140
-0.0
tensor(24.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=1.19............. Loss: 0.44491187, mean(E): -21.75717808+0.00885175j, var(E): 0.60524161
-0.0
tensor(24.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=1.19............. Loss: -0.03195536, mean(E): -21.63203223-0.00085112j, var(E): 0.47878838
-0.0
tensor(24.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=1.19............. Loss: -0.21110258, mean(E): -21.67096567-0.00203938j, var(E): 0.71905221
-0.0
tensor(24.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=1.18............. Loss: -0.51764718, mean(E): -21.56783770-0.00335921j, var(E): 0.84687740
-0.0
tensor(24.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=1.19............. Loss: -0.09744185, mean(E): -21.69842637+0.00322230j, var(E): 0.53814254
-0.0
tensor(24.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=1.18............. Loss: 0.55657239, mean(E): -21.79819622-0.00841716j, var(E): 0.40099796
-0.0
tensor(24.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=1.19............. Loss: 0.21215875, mean(E): -21.82276078-0.00193846j, var(E): 0.75188199
-0.0
tensor(24.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=1.18............. Loss: -0.73783095, mean(E): -21.64730975+0.00229391j, var(E): 1.45927378
-0.0
tensor(24.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=1.19............. Loss: -0.07944441, mean(E): -21.70687298-0.00367727j, var(E): 1.04693608
-0.0
tensor(24.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=1.18............. Loss: 0.38246302, mean(E): -21.70074734-0.00080496j, var(E): 0.44288730
-0.0
tensor(24.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=1.19............. Loss: 0.01117960, mean(E): -21.72422944+0.01238093j, var(E): 1.06706288
-0.0
tensor(24.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=1.19............. Loss: 0.14842111, mean(E): -21.77190372-0.00181731j, var(E): 0.41470771
-0.0
tensor(24.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=1.19............. Loss: 0.22166810, mean(E): -21.67545438+0.00469610j, var(E): 2.08502002
-0.0
tensor(24.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=1.18............. Loss: 0.96734965, mean(E): -21.73692049+0.00303263j, var(E): 6.87098540
-0.0
tensor(24.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=1.19............. Loss: 0.23392569, mean(E): -21.68805200+0.00461161j, var(E): 1.17704395
-0.0
tensor(24.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=1.18............. Loss: 0.00385717, mean(E): -21.69953016-0.00379804j, var(E): 0.40864669
-0.0
tensor(24.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=1.18............. Loss: 0.05399104, mean(E): -21.72014499-0.00899310j, var(E): 0.38622197
-0.0
tensor(24.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=1.18............. Loss: 0.27887957, mean(E): -21.79968720-0.00354988j, var(E): 0.65073865
-0.0
tensor(24.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=1.19............. Loss: 0.14623493, mean(E): -21.77263173+0.00430520j, var(E): 0.71731838
-0.0
tensor(24.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=1.19............. Loss: -0.26591601, mean(E): -21.70946857-0.00164112j, var(E): 0.64108951
-0.0
tensor(24.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=1.19............. Loss: 0.33818850, mean(E): -21.75284962-0.00415706j, var(E): 0.44549929
-0.0
tensor(24.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=1.19............. Loss: -0.40103397, mean(E): -21.66965117+0.00446059j, var(E): 0.81952362
-0.0
tensor(24.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=1.18............. Loss: -0.18323415, mean(E): -21.69221180+0.00110543j, var(E): 0.29149729
-0.0
tensor(24.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=1.18............. Loss: 0.53246761, mean(E): -21.70389721+0.00216478j, var(E): 0.54609224
-0.0
tensor(24.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=1.19............. Loss: -0.26603866, mean(E): -21.68048120+0.00009883j, var(E): 0.58243125
-0.0
tensor(24.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=1.18............. Loss: 0.37182788, mean(E): -21.75823382+0.00252269j, var(E): 0.59410263
-0.0
tensor(24.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=1.18............. Loss: 0.10285725, mean(E): -21.69819268+0.00216450j, var(E): 0.40020437
-0.0
tensor(24.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=1.19............. Loss: 0.61794620, mean(E): -21.83655556-0.00548008j, var(E): 0.79597535
-0.0
tensor(24.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=1.18............. Loss: -0.37804909, mean(E): -21.64485830+0.00644128j, var(E): 0.51364232
-0.0
tensor(24.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=1.18............. Loss: 0.19822421, mean(E): -21.79485808+0.00139424j, var(E): 0.49265873
-0.0
tensor(24.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=1.18............. Loss: -0.34871667, mean(E): -21.64255596+0.00377133j, var(E): 0.60269525
-0.0
tensor(24.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=1.19............. Loss: -0.18876927, mean(E): -21.72808827+0.00085566j, var(E): 0.43279954
-0.0
tensor(24.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=1.18............. Loss: 0.23961755, mean(E): -21.78845143+0.01079557j, var(E): 1.30582867
-0.0
tensor(24.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=1.18............. Loss: 0.11356571, mean(E): -21.73484770-0.00362337j, var(E): 0.93308449
-0.0
tensor(24.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=1.19............. Loss: -0.05524194, mean(E): -21.75060743-0.00135195j, var(E): 0.46485975
-0.0
tensor(24.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=1.18............. Loss: -0.58948373, mean(E): -21.56363434+0.00051196j, var(E): 0.59131785
-0.0
tensor(24.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=1.19............. Loss: -0.11858062, mean(E): -21.69402695+0.00616309j, var(E): 0.38323995
-0.0
tensor(24.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=1.19............. Loss: -0.17146581, mean(E): -21.72421559+0.00160163j, var(E): 0.50547588
-0.0
tensor(24.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=1.18............. Loss: 0.22450340, mean(E): -21.72835992-0.00447155j, var(E): 0.58767373
-0.0
tensor(24.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=1.19............. Loss: 0.04235976, mean(E): -21.76270516-0.00290663j, var(E): 0.34080572
-0.0
tensor(24.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=1.19............. Loss: 0.40425365, mean(E): -21.82192201+0.00492936j, var(E): 0.86522037
-0.0
tensor(24.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=1.19............. Loss: -0.04684761, mean(E): -21.70644075-0.00609799j, var(E): 0.37693883
-0.0
tensor(24.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=1.19............. Loss: -0.23974673, mean(E): -21.68134660+0.00266435j, var(E): 0.65987873
-0.0
tensor(24.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=1.18............. Loss: -0.22854142, mean(E): -21.71553053+0.00579286j, var(E): 0.45498083
-0.0
tensor(24.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=1.18............. Loss: -0.29229909, mean(E): -21.68847176+0.00203632j, var(E): 0.82261510
-0.0
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=1.19............. Loss: 0.22487126, mean(E): -21.78409681-0.00050278j, var(E): 0.40424550
-0.0
tensor(24.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=1.19............. Loss: -0.57851747, mean(E): -21.64915091+0.00199338j, var(E): 0.62338515
-0.0
tensor(24.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=1.18............. Loss: -0.23330350, mean(E): -21.65612150-0.00224006j, var(E): 0.35082816
-0.0
tensor(24.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=1.19............. Loss: -0.06774290, mean(E): -21.74614738-0.00327201j, var(E): 0.45875694
-0.0
tensor(24.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=1.18............. Loss: -0.66349593, mean(E): -21.60852153-0.00110170j, var(E): 1.03588066
-0.0
tensor(24.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=1.18............. Loss: -0.13319943, mean(E): -21.71800699+0.00755803j, var(E): 0.75735773
-0.0
tensor(24.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=1.19............. Loss: -0.16360472, mean(E): -21.68628786+0.00110168j, var(E): 0.61316045
-0.0
tensor(24.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=1.19............. Loss: 0.44916667, mean(E): -21.82017465-0.00371277j, var(E): 0.79927021
-0.0
tensor(24.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=1.19............. Loss: 0.05367679, mean(E): -21.69461571-0.00802380j, var(E): 0.57212321
-0.0
tensor(24.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=1.19............. Loss: -0.23894503, mean(E): -21.62813384-0.00092794j, var(E): 0.53404548
-0.0
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=1.18............. Loss: 0.03292190, mean(E): -21.76383642-0.00302033j, var(E): 0.56473252
-0.0
tensor(24.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=1.18............. Loss: -0.15280806, mean(E): -21.76024640+0.00281181j, var(E): 0.33618845
-0.0
tensor(24.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=1.19............. Loss: 0.30001673, mean(E): -21.74680897+0.00226395j, var(E): 0.90829092
-0.0
tensor(24.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=1.19............. Loss: -0.05342809, mean(E): -21.70070586+0.00819737j, var(E): 0.41580598
-0.0
tensor(24.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=1.18............. Loss: 0.27460833, mean(E): -21.78556732+0.00032446j, var(E): 0.49267019
-0.0
tensor(24.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=1.19............. Loss: 0.11249149, mean(E): -21.70493450-0.00738338j, var(E): 0.65004872
-0.0
tensor(24.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=1.19............. Loss: -0.40405477, mean(E): -21.61819425-0.00224281j, var(E): 0.53236186
-0.0
tensor(24.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=1.19............. Loss: -0.22775125, mean(E): -21.69745166+0.00049190j, var(E): 0.38459221
-0.0
tensor(24.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=1.19............. Loss: 0.05671165, mean(E): -21.79280014+0.00548780j, var(E): 0.34105146
-0.0
tensor(24.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=1.18............. Loss: -0.42045542, mean(E): -21.67472569-0.00075700j, var(E): 0.75991838
-0.0
tensor(24.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=1.18............. Loss: -0.21218390, mean(E): -21.71090321+0.00215971j, var(E): 0.46460786
-0.0
tensor(24.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(24.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=1.19............. Loss: -0.53551179, mean(E): -21.65298808-0.00691839j, var(E): 0.62509840
-0.0
tensor(25.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=1.19............. Loss: 0.11968219, mean(E): -21.68478823-0.00172921j, var(E): 0.41087835
-0.0
tensor(25.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=1.19............. Loss: 0.14629738, mean(E): -21.77529860-0.00287684j, var(E): 0.50913894
-0.0
tensor(25.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=1.19............. Loss: -0.03401371, mean(E): -21.75737449+0.00433752j, var(E): 0.41453541
-0.0
tensor(25.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=1.19............. Loss: 0.25937685, mean(E): -21.73845311-0.00375133j, var(E): 0.40631502
-0.0
tensor(25.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=1.19............. Loss: 0.09516087, mean(E): -21.77156196+0.00129737j, var(E): 0.27634831
-0.0
tensor(25.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=1.18............. Loss: 0.13354035, mean(E): -21.79932723+0.00235591j, var(E): 0.19547900
-0.0
tensor(25.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=1.19............. Loss: 0.54554018, mean(E): -21.80368242+0.00006641j, var(E): 0.72108174
-0.0
tensor(25.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=1.19............. Loss: -0.08016492, mean(E): -21.73623553-0.00240306j, var(E): 0.49953589
-0.0
tensor(25.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=1.18............. Loss: -0.14499297, mean(E): -21.71826569+0.00173837j, var(E): 0.22027127
-0.0
tensor(25.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=1.19............. Loss: -0.20813914, mean(E): -21.70754182-0.00265043j, var(E): 0.93284616
-0.0
tensor(25.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=1.18............. Loss: 0.06853995, mean(E): -21.72886105-0.00362175j, var(E): 0.38299331
-0.0
tensor(25.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=1.19............. Loss: -0.55561061, mean(E): -21.64697466-0.00586850j, var(E): 0.67077173
-0.0
tensor(25.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=1.19............. Loss: -0.37814015, mean(E): -21.65988282+0.00228513j, var(E): 0.62874533
-0.0
tensor(25.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=1.19............. Loss: -0.15746546, mean(E): -21.72687308+0.00766090j, var(E): 0.41943453
-0.0
tensor(25.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=1.19............. Loss: -0.11514694, mean(E): -21.73983987+0.00240260j, var(E): 0.51851716
-0.0
tensor(25.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=1.19............. Loss: -0.24506476, mean(E): -21.73154746+0.00096049j, var(E): 0.49545776
-0.0
tensor(25.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=1.19............. Loss: -0.19476341, mean(E): -21.69167049-0.00015781j, var(E): 0.40986678
-0.0
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=1.19............. Loss: -0.05565370, mean(E): -21.78723192-0.00021515j, var(E): 0.19158120
-0.0
tensor(25.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=1.19............. Loss: 0.50829164, mean(E): -21.78086963+0.00531819j, var(E): 0.67493153
-0.0
tensor(25.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=1.19............. Loss: -0.28458189, mean(E): -21.67537957+0.00124392j, var(E): 0.51231567
-0.0
tensor(25.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=1.19............. Loss: -0.03523866, mean(E): -21.73583319+0.00525961j, var(E): 0.48740187
-0.0
tensor(25.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=1.19............. Loss: -0.20127218, mean(E): -21.71755362-0.00175897j, var(E): 0.25106597
-0.0
tensor(25.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=1.19............. Loss: 0.54353772, mean(E): -21.83762731-0.00269094j, var(E): 0.41008107
-0.0
tensor(25.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=1.19............. Loss: 0.15745032, mean(E): -21.77682829+0.00249788j, var(E): 0.28933100
-0.0
tensor(25.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=1.19............. Loss: -0.42415049, mean(E): -21.68593458+0.00020873j, var(E): 0.57539741
-0.0
tensor(25.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=1.19............. Loss: 0.19835668, mean(E): -21.74434234-0.00040585j, var(E): 0.38084562
-0.0
tensor(25.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=1.19............. Loss: -0.32893491, mean(E): -21.75277878+0.00007649j, var(E): 0.30905105
-0.0
tensor(25.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=1.19............. Loss: 0.19298057, mean(E): -21.73335543-0.00125413j, var(E): 0.81294228
-0.0
tensor(25.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=1.19............. Loss: 0.04855072, mean(E): -21.74623676+0.00423916j, var(E): 0.37272600
-0.0
tensor(25.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=1.19............. Loss: 0.33603876, mean(E): -21.82703245-0.00445508j, var(E): 0.56587472
-0.0
tensor(25.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=1.19............. Loss: -0.29837850, mean(E): -21.67873994+0.00015971j, var(E): 0.33166253
-0.0
tensor(25.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=1.19............. Loss: 0.37491812, mean(E): -21.78793819+0.00154956j, var(E): 0.39561189
-0.0
tensor(25.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=1.19............. Loss: 0.00136305, mean(E): -21.70738154+0.00126754j, var(E): 0.38267307
-0.0
tensor(25.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=1.19............. Loss: -0.24987364, mean(E): -21.74050491-0.00027740j, var(E): 0.52134030
-0.0
tensor(25.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=1.19............. Loss: -0.06812283, mean(E): -21.75676336-0.00137932j, var(E): 0.38629608
-0.0
tensor(25.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=1.19............. Loss: -0.15592633, mean(E): -21.76712047-0.00524087j, var(E): 0.69830948
-0.0
tensor(25.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=1.19............. Loss: -0.14384012, mean(E): -21.67189447+0.00596918j, var(E): 0.42229331
-0.0
tensor(25.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=1.19............. Loss: 0.00740124, mean(E): -21.74326579+0.00234516j, var(E): 0.28711894
-0.0
tensor(25.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=1.19............. Loss: -0.05057672, mean(E): -21.74392329+0.00216057j, var(E): 0.25891055
-0.0
tensor(25.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=1.19............. Loss: 0.02255353, mean(E): -21.73510508-0.00382530j, var(E): 0.87942492
-0.0
tensor(25.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=1.19............. Loss: -0.61388587, mean(E): -21.66328661+0.00314873j, var(E): 0.64644907
-0.0
tensor(25.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=1.19............. Loss: -0.02381167, mean(E): -21.70741200+0.00138017j, var(E): 0.69632353
-0.0
tensor(25.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=1.19............. Loss: -0.35172503, mean(E): -21.68566453-0.00019187j, var(E): 0.67076028
-0.0
tensor(25.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=1.19............. Loss: 0.07959480, mean(E): -21.73295125-0.00089546j, var(E): 0.33752061
-0.0
tensor(25.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=1.19............. Loss: -0.20844315, mean(E): -21.68468523+0.00054604j, var(E): 0.30080661
-0.0
tensor(25.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=1.19............. Loss: 0.17797624, mean(E): -21.76818851+0.00076884j, var(E): 0.37682372
-0.0
tensor(25.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=1.19............. Loss: -0.22204163, mean(E): -21.73744843+0.00886396j, var(E): 0.25276621
-0.0
tensor(25.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=1.19............. Loss: 0.33555830, mean(E): -21.76454710+0.00268519j, var(E): 0.97514880
-0.0
tensor(25.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=1.19............. Loss: 0.08769678, mean(E): -21.80143237+0.00090332j, var(E): 0.26012439
-0.0
tensor(25.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=1.18............. Loss: 0.61261631, mean(E): -21.78859588-0.00143174j, var(E): 1.03874477
-0.0
tensor(25.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=1.19............. Loss: -0.41812911, mean(E): -21.66352486-0.00154988j, var(E): 0.43947013
-0.0
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=1.19............. Loss: 0.17800508, mean(E): -21.77948531-0.00038681j, var(E): 0.37458581
-0.0
tensor(25.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=1.19............. Loss: -0.11964514, mean(E): -21.77553061+0.00105240j, var(E): 0.42511815
-0.0
tensor(25.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=1.18............. Loss: 0.39479364, mean(E): -21.80540980+0.00175890j, var(E): 0.58953543
-0.0
tensor(25.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=1.19............. Loss: 0.22235570, mean(E): -21.79052462-0.00117001j, var(E): 0.77262441
-0.0
tensor(25.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=1.18............. Loss: -0.08019792, mean(E): -21.73579450-0.00271203j, var(E): 0.65400919
-0.0
tensor(25.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=1.18............. Loss: -0.15736686, mean(E): -21.73435741-0.00514636j, var(E): 0.28199094
-0.0
tensor(25.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=1.19............. Loss: 0.50929396, mean(E): -21.75084231-0.00040734j, var(E): 0.69411308
-0.0
tensor(25.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=1.18............. Loss: -0.00224478, mean(E): -21.77605058+0.00191144j, var(E): 0.38362031
-0.0
tensor(25.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=1.19............. Loss: 0.27459298, mean(E): -21.80358310+0.00511010j, var(E): 0.52511384
-0.0
tensor(25.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=1.18............. Loss: -0.04423919, mean(E): -21.74651897+0.00359130j, var(E): 0.97718600
-0.0
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=1.19............. Loss: -0.11613595, mean(E): -21.71920799+0.00205978j, var(E): 0.26344367
-0.0
tensor(25.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=1.19............. Loss: -0.17499147, mean(E): -21.68322035-0.00112217j, var(E): 0.61531611
-0.0
tensor(25.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=1.18............. Loss: 0.02906675, mean(E): -21.78203522+0.00072421j, var(E): 0.59603951
-0.0
tensor(25.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=1.19............. Loss: 0.02026659, mean(E): -21.75473172-0.00064404j, var(E): 0.50485932
-0.0
tensor(25.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=1.19............. Loss: 0.35008747, mean(E): -21.77902529-0.00066789j, var(E): 0.32222508
-0.0
tensor(25.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=1.19............. Loss: -0.21435097, mean(E): -21.68754792+0.00556807j, var(E): 0.35913465
-0.0
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=1.19............. Loss: 0.55731988, mean(E): -21.80377946-0.00079170j, var(E): 0.84137969
-0.0
tensor(25.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=1.19............. Loss: 0.03803440, mean(E): -21.76307950-0.00396609j, var(E): 0.29700969
-0.0
tensor(25.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=1.19............. Loss: 0.24937487, mean(E): -21.82278840+0.00257629j, var(E): 0.38627489
-0.0
tensor(25.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=1.19............. Loss: -0.31847833, mean(E): -21.68458939+0.00095556j, var(E): 0.36575168
-0.0
tensor(25.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=1.18............. Loss: 0.36445081, mean(E): -21.78475350-0.00432450j, var(E): 0.36820255
-0.0
tensor(25.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=1.19............. Loss: -0.18753927, mean(E): -21.74035696+0.00215936j, var(E): 0.44960555
-0.0
tensor(25.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=1.19............. Loss: 0.10662655, mean(E): -21.79670174+0.00100610j, var(E): 0.39693816
-0.0
tensor(25.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=1.18............. Loss: -0.17298118, mean(E): -21.74507753+0.00310964j, var(E): 0.48632732
-0.0
tensor(25.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=1.19............. Loss: 0.04215690, mean(E): -21.72512719-0.00048467j, var(E): 0.53459377
-0.0
tensor(25.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=1.19............. Loss: -0.31635530, mean(E): -21.65201148-0.00300141j, var(E): 0.62189633
-0.0
tensor(25.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=1.19............. Loss: 0.33615978, mean(E): -21.77327368+0.00132024j, var(E): 0.32994960
-0.0
tensor(25.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=1.19............. Loss: 0.00029601, mean(E): -21.79151599+0.00225575j, var(E): 0.19100673
-0.0
tensor(25.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=1.19............. Loss: 0.31293342, mean(E): -21.79047688+0.00117279j, var(E): 0.47815428
-0.0
tensor(25.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=1.19............. Loss: 0.31330896, mean(E): -21.83147610-0.00280857j, var(E): 0.25619286
-0.0
tensor(25.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=1.2............. Loss: -0.20201911, mean(E): -21.68815399+0.00103652j, var(E): 0.52764791
-0.0
tensor(25.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=1.19............. Loss: 0.45439644, mean(E): -21.83124899+0.00318312j, var(E): 0.85643701
-0.0
tensor(25.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=1.19............. Loss: -0.19366719, mean(E): -21.73178560-0.00309103j, var(E): 0.49548625
-0.0
tensor(25.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=1.19............. Loss: -0.10852140, mean(E): -21.77974758+0.00091666j, var(E): 0.48248889
-0.0
tensor(25.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=1.19............. Loss: -0.02825471, mean(E): -21.71163074-0.00162188j, var(E): 0.44109109
-0.0
tensor(25.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=1.18............. Loss: 1.51074575, mean(E): -21.89995322+0.00017919j, var(E): 1.95957622
-0.0
tensor(25.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=1.19............. Loss: -0.44319247, mean(E): -21.67306649-0.00347852j, var(E): 0.31510356
-0.0
tensor(25.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=1.19............. Loss: -0.33527576, mean(E): -21.68087994+0.00199017j, var(E): 0.44951436
-0.0
tensor(25.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=1.19............. Loss: -0.09111588, mean(E): -21.75409849+0.00030179j, var(E): 0.20601464
-0.0
tensor(25.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=1.19............. Loss: 0.00902812, mean(E): -21.75619336+0.00075833j, var(E): 0.31390744
-0.0
tensor(25.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=1.19............. Loss: -0.11286998, mean(E): -21.72604005+0.00063879j, var(E): 1.15450278
-0.0
tensor(25.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=1.19............. Loss: 0.14831505, mean(E): -21.74040158-0.00231940j, var(E): 0.40315404
-0.0
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=1.18............. Loss: 0.13110447, mean(E): -21.74923162+0.00254058j, var(E): 0.38406223
-0.0
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=1.19............. Loss: 0.14356877, mean(E): -21.77502884+0.00220010j, var(E): 0.16379830
-0.0
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=1.18............. Loss: 0.04092839, mean(E): -21.78225414+0.00217965j, var(E): 0.39000765
-0.0
tensor(25.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=1.19............. Loss: -0.08489681, mean(E): -21.77305241+0.00186222j, var(E): 0.41010020
-0.0
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=1.19............. Loss: -0.08971928, mean(E): -21.73913858+0.00020198j, var(E): 0.24608394
-0.0
tensor(25.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=1.19............. Loss: -0.16268945, mean(E): -21.74939062+0.00198282j, var(E): 0.21699519
-0.0
tensor(25.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=1.18............. Loss: 0.16199490, mean(E): -21.78688630-0.00077389j, var(E): 0.12778550
-0.0
tensor(25.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=1.19............. Loss: 0.25091526, mean(E): -21.82997114-0.00023865j, var(E): 0.23884946
-0.0
tensor(25.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=1.19............. Loss: -0.16736972, mean(E): -21.72458363-0.00062115j, var(E): 0.25500804
-0.0
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=1.19............. Loss: 0.05668943, mean(E): -21.76856785+0.00116914j, var(E): 0.18779045
-0.0
tensor(25.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=1.18............. Loss: -0.10135580, mean(E): -21.72991777+0.00105118j, var(E): 0.17249476
-0.0
tensor(25.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=1.19............. Loss: 0.14437544, mean(E): -21.78852099-0.00275380j, var(E): 0.18980422
-0.0
tensor(25.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=1.19............. Loss: -0.05640667, mean(E): -21.76278761-0.00075953j, var(E): 0.21014006
-0.0
tensor(25.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=1.18............. Loss: 0.34085365, mean(E): -21.78240637+0.00006987j, var(E): 0.56162941
-0.0
tensor(25.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=1.19............. Loss: -0.20493153, mean(E): -21.72537150-0.00133647j, var(E): 0.46364323
-0.0
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=1.19............. Loss: 0.51638887, mean(E): -21.81118144-0.00152225j, var(E): 0.38560095
-0.0
tensor(25.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=1.19............. Loss: 0.45655880, mean(E): -21.79999199-0.00058947j, var(E): 0.92575250
-0.0
tensor(25.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=1.18............. Loss: 0.21081680, mean(E): -21.80332464-0.00260068j, var(E): 1.52735827
-0.0
tensor(25.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=1.19............. Loss: -0.65396368, mean(E): -21.67342066+0.00153563j, var(E): 0.69506738
-0.0
tensor(25.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=1.19............. Loss: -0.09205340, mean(E): -21.71288699-0.00197074j, var(E): 0.29203645
-0.0
tensor(25.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=1.19............. Loss: 0.01291333, mean(E): -21.75277262+0.00069742j, var(E): 0.29218014
-0.0
tensor(25.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=1.19............. Loss: 0.25228584, mean(E): -21.79662687+0.00043877j, var(E): 0.34204575
-0.0
tensor(25.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=1.18............. Loss: -0.57878514, mean(E): -21.69012322+0.00053037j, var(E): 0.55114148
-0.0
tensor(25.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=1.19............. Loss: -0.07703795, mean(E): -21.75316306+0.00368375j, var(E): 0.24650721
-0.0
tensor(25.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=1.19............. Loss: 0.35066027, mean(E): -21.79067020+0.00009589j, var(E): 0.56761244
-0.0
tensor(25.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=1.19............. Loss: -0.19545448, mean(E): -21.71573111-0.00343010j, var(E): 0.37628835
-0.0
tensor(25.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=1.19............. Loss: -0.17343361, mean(E): -21.74627676+0.00147136j, var(E): 0.42537878
-0.0
tensor(25.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=1.19............. Loss: 0.01189196, mean(E): -21.73558167+0.00229467j, var(E): 0.24537675
-0.0
tensor(25.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=1.19............. Loss: 0.36163987, mean(E): -21.84867469-0.00045012j, var(E): 0.26682199
-0.0
tensor(25.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=1.19............. Loss: 0.84217245, mean(E): -21.85999137-0.00402184j, var(E): 1.50307326
-0.0
tensor(25.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=1.19............. Loss: 0.33356855, mean(E): -21.80143485-0.00163733j, var(E): 0.81017702
-0.0
tensor(25.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=1.18............. Loss: -0.29561651, mean(E): -21.70219393-0.00242287j, var(E): 0.32367679
-0.0
tensor(25.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=1.19............. Loss: -0.39550783, mean(E): -21.69868777-0.00245709j, var(E): 0.31219101
-0.0
tensor(25.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=1.18............. Loss: -0.12290698, mean(E): -21.74875095+0.00123223j, var(E): 0.29188753
-0.0
tensor(25.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=1.18............. Loss: 0.27464552, mean(E): -21.77434319+0.00135836j, var(E): 0.27875995
-0.0
tensor(25.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=1.18............. Loss: -0.01981893, mean(E): -21.74589425+0.00023466j, var(E): 0.38697066
-0.0
tensor(25.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=1.19............. Loss: 0.57814236, mean(E): -21.87165602-0.00170739j, var(E): 0.82987348
-0.0
tensor(25.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=1.19............. Loss: 0.13435994, mean(E): -21.79122943-0.00129382j, var(E): 0.51919849
-0.0
tensor(25.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=1.19............. Loss: 0.11844793, mean(E): -21.78826025+0.00032612j, var(E): 0.41628178
-0.0
tensor(25.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=1.19............. Loss: 0.36058436, mean(E): -21.81174842+0.00294927j, var(E): 0.49956817
-0.0
tensor(25.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=1.19............. Loss: 0.05175581, mean(E): -21.76349795-0.00256354j, var(E): 0.25255499
-0.0
tensor(25.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=1.19............. Loss: 0.23750093, mean(E): -21.82492656+0.00148829j, var(E): 0.51961458
-0.0
tensor(25.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=1.19............. Loss: -0.12932727, mean(E): -21.77449956+0.00214225j, var(E): 0.59415297
-0.0
tensor(25.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=1.19............. Loss: -0.11063320, mean(E): -21.73863516+0.00013588j, var(E): 0.36143304
-0.0
tensor(25.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=1.19............. Loss: 0.07302537, mean(E): -21.72210479+0.00003677j, var(E): 0.59401274
-0.0
tensor(25.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=1.19............. Loss: 0.07956045, mean(E): -21.75794265-0.00080093j, var(E): 0.66106365
-0.0
tensor(25.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=1.19............. Loss: 0.17002631, mean(E): -21.78788656-0.00129489j, var(E): 0.46169475
-0.0
tensor(25.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=1.19............. Loss: -0.37712790, mean(E): -21.71398162-0.00132967j, var(E): 0.46848374
-0.0
tensor(25.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=1.19............. Loss: 0.30292681, mean(E): -21.80307283+0.00241343j, var(E): 0.43864629
-0.0
tensor(25.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=1.19............. Loss: 0.06611843, mean(E): -21.74743569+0.00317058j, var(E): 0.36264407
-0.0
tensor(25.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=1.19............. Loss: 0.00642466, mean(E): -21.76067631-0.00111059j, var(E): 0.27622967
-0.0
tensor(25.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=1.19............. Loss: -0.02482381, mean(E): -21.74981305-0.00013083j, var(E): 0.16866029
-0.0
tensor(25.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=1.19............. Loss: 0.07894203, mean(E): -21.76736531+0.00014831j, var(E): 0.48485766
-0.0
tensor(25.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=1.19............. Loss: -0.46436044, mean(E): -21.68667684+0.00069712j, var(E): 0.45483061
-0.0
tensor(25.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=1.19............. Loss: -0.09300124, mean(E): -21.76296273+0.00096555j, var(E): 0.27281418
-0.0
tensor(25.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=1.19............. Loss: 0.12080991, mean(E): -21.77420445-0.00240345j, var(E): 0.19013306
-0.0
tensor(25.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=1.19............. Loss: -0.06353954, mean(E): -21.73926313+0.00220389j, var(E): 0.24225561
-0.0
tensor(25.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=1.19............. Loss: 0.19492588, mean(E): -21.77562434-0.00237508j, var(E): 0.30674254
-0.0
tensor(25.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=1.19............. Loss: -0.19082635, mean(E): -21.73748171+0.00114162j, var(E): 0.19983137
-0.0
tensor(25.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=1.19............. Loss: 0.13921302, mean(E): -21.77785080-0.00142554j, var(E): 0.34588887
-0.0
tensor(25.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=1.19............. Loss: -0.08205205, mean(E): -21.73357227-0.00272879j, var(E): 0.30291334
-0.0
tensor(25.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=1.19............. Loss: -0.10308563, mean(E): -21.71371720-0.00132280j, var(E): 0.18398251
-0.0
tensor(25.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=1.19............. Loss: 0.04538802, mean(E): -21.76312163+0.00238091j, var(E): 0.32247097
-0.0
tensor(25.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=1.19............. Loss: 0.47252732, mean(E): -21.83569989+0.00069602j, var(E): 0.56947555
-0.0
tensor(25.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=1.19............. Loss: 0.38195872, mean(E): -21.82230791-0.00170632j, var(E): 0.32556551
-0.0
tensor(25.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=1.19............. Loss: -0.05089701, mean(E): -21.80395219+0.00294615j, var(E): 0.37472372
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=1.19............. Loss: 0.03682844, mean(E): -21.75972129+0.00032947j, var(E): 0.32603646
-0.0
tensor(25.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=1.19............. Loss: -0.26174997, mean(E): -21.74945221-0.00077928j, var(E): 0.43440085
-0.0
tensor(25.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=1.19............. Loss: -0.07257054, mean(E): -21.77358849-0.00128193j, var(E): 0.68304669
-0.0
tensor(25.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=1.19............. Loss: 0.13510932, mean(E): -21.79678411-0.00075557j, var(E): 0.23458111
-0.0
tensor(25.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=1.19............. Loss: -0.18056162, mean(E): -21.74060781+0.00064788j, var(E): 0.24155031
-0.0
tensor(25.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=1.19............. Loss: 0.17441066, mean(E): -21.82541728+0.00060476j, var(E): 0.53449001
-0.0
tensor(25.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=1.19............. Loss: 0.10797727, mean(E): -21.81508059+0.00054539j, var(E): 0.42859358
-0.0
tensor(25.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=1.19............. Loss: -0.06851127, mean(E): -21.75712916-0.00008179j, var(E): 0.46976198
-0.0
tensor(25.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=1.19............. Loss: -0.07500464, mean(E): -21.73796494-0.00057743j, var(E): 0.18765790
-0.0
tensor(25.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=1.19............. Loss: -0.08005578, mean(E): -21.71562727-0.00003684j, var(E): 0.22577295
-0.0
tensor(25.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=1.19............. Loss: 0.27172180, mean(E): -21.80547822+0.00037542j, var(E): 0.42076471
-0.0
tensor(25.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=1.19............. Loss: 0.28396595, mean(E): -21.83002294+0.00004827j, var(E): 0.18214039
-0.0
tensor(25.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=1.19............. Loss: -0.10603664, mean(E): -21.75004220+0.00099428j, var(E): 0.16815726
-0.0
tensor(25.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=1.19............. Loss: -0.60541472, mean(E): -21.68709304+0.00109427j, var(E): 0.45715379
-0.0
tensor(25.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=1.19............. Loss: 0.13173933, mean(E): -21.79957182+0.00071329j, var(E): 0.27285708
-0.0
tensor(25.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=1.18............. Loss: 0.05902721, mean(E): -21.77256914-0.00150058j, var(E): 0.09725312
-0.0
tensor(25.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=1.18............. Loss: 0.03449339, mean(E): -21.75693220-0.00072207j, var(E): 0.12937691
-0.0
tensor(25.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=1.19............. Loss: -0.34717155, mean(E): -21.70479701-0.00013160j, var(E): 0.20299519
-0.0
tensor(25.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=1.19............. Loss: 0.26341079, mean(E): -21.77180416-0.00212115j, var(E): 0.30414085
-0.0
tensor(25.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=1.19............. Loss: 0.39860995, mean(E): -21.79155907+0.00030583j, var(E): 0.84638572
-0.0
tensor(25.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=1.19............. Loss: -0.05564333, mean(E): -21.71729972+0.00022195j, var(E): 0.32120424
-0.0
tensor(25.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=1.19............. Loss: 0.01485426, mean(E): -21.75333310+0.00053193j, var(E): 0.17790787
-0.0
tensor(25.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=1.19............. Loss: 0.07549704, mean(E): -21.74926168-0.00072067j, var(E): 0.17305757
-0.0
tensor(25.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=1.19............. Loss: -0.23075331, mean(E): -21.71115770+0.00092511j, var(E): 0.29929281
-0.0
tensor(25.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=1.19............. Loss: 0.09336984, mean(E): -21.78076013+0.00082651j, var(E): 0.45130354
-0.0
tensor(25.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=1.19............. Loss: -0.27165510, mean(E): -21.75128153-0.00155859j, var(E): 0.44488425
-0.0
tensor(25.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=1.19............. Loss: -0.36662644, mean(E): -21.69628102-0.00145747j, var(E): 0.34097668
-0.0
tensor(25.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=1.19............. Loss: -0.16794252, mean(E): -21.71902396-0.00171806j, var(E): 0.16230614
-0.0
tensor(25.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=1.19............. Loss: -0.19769828, mean(E): -21.74744297+0.00042638j, var(E): 0.26486043
-0.0
tensor(25.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=1.19............. Loss: 0.14499714, mean(E): -21.79342235-0.00024105j, var(E): 0.64050426
-0.0
tensor(25.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=1.19............. Loss: 0.07335499, mean(E): -21.75631588-0.00106789j, var(E): 0.29379433
-0.0
tensor(25.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=1.19............. Loss: 0.04532834, mean(E): -21.73773735+0.00133172j, var(E): 0.16523618
-0.0
tensor(25.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=1.19............. Loss: -0.18123779, mean(E): -21.74998174+0.00147437j, var(E): 0.24382996
-0.0
tensor(25.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=1.19............. Loss: 0.05366081, mean(E): -21.78104866-0.00066283j, var(E): 0.13299670
-0.0
tensor(25.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=1.18............. Loss: 0.14745829, mean(E): -21.74952259+0.00033681j, var(E): 0.26743317
-0.0
tensor(25.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=1.19............. Loss: 0.13509782, mean(E): -21.79308902+0.00006459j, var(E): 0.25856255
-0.0
tensor(25.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=1.18............. Loss: -0.15385352, mean(E): -21.72791813-0.00060326j, var(E): 0.57502547
-0.0
tensor(25.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=1.19............. Loss: -0.26619422, mean(E): -21.72609862+0.00143680j, var(E): 0.33650912
-0.0
tensor(25.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=1.19............. Loss: 0.05731822, mean(E): -21.73770094+0.00069733j, var(E): 0.74358628
-0.0
tensor(25.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=1.18............. Loss: -0.21433646, mean(E): -21.71335221-0.00006954j, var(E): 0.53013126
-0.0
tensor(25.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=1.19............. Loss: 0.17657424, mean(E): -21.76130417-0.00135277j, var(E): 0.16788429
-0.0
tensor(25.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=1.19............. Loss: 0.21818657, mean(E): -21.76394018-0.00032677j, var(E): 0.27621343
-0.0
tensor(25.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=1.19............. Loss: 0.04625851, mean(E): -21.79433289-0.00006073j, var(E): 0.19357011
-0.0
tensor(25.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=1.18............. Loss: -0.09776114, mean(E): -21.72014736+0.00118059j, var(E): 0.28412530
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=1.19............. Loss: 0.55200849, mean(E): -21.79710434-0.00066694j, var(E): 0.57177677
-0.0
tensor(25.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=1.19............. Loss: 0.37678859, mean(E): -21.80430204-0.00144212j, var(E): 0.60665389
-0.0
tensor(25.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=1.19............. Loss: -0.28654660, mean(E): -21.71923619-0.00109653j, var(E): 0.17549718
-0.0
tensor(25.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=1.19............. Loss: -0.07239877, mean(E): -21.77800995+0.00009188j, var(E): 0.19890295
-0.0
tensor(25.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=1.19............. Loss: -0.12184495, mean(E): -21.73545192+0.00099122j, var(E): 0.68948874
-0.0
tensor(25.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=1.19............. Loss: 0.01633345, mean(E): -21.78626502-0.00041678j, var(E): 0.18748089
-0.0
tensor(25.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=1.19............. Loss: -0.38367677, mean(E): -21.67562430-0.00154364j, var(E): 0.38980160
-0.0
tensor(25.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=1.19............. Loss: -0.09492772, mean(E): -21.72013852+0.00012800j, var(E): 0.16028558
-0.0
tensor(25.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=1.19............. Loss: 0.16725738, mean(E): -21.75055662-0.00145471j, var(E): 0.40552498
-0.0
tensor(25.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=1.19............. Loss: -0.16823590, mean(E): -21.71822385+0.00051807j, var(E): 0.17608812
-0.0
tensor(25.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=1.19............. Loss: 0.02757866, mean(E): -21.73449476+0.00055169j, var(E): 0.28786373
-0.0
tensor(25.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=1.19............. Loss: -0.26492777, mean(E): -21.68722554-0.00024174j, var(E): 0.29586997
-0.0
tensor(25.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=1.19............. Loss: -0.21540077, mean(E): -21.70318540+0.00085376j, var(E): 0.38087648
-0.0
tensor(25.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=1.19............. Loss: -0.06168259, mean(E): -21.73963226+0.00139950j, var(E): 0.31366129
-0.0
tensor(25.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=1.19............. Loss: 0.20844089, mean(E): -21.78127517-0.00016778j, var(E): 0.52881623
-0.0
tensor(25.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=1.19............. Loss: 0.11915374, mean(E): -21.81650151+0.00071981j, var(E): 0.34028469
-0.0
tensor(25.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=1.19............. Loss: -0.22183917, mean(E): -21.72752158+0.00018320j, var(E): 0.31331916
-0.0
tensor(25.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=1.19............. Loss: -0.19397416, mean(E): -21.74228687+0.00024439j, var(E): 0.27676001
-0.0
tensor(25.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=1.19............. Loss: -0.12286740, mean(E): -21.75730968+0.00118790j, var(E): 0.17041166
-0.0
tensor(25.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=1.19............. Loss: -0.17631621, mean(E): -21.72978020+0.00064140j, var(E): 0.13171873
-0.0
tensor(25.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=1.19............. Loss: 0.29627506, mean(E): -21.82039112-0.00038360j, var(E): 0.26376525
-0.0
tensor(25.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=1.19............. Loss: 0.10572353, mean(E): -21.79904294-0.00012716j, var(E): 0.15216332
-0.0
tensor(25.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=1.18............. Loss: -0.60057186, mean(E): -21.70829164+0.00021356j, var(E): 0.52400518
-0.0
tensor(25.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=1.19............. Loss: -0.73424147, mean(E): -21.63887859+0.00012513j, var(E): 0.51515808
-0.0
tensor(25.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=1.19............. Loss: -0.04496437, mean(E): -21.75716436+0.00101686j, var(E): 0.17196305
-0.0
tensor(25.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=1.19............. Loss: -0.04225307, mean(E): -21.73993997-0.00027767j, var(E): 0.14591982
-0.0
tensor(25.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=1.19............. Loss: 0.02309276, mean(E): -21.72873320+0.00028544j, var(E): 0.69244911
-0.0
tensor(25.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=1.19............. Loss: -0.25698539, mean(E): -21.72699565+0.00029946j, var(E): 0.65725882
-0.0
tensor(25.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=1.19............. Loss: 0.20401529, mean(E): -21.79977929+0.00050277j, var(E): 0.38624439
-0.0
tensor(25.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=1.19............. Loss: 0.16630469, mean(E): -21.77465273-0.00061742j, var(E): 0.20546299
-0.0
tensor(25.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=1.18............. Loss: 0.12216905, mean(E): -21.74966068+0.00019216j, var(E): 0.80960983
-0.0
tensor(25.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=1.19............. Loss: -0.15081628, mean(E): -21.70804167-0.00169257j, var(E): 0.69469025
-0.0
tensor(25.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=1.19............. Loss: -0.21867922, mean(E): -21.75608785+0.00125637j, var(E): 0.39710872
-0.0
tensor(25.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=1.19............. Loss: -0.24858331, mean(E): -21.73067828+0.00018472j, var(E): 0.38889723
-0.0
tensor(25.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=1.18............. Loss: -0.22095773, mean(E): -21.71695424+0.00058535j, var(E): 0.31301585
-0.0
tensor(25.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=1.19............. Loss: 0.02456808, mean(E): -21.76920259+0.00050643j, var(E): 0.42060742
-0.0
tensor(25.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=1.19............. Loss: 0.18372417, mean(E): -21.81635498-0.00056593j, var(E): 0.53192457
-0.0
tensor(25.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=1.19............. Loss: -0.39913602, mean(E): -21.74419390-0.00029857j, var(E): 0.33434028
-0.0
tensor(25.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=1.19............. Loss: 0.03523244, mean(E): -21.78308052-0.00130403j, var(E): 0.31414144
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=1.19............. Loss: -0.14583379, mean(E): -21.77591026-0.00004972j, var(E): 0.46202686
-0.0
tensor(25.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=1.19............. Loss: 0.01403464, mean(E): -21.77805056+0.00033382j, var(E): 0.27015297
-0.0
tensor(25.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=1.19............. Loss: 0.53084367, mean(E): -21.83210688+0.00035191j, var(E): 0.46549875
-0.0
tensor(26.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(25.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=1.19............. Loss: 0.02044048, mean(E): -21.74991763-0.00003307j, var(E): 0.10397196
-0.0
tensor(26.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=1.2............. Loss: 0.10396388, mean(E): -21.76597075-0.00077231j, var(E): 0.34156883
-0.0
tensor(26.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=1.19............. Loss: -0.21180775, mean(E): -21.72444802-0.00021851j, var(E): 0.29802536
-0.0
tensor(26.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=1.19............. Loss: -0.13810338, mean(E): -21.75183211+0.00041220j, var(E): 0.45070893
-0.0
tensor(26.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=1.19............. Loss: 0.12254622, mean(E): -21.75741913-0.00031316j, var(E): 0.13355051
-0.0
tensor(26.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=1.19............. Loss: 0.40764397, mean(E): -21.80371896+0.00048841j, var(E): 0.69856532
-0.0
tensor(26.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=1.19............. Loss: 0.25129067, mean(E): -21.77491827-0.00007111j, var(E): 0.46313345
-0.0
tensor(26.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=1.19............. Loss: -0.12617434, mean(E): -21.74127585-0.00064041j, var(E): 0.18853488
-0.0
tensor(26.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=1.19............. Loss: -0.13500375, mean(E): -21.74990431-0.00008282j, var(E): 0.27645307
-0.0
tensor(26.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=1.19............. Loss: -0.19150198, mean(E): -21.69167723+0.00007088j, var(E): 0.22919648
-0.0
tensor(26.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=1.19............. Loss: 0.26021640, mean(E): -21.79841444-0.00055188j, var(E): 0.42261136
-0.0
tensor(26.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=1.19............. Loss: -0.33619598, mean(E): -21.73617494-0.00014021j, var(E): 0.45007281
-0.0
tensor(26.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=1.19............. Loss: -0.36447697, mean(E): -21.72191836-0.00035728j, var(E): 0.68703743
-0.0
tensor(26.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=1.19............. Loss: -0.26989137, mean(E): -21.75547815-0.00010181j, var(E): 0.30929787
-0.0
tensor(26.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=1.19............. Loss: -0.06734946, mean(E): -21.78855812+0.00008693j, var(E): 0.31991757
-0.0
tensor(26.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=1.19............. Loss: -0.05950937, mean(E): -21.77067199+0.00080735j, var(E): 0.65264910
-0.0
tensor(26.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=1.19............. Loss: -0.11065862, mean(E): -21.77142215+0.00019450j, var(E): 0.33626921
-0.0
tensor(26.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=1.19............. Loss: 0.23071979, mean(E): -21.86118237+0.00005273j, var(E): 0.34872181
-0.0
tensor(26.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=1.19............. Loss: 0.23353067, mean(E): -21.82524972+0.00032324j, var(E): 0.19508144
-0.0
tensor(26.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=1.19............. Loss: 0.35895070, mean(E): -21.77299704-0.00051533j, var(E): 0.62583798
-0.0
tensor(26.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=1.19............. Loss: -0.03354663, mean(E): -21.75226277-0.00010179j, var(E): 0.47316173
-0.0
tensor(26.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=1.19............. Loss: 0.09832940, mean(E): -21.76492787+0.00020802j, var(E): 0.29633650
-0.0
tensor(26.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=1.19............. Loss: 0.19852186, mean(E): -21.77957621-0.00003698j, var(E): 0.55613920
-0.0
tensor(26.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=1.18............. Loss: -0.05488435, mean(E): -21.76851965-0.00033129j, var(E): 0.25311754
-0.0
tensor(26.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=1.19............. Loss: -0.69278976, mean(E): -21.70047402-0.00006566j, var(E): 0.62013611
-0.0
tensor(26.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=1.19............. Loss: -0.35527834, mean(E): -21.67861418-0.00054792j, var(E): 0.35870766
-0.0
tensor(26.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=1.19............. Loss: -0.62413151, mean(E): -21.69012796+0.00010238j, var(E): 0.62749553
-0.0
tensor(26.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=1.19............. Loss: 0.05240127, mean(E): -21.75284692+0.00016609j, var(E): 0.14098137
-0.0
tensor(26.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=1.19............. Loss: -0.15410671, mean(E): -21.76419334+0.00027786j, var(E): 0.26003148
-0.0
tensor(26.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=1.19............. Loss: -0.09233849, mean(E): -21.76667014-0.00018914j, var(E): 0.27580959
-0.0
tensor(26.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=1.19............. Loss: -0.10344101, mean(E): -21.76041497+0.00025518j, var(E): 0.50575778
-0.0
tensor(26.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=1.18............. Loss: -0.31294839, mean(E): -21.69767440-0.00020563j, var(E): 0.20048983
-0.0
tensor(26.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=1.19............. Loss: -0.09798068, mean(E): -21.74107433+0.00005384j, var(E): 0.25777674
-0.0
tensor(26.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=1.19............. Loss: 0.32171185, mean(E): -21.78608812+0.00019575j, var(E): 0.22428072
-0.0
tensor(26.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=1.19............. Loss: 0.24010838, mean(E): -21.82796291-0.00002488j, var(E): 0.38963425
-0.0
tensor(26.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=1.19............. Loss: 0.44400562, mean(E): -21.82170609+0.00011134j, var(E): 0.65632053
-0.0
tensor(26.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=1.19............. Loss: -0.37317551, mean(E): -21.73860884+0.00010518j, var(E): 0.45243699
-0.0
tensor(26.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=1.19............. Loss: -0.06941625, mean(E): -21.75845769-0.00007786j, var(E): 0.16396369
-0.0
tensor(26.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=1.19............. Loss: -0.27166444, mean(E): -21.72047274+0.00024461j, var(E): 0.24682282
-0.0
tensor(26.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=1.19............. Loss: 0.25192635, mean(E): -21.78021239+0.00026745j, var(E): 0.23961471
-0.0
tensor(26.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=1.19............. Loss: -0.16395444, mean(E): -21.72689540+0.00011706j, var(E): 0.25061772
-0.0
tensor(26.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=1.18............. Loss: 0.09451874, mean(E): -21.77856239-0.00000319j, var(E): 0.17587592
-0.0
tensor(26.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=1.19............. Loss: -0.47689188, mean(E): -21.71828600+0.00027308j, var(E): 0.51032522
-0.0
tensor(26.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=1.19............. Loss: 0.22753895, mean(E): -21.81100696-0.00004579j, var(E): 0.16071198
-0.0
tensor(26.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=1.19............. Loss: -0.11705019, mean(E): -21.79213243-0.00014251j, var(E): 0.28052816
-0.0
tensor(26.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=1.19............. Loss: 0.19210164, mean(E): -21.79771265+0.00026255j, var(E): 0.37933769
-0.0
tensor(26.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=1.19............. Loss: -0.33025565, mean(E): -21.73781218+0.00003026j, var(E): 0.26169931
-0.0
tensor(26.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=1.19............. Loss: 0.15951454, mean(E): -21.79085953+0.00028759j, var(E): 0.24747665
-0.0
tensor(26.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=1.18............. Loss: 0.09149310, mean(E): -21.76098136+0.00011254j, var(E): 0.23295460
-0.0
tensor(26.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=1.19............. Loss: 0.09616617, mean(E): -21.76476016+0.00005685j, var(E): 0.62690928
-0.0
tensor(26.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=1.18............. Loss: -0.05738651, mean(E): -21.79232339-0.00015367j, var(E): 0.13343019
-0.0
tensor(26.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=1.19............. Loss: 0.18645537, mean(E): -21.80164024-0.00011040j, var(E): 0.62825096
-0.0
tensor(26.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=1.19............. Loss: -0.14772559, mean(E): -21.73065440-0.00008474j, var(E): 0.93800426
-0.0
tensor(26.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=1.19............. Loss: 0.05642390, mean(E): -21.73542234+0.00003325j, var(E): 0.37950491
-0.0
tensor(26.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=1.19............. Loss: -0.24897016, mean(E): -21.70576472+0.00006705j, var(E): 0.29456175
-0.0
tensor(26.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=1.19............. Loss: -0.14027414, mean(E): -21.77562076-0.00006912j, var(E): 0.22060535
-0.0
tensor(26.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=1.18............. Loss: -0.19212282, mean(E): -21.71050076-0.00002999j, var(E): 0.17188262
-0.0
tensor(26.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=1.19............. Loss: 0.00882025, mean(E): -21.76191082+0.00011788j, var(E): 0.12046137
-0.0
tensor(26.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=1.19............. Loss: 0.13875759, mean(E): -21.80796470+0.00033923j, var(E): 0.41739388
-0.0
tensor(26.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=1.18............. Loss: -0.11939880, mean(E): -21.73187695-0.00019116j, var(E): 0.14425244
-0.0
tensor(26.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=1.18............. Loss: 0.13484844, mean(E): -21.78104050-0.00005540j, var(E): 0.27390391
-0.0
tensor(26.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=1.19............. Loss: -0.09114814, mean(E): -21.73942739-0.00011260j, var(E): 0.16323827
-0.0
tensor(26.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=1.19............. Loss: 0.34001443, mean(E): -21.82128162+0.00017093j, var(E): 0.22346683
-0.0
tensor(26.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=1.19............. Loss: 0.27309427, mean(E): -21.77448491+0.00007173j, var(E): 0.19758955
-0.0
tensor(26.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=1.19............. Loss: -0.20826367, mean(E): -21.73334157+0.00016868j, var(E): 0.27610232
-0.0
tensor(26.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=1.19............. Loss: 0.01183214, mean(E): -21.77741156+0.00033749j, var(E): 0.32969509
-0.0
tensor(26.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=1.19............. Loss: -0.03275093, mean(E): -21.75804496+0.00007730j, var(E): 0.16915762
-0.0
tensor(26.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=1.19............. Loss: -0.10350979, mean(E): -21.73557352-0.00000401j, var(E): 0.21299193
-0.0
tensor(26.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=1.18............. Loss: 0.03555934, mean(E): -21.76632399+0.00002406j, var(E): 0.10953823
-0.0
tensor(26.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=1.19............. Loss: -0.69044868, mean(E): -21.66390301-0.00001298j, var(E): 0.39207549
-0.0
tensor(26.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=1.18............. Loss: 0.13123171, mean(E): -21.80508209+0.00010542j, var(E): 0.32675086
-0.0
tensor(26.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=1.19............. Loss: 0.04255871, mean(E): -21.78738764+0.00010715j, var(E): 0.43702859
-0.0
tensor(26.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=1.2............. Loss: -0.29252378, mean(E): -21.67945428-0.00008776j, var(E): 0.31750690
-0.0
tensor(26.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=1.19............. Loss: 0.04467448, mean(E): -21.75372645-0.00007818j, var(E): 0.31028510
-0.0
tensor(26.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=1.19............. Loss: -0.19469397, mean(E): -21.69102068-0.00003720j, var(E): 0.17813446
-0.0
tensor(26.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=1.19............. Loss: -0.06001477, mean(E): -21.75355091-0.00021775j, var(E): 0.25804137
-0.0
tensor(26.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=1.19............. Loss: -0.20135539, mean(E): -21.72022094+0.00011049j, var(E): 0.22340613
-0.0
tensor(26.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=1.19............. Loss: 0.39434673, mean(E): -21.82217998+0.00002732j, var(E): 0.84304749
-0.0
tensor(26.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=1.19............. Loss: 0.05573202, mean(E): -21.78975621-0.00003373j, var(E): 0.11648487
-0.0
tensor(26.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=1.19............. Loss: -0.03835010, mean(E): -21.73519087-0.00002108j, var(E): 0.07480036
-0.0
tensor(26.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=1.19............. Loss: 0.13165685, mean(E): -21.80897071-0.00010444j, var(E): 0.31539979
-0.0
tensor(26.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=1.19............. Loss: -0.21082122, mean(E): -21.73973547-0.00011086j, var(E): 0.14358233
-0.0
tensor(26.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=1.19............. Loss: 0.37686585, mean(E): -21.82607393-0.00016766j, var(E): 0.86276615
-0.0
tensor(26.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=1.18............. Loss: -0.47356651, mean(E): -21.70958630+0.00002095j, var(E): 0.46233437
-0.0
tensor(26.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=1.19............. Loss: 0.03632282, mean(E): -21.76001197+0.00008697j, var(E): 0.25192679
-0.0
tensor(26.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=1.19............. Loss: -0.28272870, mean(E): -21.73448113-0.00000197j, var(E): 0.32480994
-0.0
tensor(26.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=1.19............. Loss: 0.21224493, mean(E): -21.82555925-0.00000945j, var(E): 0.35308868
-0.0
tensor(26.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=1.19............. Loss: -0.13347848, mean(E): -21.74512362-0.00006704j, var(E): 0.23456648
-0.0
tensor(26.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=1.19............. Loss: 0.18365873, mean(E): -21.78373228-0.00004383j, var(E): 0.09658491
-0.0
tensor(26.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=1.19............. Loss: -0.10781928, mean(E): -21.76172261-0.00011566j, var(E): 0.22975048
-0.0
tensor(26.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=1.19............. Loss: -0.53681967, mean(E): -21.70444124-0.00000493j, var(E): 0.54885069
-0.0
tensor(26.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=1.19............. Loss: 0.06172726, mean(E): -21.75337619-0.00001653j, var(E): 0.08727573
-0.0
tensor(26.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=1.19............. Loss: -0.18735587, mean(E): -21.74852957-0.00009634j, var(E): 0.26264113
-0.0
tensor(26.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=1.19............. Loss: 0.00831313, mean(E): -21.74850799-0.00000140j, var(E): 0.12016078
-0.0
tensor(26.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=1.19............. Loss: -0.60769149, mean(E): -21.71234110-0.00003879j, var(E): 1.05516197
-0.0
tensor(26.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=1.19............. Loss: 0.23752153, mean(E): -21.71893022+0.00012450j, var(E): 0.61133207
-0.0
tensor(26.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=1.19............. Loss: -0.48852116, mean(E): -21.72795772-0.00007897j, var(E): 0.59895353
-0.0
tensor(26.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=1.19............. Loss: 0.31950442, mean(E): -21.82368731-0.00002866j, var(E): 0.43954112
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=1.19............. Loss: -0.07740638, mean(E): -21.77391357+0.00002153j, var(E): 0.16845193
-0.0
tensor(26.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=1.19............. Loss: 0.13975348, mean(E): -21.77832944-0.00004060j, var(E): 0.20972097
-0.0
tensor(26.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=1.19............. Loss: -0.17922254, mean(E): -21.73187548-0.00007800j, var(E): 0.12128417
-0.0
tensor(26.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=1.19............. Loss: -0.08690498, mean(E): -21.77415742-0.00003057j, var(E): 0.16861112
-0.0
tensor(26.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=1.19............. Loss: -0.35502104, mean(E): -21.68686902-0.00002301j, var(E): 0.20769479
-0.0
tensor(26.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=1.19............. Loss: -0.08435093, mean(E): -21.75543512+0.00009798j, var(E): 0.22095126
-0.0
tensor(26.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=1.19............. Loss: -0.18316291, mean(E): -21.74283406-0.00000268j, var(E): 0.22402398
-0.0
tensor(26.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=1.19............. Loss: -0.28566138, mean(E): -21.73480839+0.00002129j, var(E): 0.21954807
-0.0
tensor(26.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=1.19............. Loss: -0.06235748, mean(E): -21.76759923-0.00000255j, var(E): 0.24113846
-0.0
tensor(26.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=1.19............. Loss: 0.11820406, mean(E): -21.80255133+0.00007257j, var(E): 0.23879538
-0.0
tensor(26.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=1.19............. Loss: -0.04201913, mean(E): -21.76599909-0.00008711j, var(E): 0.31331430
-0.0
tensor(26.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=1.19............. Loss: -0.02191864, mean(E): -21.79030026+0.00006494j, var(E): 0.22518755
-0.0
tensor(26.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=1.19............. Loss: -0.00278701, mean(E): -21.77012782-0.00004920j, var(E): 0.32357015
-0.0
tensor(26.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=1.19............. Loss: -0.66057975, mean(E): -21.70897678-0.00003670j, var(E): 0.53979697
-0.0
tensor(26.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=1.19............. Loss: 0.11617395, mean(E): -21.78840401+0.00002614j, var(E): 0.12241586
-0.0
tensor(26.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=1.19............. Loss: -0.07607101, mean(E): -21.74326913-0.00001919j, var(E): 0.13438028
-0.0
tensor(26.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=1.19............. Loss: 0.10095037, mean(E): -21.77406588-0.00000620j, var(E): 0.13804708
-0.0
tensor(26.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=1.18............. Loss: 0.11124318, mean(E): -21.78695318+0.00000586j, var(E): 0.32036356
-0.0
tensor(26.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=1.2............. Loss: -0.21260379, mean(E): -21.72843845-0.00005203j, var(E): 0.15327567
-0.0
tensor(26.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=1.19............. Loss: 0.24406974, mean(E): -21.77722595-0.00006370j, var(E): 0.29946163
-0.0
tensor(26.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=1.19............. Loss: -0.25741176, mean(E): -21.74490952-0.00001886j, var(E): 0.18654582
-0.0
tensor(26.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=1.19............. Loss: 0.07080300, mean(E): -21.79575515+0.00002298j, var(E): 0.18602468
-0.0
tensor(26.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=1.19............. Loss: 0.15382229, mean(E): -21.79321424+0.00006791j, var(E): 0.10225634
-0.0
tensor(26.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=1.19............. Loss: -0.03942560, mean(E): -21.79387359-0.00000165j, var(E): 0.15392740
-0.0
tensor(26.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=1.19............. Loss: 0.40936635, mean(E): -21.84222382-0.00001155j, var(E): 0.48467427
-0.0
tensor(26.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=1.19............. Loss: -0.38187669, mean(E): -21.71938765-0.00005536j, var(E): 0.38522875
-0.0
tensor(26.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=1.19............. Loss: -0.50850976, mean(E): -21.67457172+0.00005277j, var(E): 0.36265111
-0.0
tensor(26.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=1.19............. Loss: 0.01810606, mean(E): -21.76056661+0.00003603j, var(E): 0.23652860
-0.0
tensor(26.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=1.19............. Loss: -0.27685073, mean(E): -21.72656858-0.00000063j, var(E): 0.38065222
-0.0
tensor(26.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=1.19............. Loss: 0.12043616, mean(E): -21.79514814-0.00003358j, var(E): 0.22094510
-0.0
tensor(26.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=1.19............. Loss: 0.44570649, mean(E): -21.81356385-0.00000491j, var(E): 1.48819493
-0.0
tensor(26.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=1.19............. Loss: -0.34397796, mean(E): -21.72969881+0.00000939j, var(E): 0.22116693
-0.0
tensor(26.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=1.19............. Loss: 0.07272166, mean(E): -21.79652917+0.00003164j, var(E): 0.09469060
-0.0
tensor(26.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=1.19............. Loss: 0.04461209, mean(E): -21.77921467+0.00004843j, var(E): 0.05476958
-0.0
tensor(26.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=1.19............. Loss: 0.42542028, mean(E): -21.82837941-0.00002673j, var(E): 0.32863277
-0.0
tensor(26.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=1.19............. Loss: -0.19418601, mean(E): -21.71049404+0.00003841j, var(E): 0.31469523
-0.0
tensor(26.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=1.2............. Loss: 0.41508691, mean(E): -21.83321503-0.00001806j, var(E): 0.35329106
-0.0
tensor(26.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=1.19............. Loss: -0.32471094, mean(E): -21.74137277-0.00000560j, var(E): 0.28042142
-0.0
tensor(26.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=1.19............. Loss: 0.01887928, mean(E): -21.76664465-0.00003613j, var(E): 0.40559715
-0.0
tensor(26.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=1.19............. Loss: -0.28072159, mean(E): -21.71758067+0.00002559j, var(E): 0.17008569
-0.0
tensor(26.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=1.19............. Loss: 0.14192419, mean(E): -21.77915944+0.00000945j, var(E): 0.15404717
-0.0
tensor(26.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=1.19............. Loss: 0.08771952, mean(E): -21.78660601-0.00000251j, var(E): 0.13296416
-0.0
tensor(26.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=1.19............. Loss: -0.30090396, mean(E): -21.72438397-0.00001322j, var(E): 0.28117846
-0.0
tensor(26.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=1.19............. Loss: -0.04933039, mean(E): -21.75776127-0.00001656j, var(E): 0.19207749
-0.0
tensor(26.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=1.19............. Loss: 0.05488828, mean(E): -21.79999090-0.00001195j, var(E): 0.59887627
-0.0
tensor(26.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=1.18............. Loss: -0.23729343, mean(E): -21.66860435-0.00001508j, var(E): 0.18192675
-0.0
tensor(26.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=1.19............. Loss: 0.00914014, mean(E): -21.75071925+0.00002530j, var(E): 0.09180751
-0.0
tensor(26.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=1.19............. Loss: 0.15679572, mean(E): -21.79333585+0.00000856j, var(E): 0.10285627
-0.0
tensor(26.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=1.19............. Loss: 0.06105451, mean(E): -21.78195582-0.00000047j, var(E): 0.16151051
-0.0
tensor(26.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=1.19............. Loss: -0.06241658, mean(E): -21.75112302-0.00004591j, var(E): 0.24451829
-0.0
tensor(26.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=1.18............. Loss: 0.20699984, mean(E): -21.75293454+0.00002368j, var(E): 0.29578945
-0.0
tensor(26.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=1.19............. Loss: 0.15398897, mean(E): -21.81002450+0.00001027j, var(E): 0.11720633
-0.0
tensor(26.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=1.19............. Loss: -0.01497259, mean(E): -21.78305376+0.00001210j, var(E): 0.24703292
-0.0
tensor(26.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=1.19............. Loss: -0.11158108, mean(E): -21.74012008+0.00002230j, var(E): 0.14122913
-0.0
tensor(26.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=1.19............. Loss: -0.10836181, mean(E): -21.75798495-0.00000979j, var(E): 0.16173469
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=1.19............. Loss: 0.00421345, mean(E): -21.77505895-0.00001175j, var(E): 0.18262088
-0.0
tensor(26.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=1.19............. Loss: -0.13197431, mean(E): -21.72932976-0.00000510j, var(E): 0.07687286
-0.0
tensor(26.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=1.19............. Loss: -0.10537937, mean(E): -21.75862398-0.00000103j, var(E): 0.12074605
-0.0
tensor(26.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=1.19............. Loss: 0.07050687, mean(E): -21.81210284+0.00002229j, var(E): 0.14749174
-0.0
tensor(26.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=1.19............. Loss: 0.02122262, mean(E): -21.77303089-0.00000312j, var(E): 0.30733462
-0.0
tensor(26.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=1.19............. Loss: -0.06402591, mean(E): -21.76438289+0.00000029j, var(E): 0.11480475
-0.0
tensor(26.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=1.19............. Loss: -0.26339294, mean(E): -21.77259809-0.00000878j, var(E): 0.75625723
-0.0
tensor(26.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=1.19............. Loss: 0.06068114, mean(E): -21.77842125-0.00000698j, var(E): 0.33455170
-0.0
tensor(26.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=1.19............. Loss: -0.09645954, mean(E): -21.75271179+0.00000933j, var(E): 0.31317383
-0.0
tensor(26.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=1.19............. Loss: -0.05964183, mean(E): -21.74730947-0.00001868j, var(E): 0.12896687
-0.0
tensor(26.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=1.19............. Loss: -0.11838972, mean(E): -21.75333362-0.00000660j, var(E): 0.17551132
-0.0
tensor(26.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=1.19............. Loss: 0.01914171, mean(E): -21.77295385+0.00000885j, var(E): 0.22572785
-0.0
tensor(26.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=1.19............. Loss: 0.05970126, mean(E): -21.78196866+0.00000636j, var(E): 0.06068543
-0.0
tensor(26.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=1.19............. Loss: 0.41428741, mean(E): -21.85231817+0.00000356j, var(E): 0.72551948
-0.0
tensor(26.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=1.19............. Loss: 0.17825036, mean(E): -21.80497664-0.00000240j, var(E): 0.15969193
-0.0
tensor(26.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=1.19............. Loss: -0.20238103, mean(E): -21.73155512+0.00000412j, var(E): 0.11808273
-0.0
tensor(26.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=1.19............. Loss: -0.11813248, mean(E): -21.75768010-0.00001683j, var(E): 0.23086005
-0.0
tensor(26.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=1.19............. Loss: -0.11462656, mean(E): -21.75178145-0.00000002j, var(E): 0.34511956
-0.0
tensor(26.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=1.19............. Loss: -0.19355170, mean(E): -21.77285791-0.00000652j, var(E): 0.22515152
-0.0
tensor(26.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=1.19............. Loss: 0.06582690, mean(E): -21.78816538-0.00001284j, var(E): 0.16565298
-0.0
tensor(26.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=1.19............. Loss: -0.19829494, mean(E): -21.76902509+0.00000195j, var(E): 0.13474130
-0.0
tensor(26.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=1.19............. Loss: 0.10323518, mean(E): -21.79850749-0.00001499j, var(E): 0.30175223
-0.0
tensor(26.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=1.2............. Loss: 0.43351078, mean(E): -21.83675658-0.00000512j, var(E): 0.87481328
-0.0
tensor(26.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=1.19............. Loss: 0.09521369, mean(E): -21.73298725+0.00001958j, var(E): 0.29896253
-0.0
tensor(26.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=1.19............. Loss: 0.00303529, mean(E): -21.76683896+0.00000947j, var(E): 0.22592339
-0.0
tensor(26.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=1.19............. Loss: 0.27398255, mean(E): -21.79301948-0.00000516j, var(E): 0.14078571
-0.0
tensor(26.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=1.19............. Loss: -0.03978474, mean(E): -21.76581887-0.00000358j, var(E): 0.17258010
-0.0
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=1.19............. Loss: 0.02863378, mean(E): -21.75732164-0.00000414j, var(E): 0.19832855
-0.0
tensor(26.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=1.19............. Loss: 0.03847301, mean(E): -21.77190425+0.00000635j, var(E): 0.10713430
-0.0
tensor(26.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=1.19............. Loss: -0.30806632, mean(E): -21.71657260-0.00000319j, var(E): 0.20819888
-0.0
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=1.19............. Loss: 0.07006419, mean(E): -21.78414515-0.00000307j, var(E): 0.10870903
-0.0
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=1.19............. Loss: -0.18702969, mean(E): -21.74694213-0.00000843j, var(E): 0.13105225
-0.0
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=1.19............. Loss: -0.14311772, mean(E): -21.75278096-0.00000092j, var(E): 0.19135416
-0.0
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=1.19............. Loss: -0.08685877, mean(E): -21.76332886+0.00000151j, var(E): 0.31828353
-0.0
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=1.19............. Loss: -0.15467828, mean(E): -21.75421733-0.00000097j, var(E): 0.12384609
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=1.19............. Loss: -0.06431789, mean(E): -21.75884026+0.00000584j, var(E): 0.28118563
-0.0
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=1.19............. Loss: -0.00479781, mean(E): -21.79197633-0.00000643j, var(E): 0.28641829
-0.0
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=1.19............. Loss: -0.08602865, mean(E): -21.77224754-0.00000371j, var(E): 0.19563764
-0.0
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=1.19............. Loss: 0.04204844, mean(E): -21.74683079+0.00000028j, var(E): 0.21741960
-0.0
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=1.19............. Loss: 0.16696046, mean(E): -21.78940186+0.00001044j, var(E): 0.20746355
-0.0
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=1.19............. Loss: 0.00264416, mean(E): -21.77061910+0.00001047j, var(E): 0.18540930
-0.0
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=1.19............. Loss: -0.01436002, mean(E): -21.77035636-0.00000907j, var(E): 0.13868792
-0.0
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=1.19............. Loss: -0.07842455, mean(E): -21.73773974-0.00000335j, var(E): 0.11168721
-0.0
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=1.19............. Loss: 0.23685019, mean(E): -21.82472602-0.00000652j, var(E): 0.30084920
-0.0
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=1.19............. Loss: -0.28236479, mean(E): -21.72212381+0.00000778j, var(E): 0.18709740
-0.0
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=1.19............. Loss: -0.21517559, mean(E): -21.75193943+0.00000587j, var(E): 0.21759925
-0.0
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=1.19............. Loss: 0.19189522, mean(E): -21.80270054-0.00001325j, var(E): 0.16777001
-0.0
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=1.19............. Loss: -0.13524871, mean(E): -21.72478212+0.00001659j, var(E): 0.11151680
-0.0
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=1.2............. Loss: 0.08087520, mean(E): -21.77253200+0.00000297j, var(E): 0.46990497
-0.0
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=1.19............. Loss: -0.10904775, mean(E): -21.75784845+0.00000820j, var(E): 0.16812132
-0.0
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=1.19............. Loss: -0.07167187, mean(E): -21.75785027-0.00000055j, var(E): 0.46261962
-0.0
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=1.19............. Loss: 0.18983840, mean(E): -21.80025562-0.00001205j, var(E): 0.20758757
-0.0
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=1.19............. Loss: 0.55818042, mean(E): -21.86424432+0.00000460j, var(E): 0.36479470
-0.0
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=1.19............. Loss: -0.08806728, mean(E): -21.74924390-0.00000706j, var(E): 0.12587850
-0.0
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=1.19............. Loss: -0.47595191, mean(E): -21.72284909+0.00000931j, var(E): 0.27329925
-0.0
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=1.19............. Loss: -0.14558995, mean(E): -21.73881305-0.00001387j, var(E): 0.27102417
-0.0
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=1.19............. Loss: 0.03669981, mean(E): -21.78887229+0.00001967j, var(E): 0.27937869
-0.0
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=1.19............. Loss: 0.02256626, mean(E): -21.77954228-0.00002742j, var(E): 0.28729422
-0.0
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=1.19............. Loss: 0.12971461, mean(E): -21.79171009-0.00000448j, var(E): 0.30368745
-0.0
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=1.2............. Loss: -0.05080433, mean(E): -21.76175067+0.00003576j, var(E): 0.38905559
-0.0
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=1.19............. Loss: 0.21238653, mean(E): -21.79947186+0.00000602j, var(E): 0.20493841
-0.0
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=1.2............. Loss: 0.35162117, mean(E): -21.82973220+0.00001828j, var(E): 0.66010287
-0.0
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=1.19............. Loss: 0.03190392, mean(E): -21.79227131+0.00000282j, var(E): 0.11234398
-0.0
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=1.19............. Loss: 0.10196737, mean(E): -21.77725515+0.00000712j, var(E): 0.09275300
-0.0
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=1.19............. Loss: -0.36480698, mean(E): -21.71024437+0.00001096j, var(E): 0.50296452
-0.0
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=1.2............. Loss: 0.34680456, mean(E): -21.82812695-0.00002271j, var(E): 0.21670513
-0.0
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=1.19............. Loss: -0.22058205, mean(E): -21.72864937+0.00000782j, var(E): 0.13953872
-0.0
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=1.19............. Loss: 0.06231327, mean(E): -21.78324738+0.00003233j, var(E): 0.17230021
-0.0
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=1.2............. Loss: -0.05220327, mean(E): -21.80202214-0.00002722j, var(E): 0.20847717
-0.0
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=1.19............. Loss: 0.08020963, mean(E): -21.79899576-0.00001297j, var(E): 0.11939751
-0.0
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=1.19............. Loss: -0.35384365, mean(E): -21.69661925-0.00002161j, var(E): 0.17838865
-0.0
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=1.19............. Loss: 0.41365272, mean(E): -21.80805310+0.00003788j, var(E): 0.60720004
-0.0
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=1.19............. Loss: 0.03031469, mean(E): -21.73984288-0.00005692j, var(E): 0.32038660
-0.0
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=1.19............. Loss: -0.01585057, mean(E): -21.74661882+0.00006840j, var(E): 0.33491404
-0.0
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=1.21............. Loss: 0.07863525, mean(E): -21.76533081-0.00001034j, var(E): 0.09906938
-0.0
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=1.19............. Loss: 0.43399824, mean(E): -21.81019851+0.00006742j, var(E): 0.35430173
-0.0
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=1.19............. Loss: 0.11669348, mean(E): -21.77207635+0.00009636j, var(E): 0.17436582
-0.0
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=1.19............. Loss: -0.17617504, mean(E): -21.77624025+0.00010151j, var(E): 0.30331546
-0.0
tensor(26.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=1.19............. Loss: 0.34745609, mean(E): -21.81858942-0.00002912j, var(E): 0.41873109
-0.0
tensor(26.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=1.19............. Loss: -0.03010496, mean(E): -21.79206380-0.00001424j, var(E): 0.16381596
-0.0
tensor(26.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=1.19............. Loss: -0.25595087, mean(E): -21.74673190-0.00003924j, var(E): 0.30743340
-0.0
tensor(26.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=1.19............. Loss: 0.24264800, mean(E): -21.80262956-0.00005037j, var(E): 0.18877809
-0.0
tensor(26.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=1.19............. Loss: -0.08849114, mean(E): -21.76366636-0.00002404j, var(E): 0.12601311
-0.0
tensor(26.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=1.19............. Loss: 0.01338783, mean(E): -21.75813164-0.00007004j, var(E): 0.09496167
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=1.19............. Loss: -0.42403199, mean(E): -21.70199707+0.00006905j, var(E): 0.33413170
-0.0
tensor(26.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=1.19............. Loss: -0.06481377, mean(E): -21.77016695-0.00015731j, var(E): 0.12653544
-0.0
tensor(26.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=1.19............. Loss: -0.15270482, mean(E): -21.74939705+0.00003383j, var(E): 0.26451060
-0.0
tensor(26.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=1.19............. Loss: 0.02572049, mean(E): -21.76545126-0.00013590j, var(E): 0.13984800
-0.0
tensor(26.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=1.19............. Loss: -0.25702304, mean(E): -21.71621610-0.00030484j, var(E): 0.37082517
-0.0
tensor(26.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=1.19............. Loss: -0.35254292, mean(E): -21.70911046-0.00014087j, var(E): 0.29919078
-0.0
tensor(26.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=1.19............. Loss: 0.67418363, mean(E): -21.86938489+0.00010379j, var(E): 0.81483740
-0.0
tensor(26.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=1.19............. Loss: 0.04760634, mean(E): -21.76873574+0.00001952j, var(E): 0.29089027
-0.0
tensor(26.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=1.19............. Loss: 0.02906858, mean(E): -21.75981200+0.00003604j, var(E): 0.20857150
-0.0
tensor(26.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=1.19............. Loss: -0.00357652, mean(E): -21.77945814+0.00043156j, var(E): 0.38074130
-0.0
tensor(26.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=1.19............. Loss: -0.25889949, mean(E): -21.70201137-0.00033233j, var(E): 0.46042425
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=1.19............. Loss: -0.27279801, mean(E): -21.72989537-0.00029479j, var(E): 0.23012221
-0.0
tensor(26.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=1.19............. Loss: -0.26398642, mean(E): -21.74274856-0.00008403j, var(E): 0.25062959
-0.0
tensor(26.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=1.19............. Loss: 0.20674682, mean(E): -21.80871413+0.00048101j, var(E): 0.46110349
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=1.19............. Loss: 0.48928802, mean(E): -21.82547938+0.00033666j, var(E): 0.73837517
-0.0
tensor(26.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=1.19............. Loss: 0.14294560, mean(E): -21.80523109+0.00087895j, var(E): 0.31939692
-0.0
tensor(26.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=1.19............. Loss: -0.14490015, mean(E): -21.75483745+0.00112441j, var(E): 0.45481505
-0.0
tensor(26.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=1.19............. Loss: -0.24076221, mean(E): -21.73709705-0.00086191j, var(E): 0.61554707
-0.0
tensor(26.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=1.19............. Loss: 0.35284552, mean(E): -21.79082367-0.00035708j, var(E): 0.61348767
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=1.19............. Loss: 0.57218795, mean(E): -21.87319175-0.00043231j, var(E): 0.50311322
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=1.19............. Loss: 0.01870545, mean(E): -21.77691816+0.00064218j, var(E): 0.37444462
-0.0
tensor(26.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=1.19............. Loss: 0.15218541, mean(E): -21.81729422-0.00050136j, var(E): 0.19752337
-0.0
tensor(26.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=1.19............. Loss: 0.31234704, mean(E): -21.81751422+0.00070093j, var(E): 0.12235990
-0.0
tensor(26.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=1.19............. Loss: 0.15188944, mean(E): -21.80290889+0.00001073j, var(E): 0.25342972
-0.0
tensor(26.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=1.19............. Loss: -0.34307616, mean(E): -21.72564014+0.00079586j, var(E): 0.23796864
-0.0
tensor(26.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=1.19............. Loss: 0.12219604, mean(E): -21.81277386+0.00069013j, var(E): 0.17477165
-0.0
tensor(26.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=1.19............. Loss: 0.53070973, mean(E): -21.84763420-0.00057293j, var(E): 1.20018766
-0.0
tensor(26.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=1.19............. Loss: 0.11953445, mean(E): -21.79567360+0.00078367j, var(E): 0.10234875
-0.0
tensor(26.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=1.19............. Loss: -0.14721346, mean(E): -21.76131452+0.00237477j, var(E): 0.23094085
-0.0
tensor(26.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=1.19............. Loss: -0.28165010, mean(E): -21.70460805-0.00084489j, var(E): 0.22121144
-0.0
tensor(26.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=1.19............. Loss: 0.27549720, mean(E): -21.81212891-0.00037655j, var(E): 0.38987596
-0.0
tensor(26.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=1.19............. Loss: 0.02848642, mean(E): -21.77957718-0.00023838j, var(E): 0.28854448
-0.0
tensor(26.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=1.19............. Loss: 0.18779956, mean(E): -21.80727870-0.00293793j, var(E): 0.25285914
-0.0
tensor(26.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=1.19............. Loss: 0.02460036, mean(E): -21.79038796+0.00001081j, var(E): 0.09398237
-0.0
tensor(26.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=1.19............. Loss: -0.14690016, mean(E): -21.75359406+0.00260766j, var(E): 0.09091044
-0.0
tensor(26.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=1.19............. Loss: 0.33212364, mean(E): -21.82861043+0.00170628j, var(E): 0.36191231
-0.0
tensor(26.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=1.19............. Loss: -0.20388699, mean(E): -21.74857116+0.00144048j, var(E): 0.12664771
-0.0
tensor(26.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=1.19............. Loss: -0.19950328, mean(E): -21.76701995-0.00154850j, var(E): 0.31033398
-0.0
tensor(26.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=1.19............. Loss: -0.16835333, mean(E): -21.74512551+0.00055473j, var(E): 0.25358631
-0.0
tensor(26.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=1.19............. Loss: -0.25098286, mean(E): -21.75227876-0.00096792j, var(E): 0.46773962
-0.0
tensor(26.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=1.19............. Loss: -0.04740918, mean(E): -21.79548348-0.00047808j, var(E): 0.18472293
-0.0
tensor(26.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=1.19............. Loss: -0.33485108, mean(E): -21.72386353-0.00045560j, var(E): 0.40815887
-0.0
tensor(26.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=1.19............. Loss: 0.37515587, mean(E): -21.84091925-0.00057213j, var(E): 0.32676624
-0.0
tensor(26.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=1.19............. Loss: 0.27118196, mean(E): -21.81345766+0.00113592j, var(E): 0.25254665
-0.0
tensor(26.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=1.19............. Loss: 0.13468001, mean(E): -21.78793358+0.00009633j, var(E): 0.31480943
-0.0
tensor(26.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=1.19............. Loss: -0.41575353, mean(E): -21.72202982-0.00050950j, var(E): 0.65650556
-0.0
tensor(26.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=1.19............. Loss: -0.23113816, mean(E): -21.74424079-0.00083152j, var(E): 0.23904596
-0.0
tensor(26.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=1.19............. Loss: 0.29917885, mean(E): -21.84000439-0.00175962j, var(E): 0.14332172
-0.0
tensor(26.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=1.19............. Loss: 0.05241526, mean(E): -21.77592301+0.00133275j, var(E): 0.16346961
-0.0
tensor(26.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=1.19............. Loss: -0.52677983, mean(E): -21.66269260-0.00071569j, var(E): 0.31635802
-0.0
tensor(26.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=1.19............. Loss: -0.25405761, mean(E): -21.73342021-0.00000525j, var(E): 0.30326299
-0.0
tensor(26.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=1.19............. Loss: -0.15445379, mean(E): -21.75502410-0.00102951j, var(E): 0.20538799
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=1.19............. Loss: -0.35847070, mean(E): -21.70614498-0.00104089j, var(E): 0.26688972
-0.0
tensor(26.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=1.19............. Loss: -0.10406064, mean(E): -21.77449114+0.00012634j, var(E): 0.31531586
-0.0
tensor(26.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=1.19............. Loss: 0.19701155, mean(E): -21.80655372+0.00023727j, var(E): 0.13543395
-0.0
tensor(26.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=1.19............. Loss: -0.14831622, mean(E): -21.75661974+0.00062427j, var(E): 0.09515527
-0.0
tensor(26.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=1.19............. Loss: -0.05320889, mean(E): -21.77628902-0.00062523j, var(E): 0.06582807
-0.0
tensor(26.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=1.19............. Loss: -0.24132808, mean(E): -21.72405060+0.00056794j, var(E): 0.15766857
-0.0
tensor(26.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=1.19............. Loss: -0.10912019, mean(E): -21.73509957-0.00091087j, var(E): 0.20423498
-0.0
tensor(26.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=1.19............. Loss: -0.17032455, mean(E): -21.74466051+0.00054992j, var(E): 0.13880003
-0.0
tensor(26.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=1.19............. Loss: -0.01461228, mean(E): -21.75835323-0.00010556j, var(E): 0.10892016
-0.0
tensor(26.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=1.19............. Loss: -0.16478024, mean(E): -21.75349936-0.00014160j, var(E): 0.43485092
-0.0
tensor(26.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=1.19............. Loss: 0.23602994, mean(E): -21.80375265-0.00013856j, var(E): 0.22321838
-0.0
tensor(26.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=1.19............. Loss: -0.30579980, mean(E): -21.74288411-0.00007726j, var(E): 0.22333320
-0.0
tensor(26.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=1.19............. Loss: 0.06619067, mean(E): -21.76056593-0.00018748j, var(E): 0.07580453
-0.0
tensor(26.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=1.19............. Loss: 0.01333902, mean(E): -21.80678909+0.00000301j, var(E): 0.10619090
-0.0
tensor(26.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=1.19............. Loss: 0.38756277, mean(E): -21.80934683-0.00024418j, var(E): 0.31357319
-0.0
tensor(26.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=1.19............. Loss: 0.11243422, mean(E): -21.76506750-0.00032332j, var(E): 0.27369703
-0.0
tensor(26.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=1.19............. Loss: 0.32800028, mean(E): -21.81688292+0.00016157j, var(E): 0.25638311
-0.0
tensor(26.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=1.19............. Loss: 0.42835578, mean(E): -21.84881292-0.00058792j, var(E): 0.66233499
-0.0
tensor(26.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=1.19............. Loss: -0.22321122, mean(E): -21.74911811-0.00049114j, var(E): 0.29119978
-0.0
tensor(26.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=1.19............. Loss: 0.16400177, mean(E): -21.78307972+0.00054654j, var(E): 0.31093002
-0.0
tensor(26.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=1.19............. Loss: -0.12342635, mean(E): -21.73847159-0.00064776j, var(E): 0.33346299
-0.0
tensor(26.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=1.19............. Loss: -0.05391936, mean(E): -21.76652795+0.00026802j, var(E): 0.20816789
-0.0
tensor(26.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=1.19............. Loss: 0.10289780, mean(E): -21.82729114+0.00004488j, var(E): 0.16283605
-0.0
tensor(26.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=1.19............. Loss: -0.28179573, mean(E): -21.73436935+0.00023248j, var(E): 0.17829098
-0.0
tensor(26.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=1.19............. Loss: 0.11252065, mean(E): -21.76845788+0.00079552j, var(E): 0.21496545
-0.0
tensor(26.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=1.19............. Loss: 0.14575782, mean(E): -21.76660469-0.00002387j, var(E): 0.33668664
-0.0
tensor(26.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=1.19............. Loss: 0.69085987, mean(E): -21.87773001+0.00060405j, var(E): 0.31807527
-0.0
tensor(26.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=1.19............. Loss: 0.25373511, mean(E): -21.79071914+0.00044046j, var(E): 0.32933774
-0.0
tensor(26.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=1.19............. Loss: -0.02738373, mean(E): -21.79685893+0.00039133j, var(E): 0.15043162
-0.0
tensor(26.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=1.19............. Loss: -0.02834860, mean(E): -21.78755427+0.00023710j, var(E): 0.19175032
-0.0
tensor(26.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=1.19............. Loss: -0.05934286, mean(E): -21.75460020-0.00022827j, var(E): 0.54304276
-0.0
tensor(26.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=1.19............. Loss: -0.07522521, mean(E): -21.76210759-0.00022052j, var(E): 0.22540696
-0.0
tensor(26.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=1.19............. Loss: 0.17530470, mean(E): -21.79216792-0.00002725j, var(E): 0.24145541
-0.0
tensor(26.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=1.19............. Loss: -0.24353995, mean(E): -21.76231431+0.00016445j, var(E): 0.28331161
-0.0
tensor(26.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=1.19............. Loss: 0.07196575, mean(E): -21.79978248-0.00012705j, var(E): 0.17814498
-0.0
tensor(26.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=1.19............. Loss: -0.46321141, mean(E): -21.74256040+0.00012108j, var(E): 0.27094869
-0.0
tensor(26.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=1.19............. Loss: -0.33595027, mean(E): -21.74220357+0.00001432j, var(E): 0.32971322
-0.0
tensor(26.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=1.19............. Loss: -0.02856464, mean(E): -21.78675622+0.00021530j, var(E): 0.09494492
-0.0
tensor(26.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=1.18............. Loss: -0.24109211, mean(E): -21.72139766+0.00008037j, var(E): 0.23276834
-0.0
tensor(26.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=1.19............. Loss: 0.47561488, mean(E): -21.81980345-0.00001494j, var(E): 0.57728043
-0.0
tensor(26.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=1.19............. Loss: -0.00147394, mean(E): -21.77709711-0.00038240j, var(E): 0.17787291
-0.0
tensor(26.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=1.19............. Loss: 0.15786798, mean(E): -21.78749546+0.00001696j, var(E): 0.14405861
-0.0
tensor(26.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=1.19............. Loss: -0.14814619, mean(E): -21.74532068+0.00000386j, var(E): 0.12473570
-0.0
tensor(26.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=1.19............. Loss: 0.10132513, mean(E): -21.78773394+0.00006043j, var(E): 0.29521566
-0.0
tensor(26.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=1.19............. Loss: -0.31088153, mean(E): -21.69474466-0.00017244j, var(E): 0.20387566
-0.0
tensor(26.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=1.19............. Loss: 0.22850661, mean(E): -21.78923894+0.00016491j, var(E): 0.12747758
-0.0
tensor(26.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=1.19............. Loss: -0.13258082, mean(E): -21.75733321+0.00008084j, var(E): 0.25541926
-0.0
tensor(26.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=1.19............. Loss: -0.01606903, mean(E): -21.78185699-0.00011268j, var(E): 0.24335637
-0.0
tensor(26.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=1.19............. Loss: -0.03856255, mean(E): -21.78892325+0.00011876j, var(E): 0.10393766
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=1.19............. Loss: -0.41207458, mean(E): -21.75679395+0.00009887j, var(E): 0.34133665
-0.0
tensor(26.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=1.19............. Loss: -0.19080687, mean(E): -21.75317968+0.00002498j, var(E): 0.26656240
-0.0
tensor(26.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=1.19............. Loss: -0.17006308, mean(E): -21.78655386+0.00008972j, var(E): 0.35223039
-0.0
tensor(26.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=1.19............. Loss: -0.10960445, mean(E): -21.75077337+0.00011329j, var(E): 0.04171329
-0.0
tensor(26.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=1.19............. Loss: -0.14368744, mean(E): -21.73638877-0.00003368j, var(E): 0.27027177
-0.0
tensor(26.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=1.2............. Loss: -0.24123498, mean(E): -21.73067723-0.00002274j, var(E): 0.37302170
-0.0
tensor(26.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=1.19............. Loss: -0.15897600, mean(E): -21.78987618+0.00017402j, var(E): 0.09360441
-0.0
tensor(26.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=1.19............. Loss: 0.01735364, mean(E): -21.78139333-0.00008879j, var(E): 0.18320942
-0.0
tensor(26.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=1.19............. Loss: 0.04914363, mean(E): -21.79530932+0.00002262j, var(E): 0.25369639
-0.0
tensor(26.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=1.19............. Loss: 0.42158621, mean(E): -21.85634870-0.00003907j, var(E): 0.32836902
-0.0
tensor(26.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=1.19............. Loss: -0.12436695, mean(E): -21.76645717+0.00008956j, var(E): 0.08919804
-0.0
tensor(26.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=1.19............. Loss: 0.04237419, mean(E): -21.80263903-0.00015805j, var(E): 0.28208366
-0.0
tensor(26.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=1.19............. Loss: -0.27243923, mean(E): -21.73354527-0.00004663j, var(E): 0.29432225
-0.0
tensor(26.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=1.19............. Loss: -0.06813442, mean(E): -21.76406240+0.00001283j, var(E): 0.21332442
-0.0
tensor(26.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=1.19............. Loss: -0.14112784, mean(E): -21.77571280+0.00004612j, var(E): 0.38919906
-0.0
tensor(26.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=1.18............. Loss: 0.50422637, mean(E): -21.84423091+0.00013895j, var(E): 0.31083815
-0.0
tensor(26.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=1.19............. Loss: -0.12154506, mean(E): -21.76668788-0.00008779j, var(E): 0.23905871
-0.0
tensor(26.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=1.19............. Loss: -0.28451292, mean(E): -21.71776897+0.00007275j, var(E): 0.21706615
-0.0
tensor(26.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=1.19............. Loss: 0.55943355, mean(E): -21.84363862+0.00010103j, var(E): 0.33183683
-0.0
tensor(26.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=1.19............. Loss: -0.01523212, mean(E): -21.76647802+0.00010679j, var(E): 0.08880878
-0.0
tensor(26.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=1.19............. Loss: 0.15177425, mean(E): -21.80586812+0.00009495j, var(E): 0.21279607
-0.0
tensor(26.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=1.19............. Loss: -0.27922022, mean(E): -21.75901783-0.00009803j, var(E): 0.28121857
-0.0
tensor(26.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=1.19............. Loss: -0.33931636, mean(E): -21.71809540-0.00001460j, var(E): 0.27105149
-0.0
tensor(26.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=1.19............. Loss: -0.27784207, mean(E): -21.73665540+0.00005576j, var(E): 0.31391291
-0.0
tensor(26.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=1.19............. Loss: -0.14065694, mean(E): -21.75895964+0.00029134j, var(E): 0.16827854
-0.0
tensor(26.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=1.19............. Loss: -0.01123112, mean(E): -21.77120458+0.00033057j, var(E): 0.20592445
-0.0
tensor(26.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=1.19............. Loss: 0.18051375, mean(E): -21.80403468+0.00019373j, var(E): 0.13507597
-0.0
tensor(26.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=1.19............. Loss: -0.20875133, mean(E): -21.72929060-0.00033790j, var(E): 0.20560140
-0.0
tensor(26.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=1.19............. Loss: 0.05051135, mean(E): -21.78929399-0.00005331j, var(E): 0.07405080
-0.0
tensor(26.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=1.19............. Loss: 0.19214338, mean(E): -21.81749105+0.00014523j, var(E): 0.14709187
-0.0
tensor(26.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=1.19............. Loss: 0.25717478, mean(E): -21.79510109-0.00018074j, var(E): 0.20675187
-0.0
tensor(26.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=1.19............. Loss: 0.33643238, mean(E): -21.83336185-0.00004705j, var(E): 0.31318159
-0.0
tensor(26.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=1.19............. Loss: -0.35973406, mean(E): -21.72554656+0.00025899j, var(E): 0.25046812
-0.0
tensor(26.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=1.19............. Loss: 0.25320461, mean(E): -21.82056899-0.00025443j, var(E): 0.34441305
-0.0
tensor(26.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=1.19............. Loss: -0.07776426, mean(E): -21.77110256+0.00032243j, var(E): 0.15291312
-0.0
tensor(26.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=1.19............. Loss: 0.13746354, mean(E): -21.79698313+0.00008679j, var(E): 0.24210210
-0.0
tensor(26.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=1.19............. Loss: -0.19135954, mean(E): -21.77459924+0.00015585j, var(E): 0.15413369
-0.0
tensor(26.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=1.19............. Loss: -0.00230201, mean(E): -21.78168791-0.00043627j, var(E): 0.09882152
-0.0
tensor(26.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=1.19............. Loss: 0.01142657, mean(E): -21.74520433-0.00006554j, var(E): 0.18464144
-0.0
tensor(26.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=1.19............. Loss: 0.02143128, mean(E): -21.78905244+0.00083732j, var(E): 0.24494164
-0.0
tensor(26.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=1.19............. Loss: -0.12311308, mean(E): -21.75164104+0.00043108j, var(E): 0.23072781
-0.0
tensor(26.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=1.18............. Loss: 0.45952010, mean(E): -21.84315153+0.00022590j, var(E): 0.25049459
-0.0
tensor(26.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=1.19............. Loss: 0.38771652, mean(E): -21.80778652+0.00073287j, var(E): 0.24734034
-0.0
tensor(26.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=1.19............. Loss: -0.35645154, mean(E): -21.73278535-0.00045345j, var(E): 0.26706813
-0.0
tensor(26.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=1.19............. Loss: 0.11837627, mean(E): -21.80580002-0.00100343j, var(E): 0.18467808
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=1.19............. Loss: 0.56832560, mean(E): -21.87072388-0.00272465j, var(E): 0.48038254
-0.0
tensor(26.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=1.19............. Loss: -0.10864414, mean(E): -21.77498456+0.00050113j, var(E): 0.07783384
-0.0
tensor(26.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=1.18............. Loss: -0.09049882, mean(E): -21.77207749+0.00264296j, var(E): 0.36427952
-0.0
tensor(26.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=1.19............. Loss: -0.20407209, mean(E): -21.75267672-0.00026342j, var(E): 0.30522192
-0.0
tensor(26.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=1.19............. Loss: -0.08330406, mean(E): -21.77389701-0.00048105j, var(E): 0.24203616
-0.0
tensor(26.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=1.19............. Loss: -0.14903879, mean(E): -21.75739731+0.00019164j, var(E): 0.21150644
-0.0
tensor(26.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=1.19............. Loss: -0.66305742, mean(E): -21.64942171-0.00082819j, var(E): 0.27740949
-0.0
tensor(26.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=1.19............. Loss: 0.02511862, mean(E): -21.75872944-0.00024053j, var(E): 0.40372166
-0.0
tensor(26.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=1.19............. Loss: 0.12233889, mean(E): -21.79567496+0.00018221j, var(E): 0.15765322
-0.0
tensor(26.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=1.19............. Loss: 0.64758602, mean(E): -21.87251065-0.00064538j, var(E): 0.77459519
-0.0
tensor(26.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=1.19............. Loss: 0.17513296, mean(E): -21.81999659+0.00022943j, var(E): 0.10019493
-0.0
tensor(26.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=1.19............. Loss: 0.20842378, mean(E): -21.81193977+0.00142316j, var(E): 0.19911308
-0.0
tensor(26.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=1.19............. Loss: 0.02128850, mean(E): -21.77408822-0.00171955j, var(E): 0.16899255
-0.0
tensor(26.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=1.19............. Loss: -0.10415191, mean(E): -21.75657731-0.00100651j, var(E): 0.18165153
-0.0
tensor(26.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=1.19............. Loss: -0.59486213, mean(E): -21.68691336-0.00107533j, var(E): 0.64543145
-0.0
tensor(26.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=1.19............. Loss: 0.76534605, mean(E): -21.88964935-0.00078130j, var(E): 1.24937227
-0.0
tensor(26.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=1.19............. Loss: -0.69147823, mean(E): -21.67367608+0.00038310j, var(E): 0.54060298
-0.0
tensor(26.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=1.19............. Loss: -0.13530958, mean(E): -21.73827453+0.00039393j, var(E): 0.17779518
-0.0
tensor(26.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=1.19............. Loss: -0.25218109, mean(E): -21.73510907-0.00008605j, var(E): 0.31520670
-0.0
tensor(26.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=1.18............. Loss: 0.00829635, mean(E): -21.77695823+0.00012948j, var(E): 0.20186592
-0.0
tensor(26.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=1.19............. Loss: -0.14606109, mean(E): -21.74538363+0.00000706j, var(E): 0.16666942
-0.0
tensor(26.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=1.19............. Loss: -0.49747444, mean(E): -21.75586649-0.00022628j, var(E): 0.59720652
-0.0
tensor(26.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=1.19............. Loss: -0.01136495, mean(E): -21.74185642-0.00010493j, var(E): 0.24222278
-0.0
tensor(26.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=1.19............. Loss: 0.00682691, mean(E): -21.78338544-0.00007907j, var(E): 0.07559864
-0.0
tensor(26.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=1.19............. Loss: 0.18650082, mean(E): -21.78912539-0.00002593j, var(E): 0.35761682
-0.0
tensor(26.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=1.19............. Loss: 0.00440274, mean(E): -21.76718391-0.00009003j, var(E): 0.29973353
-0.0
tensor(26.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=1.19............. Loss: -0.40987047, mean(E): -21.72383166+0.00023685j, var(E): 0.27420125
-0.0
tensor(26.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=1.19............. Loss: 0.01266691, mean(E): -21.77127115-0.00001098j, var(E): 0.17721017
-0.0
tensor(26.8306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=1.19............. Loss: -0.02041340, mean(E): -21.77852975-0.00000734j, var(E): 0.10636722
-0.0
tensor(26.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=1.19............. Loss: -0.02983177, mean(E): -21.75811300-0.00014621j, var(E): 0.22952894
-0.0
tensor(26.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=1.19............. Loss: -0.38069541, mean(E): -21.75674667-0.00011138j, var(E): 0.47490971
-0.0
tensor(26.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=1.19............. Loss: 0.26093320, mean(E): -21.82322383-0.00015374j, var(E): 0.49167947
-0.0
tensor(26.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=1.19............. Loss: -0.03093107, mean(E): -21.75661833-0.00006989j, var(E): 0.13982941
-0.0
tensor(26.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=1.19............. Loss: 1.21972960, mean(E): -21.90384314-0.00006532j, var(E): 2.52657652
-0.0
tensor(26.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=1.19............. Loss: 0.17111808, mean(E): -21.81664858+0.00009297j, var(E): 0.12300959
-0.0
tensor(26.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=1.19............. Loss: -0.30565729, mean(E): -21.74655569-0.00002243j, var(E): 0.21327364
-0.0
tensor(26.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=1.19............. Loss: -0.07677507, mean(E): -21.76434563-0.00000459j, var(E): 0.15273314
-0.0
tensor(26.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=1.19............. Loss: -0.22114386, mean(E): -21.72422399+0.00005563j, var(E): 0.23997778
-0.0
tensor(26.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=1.18............. Loss: -0.06066042, mean(E): -21.77326202-0.00002851j, var(E): 0.21000460
-0.0
tensor(26.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=1.18............. Loss: -0.18543853, mean(E): -21.76387715+0.00001871j, var(E): 0.35989460
-0.0
tensor(26.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=1.19............. Loss: 0.06863099, mean(E): -21.82616445-0.00003603j, var(E): 0.15383149
-0.0
tensor(26.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=1.19............. Loss: 0.08453543, mean(E): -21.77420979-0.00007433j, var(E): 0.07895865
-0.0
tensor(26.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=1.19............. Loss: -0.64706151, mean(E): -21.67432630-0.00002842j, var(E): 0.75614573
-0.0
tensor(26.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=1.19............. Loss: -0.25090684, mean(E): -21.72283447-0.00004550j, var(E): 0.27142349
-0.0
tensor(26.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=1.19............. Loss: -0.05054770, mean(E): -21.76139550+0.00009675j, var(E): 0.28974738
-0.0
tensor(26.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=1.19............. Loss: -0.05502744, mean(E): -21.76926786+0.00011921j, var(E): 0.10329627
-0.0
tensor(26.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=1.19............. Loss: 0.00184094, mean(E): -21.79828527+0.00002584j, var(E): 0.27226499
-0.0
tensor(26.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=1.19............. Loss: 0.02211363, mean(E): -21.79323204+0.00011864j, var(E): 0.11396069
-0.0
tensor(26.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=1.19............. Loss: 0.20936655, mean(E): -21.79490839+0.00005617j, var(E): 0.19834385
-0.0
tensor(26.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=1.19............. Loss: -0.05513632, mean(E): -21.75684442+0.00002609j, var(E): 0.09889349
-0.0
tensor(26.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=1.19............. Loss: -0.05753848, mean(E): -21.77792091-0.00001530j, var(E): 0.13848387
-0.0
tensor(26.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=1.19............. Loss: -0.23431358, mean(E): -21.75348454+0.00010768j, var(E): 0.22069340
-0.0
tensor(26.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=1.19............. Loss: 0.55942137, mean(E): -21.85023453-0.00002518j, var(E): 0.72397390
-0.0
tensor(26.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=1.19............. Loss: -0.06538889, mean(E): -21.77886207-0.00001994j, var(E): 0.34238991
-0.0
tensor(26.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=1.19............. Loss: -0.20261957, mean(E): -21.73181971-0.00008511j, var(E): 0.13170980
-0.0
tensor(26.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=1.19............. Loss: -0.23950686, mean(E): -21.76905700+0.00007184j, var(E): 0.13423930
-0.0
tensor(26.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=1.19............. Loss: 0.43549375, mean(E): -21.83265687-0.00001246j, var(E): 0.48150903
-0.0
tensor(26.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=1.19............. Loss: -0.40333543, mean(E): -21.73718519+0.00004790j, var(E): 0.25285451
-0.0
tensor(26.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=1.19............. Loss: 0.01667678, mean(E): -21.77907282-0.00007877j, var(E): 0.12189384
-0.0
tensor(26.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=1.19............. Loss: -0.13488867, mean(E): -21.76163640-0.00005257j, var(E): 0.37779287
-0.0
tensor(26.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=1.19............. Loss: 0.23351998, mean(E): -21.79674913-0.00006646j, var(E): 0.35638219
-0.0
tensor(26.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=1.19............. Loss: 0.56439459, mean(E): -21.87445016-0.00014352j, var(E): 0.69287936
-0.0
tensor(26.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=1.19............. Loss: 0.47577899, mean(E): -21.83254655-0.00009148j, var(E): 1.07843114
-0.0
tensor(26.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=1.19............. Loss: -0.13135235, mean(E): -21.76056692+0.00016226j, var(E): 0.18417760
-0.0
tensor(26.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=1.19............. Loss: -0.20326836, mean(E): -21.77853999-0.00013551j, var(E): 0.21564565
-0.0
tensor(26.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=1.19............. Loss: 0.10703339, mean(E): -21.80755068+0.00019046j, var(E): 0.20569331
-0.0
tensor(26.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=1.19............. Loss: 0.10911689, mean(E): -21.79991658+0.00013536j, var(E): 0.11596694
-0.0
tensor(26.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=1.19............. Loss: -0.14049414, mean(E): -21.75261286-0.00000717j, var(E): 0.14694104
-0.0
tensor(26.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=1.19............. Loss: 0.06456145, mean(E): -21.79873181-0.00013808j, var(E): 0.07143804
-0.0
tensor(26.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=1.19............. Loss: 0.19849179, mean(E): -21.78887475-0.00014711j, var(E): 0.36307457
-0.0
tensor(26.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=1.19............. Loss: -0.09244355, mean(E): -21.76260657+0.00047433j, var(E): 0.17530868
-0.0
tensor(26.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=1.19............. Loss: 0.05048008, mean(E): -21.81037135+0.00018579j, var(E): 0.11691467
-0.0
tensor(26.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=1.19............. Loss: 0.17944281, mean(E): -21.77313430+0.00020336j, var(E): 1.00043832
-0.0
tensor(26.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=1.19............. Loss: -0.30627283, mean(E): -21.73781201+0.00011875j, var(E): 0.23998443
-0.0
tensor(26.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=1.19............. Loss: -0.19703560, mean(E): -21.77560033-0.00012417j, var(E): 0.26245243
-0.0
tensor(26.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=1.19............. Loss: 0.10494521, mean(E): -21.80831647+0.00028610j, var(E): 0.15088407
-0.0
tensor(26.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=1.19............. Loss: 0.41368136, mean(E): -21.85556553-0.00019401j, var(E): 0.30009089
-0.0
tensor(26.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=1.19............. Loss: 0.10924526, mean(E): -21.79453040-0.00037294j, var(E): 0.09407974
-0.0
tensor(26.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=1.19............. Loss: -0.03225947, mean(E): -21.77961776-0.00004234j, var(E): 0.12850601
-0.0
tensor(26.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=1.19............. Loss: -0.47680248, mean(E): -21.70214375-0.00027039j, var(E): 0.21187147
-0.0
tensor(26.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=1.19............. Loss: -0.40557020, mean(E): -21.72018297-0.00007759j, var(E): 0.21206564
-0.0
tensor(26.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=1.19............. Loss: 0.10824488, mean(E): -21.81052262+0.00055683j, var(E): 0.16236081
-0.0
tensor(26.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=1.19............. Loss: 0.17070138, mean(E): -21.81766914+0.00038977j, var(E): 0.11051835
-0.0
tensor(26.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=1.19............. Loss: 0.40841324, mean(E): -21.82344660+0.00020290j, var(E): 0.27816343
-0.0
tensor(26.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=1.19............. Loss: -0.11782223, mean(E): -21.75588468+0.00003026j, var(E): 0.16074568
-0.0
tensor(26.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=1.19............. Loss: 0.17544973, mean(E): -21.81476315-0.00002408j, var(E): 0.24478649
-0.0
tensor(26.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=1.19............. Loss: -0.17850218, mean(E): -21.74037379-0.00007080j, var(E): 0.21654102
-0.0
tensor(26.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=1.19............. Loss: -0.62915962, mean(E): -21.67360870-0.00037983j, var(E): 0.26454703
-0.0
tensor(26.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=1.19............. Loss: 0.00980136, mean(E): -21.77150585+0.00048324j, var(E): 0.09277768
-0.0
tensor(26.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=1.19............. Loss: -0.15566325, mean(E): -21.76886424+0.00001297j, var(E): 0.18676356
-0.0
tensor(26.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=1.2............. Loss: 0.33204541, mean(E): -21.82552827+0.00063143j, var(E): 0.17061664
-0.0
tensor(26.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=1.19............. Loss: -0.22466777, mean(E): -21.74197452-0.00035032j, var(E): 0.25419166
-0.0
tensor(26.9256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=1.19............. Loss: -0.02106819, mean(E): -21.77797830+0.00071523j, var(E): 0.36395612
-0.0
tensor(26.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=1.19............. Loss: -0.21389890, mean(E): -21.76652126+0.00044467j, var(E): 0.13844484
-0.0
tensor(26.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=1.19............. Loss: -0.36201209, mean(E): -21.73256897-0.00071951j, var(E): 0.34533774
-0.0
tensor(26.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=1.19............. Loss: -0.33510347, mean(E): -21.69306549-0.00058663j, var(E): 0.21716638
-0.0
tensor(26.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=1.19............. Loss: -0.14573289, mean(E): -21.78310200-0.00058851j, var(E): 0.25340659
-0.0
tensor(26.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=1.19............. Loss: -0.00120091, mean(E): -21.76065766+0.00126944j, var(E): 0.15563099
-0.0
tensor(26.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=1.19............. Loss: 0.09271007, mean(E): -21.80927825+0.00094899j, var(E): 0.20128689
-0.0
tensor(26.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=1.19............. Loss: 0.22542488, mean(E): -21.81273922+0.00155543j, var(E): 0.11161091
-0.0
tensor(26.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=1.19............. Loss: 0.01351417, mean(E): -21.78355023+0.00000984j, var(E): 0.05580244
-0.0
tensor(26.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=1.19............. Loss: -0.11689884, mean(E): -21.74674790+0.00002511j, var(E): 0.08570833
-0.0
tensor(26.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=1.19............. Loss: -0.02341891, mean(E): -21.77404034+0.00068331j, var(E): 0.13781455
-0.0
tensor(26.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=1.19............. Loss: -0.36858002, mean(E): -21.72088525+0.00084635j, var(E): 0.19153664
-0.0
tensor(26.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=1.19............. Loss: -0.02653480, mean(E): -21.76763613-0.00027720j, var(E): 0.27386767
-0.0
tensor(26.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=1.19............. Loss: 0.01890167, mean(E): -21.78713916-0.00062492j, var(E): 0.12705720
-0.0
tensor(26.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=1.19............. Loss: 0.09927640, mean(E): -21.77103814-0.00187250j, var(E): 0.19023730
-0.0
tensor(26.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=1.19............. Loss: -0.03333607, mean(E): -21.78441257+0.00090244j, var(E): 0.12483764
-0.0
tensor(26.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=1.19............. Loss: -0.26602136, mean(E): -21.76060003-0.00154515j, var(E): 0.15691712
-0.0
tensor(26.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=1.19............. Loss: 0.08063098, mean(E): -21.79618704-0.00104286j, var(E): 0.24383887
-0.0
tensor(26.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=1.19............. Loss: 0.30728278, mean(E): -21.80767396-0.00016080j, var(E): 0.23969822
-0.0
tensor(26.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=1.19............. Loss: -0.02927714, mean(E): -21.78476323-0.00052673j, var(E): 0.12320961
-0.0
tensor(26.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=1.19............. Loss: -0.14940716, mean(E): -21.75129246+0.00014515j, var(E): 0.12347474
-0.0
tensor(26.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=1.19............. Loss: -0.17491267, mean(E): -21.76474002-0.00081322j, var(E): 0.08702867
-0.0
tensor(26.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=1.19............. Loss: 0.04308773, mean(E): -21.78773029+0.00038175j, var(E): 0.08038248
-0.0
tensor(26.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=1.19............. Loss: 0.03067788, mean(E): -21.80092814-0.00014137j, var(E): 0.19438568
-0.0
tensor(26.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=1.19............. Loss: 0.48285484, mean(E): -21.84467203-0.00012878j, var(E): 0.49807466
-0.0
tensor(26.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=1.19............. Loss: -0.06270979, mean(E): -21.75952249-0.00028897j, var(E): 0.16420793
-0.0
tensor(26.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=1.19............. Loss: -0.05269571, mean(E): -21.74649400-0.00078662j, var(E): 0.84001532
-0.0
tensor(26.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=1.19............. Loss: 0.05387734, mean(E): -21.77540337+0.00007472j, var(E): 0.18460900
-0.0
tensor(26.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=1.19............. Loss: -0.02732267, mean(E): -21.77922092-0.00010422j, var(E): 0.11376250
-0.0
tensor(26.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=1.19............. Loss: 0.10972168, mean(E): -21.79556356-0.00052939j, var(E): 0.24341425
-0.0
tensor(26.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=1.19............. Loss: -0.12750285, mean(E): -21.75974209-0.00032547j, var(E): 0.15477639
-0.0
tensor(26.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=1.19............. Loss: 0.14151955, mean(E): -21.80933460-0.00005378j, var(E): 0.17286165
-0.0
tensor(26.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=1.19............. Loss: 0.33326347, mean(E): -21.82328740-0.00001919j, var(E): 0.60292691
-0.0
tensor(26.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=1.19............. Loss: 0.31944473, mean(E): -21.82892220-0.00007387j, var(E): 0.15869567
-0.0
tensor(26.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=1.19............. Loss: -0.16720300, mean(E): -21.75507834-0.00007480j, var(E): 0.10669361
-0.0
tensor(26.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=1.19............. Loss: -0.15629261, mean(E): -21.73364615-0.00009263j, var(E): 0.34566814
-0.0
tensor(26.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=1.19............. Loss: -0.04188409, mean(E): -21.82537756-0.00018019j, var(E): 0.17706626
-0.0
tensor(26.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=1.19............. Loss: -0.14053918, mean(E): -21.78805052-0.00004150j, var(E): 0.10634048
-0.0
tensor(26.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=1.19............. Loss: 0.18519771, mean(E): -21.82409641-0.00003818j, var(E): 0.28807077
-0.0
tensor(26.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=1.19............. Loss: 0.13557245, mean(E): -21.79510706-0.00014681j, var(E): 0.13025080
-0.0
tensor(26.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(26.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=1.19............. Loss: -0.09554497, mean(E): -21.77168179+0.00004178j, var(E): 0.22505122
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=1.19............. Loss: 0.16027107, mean(E): -21.76927250-0.00003622j, var(E): 0.33579184
-0.0
tensor(27.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=1.19............. Loss: 0.17461034, mean(E): -21.81466087-0.00000701j, var(E): 0.12829381
-0.0
tensor(27.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=1.19............. Loss: -0.20577968, mean(E): -21.75597784-0.00009611j, var(E): 0.24110948
-0.0
tensor(27.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=1.2............. Loss: 0.10763390, mean(E): -21.80240370-0.00003748j, var(E): 0.18156021
-0.0
tensor(27.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=1.19............. Loss: -0.30409273, mean(E): -21.73305963-0.00033276j, var(E): 0.19517210
-0.0
tensor(27.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=1.19............. Loss: -0.08253887, mean(E): -21.74614228-0.00032099j, var(E): 0.09651225
-0.0
tensor(27.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=1.2............. Loss: 0.39342596, mean(E): -21.84340422+0.00022375j, var(E): 0.23732868
-0.0
tensor(27.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=1.19............. Loss: 0.06587750, mean(E): -21.77964984+0.00011327j, var(E): 0.08130921
-0.0
tensor(27.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=1.19............. Loss: 0.16093575, mean(E): -21.80441334-0.00009924j, var(E): 0.25080006
-0.0
tensor(27.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=1.19............. Loss: -0.25311243, mean(E): -21.73134435+0.00023480j, var(E): 0.13271153
-0.0
tensor(27.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=1.2............. Loss: -0.15371258, mean(E): -21.72671842+0.00011978j, var(E): 0.13541681
-0.0
tensor(27.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=1.2............. Loss: 0.07895188, mean(E): -21.77617150-0.00016588j, var(E): 0.11204326
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=1.2............. Loss: 0.08034146, mean(E): -21.78445472+0.00002033j, var(E): 0.18479000
-0.0
tensor(27.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=1.19............. Loss: 0.05659484, mean(E): -21.77290765-0.00003308j, var(E): 0.10167163
-0.0
tensor(27.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=1.19............. Loss: 0.12877585, mean(E): -21.81384618+0.00010965j, var(E): 0.09479633
-0.0
tensor(27.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=1.19............. Loss: 0.05316618, mean(E): -21.78552273-0.00005444j, var(E): 0.30440814
-0.0
tensor(27.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=1.19............. Loss: 0.07706619, mean(E): -21.79088342-0.00001979j, var(E): 0.16512510
-0.0
tensor(27.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=1.19............. Loss: -0.02022986, mean(E): -21.74008927-0.00012017j, var(E): 0.12445632
-0.0
tensor(27.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=1.19............. Loss: -0.03285063, mean(E): -21.77557307-0.00022895j, var(E): 0.12359229
-0.0
tensor(27.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=1.19............. Loss: 0.02484150, mean(E): -21.77327463-0.00001702j, var(E): 0.12473651
-0.0
tensor(27.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=1.19............. Loss: -0.10939847, mean(E): -21.74374183-0.00009940j, var(E): 0.16938013
-0.0
tensor(27.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=1.19............. Loss: -0.43086627, mean(E): -21.67338311-0.00016295j, var(E): 0.50321758
-0.0
tensor(27.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=1.19............. Loss: 0.12012401, mean(E): -21.79070100+0.00036748j, var(E): 0.10829617
-0.0
tensor(27.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=1.19............. Loss: -0.14551181, mean(E): -21.74884446-0.00025960j, var(E): 0.08269432
-0.0
tensor(27.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=1.19............. Loss: 0.13171379, mean(E): -21.78044552-0.00056838j, var(E): 0.17249109
-0.0
tensor(27.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=1.19............. Loss: -0.30581908, mean(E): -21.77308975+0.00036926j, var(E): 0.24532679
-0.0
tensor(27.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=1.19............. Loss: 0.35951448, mean(E): -21.79657355+0.00069509j, var(E): 0.38377531
-0.0
tensor(27.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=1.19............. Loss: 0.08718613, mean(E): -21.79376369+0.00010806j, var(E): 0.10219569
-0.0
tensor(27.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=1.2............. Loss: 0.17757704, mean(E): -21.81659502+0.00002907j, var(E): 0.49632287
-0.0
tensor(27.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=1.19............. Loss: 0.26126359, mean(E): -21.81516914-0.00056898j, var(E): 0.27196832
-0.0
tensor(27.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=1.19............. Loss: 0.20091115, mean(E): -21.80757238+0.00023031j, var(E): 0.14773242
-0.0
tensor(27.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=1.19............. Loss: -0.03289056, mean(E): -21.75742722+0.00024115j, var(E): 0.32694500
-0.0
tensor(27.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=1.19............. Loss: 0.14735991, mean(E): -21.78509865-0.00006092j, var(E): 0.14602611
-0.0
tensor(27.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=1.19............. Loss: 0.01184982, mean(E): -21.77463714-0.00006445j, var(E): 0.09097597
-0.0
tensor(27.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=1.19............. Loss: -0.11746963, mean(E): -21.77697703+0.00031647j, var(E): 0.16036967
-0.0
tensor(27.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=1.19............. Loss: 0.11729488, mean(E): -21.84643799-0.00034705j, var(E): 0.27145231
-0.0
tensor(27.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=1.19............. Loss: -0.06261500, mean(E): -21.78999177+0.00032361j, var(E): 0.06845112
-0.0
tensor(27.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=1.19............. Loss: 0.28810943, mean(E): -21.81815841+0.00067455j, var(E): 0.41505658
-0.0
tensor(27.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=1.19............. Loss: -0.34749375, mean(E): -21.74978243-0.00096379j, var(E): 0.33879977
-0.0
tensor(27.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=1.19............. Loss: -0.18338226, mean(E): -21.75874964+0.00037205j, var(E): 0.17210759
-0.0
tensor(27.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=1.19............. Loss: 0.23791592, mean(E): -21.80395148+0.00046486j, var(E): 0.25611745
-0.0
tensor(27.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=1.19............. Loss: 0.28500670, mean(E): -21.81612452-0.00072464j, var(E): 0.28335641
-0.0
tensor(27.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=1.19............. Loss: -0.04167198, mean(E): -21.76100633-0.00038596j, var(E): 0.11978711
-0.0
tensor(27.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=1.19............. Loss: 0.06880793, mean(E): -21.78308187+0.00178447j, var(E): 0.24221441
-0.0
tensor(27.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=1.19............. Loss: -0.20025949, mean(E): -21.76062256+0.00072593j, var(E): 0.09090640
-0.0
tensor(27.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=1.19............. Loss: 0.33749443, mean(E): -21.82130530-0.00063946j, var(E): 0.45931733
-0.0
tensor(27.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=1.19............. Loss: 0.01922841, mean(E): -21.79846061-0.00163169j, var(E): 0.10876191
-0.0
tensor(27.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=1.19............. Loss: -0.04358729, mean(E): -21.75710210-0.00032707j, var(E): 0.12137564
-0.0
tensor(27.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=1.19............. Loss: 0.23548352, mean(E): -21.76860561-0.00026410j, var(E): 0.38982256
-0.0
tensor(27.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=1.2............. Loss: 0.74169284, mean(E): -21.86505415-0.00007164j, var(E): 0.49868659
-0.0
tensor(27.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=1.19............. Loss: 0.15646905, mean(E): -21.79322209-0.00058254j, var(E): 0.16907802
-0.0
tensor(27.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=1.19............. Loss: 0.27777590, mean(E): -21.81947400-0.00092692j, var(E): 0.17168228
-0.0
tensor(27.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=1.19............. Loss: -0.20737586, mean(E): -21.72313639-0.00009256j, var(E): 0.12713114
-0.0
tensor(27.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=1.19............. Loss: -0.00581385, mean(E): -21.75845509-0.00130197j, var(E): 0.17137270
-0.0
tensor(27.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=1.19............. Loss: -0.05081867, mean(E): -21.77887130+0.00006450j, var(E): 0.14505896
-0.0
tensor(27.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=1.19............. Loss: 0.12147324, mean(E): -21.78261305+0.00075402j, var(E): 0.06409891
-0.0
tensor(27.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=1.19............. Loss: 0.09184865, mean(E): -21.78709449-0.00050876j, var(E): 0.10307319
-0.0
tensor(27.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=1.19............. Loss: -0.18697172, mean(E): -21.75155144+0.00025839j, var(E): 0.16491690
-0.0
tensor(27.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=1.19............. Loss: 0.01279389, mean(E): -21.81085293-0.00075765j, var(E): 0.23571131
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=1.19............. Loss: 0.27785670, mean(E): -21.83055407-0.00008940j, var(E): 0.22434833
-0.0
tensor(27.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=1.19............. Loss: -0.14400339, mean(E): -21.75566560+0.00004323j, var(E): 0.12632068
-0.0
tensor(27.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=1.19............. Loss: -0.21042789, mean(E): -21.75847738-0.00017790j, var(E): 0.44208508
-0.0
tensor(27.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=1.19............. Loss: 0.06345652, mean(E): -21.78481094-0.00012109j, var(E): 0.34803617
-0.0
tensor(27.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=1.19............. Loss: -0.06282291, mean(E): -21.76021539+0.00029211j, var(E): 0.15544581
-0.0
tensor(27.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=1.19............. Loss: -0.06821357, mean(E): -21.76041307-0.00000535j, var(E): 0.10189969
-0.0
tensor(27.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=1.19............. Loss: 0.07668526, mean(E): -21.79794261+0.00001182j, var(E): 0.09831713
-0.0
tensor(27.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=1.19............. Loss: -0.42785898, mean(E): -21.72462105-0.00007741j, var(E): 0.33915083
-0.0
tensor(27.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=1.19............. Loss: -0.02817661, mean(E): -21.77712107-0.00008780j, var(E): 0.06424464
-0.0
tensor(27.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=1.19............. Loss: -0.19443885, mean(E): -21.74164338+0.00020372j, var(E): 0.08768966
-0.0
tensor(27.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=1.19............. Loss: 0.15045937, mean(E): -21.81213270-0.00010908j, var(E): 0.10746610
-0.0
tensor(27.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=1.19............. Loss: 0.27098061, mean(E): -21.81322227-0.00010293j, var(E): 0.15591177
-0.0
tensor(27.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=1.19............. Loss: 0.07513770, mean(E): -21.77000450+0.00015330j, var(E): 0.26160220
-0.0
tensor(27.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=1.19............. Loss: 0.07249824, mean(E): -21.79534758+0.00017264j, var(E): 0.30317477
-0.0
tensor(27.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=1.19............. Loss: -0.16389908, mean(E): -21.72945107+0.00000192j, var(E): 0.18565844
-0.0
tensor(27.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=1.19............. Loss: 0.01715182, mean(E): -21.75931655-0.00035707j, var(E): 0.05902479
-0.0
tensor(27.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=1.19............. Loss: 0.31909647, mean(E): -21.83166826-0.00017133j, var(E): 0.23290595
-0.0
tensor(27.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=1.19............. Loss: -0.07692315, mean(E): -21.77343442-0.00026679j, var(E): 0.12137811
-0.0
tensor(27.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=1.19............. Loss: -0.12738483, mean(E): -21.76254326-0.00004141j, var(E): 0.15006140
-0.0
tensor(27.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=1.19............. Loss: 0.00107873, mean(E): -21.79485566+0.00005516j, var(E): 0.23766688
-0.0
tensor(27.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=1.19............. Loss: -0.03123381, mean(E): -21.78309242-0.00040119j, var(E): 0.12495102
-0.0
tensor(27.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=1.19............. Loss: 0.17109868, mean(E): -21.81086959-0.00014401j, var(E): 0.16907821
-0.0
tensor(27.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=1.19............. Loss: 0.00093055, mean(E): -21.78940558+0.00044480j, var(E): 0.08124046
-0.0
tensor(27.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=1.19............. Loss: -0.00758229, mean(E): -21.78743327+0.00019917j, var(E): 0.08091974
-0.0
tensor(27.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=1.19............. Loss: -0.11196481, mean(E): -21.74165368-0.00022306j, var(E): 0.10817489
-0.0
tensor(27.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=1.2............. Loss: -0.35732190, mean(E): -21.75697934+0.00038722j, var(E): 0.25042608
-0.0
tensor(27.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=1.19............. Loss: 0.09479548, mean(E): -21.78931864+0.00053444j, var(E): 0.12913778
-0.0
tensor(27.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=1.19............. Loss: -0.01237292, mean(E): -21.78637798-0.00004669j, var(E): 0.08890414
-0.0
tensor(27.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=1.19............. Loss: -0.14182749, mean(E): -21.76655145+0.00013487j, var(E): 0.14771278
-0.0
tensor(27.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=1.19............. Loss: 0.68084152, mean(E): -21.88562204+0.00036851j, var(E): 0.63431240
-0.0
tensor(27.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=1.19............. Loss: -0.11431540, mean(E): -21.79269440-0.00032138j, var(E): 0.07764804
-0.0
tensor(27.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=1.2............. Loss: -0.13614946, mean(E): -21.77654644-0.00038784j, var(E): 0.38975811
-0.0
tensor(27.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=1.19............. Loss: 0.17051065, mean(E): -21.80042803+0.00020688j, var(E): 0.29962684
-0.0
tensor(27.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=1.19............. Loss: -0.25063571, mean(E): -21.75438018-0.00021140j, var(E): 0.15774794
-0.0
tensor(27.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=1.19............. Loss: 0.19168359, mean(E): -21.81787360-0.00033001j, var(E): 0.18086572
-0.0
tensor(27.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=1.19............. Loss: 0.13825151, mean(E): -21.81509439+0.00025776j, var(E): 0.44998294
-0.0
tensor(27.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=1.19............. Loss: 0.07741893, mean(E): -21.77328722+0.00002033j, var(E): 0.14967543
-0.0
tensor(27.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=1.19............. Loss: 0.03747068, mean(E): -21.79676953+0.00054166j, var(E): 0.08302262
-0.0
tensor(27.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=1.19............. Loss: -0.00428645, mean(E): -21.76743564-0.00051982j, var(E): 0.08751113
-0.0
tensor(27.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=1.19............. Loss: 0.05753349, mean(E): -21.81136530+0.00021533j, var(E): 0.13352898
-0.0
tensor(27.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=1.19............. Loss: 0.10112742, mean(E): -21.78293061+0.00139583j, var(E): 0.24420359
-0.0
tensor(27.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=1.19............. Loss: 0.26912732, mean(E): -21.81475733+0.00048649j, var(E): 0.17997908
-0.0
tensor(27.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=1.2............. Loss: -0.08453891, mean(E): -21.76139711-0.00040538j, var(E): 0.26180426
-0.0
tensor(27.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=1.19............. Loss: 0.09226000, mean(E): -21.80458617+0.00038240j, var(E): 0.10190675
-0.0
tensor(27.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=1.19............. Loss: -0.02848816, mean(E): -21.78581799+0.00052759j, var(E): 0.12565825
-0.0
tensor(27.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=1.2............. Loss: -0.03528146, mean(E): -21.77914080-0.00075449j, var(E): 0.09505807
-0.0
tensor(27.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=1.19............. Loss: 0.09950984, mean(E): -21.79306129+0.00120304j, var(E): 0.34007038
-0.0
tensor(27.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=1.19............. Loss: 0.12895701, mean(E): -21.80293590+0.00035823j, var(E): 0.09177165
-0.0
tensor(27.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=1.19............. Loss: 0.14134395, mean(E): -21.80441508-0.00093359j, var(E): 0.10207838
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=1.19............. Loss: -0.43128018, mean(E): -21.71304421+0.00011138j, var(E): 0.36693213
-0.0
tensor(27.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=1.19............. Loss: 0.10189396, mean(E): -21.78482068-0.00088729j, var(E): 0.24946889
-0.0
tensor(27.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=1.19............. Loss: 0.55271694, mean(E): -21.84842814+0.00265665j, var(E): 0.47332448
-0.0
tensor(27.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=1.19............. Loss: 0.06729614, mean(E): -21.79565120+0.00166663j, var(E): 0.08541614
-0.0
tensor(27.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=1.19............. Loss: -0.11914470, mean(E): -21.77459111+0.00094097j, var(E): 0.19731192
-0.0
tensor(27.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=1.19............. Loss: -0.15123229, mean(E): -21.76795304-0.00134026j, var(E): 0.11672041
-0.0
tensor(27.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=1.19............. Loss: -0.31653700, mean(E): -21.72707834-0.00026005j, var(E): 0.12871260
-0.0
tensor(27.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=1.19............. Loss: 0.08185686, mean(E): -21.79380703-0.00003867j, var(E): 0.25247542
-0.0
tensor(27.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=1.19............. Loss: 0.18922772, mean(E): -21.79745557+0.00044070j, var(E): 0.13238224
-0.0
tensor(27.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=1.19............. Loss: 0.09229360, mean(E): -21.77819629+0.00046470j, var(E): 0.15442199
-0.0
tensor(27.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=1.19............. Loss: 0.21798991, mean(E): -21.83111757+0.00052417j, var(E): 0.13680675
-0.0
tensor(27.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=1.19............. Loss: -0.18176649, mean(E): -21.76698438+0.00076421j, var(E): 0.23447133
-0.0
tensor(27.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=1.19............. Loss: 0.00680763, mean(E): -21.75771383-0.00040422j, var(E): 0.10008560
-0.0
tensor(27.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=1.19............. Loss: 0.42541580, mean(E): -21.84495327+0.00066982j, var(E): 0.35416829
-0.0
tensor(27.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=1.19............. Loss: 0.00345194, mean(E): -21.79800911+0.00098983j, var(E): 0.18036619
-0.0
tensor(27.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=1.19............. Loss: -0.16706916, mean(E): -21.76263019-0.00026848j, var(E): 0.10026054
-0.0
tensor(27.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=1.19............. Loss: 0.08510910, mean(E): -21.77753539-0.00055772j, var(E): 0.38847207
-0.0
tensor(27.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=1.19............. Loss: 0.17190786, mean(E): -21.80483966+0.00107736j, var(E): 0.19492354
-0.0
tensor(27.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=1.19............. Loss: -0.08346442, mean(E): -21.77818685+0.00032652j, var(E): 0.09625521
-0.0
tensor(27.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=1.19............. Loss: -0.09677204, mean(E): -21.78491743+0.00060280j, var(E): 0.08243804
-0.0
tensor(27.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=1.19............. Loss: 0.09283950, mean(E): -21.80206722+0.00014975j, var(E): 0.08201614
-0.0
tensor(27.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=1.19............. Loss: 0.25239768, mean(E): -21.85643576+0.00088108j, var(E): 0.19716928
-0.0
tensor(27.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=1.19............. Loss: -0.03757823, mean(E): -21.78014024-0.00025026j, var(E): 0.03719089
-0.0
tensor(27.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=1.18............. Loss: -0.67595391, mean(E): -21.72323140+0.00019897j, var(E): 0.60951171
-0.0
tensor(27.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=1.19............. Loss: 0.43918783, mean(E): -21.83732960+0.00006070j, var(E): 0.34934024
-0.0
tensor(27.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=1.19............. Loss: -0.12485498, mean(E): -21.77864511+0.00014923j, var(E): 0.16111290
-0.0
tensor(27.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=1.19............. Loss: -0.39413214, mean(E): -21.75776683+0.00053605j, var(E): 0.32557929
-0.0
tensor(27.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=1.19............. Loss: -0.00745784, mean(E): -21.77240376-0.00026410j, var(E): 0.08153071
-0.0
tensor(27.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=1.19............. Loss: -0.21668079, mean(E): -21.74485323-0.00053757j, var(E): 0.24187531
-0.0
tensor(27.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=1.19............. Loss: 0.14462855, mean(E): -21.81280314-0.00060492j, var(E): 0.06346244
-0.0
tensor(27.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=1.19............. Loss: -0.25794377, mean(E): -21.74266042-0.00017790j, var(E): 0.19522318
-0.0
tensor(27.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=1.19............. Loss: 0.34257877, mean(E): -21.81253144-0.00037959j, var(E): 0.31403389
-0.0
tensor(27.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=1.19............. Loss: 0.08561327, mean(E): -21.80237648-0.00008779j, var(E): 0.24137806
-0.0
tensor(27.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=1.19............. Loss: -0.02923936, mean(E): -21.77124720+0.00025444j, var(E): 0.20796581
-0.0
tensor(27.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=1.19............. Loss: -0.46061031, mean(E): -21.66344014+0.00020399j, var(E): 0.39086500
-0.0
tensor(27.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=1.19............. Loss: -0.32888486, mean(E): -21.72587605-0.00032061j, var(E): 0.38736413
-0.0
tensor(27.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=1.19............. Loss: -0.15875162, mean(E): -21.75652499+0.00048450j, var(E): 0.33062361
-0.0
tensor(27.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=1.19............. Loss: 0.15280374, mean(E): -21.81495785+0.00020192j, var(E): 0.06929822
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=1.19............. Loss: -0.53606977, mean(E): -21.71881155-0.00007709j, var(E): 0.29454849
-0.0
tensor(27.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=1.19............. Loss: -0.14531916, mean(E): -21.74019479+0.00013509j, var(E): 0.16204315
-0.0
tensor(27.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=1.19............. Loss: -0.42591792, mean(E): -21.70847891+0.00008650j, var(E): 0.22946510
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=1.19............. Loss: 0.17563528, mean(E): -21.80479016+0.00018712j, var(E): 0.39328202
-0.0
tensor(27.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=1.19............. Loss: 0.28621285, mean(E): -21.82728155+0.00003039j, var(E): 0.21048441
-0.0
tensor(27.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=1.19............. Loss: 1.01364022, mean(E): -21.88086504-0.00010304j, var(E): 1.58033741
-0.0
tensor(27.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=1.19............. Loss: 0.06860859, mean(E): -21.79603233+0.00006680j, var(E): 0.04255005
-0.0
tensor(27.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=1.19............. Loss: -0.01003815, mean(E): -21.77493701+0.00009501j, var(E): 0.17532480
-0.0
tensor(27.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=1.19............. Loss: 0.15329978, mean(E): -21.82191986+0.00009892j, var(E): 0.43231602
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=1.19............. Loss: -0.36014194, mean(E): -21.74388424+0.00010673j, var(E): 0.14435430
-0.0
tensor(27.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=1.19............. Loss: -0.01111672, mean(E): -21.76026274+0.00008476j, var(E): 0.09487426
-0.0
tensor(27.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=1.19............. Loss: 0.39090020, mean(E): -21.82919203+0.00008486j, var(E): 0.19627770
-0.0
tensor(27.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=1.19............. Loss: 0.02400374, mean(E): -21.77903340+0.00002713j, var(E): 0.29515180
-0.0
tensor(27.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=1.19............. Loss: 0.28076446, mean(E): -21.80648281-0.00003015j, var(E): 0.32591400
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=1.19............. Loss: 0.08242466, mean(E): -21.79209196-0.00000815j, var(E): 0.11443661
-0.0
tensor(27.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=1.19............. Loss: -0.25524656, mean(E): -21.75559499-0.00004944j, var(E): 0.39701740
-0.0
tensor(27.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=1.2............. Loss: -0.03352224, mean(E): -21.76813869+0.00002450j, var(E): 0.11040822
-0.0
tensor(27.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=1.19............. Loss: -0.01623240, mean(E): -21.78759659+0.00004668j, var(E): 0.16833603
-0.0
tensor(27.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=1.19............. Loss: 0.48016386, mean(E): -21.83480767-0.00004726j, var(E): 0.19441748
-0.0
tensor(27.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=1.19............. Loss: -0.16690442, mean(E): -21.76319633+0.00001203j, var(E): 0.08551514
-0.0
tensor(27.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=1.19............. Loss: 0.31158518, mean(E): -21.82122917+0.00002858j, var(E): 0.23558323
-0.0
tensor(27.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=1.19............. Loss: 0.08459661, mean(E): -21.80177228+0.00000924j, var(E): 0.10052112
-0.0
tensor(27.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=1.19............. Loss: -0.06160145, mean(E): -21.78178322-0.00003114j, var(E): 0.17750834
-0.0
tensor(27.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=1.19............. Loss: 0.46194954, mean(E): -21.84446999+0.00001760j, var(E): 0.69328868
-0.0
tensor(27.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=1.19............. Loss: -0.10145663, mean(E): -21.77414199-0.00002100j, var(E): 0.10240861
-0.0
tensor(27.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=1.19............. Loss: -0.06740257, mean(E): -21.78079233-0.00000738j, var(E): 0.17517940
-0.0
tensor(27.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=1.19............. Loss: -0.13864137, mean(E): -21.76614786+0.00000009j, var(E): 0.16049496
-0.0
tensor(27.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=1.19............. Loss: 0.06891287, mean(E): -21.79245080-0.00002923j, var(E): 0.14619801
-0.0
tensor(27.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=1.19............. Loss: -0.11432158, mean(E): -21.77746738-0.00004127j, var(E): 0.14311230
-0.0
tensor(27.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=1.19............. Loss: 0.02901263, mean(E): -21.77994841-0.00000880j, var(E): 0.14834982
-0.0
tensor(27.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=1.19............. Loss: 0.37393385, mean(E): -21.81596899+0.00000695j, var(E): 0.43612426
-0.0
tensor(27.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=1.19............. Loss: -0.35272766, mean(E): -21.71527512+0.00003709j, var(E): 0.29322029
-0.0
tensor(27.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=1.19............. Loss: 0.09603927, mean(E): -21.79652739-0.00007421j, var(E): 0.38553710
-0.0
tensor(27.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=1.19............. Loss: 0.39955100, mean(E): -21.82331769-0.00001969j, var(E): 0.21726462
-0.0
tensor(27.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=1.19............. Loss: -0.18788220, mean(E): -21.73325233-0.00001331j, var(E): 0.11300876
-0.0
tensor(27.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=1.19............. Loss: -0.01348041, mean(E): -21.79188619-0.00003156j, var(E): 0.10038416
-0.0
tensor(27.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=1.19............. Loss: -0.24700574, mean(E): -21.71797857-0.00000513j, var(E): 0.17564823
-0.0
tensor(27.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=1.2............. Loss: -0.19120152, mean(E): -21.72526654+0.00006599j, var(E): 0.30486193
-0.0
tensor(27.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=1.19............. Loss: -0.01404029, mean(E): -21.76178905-0.00000078j, var(E): 0.06446678
-0.0
tensor(27.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=1.19............. Loss: -0.13555387, mean(E): -21.77944855+0.00011288j, var(E): 0.17098456
-0.0
tensor(27.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=1.19............. Loss: -0.12655268, mean(E): -21.77452381-0.00001850j, var(E): 0.13155040
-0.0
tensor(27.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=1.2............. Loss: -0.02835338, mean(E): -21.75837575+0.00008436j, var(E): 0.12872562
-0.0
tensor(27.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=1.2............. Loss: 0.13157181, mean(E): -21.80087518-0.00002871j, var(E): 0.05729389
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=1.19............. Loss: -0.03384465, mean(E): -21.78966029+0.00004317j, var(E): 0.24559121
-0.0
tensor(27.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=1.19............. Loss: -0.00294072, mean(E): -21.79237738+0.00003561j, var(E): 0.09773666
-0.0
tensor(27.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=1.19............. Loss: 0.07460222, mean(E): -21.78755842+0.00004317j, var(E): 0.06703828
-0.0
tensor(27.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=1.19............. Loss: 0.12278162, mean(E): -21.78992254-0.00011451j, var(E): 0.13432740
-0.0
tensor(27.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=1.19............. Loss: 0.00410427, mean(E): -21.76323727+0.00002468j, var(E): 0.27100202
-0.0
tensor(27.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=1.19............. Loss: 0.12565870, mean(E): -21.80031322-0.00000211j, var(E): 0.05821482
-0.0
tensor(27.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=1.19............. Loss: -0.16816753, mean(E): -21.77066380-0.00008559j, var(E): 0.40387527
-0.0
tensor(27.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=1.19............. Loss: 0.24402444, mean(E): -21.78978451+0.00011005j, var(E): 0.32249397
-0.0
tensor(27.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=1.19............. Loss: -0.09607972, mean(E): -21.78125625-0.00004506j, var(E): 0.12678960
-0.0
tensor(27.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=1.19............. Loss: 0.04555998, mean(E): -21.79709267-0.00007230j, var(E): 0.34574633
-0.0
tensor(27.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=1.19............. Loss: -0.20339872, mean(E): -21.74213810-0.00017580j, var(E): 0.13925084
-0.0
tensor(27.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=1.19............. Loss: -0.29163946, mean(E): -21.71887145-0.00028808j, var(E): 0.18784619
-0.0
tensor(27.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=1.19............. Loss: -0.24219023, mean(E): -21.74933632+0.00052372j, var(E): 0.13503678
-0.0
tensor(27.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=1.19............. Loss: 0.15820166, mean(E): -21.79939434-0.00026746j, var(E): 0.23225233
-0.0
tensor(27.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=1.19............. Loss: -0.09544091, mean(E): -21.75259567-0.00003297j, var(E): 0.23685878
-0.0
tensor(27.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=1.19............. Loss: -0.07449345, mean(E): -21.76869487+0.00040725j, var(E): 0.14943017
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=1.19............. Loss: 0.28398342, mean(E): -21.79485327-0.00013041j, var(E): 0.28356490
-0.0
tensor(27.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=1.19............. Loss: 0.00007690, mean(E): -21.77408723-0.00012263j, var(E): 0.16685688
-0.0
tensor(27.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=1.19............. Loss: -0.22043867, mean(E): -21.74583664+0.00004588j, var(E): 0.33263642
-0.0
tensor(27.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=1.19............. Loss: -0.03410043, mean(E): -21.77235351+0.00006844j, var(E): 0.06553367
-0.0
tensor(27.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=1.19............. Loss: 0.26486492, mean(E): -21.81110478+0.00006780j, var(E): 0.08646615
-0.0
tensor(27.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=1.19............. Loss: -0.32557950, mean(E): -21.72039730+0.00021140j, var(E): 0.28162459
-0.0
tensor(27.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=1.19............. Loss: 0.20616714, mean(E): -21.80619175-0.00048069j, var(E): 0.20485791
-0.0
tensor(27.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=1.19............. Loss: 0.12538327, mean(E): -21.81553937+0.00019859j, var(E): 0.12182383
-0.0
tensor(27.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=1.19............. Loss: 0.13472025, mean(E): -21.79394394+0.00075743j, var(E): 0.11613054
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=1.19............. Loss: -0.08373601, mean(E): -21.78327498+0.00030367j, var(E): 0.18981958
-0.0
tensor(27.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=1.19............. Loss: 0.00235164, mean(E): -21.81231563-0.00069152j, var(E): 0.25293994
-0.0
tensor(27.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=1.19............. Loss: 0.02612247, mean(E): -21.78732366+0.00021898j, var(E): 0.04367906
-0.0
tensor(27.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=1.19............. Loss: -0.01832605, mean(E): -21.78036100-0.00122177j, var(E): 0.10343745
-0.0
tensor(27.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=1.19............. Loss: 0.14294653, mean(E): -21.80582340+0.00075777j, var(E): 0.08958232
-0.0
tensor(27.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=1.19............. Loss: -0.07986350, mean(E): -21.75693600-0.00039041j, var(E): 0.06748365
-0.0
tensor(27.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=1.2............. Loss: -0.09767637, mean(E): -21.76744530-0.00057939j, var(E): 0.07094420
-0.0
tensor(27.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=1.19............. Loss: -0.01058750, mean(E): -21.80236524-0.00141764j, var(E): 0.10231173
-0.0
tensor(27.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=1.19............. Loss: -0.21699609, mean(E): -21.74215689-0.00052504j, var(E): 0.09724324
-0.0
tensor(27.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=1.19............. Loss: -0.25117729, mean(E): -21.76055464-0.00070518j, var(E): 0.18080474
-0.0
tensor(27.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=1.19............. Loss: -0.24346849, mean(E): -21.76406500-0.00095708j, var(E): 0.20280701
-0.0
tensor(27.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=1.2............. Loss: 0.04154374, mean(E): -21.79679355-0.00013057j, var(E): 0.19176713
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=1.19............. Loss: 0.37405941, mean(E): -21.81918633+0.00017469j, var(E): 0.37836261
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=1.19............. Loss: 0.07433582, mean(E): -21.78432549+0.00054631j, var(E): 0.13228529
-0.0
tensor(27.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=1.19............. Loss: 0.00143852, mean(E): -21.77666608+0.00050064j, var(E): 0.18952324
-0.0
tensor(27.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=1.19............. Loss: 0.02881745, mean(E): -21.78783886+0.00067581j, var(E): 0.17513395
-0.0
tensor(27.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=1.19............. Loss: 0.05486649, mean(E): -21.78922739+0.00031865j, var(E): 0.18205439
-0.0
tensor(27.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=1.19............. Loss: -0.05048595, mean(E): -21.78576169+0.00049065j, var(E): 0.07537899
-0.0
tensor(27.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=1.19............. Loss: -0.00475739, mean(E): -21.77710072+0.00068145j, var(E): 0.21043031
-0.0
tensor(27.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=1.19............. Loss: 0.19772579, mean(E): -21.81146092+0.00007433j, var(E): 0.09844384
-0.0
tensor(27.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=1.19............. Loss: -0.19418274, mean(E): -21.77357170+0.00102562j, var(E): 0.13205567
-0.0
tensor(27.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=1.19............. Loss: -0.16634919, mean(E): -21.75809571-0.00040418j, var(E): 0.13415153
-0.0
tensor(27.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=1.19............. Loss: 0.01850682, mean(E): -21.78515651+0.00003490j, var(E): 0.06197790
-0.0
tensor(27.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=1.19............. Loss: -0.02077917, mean(E): -21.76500349-0.00037418j, var(E): 0.19510226
-0.0
tensor(27.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=1.2............. Loss: 0.09522672, mean(E): -21.78994405-0.00086158j, var(E): 0.14113750
-0.0
tensor(27.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=1.19............. Loss: 0.14962823, mean(E): -21.81630119+0.00086446j, var(E): 0.09835225
-0.0
tensor(27.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=1.19............. Loss: -0.19096937, mean(E): -21.77187557+0.00022100j, var(E): 0.22202925
-0.0
tensor(27.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=1.19............. Loss: -0.43220820, mean(E): -21.71012480-0.00014522j, var(E): 0.24498214
-0.0
tensor(27.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=1.19............. Loss: 0.07888709, mean(E): -21.80132360+0.00078564j, var(E): 0.07410780
-0.0
tensor(27.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=1.19............. Loss: -0.22748198, mean(E): -21.76469100+0.00010927j, var(E): 0.15013018
-0.0
tensor(27.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=1.19............. Loss: 0.16755120, mean(E): -21.81717751-0.00014794j, var(E): 0.09989152
-0.0
tensor(27.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=1.19............. Loss: -0.27916040, mean(E): -21.74428302-0.00097449j, var(E): 0.22009832
-0.0
tensor(27.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=1.19............. Loss: -0.09461516, mean(E): -21.79292504+0.00069888j, var(E): 0.10590968
-0.0
tensor(27.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=1.19............. Loss: 0.23550296, mean(E): -21.83070312+0.00027040j, var(E): 0.22955923
-0.0
tensor(27.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=1.19............. Loss: -0.13549063, mean(E): -21.77236693-0.00049329j, var(E): 0.14047547
-0.0
tensor(27.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=1.19............. Loss: -0.08148511, mean(E): -21.78326135-0.00026488j, var(E): 0.06139641
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=1.19............. Loss: 0.23565985, mean(E): -21.82325114-0.00066408j, var(E): 0.21281660
-0.0
tensor(27.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=1.19............. Loss: -0.34153151, mean(E): -21.72373450-0.00013480j, var(E): 0.19097663
-0.0
tensor(27.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=1.19............. Loss: -0.26885022, mean(E): -21.74932624+0.00016185j, var(E): 0.17014724
-0.0
tensor(27.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=1.19............. Loss: -0.26411547, mean(E): -21.74889452+0.00021151j, var(E): 0.18475068
-0.0
tensor(27.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=1.19............. Loss: -0.06219978, mean(E): -21.77242884-0.00008114j, var(E): 0.18925532
-0.0
tensor(27.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=1.19............. Loss: -0.09833980, mean(E): -21.76550230+0.00026401j, var(E): 0.09914538
-0.0
tensor(27.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=1.19............. Loss: 0.17087938, mean(E): -21.81799011+0.00073582j, var(E): 0.28790132
-0.0
tensor(27.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=1.19............. Loss: 0.02490078, mean(E): -21.77853851-0.00036073j, var(E): 0.09999623
-0.0
tensor(27.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=1.19............. Loss: -0.02262085, mean(E): -21.77983994+0.00034711j, var(E): 0.15315595
-0.0
tensor(27.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=1.19............. Loss: 0.94355310, mean(E): -21.88259584+0.00032147j, var(E): 1.76740275
-0.0
tensor(27.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=1.19............. Loss: 0.07816861, mean(E): -21.80591503-0.00023868j, var(E): 0.10218906
-0.0
tensor(27.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=1.19............. Loss: 0.32741846, mean(E): -21.77573520-0.00030624j, var(E): 1.54077035
-0.0
tensor(27.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=1.19............. Loss: -0.29224828, mean(E): -21.75095000-0.00016348j, var(E): 0.11452445
-0.0
tensor(27.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=1.19............. Loss: -0.00526390, mean(E): -21.79249932-0.00000673j, var(E): 0.06111119
-0.0
tensor(27.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=1.2............. Loss: 0.29390212, mean(E): -21.82084085+0.00003866j, var(E): 0.20605096
-0.0
tensor(27.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=1.19............. Loss: 0.59373536, mean(E): -21.84917343+0.00013192j, var(E): 0.31214936
-0.0
tensor(27.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=1.2............. Loss: -0.02822362, mean(E): -21.76600122+0.00017741j, var(E): 0.10390930
-0.0
tensor(27.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=1.19............. Loss: 0.09341969, mean(E): -21.77307980+0.00018186j, var(E): 0.31321329
-0.0
tensor(27.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=1.19............. Loss: 0.04080088, mean(E): -21.78035207+0.00015950j, var(E): 0.45977348
-0.0
tensor(27.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=1.19............. Loss: 0.08072051, mean(E): -21.82863009+0.00006136j, var(E): 0.08933097
-0.0
tensor(27.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=1.18............. Loss: 0.62470760, mean(E): -21.86492697+0.00018817j, var(E): 1.26712117
-0.0
tensor(27.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=1.19............. Loss: -0.11154813, mean(E): -21.76654234+0.00033036j, var(E): 0.22620692
-0.0
tensor(27.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=1.19............. Loss: -0.05905115, mean(E): -21.75631390-0.00015787j, var(E): 0.08867713
-0.0
tensor(27.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=1.19............. Loss: 0.11655849, mean(E): -21.78353993+0.00009523j, var(E): 0.47034286
-0.0
tensor(27.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=1.19............. Loss: 0.26001034, mean(E): -21.82460455-0.00001655j, var(E): 0.12070158
-0.0
tensor(27.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=1.19............. Loss: 0.03190047, mean(E): -21.80953056+0.00022764j, var(E): 0.09872092
-0.0
tensor(27.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=1.19............. Loss: 0.46002366, mean(E): -21.83394670-0.00000943j, var(E): 1.08200330
-0.0
tensor(27.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=1.19............. Loss: -0.10185746, mean(E): -21.76616230+0.00009825j, var(E): 0.12697994
-0.0
tensor(27.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=1.19............. Loss: -0.27073289, mean(E): -21.75309017-0.00000417j, var(E): 0.48116400
-0.0
tensor(27.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=1.19............. Loss: -0.29560790, mean(E): -21.75359721-0.00004251j, var(E): 0.52056593
-0.0
tensor(27.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=1.19............. Loss: -0.13844508, mean(E): -21.78438072+0.00008536j, var(E): 0.16947807
-0.0
tensor(27.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=1.19............. Loss: 0.06048342, mean(E): -21.79312277+0.00012905j, var(E): 0.19224592
-0.0
tensor(27.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=1.19............. Loss: 0.11065021, mean(E): -21.80281110+0.00009490j, var(E): 0.08567709
-0.0
tensor(27.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=1.19............. Loss: 0.07573741, mean(E): -21.79816397+0.00000244j, var(E): 0.10134579
-0.0
tensor(27.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=1.19............. Loss: -0.07249319, mean(E): -21.78041632-0.00010924j, var(E): 0.13617975
-0.0
tensor(27.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=1.19............. Loss: 0.25128796, mean(E): -21.81661624+0.00010777j, var(E): 0.09673736
-0.0
tensor(27.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=1.19............. Loss: -0.03880167, mean(E): -21.78989177-0.00015770j, var(E): 0.07533251
-0.0
tensor(27.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=1.19............. Loss: 0.04084787, mean(E): -21.80317551+0.00002444j, var(E): 0.31394386
-0.0
tensor(27.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=1.19............. Loss: -0.50952004, mean(E): -21.71584498-0.00006035j, var(E): 0.25422545
-0.0
tensor(27.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=1.19............. Loss: 0.02045489, mean(E): -21.77198137+0.00007571j, var(E): 0.03677660
-0.0
tensor(27.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=1.19............. Loss: 0.23995145, mean(E): -21.80095786+0.00034238j, var(E): 0.52560423
-0.0
tensor(27.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=1.19............. Loss: 0.04572585, mean(E): -21.80498295+0.00003728j, var(E): 0.21287554
-0.0
tensor(27.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=1.19............. Loss: 0.08195420, mean(E): -21.80541715-0.00006976j, var(E): 0.10104976
-0.0
tensor(27.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=1.19............. Loss: 0.00413032, mean(E): -21.79423080+0.00025022j, var(E): 0.11372529
-0.0
tensor(27.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=1.19............. Loss: 0.31438379, mean(E): -21.82069894+0.00028678j, var(E): 0.11293620
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=1.19............. Loss: 0.02825820, mean(E): -21.81667759+0.00022206j, var(E): 0.11204601
-0.0
tensor(27.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=1.19............. Loss: -0.23262593, mean(E): -21.76264516+0.00034555j, var(E): 0.27463826
-0.0
tensor(27.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=1.19............. Loss: -0.31806686, mean(E): -21.74560993-0.00014320j, var(E): 0.15614903
-0.0
tensor(27.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=1.19............. Loss: -0.61044973, mean(E): -21.71328203-0.00009258j, var(E): 0.37065618
-0.0
tensor(27.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=1.19............. Loss: -0.35873418, mean(E): -21.72186391-0.00007218j, var(E): 0.42726261
-0.0
tensor(27.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=1.19............. Loss: -0.01053469, mean(E): -21.78818086-0.00056179j, var(E): 0.03392814
-0.0
tensor(27.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=1.19............. Loss: 0.05467462, mean(E): -21.78613779+0.00031854j, var(E): 0.06967203
-0.0
tensor(27.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=1.19............. Loss: 0.02100454, mean(E): -21.77895914-0.00026450j, var(E): 0.10094676
-0.0
tensor(27.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=1.19............. Loss: -0.29245422, mean(E): -21.73264575+0.00024726j, var(E): 0.18240478
-0.0
tensor(27.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=1.19............. Loss: -0.00817379, mean(E): -21.78658410-0.00008717j, var(E): 0.12196195
-0.0
tensor(27.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=1.19............. Loss: 0.26943505, mean(E): -21.80859413-0.00010536j, var(E): 0.22840660
-0.0
tensor(27.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=1.19............. Loss: 0.14182052, mean(E): -21.79959752-0.00007631j, var(E): 0.48693317
-0.0
tensor(27.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=1.19............. Loss: 0.48495700, mean(E): -21.84868298+0.00069944j, var(E): 0.60655079
-0.0
tensor(27.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=1.19............. Loss: 0.14354375, mean(E): -21.81679603+0.00019106j, var(E): 0.18363232
-0.0
tensor(27.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=1.19............. Loss: -0.32668671, mean(E): -21.73435098+0.00008331j, var(E): 0.09666231
-0.0
tensor(27.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=1.19............. Loss: -0.18066031, mean(E): -21.75876704+0.00064723j, var(E): 0.11305894
-0.0
tensor(27.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=1.19............. Loss: -0.01091458, mean(E): -21.77815124-0.00073269j, var(E): 0.17440701
-0.0
tensor(27.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=1.19............. Loss: -0.17519006, mean(E): -21.76763838+0.00041983j, var(E): 0.26289531
-0.0
tensor(27.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=1.19............. Loss: -0.10110962, mean(E): -21.77227359+0.00047477j, var(E): 0.04129524
-0.0
tensor(27.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=1.19............. Loss: -0.12978794, mean(E): -21.74116195-0.00022531j, var(E): 0.47952083
-0.0
tensor(27.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=1.19............. Loss: 0.10277422, mean(E): -21.78914247+0.00183918j, var(E): 0.13428979
-0.0
tensor(27.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=1.19............. Loss: 0.31981770, mean(E): -21.79868851-0.00048315j, var(E): 0.17792305
-0.0
tensor(27.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=1.19............. Loss: -0.32739257, mean(E): -21.75197428+0.00100155j, var(E): 0.13066460
-0.0
tensor(27.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=1.19............. Loss: 0.34124937, mean(E): -21.81084179+0.00041772j, var(E): 0.35374499
-0.0
tensor(27.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=1.2............. Loss: -0.19932724, mean(E): -21.74155579-0.00095418j, var(E): 0.13367173
-0.0
tensor(27.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=1.19............. Loss: 0.14774273, mean(E): -21.80717033-0.00085498j, var(E): 0.05228975
-0.0
tensor(27.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=1.19............. Loss: -0.22420522, mean(E): -21.75126590+0.00003010j, var(E): 0.19579710
-0.0
tensor(27.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=1.19............. Loss: 0.24001942, mean(E): -21.81155756-0.00044137j, var(E): 0.31390695
-0.0
tensor(27.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=1.19............. Loss: -0.20173626, mean(E): -21.76024179+0.00059615j, var(E): 0.14981291
-0.0
tensor(27.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=1.19............. Loss: 0.84830948, mean(E): -21.85343720+0.00020425j, var(E): 1.21120808
-0.0
tensor(27.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=1.2............. Loss: -0.08325383, mean(E): -21.78556861-0.00050978j, var(E): 0.19724340
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=1.19............. Loss: 0.01034781, mean(E): -21.81842120-0.00004488j, var(E): 0.12270140
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=1.19............. Loss: 0.03634551, mean(E): -21.76474652-0.00057613j, var(E): 0.26604808
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=1.19............. Loss: 0.08124802, mean(E): -21.77653838-0.00129499j, var(E): 0.34097306
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=1.19............. Loss: 0.18435291, mean(E): -21.81243918+0.00051207j, var(E): 0.17547449
-0.0
tensor(27.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=1.19............. Loss: 0.02180428, mean(E): -21.79597578+0.00055705j, var(E): 0.36898567
-0.0
tensor(27.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=1.19............. Loss: -0.15784609, mean(E): -21.75180533-0.00037294j, var(E): 0.10566185
-0.0
tensor(27.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=1.19............. Loss: 0.14263140, mean(E): -21.82783515-0.00014270j, var(E): 0.09268069
-0.0
tensor(27.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=1.19............. Loss: 0.16958550, mean(E): -21.80985072-0.00004564j, var(E): 0.14137545
-0.0
tensor(27.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=1.19............. Loss: 0.15413251, mean(E): -21.80132164-0.00048557j, var(E): 0.09222939
-0.0
tensor(27.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=1.19............. Loss: -0.00871164, mean(E): -21.77556950+0.00039681j, var(E): 0.20278984
-0.0
tensor(27.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=1.19............. Loss: -0.09037741, mean(E): -21.77746170-0.00033196j, var(E): 0.12162507
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=1.19............. Loss: -0.05316711, mean(E): -21.78183140-0.00007809j, var(E): 0.28911736
-0.0
tensor(27.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=1.19............. Loss: -0.18215432, mean(E): -21.76934666-0.00010331j, var(E): 0.42169321
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=1.19............. Loss: 0.37958155, mean(E): -21.80913894-0.00025005j, var(E): 0.66800418
-0.0
tensor(27.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=1.19............. Loss: -0.07118855, mean(E): -21.76968048-0.00021649j, var(E): 0.08870685
-0.0
tensor(27.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=1.19............. Loss: -0.42086898, mean(E): -21.70675642+0.00030827j, var(E): 0.21433756
-0.0
tensor(27.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=1.19............. Loss: -0.00628835, mean(E): -21.79003874+0.00012487j, var(E): 0.09999273
-0.0
tensor(27.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=1.19............. Loss: -0.08473964, mean(E): -21.78278767-0.00017009j, var(E): 0.14463184
-0.0
tensor(27.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=1.2............. Loss: -0.46587774, mean(E): -21.72776479-0.00025914j, var(E): 0.31384788
-0.0
tensor(27.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=1.19............. Loss: -0.09914167, mean(E): -21.77707358+0.00032904j, var(E): 0.07840632
-0.0
tensor(27.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=1.19............. Loss: 0.00744632, mean(E): -21.79417283-0.00026630j, var(E): 0.22724413
-0.0
tensor(27.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=1.19............. Loss: 0.11119544, mean(E): -21.79941987-0.00060233j, var(E): 0.06248446
-0.0
tensor(27.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=1.19............. Loss: -0.26382257, mean(E): -21.73855087+0.00017310j, var(E): 0.13471236
-0.0
tensor(27.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=1.19............. Loss: -0.51769613, mean(E): -21.69358781-0.00000958j, var(E): 0.33950112
-0.0
tensor(27.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=1.19............. Loss: -0.06580153, mean(E): -21.76220562+0.00006560j, var(E): 0.12713713
-0.0
tensor(27.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=1.19............. Loss: 0.23798258, mean(E): -21.83709023-0.00006536j, var(E): 0.42679929
-0.0
tensor(27.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=1.19............. Loss: 0.38018009, mean(E): -21.80331572+0.00003517j, var(E): 0.20642094
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=1.19............. Loss: -0.19725609, mean(E): -21.75373994+0.00011179j, var(E): 0.21076046
-0.0
tensor(27.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=1.2............. Loss: -0.04243763, mean(E): -21.77079073-0.00016017j, var(E): 0.13100911
-0.0
tensor(27.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=1.19............. Loss: -0.13223399, mean(E): -21.74755744+0.00013397j, var(E): 0.20287529
-0.0
tensor(27.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=1.19............. Loss: -0.10408092, mean(E): -21.77642115-0.00008052j, var(E): 0.08195872
-0.0
tensor(27.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=1.19............. Loss: 0.35712980, mean(E): -21.83228670-0.00010791j, var(E): 0.28151010
-0.0
tensor(27.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=1.2............. Loss: -0.05583636, mean(E): -21.75725005-0.00009747j, var(E): 0.10146395
-0.0
tensor(27.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=1.19............. Loss: -0.26532265, mean(E): -21.75432400-0.00003752j, var(E): 0.14312422
-0.0
tensor(27.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=1.19............. Loss: -0.18323404, mean(E): -21.75921970+0.00004202j, var(E): 0.14041529
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=1.2............. Loss: 0.01217061, mean(E): -21.78948880+0.00007438j, var(E): 0.07000309
-0.0
tensor(27.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=1.19............. Loss: 0.51842887, mean(E): -21.84289923-0.00002461j, var(E): 0.52577650
-0.0
tensor(27.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=1.19............. Loss: 0.14947859, mean(E): -21.81821093+0.00007454j, var(E): 0.06800156
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=1.19............. Loss: -0.07563746, mean(E): -21.79657269+0.00000782j, var(E): 0.11585290
-0.0
tensor(27.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=1.2............. Loss: 0.10596956, mean(E): -21.79609907-0.00001472j, var(E): 0.26260401
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=1.19............. Loss: 0.00394441, mean(E): -21.78404201+0.00002252j, var(E): 0.06562337
-0.0
tensor(27.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=1.19............. Loss: -0.41863062, mean(E): -21.73020377+0.00004740j, var(E): 0.39564016
-0.0
tensor(27.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=1.19............. Loss: 0.04910323, mean(E): -21.78531713+0.00001630j, var(E): 0.02965750
-0.0
tensor(27.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=1.19............. Loss: -0.28498198, mean(E): -21.75477820+0.00001792j, var(E): 0.29844866
-0.0
tensor(27.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=1.19............. Loss: 0.20645127, mean(E): -21.80098575-0.00000270j, var(E): 0.24618167
-0.0
tensor(27.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=1.19............. Loss: 0.03487270, mean(E): -21.78826111+0.00001886j, var(E): 0.12137938
-0.0
tensor(27.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=1.19............. Loss: -0.16642115, mean(E): -21.77527759+0.00004446j, var(E): 0.11559494
-0.0
tensor(27.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=1.19............. Loss: -0.03337638, mean(E): -21.77979024+0.00012127j, var(E): 0.06793756
-0.0
tensor(27.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=1.19............. Loss: -0.22543787, mean(E): -21.77802976+0.00010831j, var(E): 0.19048343
-0.0
tensor(27.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=1.19............. Loss: 0.01356926, mean(E): -21.80299588+0.00007960j, var(E): 0.09988119
-0.0
tensor(27.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=1.19............. Loss: -0.21386550, mean(E): -21.74894663-0.00001390j, var(E): 0.11896469
-0.0
tensor(27.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=1.19............. Loss: 0.09264673, mean(E): -21.79557554+0.00001342j, var(E): 0.43063196
-0.0
tensor(27.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=1.19............. Loss: -0.35510738, mean(E): -21.74383003-0.00002627j, var(E): 0.16081687
-0.0
tensor(27.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=1.19............. Loss: 0.11005183, mean(E): -21.78870306-0.00021608j, var(E): 0.09412998
-0.0
tensor(27.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=1.19............. Loss: -0.25804787, mean(E): -21.74896608+0.00006913j, var(E): 0.23525590
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=1.19............. Loss: -0.18687386, mean(E): -21.74233697+0.00002628j, var(E): 0.33719845
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=1.19............. Loss: -0.40024207, mean(E): -21.70616401+0.00012466j, var(E): 0.25002088
-0.0
tensor(27.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=1.19............. Loss: -0.30650528, mean(E): -21.74484870+0.00010767j, var(E): 0.36243065
-0.0
tensor(27.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=1.19............. Loss: 0.04520555, mean(E): -21.77806691+0.00005115j, var(E): 0.10739791
-0.0
tensor(27.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=1.19............. Loss: 0.02209918, mean(E): -21.78882360-0.00000180j, var(E): 0.14255983
-0.0
tensor(27.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=1.19............. Loss: -0.00424836, mean(E): -21.77526242-0.00007044j, var(E): 0.23136386
-0.0
tensor(27.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=1.19............. Loss: -0.01358086, mean(E): -21.79013230+0.00015221j, var(E): 0.04564049
-0.0
tensor(27.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=1.19............. Loss: -0.21409315, mean(E): -21.73857231+0.00001266j, var(E): 0.09936931
-0.0
tensor(27.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=1.19............. Loss: 0.08513751, mean(E): -21.80164338-0.00001486j, var(E): 0.07781479
-0.0
tensor(27.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=1.19............. Loss: -0.03010080, mean(E): -21.79961228-0.00006729j, var(E): 0.09653225
-0.0
tensor(27.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=1.19............. Loss: -0.14625543, mean(E): -21.75898813-0.00003455j, var(E): 0.17568261
-0.0
tensor(27.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=1.19............. Loss: -0.23947257, mean(E): -21.74165249+0.00013935j, var(E): 0.15102750
-0.0
tensor(27.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=1.19............. Loss: 0.07204195, mean(E): -21.78533088-0.00026799j, var(E): 0.04120327
-0.0
tensor(27.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=1.19............. Loss: 0.19679703, mean(E): -21.80357279+0.00017575j, var(E): 0.18733181
-0.0
tensor(27.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=1.19............. Loss: 0.06049987, mean(E): -21.79730043-0.00005012j, var(E): 0.07997292
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=1.19............. Loss: 0.40550014, mean(E): -21.82138240-0.00028348j, var(E): 0.34222733
-0.0
tensor(27.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=1.19............. Loss: 0.00617397, mean(E): -21.77025027-0.00092112j, var(E): 0.11638839
-0.0
tensor(27.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=1.19............. Loss: -0.14615864, mean(E): -21.77030298-0.00003013j, var(E): 0.17331000
-0.0
tensor(27.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=1.19............. Loss: 0.17812415, mean(E): -21.79968997-0.00011120j, var(E): 0.10611424
-0.0
tensor(27.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=1.19............. Loss: -0.00203839, mean(E): -21.78290754+0.00009444j, var(E): 0.08478324
-0.0
tensor(27.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=1.19............. Loss: -0.00235700, mean(E): -21.78376027-0.00000711j, var(E): 0.29375632
-0.0
tensor(27.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=1.19............. Loss: 0.05727120, mean(E): -21.80161958-0.00021954j, var(E): 0.16696529
-0.0
tensor(27.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=1.19............. Loss: 0.24722910, mean(E): -21.81958114-0.00004333j, var(E): 0.29864751
-0.0
tensor(27.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=1.19............. Loss: -0.04511489, mean(E): -21.78734782-0.00036639j, var(E): 0.14125991
-0.0
tensor(27.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=1.19............. Loss: 0.11477194, mean(E): -21.77686607-0.00014383j, var(E): 0.20643235
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=1.19............. Loss: 0.26803496, mean(E): -21.79476539+0.00007231j, var(E): 0.18665758
-0.0
tensor(27.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=1.19............. Loss: -0.09890940, mean(E): -21.77662919-0.00042136j, var(E): 0.06332902
-0.0
tensor(27.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=1.19............. Loss: 0.53836730, mean(E): -21.87839507+0.00026600j, var(E): 0.36714816
-0.0
tensor(27.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=1.19............. Loss: 0.02946950, mean(E): -21.77936976+0.00048282j, var(E): 0.28331677
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=1.19............. Loss: -0.19169771, mean(E): -21.75369559+0.00053641j, var(E): 0.14204099
-0.0
tensor(27.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=1.19............. Loss: -0.09342924, mean(E): -21.75800317-0.00021361j, var(E): 0.16132980
-0.0
tensor(27.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=1.19............. Loss: 0.03985749, mean(E): -21.79065919+0.00008241j, var(E): 0.11505679
-0.0
tensor(27.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=1.19............. Loss: 0.39566453, mean(E): -21.83107149-0.00032184j, var(E): 0.20778295
-0.0
tensor(27.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=1.19............. Loss: 0.02344010, mean(E): -21.80784836+0.00077871j, var(E): 0.25668861
-0.0
tensor(27.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=1.19............. Loss: -0.01438103, mean(E): -21.78070199+0.00021052j, var(E): 0.04960928
-0.0
tensor(27.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=1.19............. Loss: 0.09286063, mean(E): -21.79365271+0.00008514j, var(E): 0.04238467
-0.0
tensor(27.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=1.2............. Loss: -0.42629316, mean(E): -21.72926616+0.00018063j, var(E): 0.20621186
-0.0
tensor(27.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=1.19............. Loss: -0.21063999, mean(E): -21.76347734-0.00060580j, var(E): 0.25317313
-0.0
tensor(27.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=1.19............. Loss: 0.34763382, mean(E): -21.84392922-0.00024889j, var(E): 0.21683369
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=1.19............. Loss: 0.11017084, mean(E): -21.79594750+0.00027337j, var(E): 0.13053336
-0.0
tensor(27.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=1.19............. Loss: -0.13348734, mean(E): -21.75108206+0.00097463j, var(E): 0.20962569
-0.0
tensor(27.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=1.19............. Loss: 0.07831010, mean(E): -21.79933701-0.00001632j, var(E): 0.11277454
-0.0
tensor(27.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=1.19............. Loss: -0.32866989, mean(E): -21.73424085-0.00023678j, var(E): 0.19733550
-0.0
tensor(27.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=1.19............. Loss: 0.09739785, mean(E): -21.79808307-0.00029996j, var(E): 0.04016480
-0.0
tensor(27.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=1.19............. Loss: 0.03705885, mean(E): -21.79431748+0.00065168j, var(E): 0.41105006
-0.0
tensor(27.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=1.19............. Loss: 0.05623483, mean(E): -21.80542227-0.00019691j, var(E): 0.22547449
-0.0
tensor(27.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=1.19............. Loss: 0.02706542, mean(E): -21.78123312-0.00023679j, var(E): 0.38292643
-0.0
tensor(27.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=1.19............. Loss: -0.16564182, mean(E): -21.76018062-0.00062099j, var(E): 0.15642700
-0.0
tensor(27.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=1.19............. Loss: 0.07003262, mean(E): -21.80176988-0.00124380j, var(E): 0.05178684
-0.0
tensor(27.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=1.19............. Loss: -0.02486734, mean(E): -21.78436605-0.00065520j, var(E): 0.18244614
-0.0
tensor(27.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=1.19............. Loss: 0.09499911, mean(E): -21.81565204-0.00006791j, var(E): 0.08634816
-0.0
tensor(27.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=1.19............. Loss: -0.22478903, mean(E): -21.75713678+0.00023022j, var(E): 0.16225404
-0.0
tensor(27.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=1.19............. Loss: 0.05996158, mean(E): -21.76814257-0.00085855j, var(E): 0.06059230
-0.0
tensor(27.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=1.19............. Loss: -0.04394750, mean(E): -21.76464422-0.00036619j, var(E): 0.04767097
-0.0
tensor(27.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=1.19............. Loss: -0.03094165, mean(E): -21.76546852+0.00070893j, var(E): 0.07728159
-0.0
tensor(27.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=1.19............. Loss: 0.01443322, mean(E): -21.76941351-0.00045460j, var(E): 0.06447441
-0.0
tensor(27.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=1.19............. Loss: -0.24669340, mean(E): -21.75316206-0.00013308j, var(E): 0.17212809
-0.0
tensor(27.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=1.19............. Loss: -0.01842044, mean(E): -21.77984301-0.00039718j, var(E): 0.09178434
-0.0
tensor(27.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=1.19............. Loss: 0.44297767, mean(E): -21.84397010+0.00190982j, var(E): 0.26988413
-0.0
tensor(27.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=1.19............. Loss: 0.08448836, mean(E): -21.78914541+0.00103742j, var(E): 0.08369623
-0.0
tensor(27.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=1.19............. Loss: -0.09987941, mean(E): -21.77260483+0.00010067j, var(E): 0.06011464
-0.0
tensor(27.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=1.2............. Loss: -0.00846165, mean(E): -21.78545287+0.00019354j, var(E): 0.05505009
-0.0
tensor(27.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=1.19............. Loss: 0.15165755, mean(E): -21.80428783-0.00051794j, var(E): 0.11898676
-0.0
tensor(27.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=1.19............. Loss: -0.18828354, mean(E): -21.76344878+0.00156251j, var(E): 0.23040633
-0.0
tensor(27.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=1.19............. Loss: -0.09233458, mean(E): -21.77651335-0.00057280j, var(E): 0.10142817
-0.0
tensor(27.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=1.19............. Loss: -0.21583630, mean(E): -21.76743213+0.00085397j, var(E): 0.17502575
-0.0
tensor(27.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=1.19............. Loss: 0.14067820, mean(E): -21.81520146+0.00048359j, var(E): 0.06047934
-0.0
tensor(27.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=1.19............. Loss: -0.23526275, mean(E): -21.74334481+0.00014590j, var(E): 0.15039428
-0.0
tensor(27.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=1.19............. Loss: -0.09253092, mean(E): -21.77935158-0.00030792j, var(E): 0.15367735
-0.0
tensor(27.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=1.2............. Loss: -0.00389620, mean(E): -21.79770338+0.00012292j, var(E): 0.10247536
-0.0
tensor(27.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=1.19............. Loss: -0.05562198, mean(E): -21.77721404-0.00033473j, var(E): 0.05745398
-0.0
tensor(27.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=1.19............. Loss: 0.13870118, mean(E): -21.77787331+0.00019370j, var(E): 0.27002267
-0.0
tensor(27.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=1.2............. Loss: -0.32545085, mean(E): -21.75462184-0.00020804j, var(E): 0.25847276
-0.0
tensor(27.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=1.19............. Loss: 0.26020765, mean(E): -21.81359236-0.00077440j, var(E): 0.15598660
-0.0
tensor(27.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=1.2............. Loss: 0.31486126, mean(E): -21.82739410-0.00023538j, var(E): 0.16627236
-0.0
tensor(27.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=1.19............. Loss: -0.40218643, mean(E): -21.72631950-0.00039156j, var(E): 0.20175557
-0.0
tensor(27.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=1.2............. Loss: 0.05672985, mean(E): -21.75572221+0.00036777j, var(E): 0.39849104
-0.0
tensor(27.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=1.19............. Loss: 0.07732607, mean(E): -21.80131689+0.00032348j, var(E): 0.09125945
-0.0
tensor(27.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=1.19............. Loss: -0.12845437, mean(E): -21.73881216-0.00040076j, var(E): 0.11714181
-0.0
tensor(27.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=1.19............. Loss: 0.00002801, mean(E): -21.77790961-0.00006623j, var(E): 0.10794240
-0.0
tensor(27.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=1.19............. Loss: -0.16967626, mean(E): -21.74739978+0.00002614j, var(E): 0.11709586
-0.0
tensor(27.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=1.19............. Loss: 0.02433851, mean(E): -21.75910500-0.00016205j, var(E): 0.04894272
-0.0
tensor(27.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=1.2............. Loss: 0.00201991, mean(E): -21.77528402-0.00007972j, var(E): 0.04476104
-0.0
tensor(27.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=1.19............. Loss: -0.37548924, mean(E): -21.74198600+0.00003510j, var(E): 0.18711187
-0.0
tensor(27.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=1.19............. Loss: -0.05787139, mean(E): -21.78661086+0.00001191j, var(E): 0.07561658
-0.0
tensor(27.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=1.19............. Loss: -0.46414874, mean(E): -21.72426972-0.00022498j, var(E): 0.33932891
-0.0
tensor(27.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=1.19............. Loss: -0.08786674, mean(E): -21.78774960+0.00000819j, var(E): 0.14098324
-0.0
tensor(27.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=1.19............. Loss: -0.08290240, mean(E): -21.79873917+0.00007936j, var(E): 0.19470450
-0.0
tensor(27.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=1.19............. Loss: -0.11034164, mean(E): -21.76355443-0.00014493j, var(E): 0.09083495
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=1.19............. Loss: 0.05878880, mean(E): -21.80391109-0.00007861j, var(E): 0.05137153
-0.0
tensor(27.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=1.19............. Loss: 0.08394457, mean(E): -21.80418307-0.00013565j, var(E): 0.08535188
-0.0
tensor(27.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=1.19............. Loss: -0.14305075, mean(E): -21.77334144-0.00017238j, var(E): 0.15183130
-0.0
tensor(27.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=1.19............. Loss: -0.10168190, mean(E): -21.78873519+0.00014171j, var(E): 0.11469467
-0.0
tensor(27.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=1.19............. Loss: 0.27440879, mean(E): -21.80079330+0.00006292j, var(E): 0.14403793
-0.0
tensor(27.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=1.19............. Loss: -0.14102225, mean(E): -21.74164476-0.00000543j, var(E): 0.08348855
-0.0
tensor(27.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=1.19............. Loss: -0.03352548, mean(E): -21.77229827+0.00002888j, var(E): 0.10017428
-0.0
tensor(27.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=1.19............. Loss: 0.08190550, mean(E): -21.77243259-0.00014736j, var(E): 0.06138567
-0.0
tensor(27.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=1.19............. Loss: -0.09645438, mean(E): -21.76869629-0.00016689j, var(E): 0.56053823
-0.0
tensor(27.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=1.19............. Loss: -0.16047216, mean(E): -21.74614495+0.00003799j, var(E): 0.09552466
-0.0
tensor(27.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=1.19............. Loss: 1.05246804, mean(E): -21.86510268+0.00005328j, var(E): 0.62402508
-0.0
tensor(27.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=1.19............. Loss: 0.00379825, mean(E): -21.78008055-0.00002590j, var(E): 0.06620363
-0.0
tensor(27.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=1.19............. Loss: -0.07782462, mean(E): -21.76967092+0.00007937j, var(E): 0.06098217
-0.0
tensor(27.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=1.19............. Loss: 0.06486422, mean(E): -21.78863538+0.00004716j, var(E): 0.28311492
-0.0
tensor(27.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=1.19............. Loss: -0.31932438, mean(E): -21.74275756-0.00001069j, var(E): 0.23859451
-0.0
tensor(27.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=1.19............. Loss: 0.06492888, mean(E): -21.79340576+0.00000530j, var(E): 0.20406652
-0.0
tensor(27.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=1.19............. Loss: 0.04770171, mean(E): -21.78403593-0.00001047j, var(E): 0.06955276
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=1.19............. Loss: -0.05106515, mean(E): -21.76257642-0.00000669j, var(E): 0.18113289
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=1.19............. Loss: 0.40758067, mean(E): -21.77314662+0.00001296j, var(E): 0.59132608
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=1.19............. Loss: 0.06279283, mean(E): -21.79436744-0.00000677j, var(E): 0.40330243
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=1.19............. Loss: 0.06653460, mean(E): -21.78782361+0.00001524j, var(E): 0.06025533
-0.0
tensor(27.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=1.19............. Loss: 0.22676131, mean(E): -21.81197349+0.00000380j, var(E): 0.18196281
-0.0
tensor(27.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=1.19............. Loss: -0.49242176, mean(E): -21.72673756-0.00000625j, var(E): 0.31257855
-0.0
tensor(27.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=1.19............. Loss: 0.28469911, mean(E): -21.82026232-0.00000631j, var(E): 0.22401807
-0.0
tensor(27.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=1.19............. Loss: -0.12820607, mean(E): -21.76917152+0.00003791j, var(E): 0.10257744
-0.0
tensor(27.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=1.19............. Loss: 0.39900526, mean(E): -21.83827505+0.00000547j, var(E): 0.31063058
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=1.19............. Loss: -0.30190188, mean(E): -21.74604650+0.00003469j, var(E): 0.19180510
-0.0
tensor(27.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=1.19............. Loss: 0.07295724, mean(E): -21.81107761-0.00001755j, var(E): 0.07238184
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=1.19............. Loss: 0.12783540, mean(E): -21.78030330-0.00000019j, var(E): 0.06822682
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=1.19............. Loss: -0.10109949, mean(E): -21.77724764-0.00003082j, var(E): 0.10186676
-0.0
tensor(27.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=1.19............. Loss: 0.05295200, mean(E): -21.76463046+0.00001746j, var(E): 0.14123683
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=1.19............. Loss: 0.15531455, mean(E): -21.80120425+0.00006555j, var(E): 0.12873299
-0.0
tensor(27.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=1.19............. Loss: 0.06553043, mean(E): -21.83229295-0.00003168j, var(E): 0.12790264
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=1.19............. Loss: -0.03705051, mean(E): -21.77902652+0.00000462j, var(E): 0.11619966
-0.0
tensor(27.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=1.19............. Loss: 0.10749219, mean(E): -21.81586522+0.00004356j, var(E): 0.35015195
-0.0
tensor(27.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=1.19............. Loss: 0.25555709, mean(E): -21.83239510-0.00002121j, var(E): 0.12596315
-0.0
tensor(27.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=1.19............. Loss: -0.22964355, mean(E): -21.77521024-0.00004390j, var(E): 0.24426681
-0.0
tensor(27.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=1.19............. Loss: -0.25669866, mean(E): -21.77497163-0.00002473j, var(E): 0.19310901
-0.0
tensor(27.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=1.19............. Loss: 0.23684978, mean(E): -21.81120678-0.00000246j, var(E): 0.10514225
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=1.19............. Loss: 0.45887406, mean(E): -21.84512170-0.00006247j, var(E): 0.36020334
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=1.19............. Loss: 0.03782626, mean(E): -21.79849999+0.00002890j, var(E): 0.10906716
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=1.19............. Loss: -0.19498494, mean(E): -21.75825192-0.00008428j, var(E): 0.08523699
-0.0
tensor(27.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=1.19............. Loss: 0.08900022, mean(E): -21.80881036+0.00001480j, var(E): 0.09060095
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=1.19............. Loss: -0.08366994, mean(E): -21.74958372+0.00004396j, var(E): 0.40069468
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=1.19............. Loss: 0.08593616, mean(E): -21.75398085+0.00005062j, var(E): 0.43076740
-0.0
tensor(27.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=1.19............. Loss: 0.09847730, mean(E): -21.79232799-0.00003622j, var(E): 0.11333526
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=1.19............. Loss: -0.05989652, mean(E): -21.76446811-0.00004127j, var(E): 0.09832631
-0.0
tensor(27.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=1.19............. Loss: -0.19528665, mean(E): -21.74583244-0.00004900j, var(E): 0.08950906
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=1.19............. Loss: 0.26227297, mean(E): -21.80953906-0.00007552j, var(E): 0.22001673
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=1.19............. Loss: 0.00099626, mean(E): -21.79672128+0.00001763j, var(E): 0.07705007
-0.0
tensor(27.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=1.19............. Loss: -0.01414881, mean(E): -21.78016645-0.00000465j, var(E): 0.09649154
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=1.19............. Loss: 0.17490284, mean(E): -21.81035872+0.00009789j, var(E): 0.34937683
-0.0
tensor(27.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=1.19............. Loss: -0.25532776, mean(E): -21.72273453+0.00002266j, var(E): 0.41994506
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=1.19............. Loss: -0.09596055, mean(E): -21.76976495+0.00001108j, var(E): 0.13068214
-0.0
tensor(27.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=1.19............. Loss: 0.17208162, mean(E): -21.79141374+0.00001513j, var(E): 0.17509367
-0.0
tensor(27.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=1.19............. Loss: 0.11420509, mean(E): -21.80369020+0.00002512j, var(E): 0.12212200
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=1.19............. Loss: -0.21776489, mean(E): -21.75981396+0.00001178j, var(E): 0.11082228
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=1.19............. Loss: -0.04646596, mean(E): -21.79844363+0.00004547j, var(E): 0.12619490
-0.0
tensor(27.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=1.19............. Loss: 0.19258009, mean(E): -21.79670294+0.00010309j, var(E): 0.16126090
-0.0
tensor(27.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=1.19............. Loss: 0.09069411, mean(E): -21.81122780-0.00014647j, var(E): 0.22381237
-0.0
tensor(27.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=1.19............. Loss: -0.16975173, mean(E): -21.78630413-0.00028787j, var(E): 0.21815755
-0.0
tensor(27.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=1.19............. Loss: -0.05190429, mean(E): -21.79081888+0.00004223j, var(E): 0.25909399
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=1.19............. Loss: -0.28572396, mean(E): -21.76146031-0.00024969j, var(E): 0.23145614
-0.0
tensor(27.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=1.19............. Loss: -0.12574993, mean(E): -21.77117739-0.00009213j, var(E): 0.16494054
-0.0
tensor(27.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=1.19............. Loss: -0.08622739, mean(E): -21.75780859+0.00034992j, var(E): 0.21523840
-0.0
tensor(27.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=1.19............. Loss: -0.14430426, mean(E): -21.74251648-0.00019406j, var(E): 0.36456059
-0.0
tensor(27.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=1.19............. Loss: -0.33875012, mean(E): -21.75329665+0.00033470j, var(E): 0.33626373
-0.0
tensor(27.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=1.19............. Loss: 0.00104208, mean(E): -21.78386539+0.00016836j, var(E): 0.04106644
-0.0
tensor(27.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=1.19............. Loss: 0.05456219, mean(E): -21.79260993-0.00002921j, var(E): 0.03704511
-0.0
tensor(27.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=1.19............. Loss: -0.04559892, mean(E): -21.78978097-0.00063291j, var(E): 0.07001864
-0.0
tensor(27.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=1.19............. Loss: -0.08870825, mean(E): -21.77490318-0.00036696j, var(E): 0.16014256
-0.0
tensor(27.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=1.19............. Loss: 0.02971932, mean(E): -21.79042554+0.00063299j, var(E): 0.06558570
-0.0
tensor(27.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=1.19............. Loss: -0.15781895, mean(E): -21.76513775-0.00023952j, var(E): 0.19319931
-0.0
tensor(27.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=1.19............. Loss: 0.34838963, mean(E): -21.83203646-0.00019674j, var(E): 0.20280581
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=1.19............. Loss: 0.03915054, mean(E): -21.78984557-0.00077929j, var(E): 0.04738431
-0.0
tensor(27.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=1.19............. Loss: 0.58368950, mean(E): -21.86507712+0.00046595j, var(E): 0.99691149
-0.0
tensor(27.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=1.19............. Loss: -0.05063900, mean(E): -21.78718521-0.00016409j, var(E): 0.38410386
-0.0
tensor(27.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=1.19............. Loss: -0.01060144, mean(E): -21.80105146+0.00007267j, var(E): 0.08530209
-0.0
tensor(27.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=1.19............. Loss: 0.14355136, mean(E): -21.82636611-0.00037386j, var(E): 0.10061833
-0.0
tensor(27.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=1.19............. Loss: 0.02926073, mean(E): -21.78321832+0.00000412j, var(E): 0.15813674
-0.0
tensor(27.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=1.19............. Loss: -0.09139710, mean(E): -21.77394899-0.00113109j, var(E): 0.16008948
-0.0
tensor(27.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=1.19............. Loss: 0.12177937, mean(E): -21.80922566-0.00011556j, var(E): 0.18433670
-0.0
tensor(27.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=1.19............. Loss: -0.10284606, mean(E): -21.77498917+0.00049340j, var(E): 0.07095552
-0.0
tensor(27.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=1.19............. Loss: 0.09359011, mean(E): -21.79432626-0.00073556j, var(E): 0.18175950
-0.0
tensor(27.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=1.19............. Loss: -0.00740942, mean(E): -21.79449791-0.00035708j, var(E): 0.17161639
-0.0
tensor(27.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=1.19............. Loss: 0.61495727, mean(E): -21.85254048-0.00027087j, var(E): 0.75725572
-0.0
tensor(27.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=1.19............. Loss: 0.17929293, mean(E): -21.80451661+0.00169121j, var(E): 0.09934176
-0.0
tensor(27.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=1.19............. Loss: 0.13782522, mean(E): -21.81206010-0.00040717j, var(E): 0.23800509
-0.0
tensor(27.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=1.19............. Loss: -0.18236519, mean(E): -21.76124902-0.00092476j, var(E): 0.17667318
-0.0
tensor(27.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=1.19............. Loss: -0.02319214, mean(E): -21.79843019+0.00052829j, var(E): 0.10729277
-0.0
tensor(27.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=1.19............. Loss: -0.01299538, mean(E): -21.77376775+0.00005705j, var(E): 0.08554820
-0.0
tensor(27.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=1.19............. Loss: -0.03072478, mean(E): -21.77846955-0.00105656j, var(E): 0.05740316
-0.0
tensor(27.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=1.19............. Loss: 0.09852874, mean(E): -21.81330211-0.00115850j, var(E): 0.03973680
-0.0
tensor(27.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=1.19............. Loss: 0.01410671, mean(E): -21.79785544+0.00058121j, var(E): 0.10069525
-0.0
tensor(27.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=1.2............. Loss: -0.18438553, mean(E): -21.76632838+0.00019274j, var(E): 0.14534714
-0.0
tensor(27.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=1.2............. Loss: -0.05593874, mean(E): -21.78631899+0.00050897j, var(E): 0.07041365
-0.0
tensor(27.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=1.19............. Loss: -0.05865003, mean(E): -21.79033306+0.00110058j, var(E): 0.13728605
-0.0
tensor(27.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=1.19............. Loss: 0.10161268, mean(E): -21.79513799+0.00046095j, var(E): 0.10927207
-0.0
tensor(27.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=1.19............. Loss: -0.08045557, mean(E): -21.77821335+0.00052119j, var(E): 0.23487310
-0.0
tensor(27.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=1.19............. Loss: -0.07445096, mean(E): -21.76907593+0.00007058j, var(E): 0.23508622
-0.0
tensor(27.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=1.19............. Loss: 0.15979627, mean(E): -21.82545042+0.00027814j, var(E): 0.32337376
-0.0
tensor(27.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=1.19............. Loss: 0.04583216, mean(E): -21.80216974-0.00079718j, var(E): 0.12867584
-0.0
tensor(27.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=1.19............. Loss: 0.12601730, mean(E): -21.81076037-0.00024166j, var(E): 0.13222467
-0.0
tensor(27.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=1.19............. Loss: 0.01569222, mean(E): -21.80457773-0.00015393j, var(E): 0.13621231
-0.0
tensor(27.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=1.19............. Loss: -0.11748066, mean(E): -21.78004951+0.00037909j, var(E): 0.22628357
-0.0
tensor(27.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=1.19............. Loss: -0.36621172, mean(E): -21.75684425+0.00006660j, var(E): 0.39340735
-0.0
tensor(27.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=1.19............. Loss: -0.09481170, mean(E): -21.77865138-0.00013202j, var(E): 0.09666479
-0.0
tensor(27.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=1.19............. Loss: -0.12005930, mean(E): -21.77589331-0.00001729j, var(E): 0.29877500
-0.0
tensor(27.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=1.19............. Loss: -0.11026823, mean(E): -21.76293401+0.00020092j, var(E): 0.11982498
-0.0
tensor(27.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=1.19............. Loss: -0.40975403, mean(E): -21.73129692+0.00020298j, var(E): 0.29883129
-0.0
tensor(27.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=1.19............. Loss: 0.12609587, mean(E): -21.79725609-0.00010722j, var(E): 0.10494944
-0.0
tensor(27.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=1.19............. Loss: -0.04160132, mean(E): -21.77510086+0.00006456j, var(E): 0.12091747
-0.0
tensor(27.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=1.19............. Loss: -0.17614066, mean(E): -21.76830694-0.00036398j, var(E): 0.26689278
-0.0
tensor(27.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=1.19............. Loss: 0.48931265, mean(E): -21.82625657+0.00028719j, var(E): 0.32714223
-0.0
tensor(27.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=1.2............. Loss: -0.04954699, mean(E): -21.79655155-0.00016557j, var(E): 0.16832821
-0.0
tensor(27.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=1.19............. Loss: 0.83096892, mean(E): -21.83423022+0.00024767j, var(E): 1.42479834
-0.0
tensor(27.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=1.19............. Loss: 0.07461431, mean(E): -21.80762751+0.00024958j, var(E): 0.15231615
-0.0
tensor(27.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=1.19............. Loss: -0.12746016, mean(E): -21.75753555+0.00004403j, var(E): 0.14557273
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=1.19............. Loss: 0.19817788, mean(E): -21.81689556+0.00005502j, var(E): 0.19330353
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=1.19............. Loss: -0.06647748, mean(E): -21.76849981-0.00041670j, var(E): 0.30892229
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=1.19............. Loss: -0.21814867, mean(E): -21.77637738-0.00007639j, var(E): 0.14154103
-0.0
tensor(27.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=1.19............. Loss: -0.07527059, mean(E): -21.78809034+0.00017691j, var(E): 0.05427267
-0.0
tensor(27.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=1.19............. Loss: -0.02962891, mean(E): -21.79144541+0.00001569j, var(E): 0.13934277
-0.0
tensor(27.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=1.19............. Loss: 0.46681557, mean(E): -21.85769159+0.00008134j, var(E): 0.25812978
-0.0
tensor(27.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=1.2............. Loss: 0.01585203, mean(E): -21.78131745+0.00008264j, var(E): 0.07981307
-0.0
tensor(27.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=1.19............. Loss: -0.40453018, mean(E): -21.73188248-0.00005507j, var(E): 0.31796592
-0.0
tensor(27.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=1.19............. Loss: 0.05075801, mean(E): -21.78501186+0.00008560j, var(E): 0.27799150
-0.0
tensor(27.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=1.19............. Loss: -0.00270113, mean(E): -21.78913853+0.00004648j, var(E): 0.03396195
-0.0
tensor(27.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=1.19............. Loss: 0.10567105, mean(E): -21.77069168-0.00006139j, var(E): 0.38771166
-0.0
tensor(27.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=1.19............. Loss: -0.13143840, mean(E): -21.77015480-0.00014207j, var(E): 0.07325218
-0.0
tensor(27.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=1.19............. Loss: -0.07559723, mean(E): -21.76718445+0.00006223j, var(E): 0.10867396
-0.0
tensor(27.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=1.19............. Loss: 0.01279834, mean(E): -21.77349292+0.00006572j, var(E): 0.06287591
-0.0
tensor(27.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=1.19............. Loss: -0.09651580, mean(E): -21.77093664-0.00005166j, var(E): 0.34848051
-0.0
tensor(27.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=1.19............. Loss: -0.39125995, mean(E): -21.73914348-0.00007117j, var(E): 0.28343464
-0.0
tensor(27.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=1.19............. Loss: 0.05490801, mean(E): -21.78894424+0.00000562j, var(E): 0.04219681
-0.0
tensor(27.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=1.19............. Loss: 0.33423106, mean(E): -21.83803073+0.00000936j, var(E): 0.15401643
-0.0
tensor(27.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=1.19............. Loss: -0.05930178, mean(E): -21.79607804+0.00006463j, var(E): 0.22354278
-0.0
tensor(27.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=1.19............. Loss: -0.34067888, mean(E): -21.73759703+0.00002817j, var(E): 0.22327307
-0.0
tensor(27.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=1.21............. Loss: -0.25776745, mean(E): -21.76450836+0.00005883j, var(E): 0.30538210
-0.0
tensor(27.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=1.19............. Loss: 0.30301591, mean(E): -21.80549792-0.00004387j, var(E): 0.12816264
-0.0
tensor(27.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=1.19............. Loss: -0.18814574, mean(E): -21.77005411+0.00004461j, var(E): 0.19595138
-0.0
tensor(27.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=1.19............. Loss: -0.42018890, mean(E): -21.72051846+0.00007368j, var(E): 0.37259386
-0.0
tensor(27.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=1.2............. Loss: -0.13937719, mean(E): -21.77064890-0.00006214j, var(E): 0.12351993
-0.0
tensor(27.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=1.19............. Loss: 0.18080648, mean(E): -21.82521064+0.00000011j, var(E): 0.09796297
-0.0
tensor(27.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=1.19............. Loss: -0.01051475, mean(E): -21.77785364+0.00001737j, var(E): 0.06151734
-0.0
tensor(27.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=1.19............. Loss: -0.21923317, mean(E): -21.77745612-0.00009592j, var(E): 0.35096421
-0.0
tensor(27.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=1.19............. Loss: -0.11135305, mean(E): -21.76730298+0.00005639j, var(E): 0.12716295
-0.0
tensor(27.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=1.19............. Loss: 0.00591973, mean(E): -21.79560661-0.00000468j, var(E): 0.08982948
-0.0
tensor(27.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=1.19............. Loss: -0.09318922, mean(E): -21.75652806-0.00000321j, var(E): 0.23351367
-0.0
tensor(27.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=1.19............. Loss: -0.03404348, mean(E): -21.77924726+0.00002581j, var(E): 0.03966254
-0.0
tensor(27.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=1.19............. Loss: 0.38960855, mean(E): -21.84407092-0.00012054j, var(E): 0.15688135
-0.0
tensor(27.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=1.19............. Loss: -0.01313869, mean(E): -21.78537985-0.00006576j, var(E): 0.04257346
-0.0
tensor(27.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=1.19............. Loss: -0.25869628, mean(E): -21.75463940-0.00008745j, var(E): 0.28683821
-0.0
tensor(27.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=1.19............. Loss: -0.27632552, mean(E): -21.74500168-0.00002893j, var(E): 0.12413154
-0.0
tensor(27.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=1.19............. Loss: -0.09800310, mean(E): -21.76541438-0.00000327j, var(E): 0.12966611
-0.0
tensor(27.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=1.19............. Loss: -0.25036299, mean(E): -21.76614678+0.00009779j, var(E): 0.14779799
-0.0
tensor(27.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=1.19............. Loss: -0.04894128, mean(E): -21.76692746-0.00004613j, var(E): 0.11722371
-0.0
tensor(27.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=1.19............. Loss: -0.03928893, mean(E): -21.76552453+0.00001236j, var(E): 0.19291999
-0.0
tensor(27.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=1.19............. Loss: -0.06850230, mean(E): -21.76282394+0.00010219j, var(E): 0.12901110
-0.0
tensor(27.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=1.19............. Loss: -0.03702314, mean(E): -21.78931912-0.00011029j, var(E): 0.07747943
-0.0
tensor(27.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=1.19............. Loss: 0.09161180, mean(E): -21.79932412-0.00006525j, var(E): 0.04649209
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=1.19............. Loss: 0.08362035, mean(E): -21.79687562+0.00010117j, var(E): 0.22718722
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=1.19............. Loss: -0.15625155, mean(E): -21.76300729+0.00006797j, var(E): 0.14695182
-0.0
tensor(27.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=1.19............. Loss: -0.06751837, mean(E): -21.77881011-0.00011181j, var(E): 0.27840655
-0.0
tensor(27.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=1.19............. Loss: 0.03967740, mean(E): -21.79744198-0.00006359j, var(E): 0.10449868
-0.0
tensor(27.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=1.19............. Loss: 0.08308771, mean(E): -21.79775441-0.00011220j, var(E): 0.09627273
-0.0
tensor(27.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=1.19............. Loss: 0.16794933, mean(E): -21.79289747+0.00016089j, var(E): 0.07962003
-0.0
tensor(27.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=1.19............. Loss: -0.04062803, mean(E): -21.78517040+0.00022164j, var(E): 0.33166875
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=1.19............. Loss: -0.12437552, mean(E): -21.75466293+0.00039138j, var(E): 0.09108317
-0.0
tensor(27.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=1.19............. Loss: 0.08150764, mean(E): -21.80256012+0.00010916j, var(E): 0.05437589
-0.0
tensor(27.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=1.19............. Loss: 0.16603945, mean(E): -21.80864904-0.00020490j, var(E): 0.13671152
-0.0
tensor(27.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=1.19............. Loss: -0.22534986, mean(E): -21.75006921+0.00030534j, var(E): 0.11546018
-0.0
tensor(27.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=1.19............. Loss: -0.02895835, mean(E): -21.77254472+0.00034357j, var(E): 0.20656881
-0.0
tensor(27.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=1.19............. Loss: -0.07036885, mean(E): -21.75809028-0.00009205j, var(E): 0.06149352
-0.0
tensor(27.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=1.19............. Loss: 0.05098437, mean(E): -21.77984354+0.00009844j, var(E): 0.22803267
-0.0
tensor(27.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=1.19............. Loss: 0.22968938, mean(E): -21.84296255-0.00000356j, var(E): 0.13104333
-0.0
tensor(27.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=1.19............. Loss: -0.14518542, mean(E): -21.77485402+0.00011497j, var(E): 0.09565305
-0.0
tensor(27.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=1.19............. Loss: 0.02358719, mean(E): -21.77855698+0.00015651j, var(E): 0.10037207
-0.0
tensor(27.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=1.19............. Loss: 0.12894997, mean(E): -21.81115805-0.00020719j, var(E): 0.09763632
-0.0
tensor(27.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=1.19............. Loss: 0.62439564, mean(E): -21.86295298+0.00055083j, var(E): 0.41777164
-0.0
tensor(27.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=1.19............. Loss: -0.00744324, mean(E): -21.78756308-0.00038859j, var(E): 0.09749398
-0.0
tensor(27.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=1.19............. Loss: 0.14891303, mean(E): -21.81566228+0.00021541j, var(E): 0.06122657
-0.0
tensor(27.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=1.19............. Loss: -0.34922140, mean(E): -21.73953261-0.00009669j, var(E): 0.19821743
-0.0
tensor(27.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=1.19............. Loss: -0.05273786, mean(E): -21.79327593+0.00006023j, var(E): 0.20527406
-0.0
tensor(27.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=1.19............. Loss: -0.25190295, mean(E): -21.75289965+0.00029808j, var(E): 0.34043435
-0.0
tensor(27.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=1.19............. Loss: 0.05411945, mean(E): -21.77655459-0.00027442j, var(E): 0.20209700
-0.0
tensor(27.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=1.19............. Loss: 0.06275169, mean(E): -21.79275040+0.00012423j, var(E): 0.12403636
-0.0
tensor(27.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=1.19............. Loss: -0.32642681, mean(E): -21.72107758+0.00078741j, var(E): 0.13223640
-0.0
tensor(27.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=1.19............. Loss: 0.27443956, mean(E): -21.84494884+0.00024493j, var(E): 0.14020028
-0.0
tensor(27.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=1.19............. Loss: 0.06927239, mean(E): -21.80360714+0.00047601j, var(E): 0.13698185
-0.0
tensor(27.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=1.19............. Loss: -0.07089161, mean(E): -21.77861579-0.00012992j, var(E): 0.07318620
-0.0
tensor(27.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=1.19............. Loss: -0.11833839, mean(E): -21.77001481+0.00081382j, var(E): 0.16964185
-0.0
tensor(27.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=1.19............. Loss: -0.11669597, mean(E): -21.76950616+0.00025198j, var(E): 0.08417433
-0.0
tensor(27.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=1.19............. Loss: 0.20439370, mean(E): -21.80444116+0.00010245j, var(E): 0.11956760
-0.0
tensor(27.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=1.19............. Loss: 0.10133127, mean(E): -21.79909518-0.00002467j, var(E): 0.19623559
-0.0
tensor(27.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=1.19............. Loss: 0.32785237, mean(E): -21.81419813+0.00036954j, var(E): 0.29855022
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=1.2............. Loss: -0.06207834, mean(E): -21.80050373-0.00039296j, var(E): 0.13577564
-0.0
tensor(27.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=1.19............. Loss: 0.23082723, mean(E): -21.79816799+0.00063532j, var(E): 0.17869955
-0.0
tensor(27.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=1.19............. Loss: 0.26942501, mean(E): -21.80867230-0.00026163j, var(E): 0.22996695
-0.0
tensor(27.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=1.19............. Loss: -0.13994535, mean(E): -21.77086571-0.00015003j, var(E): 0.09523320
-0.0
tensor(27.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=1.19............. Loss: -0.11661987, mean(E): -21.77440800-0.00014453j, var(E): 0.24201640
-0.0
tensor(27.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=1.19............. Loss: 0.04318410, mean(E): -21.77413872+0.00072842j, var(E): 0.11883234
-0.0
tensor(27.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=1.19............. Loss: 0.05456809, mean(E): -21.79570698-0.00007518j, var(E): 0.14421686
-0.0
tensor(27.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=1.19............. Loss: -0.25575468, mean(E): -21.72901622-0.00048701j, var(E): 0.11272584
-0.0
tensor(27.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=1.19............. Loss: -0.03059993, mean(E): -21.77801119+0.00014667j, var(E): 0.07637735
-0.0
tensor(27.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=1.19............. Loss: 0.21710243, mean(E): -21.81057108+0.00008653j, var(E): 0.11627407
-0.0
tensor(27.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=1.19............. Loss: 0.24907767, mean(E): -21.82932060-0.00017906j, var(E): 0.09424492
-0.0
tensor(27.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=1.19............. Loss: 0.05199157, mean(E): -21.81489685+0.00012533j, var(E): 0.23660305
-0.0
tensor(27.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=1.2............. Loss: 0.07025595, mean(E): -21.79856084+0.00005162j, var(E): 0.07923193
-0.0
tensor(27.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=1.19............. Loss: 0.06980307, mean(E): -21.81327871+0.00009302j, var(E): 0.02507262
-0.0
tensor(27.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(27.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=1.19............. Loss: 0.61640884, mean(E): -21.86223688+0.00016036j, var(E): 0.79565342
