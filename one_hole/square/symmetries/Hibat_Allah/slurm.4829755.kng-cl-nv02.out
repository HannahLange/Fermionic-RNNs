/var/spool/slurmd/job4829755/slurm_script: line 14: ../../ML_Environment/bin/activate: No such file or directory
1.13.1+cu117
GPU is available
Namespace(Jp=0.0, Jz=1.0, Nx=4, Ny=4, U=1.0, antisym=0.0, bounds=1, boundsx=0, boundsy=0, density=0.9375, hd=70, load_model=0, sym=0.0, t=3.0)
4x4_qubits/periodic/Jp=0.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=2.14............. Loss: 3.81567878, mean(E): -17.68672123-0.00785648j, var(E): 15.84817499
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=0.26............. Loss: 2.67349830, mean(E): -17.91663009-0.01701243j, var(E): 12.74738625
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=0.26............. Loss: 2.16891233, mean(E): -18.54555536-0.03734054j, var(E): 13.24814615
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=0.26............. Loss: 1.20598759, mean(E): -18.94475783-0.27435597j, var(E): 13.50745574
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=0.26............. Loss: 1.08717924, mean(E): -19.21520286-0.28207378j, var(E): 10.92887322
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=0.26............. Loss: 0.31127826, mean(E): -19.40832343-0.24577083j, var(E): 7.94829903
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=0.26............. Loss: -0.24533620, mean(E): -20.12509211+0.02843558j, var(E): 9.25903133
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=0.26............. Loss: -0.93058091, mean(E): -20.03621530+0.03662067j, var(E): 6.36886890
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=0.26............. Loss: 0.54590506, mean(E): -20.94811907-0.03361227j, var(E): 8.42165857
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=0.26............. Loss: -0.59178474, mean(E): -20.76033569-0.10139990j, var(E): 6.88700542
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=0.26............. Loss: -0.25398515, mean(E): -20.88079707+0.07744779j, var(E): 5.61659520
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=0.26............. Loss: -0.69542783, mean(E): -20.84227727-0.03813911j, var(E): 5.82725119
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=0.26............. Loss: -0.49362166, mean(E): -20.81252438+0.01139797j, var(E): 5.83845995
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=0.26............. Loss: -0.47654701, mean(E): -21.01080061+0.03363061j, var(E): 4.28895345
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=0.26............. Loss: 0.32157985, mean(E): -21.07373346-0.03721437j, var(E): 4.96771977
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=0.26............. Loss: -0.16005666, mean(E): -21.16592500+0.02250244j, var(E): 4.02510604
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=0.26............. Loss: 0.03086642, mean(E): -21.23949160-0.09939691j, var(E): 2.68218415
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=0.26............. Loss: -0.54971564, mean(E): -21.14252353+0.07669733j, var(E): 3.34620292
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=0.26............. Loss: -0.74675220, mean(E): -21.23591152+0.02565371j, var(E): 3.26928539
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=0.26............. Loss: -0.29756874, mean(E): -21.30143476+0.10005008j, var(E): 2.06316931
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=0.26............. Loss: 0.92534846, mean(E): -21.48938723+0.03139060j, var(E): 2.45061677
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=0.26............. Loss: -0.29539263, mean(E): -21.35383519-0.01667911j, var(E): 2.68681757
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=0.29............. Loss: -0.01143103, mean(E): -21.47492791-0.02742639j, var(E): 2.00967033
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=0.26............. Loss: -0.27368536, mean(E): -21.32556289+0.00690046j, var(E): 2.77495914
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=0.26............. Loss: 0.41973529, mean(E): -21.59160765-0.04855690j, var(E): 2.63536399
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=0.26............. Loss: -0.60858085, mean(E): -21.47140667-0.03890881j, var(E): 2.54696406
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=0.26............. Loss: -0.06605743, mean(E): -21.56105767-0.02552363j, var(E): 2.41120885
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=0.26............. Loss: 0.80014974, mean(E): -21.38040068+0.06758575j, var(E): 7.11946008
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=0.26............. Loss: -0.00982182, mean(E): -21.51858007-0.01228947j, var(E): 2.90489559
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=0.26............. Loss: -0.50090149, mean(E): -21.46461580-0.02124369j, var(E): 1.76406960
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=0.26............. Loss: 0.12611664, mean(E): -21.58680000-0.06027357j, var(E): 2.52743724
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=0.26............. Loss: 0.27750308, mean(E): -21.49503282-0.03186475j, var(E): 1.47047708
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=0.26............. Loss: -0.72517907, mean(E): -21.43478302+0.06579085j, var(E): 1.70041225
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=0.26............. Loss: 0.57685934, mean(E): -21.62065613+0.01281168j, var(E): 2.05865192
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=0.26............. Loss: -0.24501169, mean(E): -21.55719257-0.03620381j, var(E): 1.46485363
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=0.26............. Loss: 0.00000060, mean(E): -21.52312060+0.03959131j, var(E): 1.82679519
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=0.26............. Loss: -0.50943212, mean(E): -21.51417968+0.04867124j, var(E): 1.93001108
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=0.26............. Loss: 0.26555112, mean(E): -21.60887583+0.02433740j, var(E): 1.25276991
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=0.26............. Loss: -0.48272331, mean(E): -21.49200665-0.02268413j, var(E): 1.57768521
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=0.27............. Loss: -0.04285385, mean(E): -21.52471990-0.02991442j, var(E): 1.33238659
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=0.26............. Loss: 0.22968690, mean(E): -21.57908266+0.01260535j, var(E): 1.26245683
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=0.26............. Loss: 0.52481130, mean(E): -21.59660335+0.01067746j, var(E): 1.59727895
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=0.26............. Loss: 0.57348324, mean(E): -21.76343057-0.00975307j, var(E): 2.18738847
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=0.26............. Loss: -0.19837422, mean(E): -21.56966606+0.02225920j, var(E): 1.42703841
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=0.26............. Loss: 0.30286033, mean(E): -21.66601028+0.05084156j, var(E): 1.30761439
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=0.26............. Loss: -0.00436560, mean(E): -21.51634578-0.01078599j, var(E): 2.36971180
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=0.26............. Loss: -0.46189044, mean(E): -21.57101383-0.02939000j, var(E): 0.84439292
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=0.26............. Loss: -0.45337805, mean(E): -21.47687994-0.05375776j, var(E): 1.97132947
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=0.26............. Loss: -0.54822356, mean(E): -21.57191873-0.03145928j, var(E): 1.31619546
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=0.26............. Loss: 0.28631628, mean(E): -21.61791098+0.00376784j, var(E): 1.17290916
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=0.26............. Loss: 0.01874723, mean(E): -21.67218908+0.01929074j, var(E): 1.71282960
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=0.26............. Loss: 0.30763296, mean(E): -21.68339451+0.00524823j, var(E): 1.12293805
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=0.26............. Loss: -0.09494024, mean(E): -21.69252822+0.02050497j, var(E): 1.65230678
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=0.26............. Loss: -0.10237842, mean(E): -21.64185889-0.02403528j, var(E): 0.97007341
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=0.26............. Loss: -0.07399409, mean(E): -21.60938350+0.01895933j, var(E): 1.67479862
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=0.26............. Loss: 0.43210667, mean(E): -21.67622248-0.03927055j, var(E): 1.00051957
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=0.26............. Loss: 0.24819441, mean(E): -21.64386287+0.00041903j, var(E): 0.94092510
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=0.26............. Loss: -0.12539867, mean(E): -21.57818181-0.01832407j, var(E): 1.40718070
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=0.26............. Loss: 0.02483208, mean(E): -21.63513449+0.00782135j, var(E): 0.95206006
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=0.26............. Loss: 0.20044871, mean(E): -21.60356037+0.00219888j, var(E): 0.84591879
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=0.26............. Loss: -0.04954113, mean(E): -21.60300471+0.00038658j, var(E): 1.23649064
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=0.26............. Loss: -0.24059634, mean(E): -21.59469675-0.00042319j, var(E): 1.22106723
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=0.27............. Loss: 0.17740055, mean(E): -21.62037836-0.00810674j, var(E): 1.55570437
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=0.26............. Loss: 0.41708495, mean(E): -21.64400607-0.02053434j, var(E): 1.28478945
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=0.26............. Loss: 0.54378072, mean(E): -21.77343061+0.03428156j, var(E): 1.26830656
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=0.26............. Loss: -0.32485243, mean(E): -21.60448756-0.01377662j, var(E): 1.00833122
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=0.26............. Loss: 0.16965804, mean(E): -21.67178953-0.00423887j, var(E): 1.04706211
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=0.26............. Loss: 0.95881634, mean(E): -21.73231996+0.05902113j, var(E): 0.97717837
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=0.26............. Loss: -0.21241751, mean(E): -21.59860167+0.04417680j, var(E): 0.82328004
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=0.26............. Loss: 0.33665037, mean(E): -21.63654890+0.00315164j, var(E): 0.86007700
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=0.26............. Loss: 0.12467366, mean(E): -21.70692149+0.01210520j, var(E): 1.42000288
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=0.26............. Loss: -0.19816237, mean(E): -21.63512646-0.04576903j, var(E): 1.09444905
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=0.26............. Loss: 0.41383084, mean(E): -21.69925466+0.02327526j, var(E): 1.15435327
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=0.26............. Loss: 0.26551682, mean(E): -21.73985523+0.00341694j, var(E): 0.76468891
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=0.26............. Loss: 0.52505892, mean(E): -21.72855001-0.01255892j, var(E): 1.48733817
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=0.26............. Loss: 0.13738539, mean(E): -21.72913777+0.03686799j, var(E): 0.77962257
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=0.26............. Loss: -0.48641279, mean(E): -21.58274408+0.00991299j, var(E): 1.71185698
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=0.26............. Loss: 0.07269106, mean(E): -21.67225318-0.00240508j, var(E): 0.95477214
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=0.26............. Loss: -0.69982553, mean(E): -21.63108940+0.00213295j, var(E): 1.06908586
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=0.26............. Loss: 0.28928724, mean(E): -21.70500759-0.00102114j, var(E): 1.08667226
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=0.26............. Loss: -0.42347740, mean(E): -21.56954586+0.02109476j, var(E): 1.34182209
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=0.26............. Loss: -0.03285281, mean(E): -21.70152611+0.02937023j, var(E): 0.72507070
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=0.26............. Loss: -0.29323060, mean(E): -21.54989702+0.00514709j, var(E): 1.11467707
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=0.26............. Loss: 0.06590587, mean(E): -21.68608067-0.00832115j, var(E): 1.39397552
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=0.26............. Loss: -0.36472701, mean(E): -21.71529590+0.00442608j, var(E): 0.80043503
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=0.26............. Loss: -0.73457134, mean(E): -21.58849361+0.01626926j, var(E): 0.75615897
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=0.26............. Loss: 0.40859380, mean(E): -21.74557111+0.01566683j, var(E): 1.18912534
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=0.26............. Loss: -0.14106120, mean(E): -21.65106773+0.04024056j, var(E): 0.87804439
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=0.26............. Loss: 0.21195071, mean(E): -21.72459357-0.00715367j, var(E): 0.32337966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=0.26............. Loss: 0.36384222, mean(E): -21.79996524+0.00201494j, var(E): 1.08441268
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=0.26............. Loss: 0.23220608, mean(E): -21.69742540+0.05659569j, var(E): 1.02183248
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=0.26............. Loss: -0.12443019, mean(E): -21.60238949+0.02683779j, var(E): 0.58458769
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=0.26............. Loss: -0.50095172, mean(E): -21.62031273+0.00836128j, var(E): 0.84962760
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=0.26............. Loss: 0.00822153, mean(E): -21.69670436-0.02340468j, var(E): 1.11562593
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=0.26............. Loss: -0.18003346, mean(E): -21.62823932+0.02639840j, var(E): 0.74466514
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=0.26............. Loss: 0.43290368, mean(E): -21.78762094+0.01224534j, var(E): 1.57698407
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=0.26............. Loss: -0.12167779, mean(E): -21.72343517-0.01640328j, var(E): 0.52528552
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=0.26............. Loss: -0.13876227, mean(E): -21.65177480-0.00012797j, var(E): 0.56302053
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=0.26............. Loss: 0.40689421, mean(E): -21.78222039-0.00508751j, var(E): 1.46968966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=0.26............. Loss: 0.10750231, mean(E): -21.72317969+0.01697449j, var(E): 0.77610571
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=0.26............. Loss: 0.43473747, mean(E): -21.76271618-0.00673134j, var(E): 0.86299109
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=0.26............. Loss: -0.18235097, mean(E): -21.67420390+0.00280337j, var(E): 0.77103126
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=0.26............. Loss: -0.36994088, mean(E): -21.56066665+0.00474796j, var(E): 0.83937461
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=0.26............. Loss: 0.02786880, mean(E): -21.73574318+0.00935195j, var(E): 0.84017377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=0.26............. Loss: -1.01769674, mean(E): -21.51723574+0.03042202j, var(E): 1.10709487
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=0.26............. Loss: 0.24181925, mean(E): -21.74568975+0.01627677j, var(E): 0.54363120
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=0.26............. Loss: -0.54478253, mean(E): -21.67709779+0.04477522j, var(E): 0.74438140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=0.26............. Loss: -0.17141998, mean(E): -21.64905574+0.01094228j, var(E): 0.89807402
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=0.27............. Loss: 0.09363413, mean(E): -21.65351711+0.02379535j, var(E): 1.00775812
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=0.26............. Loss: 0.09694862, mean(E): -21.74471493-0.00465297j, var(E): 0.93894181
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=0.26............. Loss: -0.03871417, mean(E): -21.72187602+0.04035732j, var(E): 0.51494430
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=0.26............. Loss: 0.03938375, mean(E): -21.70414758-0.00567249j, var(E): 0.54953583
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=0.26............. Loss: -0.10294119, mean(E): -21.67723414+0.00615046j, var(E): 0.35402676
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=0.26............. Loss: -0.00651975, mean(E): -21.65823856-0.00529980j, var(E): 1.00291754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=0.26............. Loss: 0.34923029, mean(E): -21.73966313+0.00907395j, var(E): 0.71805071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=0.26............. Loss: -0.01358763, mean(E): -21.70703977-0.01989503j, var(E): 0.73501032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=0.26............. Loss: 0.07194918, mean(E): -21.73229491+0.03038150j, var(E): 0.42433429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=0.26............. Loss: -0.02131060, mean(E): -21.75344093+0.00835703j, var(E): 0.65472452
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=0.26............. Loss: -0.02340764, mean(E): -21.69377060+0.01941229j, var(E): 0.60291588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=0.26............. Loss: 0.39098628, mean(E): -21.78201577-0.00090097j, var(E): 1.47299428
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=0.26............. Loss: -0.24547043, mean(E): -21.66314858+0.02239271j, var(E): 0.55944225
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=0.26............. Loss: -0.18686477, mean(E): -21.72562697+0.00034726j, var(E): 0.87370968
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=0.26............. Loss: 0.40706824, mean(E): -21.79546703+0.02729922j, var(E): 0.60593132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=0.26............. Loss: -0.60128014, mean(E): -21.59846777+0.02402030j, var(E): 0.89087345
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=0.26............. Loss: -0.45155470, mean(E): -21.66463225+0.03212845j, var(E): 0.67691455
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(16.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=0.26............. Loss: 0.09668047, mean(E): -21.76360534+0.01047088j, var(E): 0.33274068
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=0.26............. Loss: 0.14254156, mean(E): -21.73291139-0.01029794j, var(E): 0.73274139
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=0.26............. Loss: 0.23823371, mean(E): -21.78161378+0.01552085j, var(E): 0.55028339
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=0.26............. Loss: -0.03753580, mean(E): -21.74390565+0.00216742j, var(E): 0.51512412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=0.26............. Loss: 0.06042633, mean(E): -21.72915896-0.00286544j, var(E): 0.43920629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=0.26............. Loss: 0.23836812, mean(E): -21.70535695-0.01039052j, var(E): 0.88091289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=0.28............. Loss: -0.21027654, mean(E): -21.72924599-0.00942579j, var(E): 0.31152553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=0.26............. Loss: 0.16891162, mean(E): -21.73121285-0.01710450j, var(E): 0.94605252
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=0.26............. Loss: -0.03522386, mean(E): -21.72939270+0.00288050j, var(E): 0.51291769
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=0.26............. Loss: 0.00451863, mean(E): -21.77757834-0.02874852j, var(E): 0.79894181
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=0.26............. Loss: -0.18130444, mean(E): -21.69891524-0.00442959j, var(E): 0.54093961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=0.26............. Loss: 0.15559750, mean(E): -21.70805852+0.00156916j, var(E): 0.44003626
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=0.27............. Loss: -0.07111549, mean(E): -21.64120522-0.00844603j, var(E): 0.33114639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=0.26............. Loss: 0.18925710, mean(E): -21.74684151+0.01415153j, var(E): 0.34380351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=0.26............. Loss: 0.08715317, mean(E): -21.74568463-0.00021216j, var(E): 0.74464955
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=0.26............. Loss: -0.25168279, mean(E): -21.68968226+0.00896064j, var(E): 0.68220035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=0.26............. Loss: 0.18922223, mean(E): -21.72643949+0.01017660j, var(E): 0.60596140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=0.26............. Loss: 1.02139605, mean(E): -21.88254374+0.02414478j, var(E): 4.26825440
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=0.26............. Loss: 0.05350720, mean(E): -21.72340451+0.00134602j, var(E): 0.53623421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=0.26............. Loss: -0.10950868, mean(E): -21.68837369+0.02280845j, var(E): 0.86876679
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=0.26............. Loss: -0.05848279, mean(E): -21.70520260-0.05198808j, var(E): 0.51959016
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=0.26............. Loss: 0.02729955, mean(E): -21.73144377-0.01382378j, var(E): 0.68773462
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=0.26............. Loss: 0.25693644, mean(E): -21.78514166+0.00861685j, var(E): 0.52271990
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=0.26............. Loss: -0.01849327, mean(E): -21.74100388-0.01520838j, var(E): 0.54968288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=0.26............. Loss: -0.28708037, mean(E): -21.67691892-0.00040675j, var(E): 0.74708241
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=0.26............. Loss: 0.29340466, mean(E): -21.77930470+0.01463631j, var(E): 0.54000711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=0.26............. Loss: -0.24553928, mean(E): -21.71735545+0.01222356j, var(E): 0.45403775
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=0.29............. Loss: 0.21724091, mean(E): -21.74611186+0.04368454j, var(E): 0.96859076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=0.26............. Loss: -0.76382839, mean(E): -21.57322178-0.03203759j, var(E): 1.09961472
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=0.26............. Loss: 0.42718441, mean(E): -21.78693685+0.02858784j, var(E): 0.49626791
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=0.26............. Loss: 0.10953938, mean(E): -21.80447207-0.00041629j, var(E): 0.37204584
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=0.26............. Loss: -0.30879956, mean(E): -21.68262393+0.02723374j, var(E): 0.45166501
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=0.26............. Loss: -0.05778306, mean(E): -21.72319955-0.04135168j, var(E): 1.11453430
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=0.26............. Loss: -0.33367260, mean(E): -21.72280454+0.00298427j, var(E): 0.66808005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=0.26............. Loss: 0.10310196, mean(E): -21.76951492-0.01744637j, var(E): 0.60103680
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=0.26............. Loss: -0.53965234, mean(E): -21.63263278-0.00285434j, var(E): 0.50464001
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=0.26............. Loss: -0.09469943, mean(E): -21.70958853-0.01608411j, var(E): 0.30939253
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=0.26............. Loss: -0.83841671, mean(E): -21.60121455-0.00833069j, var(E): 0.74371415
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=0.26............. Loss: 0.12637504, mean(E): -21.76172322+0.01346991j, var(E): 0.51612677
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=0.26............. Loss: -0.07226560, mean(E): -21.74472977-0.02018049j, var(E): 0.38985601
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=0.26............. Loss: -0.05809267, mean(E): -21.72792399+0.01808976j, var(E): 0.33892537
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=0.26............. Loss: 0.49245643, mean(E): -21.81204256-0.02278803j, var(E): 0.30131020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=0.26............. Loss: -0.20504414, mean(E): -21.69909393+0.01208576j, var(E): 0.54728380
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=0.26............. Loss: -0.40021385, mean(E): -21.68013493+0.01063229j, var(E): 0.57150048
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=0.26............. Loss: -0.59450520, mean(E): -21.68194482+0.01127896j, var(E): 0.92378046
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=0.26............. Loss: -0.21643403, mean(E): -21.67455500-0.02322604j, var(E): 1.11212281
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=0.26............. Loss: -0.01257499, mean(E): -21.75076012-0.01162917j, var(E): 0.44736597
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=0.26............. Loss: -0.08105597, mean(E): -21.73699680-0.02148107j, var(E): 0.30470882
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=0.26............. Loss: 1.32412934, mean(E): -21.90163329+0.02963110j, var(E): 3.27280308
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=0.26............. Loss: -0.23870084, mean(E): -21.70957859+0.00100419j, var(E): 0.99805977
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(17.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=0.26............. Loss: 0.18701903, mean(E): -21.74991042-0.01319009j, var(E): 0.31449210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=0.26............. Loss: -0.12188515, mean(E): -21.68808327-0.00276543j, var(E): 0.25096403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=0.26............. Loss: 0.21757335, mean(E): -21.75850908+0.00809174j, var(E): 0.29530731
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=0.26............. Loss: -0.53214473, mean(E): -21.67781270+0.01783470j, var(E): 1.03045557
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=0.26............. Loss: 0.11044168, mean(E): -21.77783530+0.01751698j, var(E): 0.39247123
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=0.26............. Loss: -0.37136041, mean(E): -21.67434922-0.02041631j, var(E): 0.63648830
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=0.26............. Loss: -0.13469894, mean(E): -21.66709559-0.04031419j, var(E): 0.33281220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=0.26............. Loss: 0.21923926, mean(E): -21.74652677+0.00650614j, var(E): 0.50934777
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=0.26............. Loss: -0.49668212, mean(E): -21.69681241-0.00056080j, var(E): 0.56994869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=0.26............. Loss: -0.42962980, mean(E): -21.62433187-0.00157376j, var(E): 0.86429076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=0.26............. Loss: 0.42966052, mean(E): -21.76995382-0.00873488j, var(E): 0.79051151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=0.26............. Loss: -0.25001422, mean(E): -21.73080639+0.00123707j, var(E): 0.40620174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=0.26............. Loss: 0.09499011, mean(E): -21.75787107-0.01491258j, var(E): 0.25721920
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=0.26............. Loss: -0.21667740, mean(E): -21.71014059-0.00224052j, var(E): 0.61538224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=0.26............. Loss: 0.05594865, mean(E): -21.76011576-0.00750644j, var(E): 0.51515318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=0.26............. Loss: -0.29644756, mean(E): -21.76777317+0.00394241j, var(E): 0.63006408
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=0.26............. Loss: -0.13448484, mean(E): -21.78030869+0.00008998j, var(E): 0.42597376
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=0.26............. Loss: -0.19753120, mean(E): -21.76734244-0.01599515j, var(E): 0.72034732
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=0.26............. Loss: 0.17427054, mean(E): -21.75764702+0.01896900j, var(E): 0.39055668
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=0.26............. Loss: 0.14707897, mean(E): -21.73290936-0.02107229j, var(E): 0.25685770
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=0.26............. Loss: -0.89013573, mean(E): -21.66748043-0.00424497j, var(E): 0.78468903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=0.26............. Loss: -0.10328419, mean(E): -21.73711781-0.03271282j, var(E): 0.27522906
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=0.26............. Loss: -0.15108526, mean(E): -21.73321245+0.01644369j, var(E): 0.25773886
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=0.26............. Loss: 0.04577267, mean(E): -21.77809096-0.00876325j, var(E): 0.38498059
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=0.26............. Loss: -0.06199471, mean(E): -21.72056887-0.00517815j, var(E): 0.40838374
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=0.26............. Loss: 0.03711325, mean(E): -21.74069325+0.00092362j, var(E): 0.40118775
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=0.26............. Loss: 0.11304451, mean(E): -21.79610747+0.01495539j, var(E): 0.24493533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=0.26............. Loss: -0.17790218, mean(E): -21.72112607-0.01608238j, var(E): 0.28718793
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=0.26............. Loss: 0.08967833, mean(E): -21.75351116-0.01712352j, var(E): 0.29630975
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=0.26............. Loss: 0.14878970, mean(E): -21.75757837-0.01076867j, var(E): 0.49822258
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=0.26............. Loss: 0.13175974, mean(E): -21.78290605+0.00540186j, var(E): 0.43410719
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=0.26............. Loss: -0.37835988, mean(E): -21.69797985+0.00437432j, var(E): 0.58354246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=0.26............. Loss: 0.00530868, mean(E): -21.71647035-0.00513915j, var(E): 0.62127178
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=0.26............. Loss: -0.25932553, mean(E): -21.71039792+0.01202459j, var(E): 0.38363634
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=0.26............. Loss: 0.12133375, mean(E): -21.78741857+0.00596390j, var(E): 0.48145148
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=0.27............. Loss: 0.16138605, mean(E): -21.81553431-0.00998807j, var(E): 0.52201058
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=0.26............. Loss: 0.10631803, mean(E): -21.82894173-0.01742324j, var(E): 0.36512498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=0.26............. Loss: -0.11793965, mean(E): -21.76906259+0.00065976j, var(E): 0.47707552
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=0.26............. Loss: -0.08879723, mean(E): -21.77400376-0.00480152j, var(E): 0.47721752
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=0.26............. Loss: 0.07313935, mean(E): -21.73488158-0.01867797j, var(E): 0.42840883
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=0.26............. Loss: 0.02333862, mean(E): -21.77027564+0.00967086j, var(E): 0.37635744
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=0.26............. Loss: 0.12413092, mean(E): -21.78872233-0.01591315j, var(E): 0.18979773
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=0.26............. Loss: -0.15384309, mean(E): -21.74181702+0.00163877j, var(E): 0.19189979
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=0.26............. Loss: 0.15957927, mean(E): -21.78248799-0.05370896j, var(E): 0.19344231
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=0.27............. Loss: -0.36428642, mean(E): -21.70503785-0.01002620j, var(E): 0.64425334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=0.26............. Loss: 0.55657244, mean(E): -21.80571285-0.00473671j, var(E): 0.37406441
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=0.26............. Loss: -0.36169420, mean(E): -21.72956588-0.01872961j, var(E): 0.67103665
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=0.26............. Loss: 0.42119767, mean(E): -21.83330629-0.01700598j, var(E): 0.41454027
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=0.26............. Loss: -0.32858400, mean(E): -21.71247980+0.02268908j, var(E): 0.30646514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=0.26............. Loss: -0.44429192, mean(E): -21.70658901-0.02856995j, var(E): 0.39481444
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=0.26............. Loss: -0.63704309, mean(E): -21.61015610+0.02910368j, var(E): 0.73366675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=0.26............. Loss: 0.02640348, mean(E): -21.73954184-0.01215113j, var(E): 0.62683929
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=0.26............. Loss: -0.45904823, mean(E): -21.64447344-0.00865845j, var(E): 0.55150496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=0.26............. Loss: 0.19270730, mean(E): -21.75661850-0.01048277j, var(E): 0.35426192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=0.26............. Loss: 0.54788139, mean(E): -21.80138619-0.00412598j, var(E): 0.41308958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=0.26............. Loss: 0.07280816, mean(E): -21.77325209-0.01208911j, var(E): 0.29351546
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=0.26............. Loss: 0.00562235, mean(E): -21.79082157-0.01945161j, var(E): 0.36937254
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=0.26............. Loss: 0.34153959, mean(E): -21.78474974-0.00434370j, var(E): 0.35003038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=0.26............. Loss: 0.14382376, mean(E): -21.79839019+0.01355884j, var(E): 0.19846985
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=0.26............. Loss: 0.09061218, mean(E): -21.78571904-0.03263869j, var(E): 0.16661779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(18.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=0.26............. Loss: -0.27820928, mean(E): -21.72923345+0.00705323j, var(E): 0.37795188
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=0.26............. Loss: 0.26576511, mean(E): -21.74695680-0.02019159j, var(E): 0.72036960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=0.26............. Loss: -0.00518833, mean(E): -21.76708858-0.01749877j, var(E): 0.41266027
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=0.27............. Loss: 0.31854598, mean(E): -21.82788299-0.02183951j, var(E): 0.28247351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=0.26............. Loss: -0.26533210, mean(E): -21.72743741+0.02090343j, var(E): 0.46950159
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=0.26............. Loss: -0.08356242, mean(E): -21.75922184+0.00360780j, var(E): 0.11299162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=0.26............. Loss: 0.31040521, mean(E): -21.85681258-0.00505792j, var(E): 0.42407530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=0.27............. Loss: -0.01938903, mean(E): -21.76808276-0.01632760j, var(E): 0.51858157
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=0.26............. Loss: -0.18078225, mean(E): -21.74695093+0.00972118j, var(E): 0.46839445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=0.26............. Loss: -0.34703567, mean(E): -21.70424229+0.02095620j, var(E): 0.35204914
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=0.26............. Loss: 0.03460845, mean(E): -21.77724198-0.00737974j, var(E): 0.32247397
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=0.26............. Loss: -0.14586041, mean(E): -21.66178476-0.00258953j, var(E): 0.45445855
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=0.26............. Loss: -0.60468579, mean(E): -21.64859960+0.02328933j, var(E): 0.92487374
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=0.26............. Loss: 0.23818845, mean(E): -21.78022981-0.03681112j, var(E): 0.37056810
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=0.26............. Loss: -0.36845771, mean(E): -21.65498291+0.00687553j, var(E): 1.09088466
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=0.26............. Loss: 0.01970989, mean(E): -21.68697757+0.03079117j, var(E): 0.67715087
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=0.26............. Loss: -0.10679093, mean(E): -21.70030310+0.03237649j, var(E): 0.41040812
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=0.26............. Loss: -0.17544362, mean(E): -21.73636114-0.03948010j, var(E): 0.63952687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=0.26............. Loss: 0.08404626, mean(E): -21.78240537+0.02147209j, var(E): 0.29166712
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=0.26............. Loss: -0.44355958, mean(E): -21.64431087+0.02020670j, var(E): 0.81715396
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=0.26............. Loss: -0.27004058, mean(E): -21.70732589+0.00412143j, var(E): 0.55008531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=0.26............. Loss: -0.12544646, mean(E): -21.76472818+0.00004241j, var(E): 0.34300473
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=0.26............. Loss: -0.22642187, mean(E): -21.67174161+0.00433434j, var(E): 0.93702878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=0.26............. Loss: -0.57387602, mean(E): -21.72385469+0.02811871j, var(E): 0.58397610
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=0.26............. Loss: -0.81183622, mean(E): -21.56945596-0.00665915j, var(E): 0.83510826
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=0.26............. Loss: -0.18160808, mean(E): -21.70397693-0.03296535j, var(E): 0.13790531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=0.27............. Loss: -0.04767545, mean(E): -21.77355861-0.00072623j, var(E): 0.74626356
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=0.26............. Loss: -0.49775406, mean(E): -21.63877661+0.01508576j, var(E): 0.62965283
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=0.26............. Loss: 0.03774853, mean(E): -21.75517093-0.01499520j, var(E): 0.33674833
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=0.26............. Loss: 0.02921358, mean(E): -21.80761539-0.00907429j, var(E): 0.31683797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=0.26............. Loss: 0.39828183, mean(E): -21.80668955-0.01244788j, var(E): 0.48639114
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=0.26............. Loss: 0.47542718, mean(E): -21.84392828+0.02714913j, var(E): 0.37753798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=0.26............. Loss: 0.19789492, mean(E): -21.78449480+0.00608844j, var(E): 0.26716103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=0.26............. Loss: 0.12732765, mean(E): -21.78095849-0.01357318j, var(E): 0.54163241
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=0.26............. Loss: -0.27466072, mean(E): -21.74386315-0.01001670j, var(E): 0.21697042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=0.26............. Loss: 0.00965455, mean(E): -21.72377795-0.01266478j, var(E): 0.49224064
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=0.26............. Loss: 0.03756162, mean(E): -21.79490072+0.01619211j, var(E): 0.20200652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=0.26............. Loss: -0.14498661, mean(E): -21.75483588+0.00775085j, var(E): 0.28802794
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=0.26............. Loss: 0.09769651, mean(E): -21.81030379+0.01282648j, var(E): 0.32314605
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=0.26............. Loss: -0.21364639, mean(E): -21.73835430-0.00938801j, var(E): 0.53763285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=0.26............. Loss: -0.13112921, mean(E): -21.75559384-0.01811545j, var(E): 0.25555929
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=0.26............. Loss: 0.17191089, mean(E): -21.79721399+0.01052324j, var(E): 0.25842245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=0.26............. Loss: 0.24449408, mean(E): -21.81474133-0.02261864j, var(E): 0.29857398
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=0.26............. Loss: -0.14147516, mean(E): -21.75381655+0.00224093j, var(E): 0.16163235
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=0.26............. Loss: 0.06476542, mean(E): -21.78474032+0.01621231j, var(E): 0.34076369
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=0.26............. Loss: 0.11065542, mean(E): -21.78009430-0.01958089j, var(E): 0.26551315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=0.26............. Loss: -0.25233670, mean(E): -21.73856948-0.01362020j, var(E): 0.29425519
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=0.26............. Loss: -0.08458634, mean(E): -21.75738177+0.01266747j, var(E): 0.37588289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=0.26............. Loss: 0.27918705, mean(E): -21.82231786-0.00594036j, var(E): 0.28700787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=0.27............. Loss: -0.11412851, mean(E): -21.78553755-0.00824066j, var(E): 0.43570787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=0.26............. Loss: -0.09000313, mean(E): -21.76130282+0.00691814j, var(E): 0.22588592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=0.26............. Loss: 0.25218456, mean(E): -21.80854882-0.00094328j, var(E): 0.47379690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=0.26............. Loss: -0.12502235, mean(E): -21.71551501-0.02739755j, var(E): 0.42179371
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=0.26............. Loss: 0.24856070, mean(E): -21.85954838-0.01733471j, var(E): 0.24357628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=0.26............. Loss: -0.18354643, mean(E): -21.71915295-0.00276696j, var(E): 0.44599964
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=0.26............. Loss: 0.12356790, mean(E): -21.79389821-0.00979850j, var(E): 0.22128624
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=0.26............. Loss: 0.37689598, mean(E): -21.77286504-0.00062958j, var(E): 0.38928937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=0.26............. Loss: 0.00623811, mean(E): -21.77229181+0.00666399j, var(E): 0.28972753
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=0.26............. Loss: -0.55223404, mean(E): -21.69363541+0.01609222j, var(E): 0.50782507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=0.26............. Loss: 0.07883707, mean(E): -21.74688264+0.00155414j, var(E): 0.40556240
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=0.26............. Loss: -0.19484406, mean(E): -21.70221136-0.00683533j, var(E): 0.33718920
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=0.26............. Loss: 0.05233971, mean(E): -21.80540413-0.00544998j, var(E): 0.48886348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=0.26............. Loss: -0.13045604, mean(E): -21.70889495-0.00217942j, var(E): 0.41071550
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=0.26............. Loss: 0.01013575, mean(E): -21.74852928+0.02274373j, var(E): 0.22351275
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=0.26............. Loss: -0.29229245, mean(E): -21.71617575+0.00526867j, var(E): 0.49051707
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(19.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=0.26............. Loss: -0.39159416, mean(E): -21.71818937+0.00841277j, var(E): 0.42520197
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=0.26............. Loss: 0.40719144, mean(E): -21.85364599+0.00160442j, var(E): 0.32646576
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=0.26............. Loss: -0.37089290, mean(E): -21.71388153-0.00422443j, var(E): 0.53753808
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=0.26............. Loss: -0.11932257, mean(E): -21.79730092+0.01448191j, var(E): 0.25469997
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=0.26............. Loss: -0.07778938, mean(E): -21.77835385+0.02157871j, var(E): 0.46265128
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=0.26............. Loss: -0.14966377, mean(E): -21.77054809+0.01869592j, var(E): 0.57581260
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=0.26............. Loss: -0.31677197, mean(E): -21.73056903-0.00423857j, var(E): 0.39809659
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=0.26............. Loss: 0.16858901, mean(E): -21.80268250+0.00008918j, var(E): 0.38143878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=0.26............. Loss: -0.22756138, mean(E): -21.72839252+0.02724944j, var(E): 0.23223607
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=0.26............. Loss: 0.01242370, mean(E): -21.76275542+0.01103836j, var(E): 0.31158198
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=0.26............. Loss: 0.08510080, mean(E): -21.78449354+0.01609914j, var(E): 0.48811070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=0.26............. Loss: -0.03099646, mean(E): -21.72403838+0.00842965j, var(E): 0.25796722
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=0.26............. Loss: -0.06404700, mean(E): -21.72080775-0.01347260j, var(E): 0.52791225
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=0.26............. Loss: -0.09470057, mean(E): -21.72887503-0.00987795j, var(E): 0.28202186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=0.26............. Loss: -0.19358515, mean(E): -21.78096841-0.00640105j, var(E): 0.43668706
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=0.26............. Loss: 0.20374161, mean(E): -21.87347801+0.00105956j, var(E): 0.61242453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=0.26............. Loss: -0.11066893, mean(E): -21.71209051-0.03243217j, var(E): 0.64233434
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=0.26............. Loss: -0.17079674, mean(E): -21.75299492-0.01792460j, var(E): 0.50927493
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=0.26............. Loss: 0.10172093, mean(E): -21.83547892-0.00779543j, var(E): 0.31073899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=0.26............. Loss: -0.46424293, mean(E): -21.74204223-0.00517793j, var(E): 0.44471982
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=0.27............. Loss: -0.76661861, mean(E): -21.68424995-0.00497808j, var(E): 0.62706092
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=0.26............. Loss: 0.02669782, mean(E): -21.75701235+0.00571458j, var(E): 0.26934191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=0.26............. Loss: -0.13470253, mean(E): -21.72236331-0.01759240j, var(E): 0.22587851
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=0.26............. Loss: -0.28776137, mean(E): -21.73520096+0.00316642j, var(E): 0.30827864
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=0.26............. Loss: -0.08216103, mean(E): -21.75869850+0.00803865j, var(E): 0.26220948
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=0.26............. Loss: 0.11880772, mean(E): -21.79022379-0.00132758j, var(E): 0.36558207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=0.27............. Loss: -0.43192667, mean(E): -21.69501548-0.01727345j, var(E): 0.49854010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=0.26............. Loss: 0.05301265, mean(E): -21.77340452+0.00835439j, var(E): 0.19950246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=0.26............. Loss: -0.34441621, mean(E): -21.70803876+0.00402502j, var(E): 0.21193442
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=0.26............. Loss: 0.11903789, mean(E): -21.81765017-0.00499656j, var(E): 0.35144520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=0.27............. Loss: 0.13849042, mean(E): -21.79141323+0.01239903j, var(E): 0.82267365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=0.26............. Loss: -0.21089674, mean(E): -21.69834933-0.00972968j, var(E): 0.45246920
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=0.28............. Loss: 0.09575428, mean(E): -21.82146330+0.00729244j, var(E): 0.76660132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=0.26............. Loss: 0.08553105, mean(E): -21.77477966+0.00059774j, var(E): 0.47063397
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=0.26............. Loss: 0.12057900, mean(E): -21.80095574+0.00173209j, var(E): 0.50157542
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=0.26............. Loss: -0.26100511, mean(E): -21.75141676-0.01730332j, var(E): 0.27913821
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=0.26............. Loss: 0.21397911, mean(E): -21.81936495-0.00975409j, var(E): 0.39295754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=0.26............. Loss: 0.34742482, mean(E): -21.81894491-0.00020389j, var(E): 0.79010288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=0.26............. Loss: -0.13758539, mean(E): -21.73742508+0.00052758j, var(E): 0.19427156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=0.26............. Loss: 0.00853418, mean(E): -21.74369670-0.01364335j, var(E): 0.31335254
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=0.26............. Loss: -0.05311080, mean(E): -21.76628751-0.00946635j, var(E): 0.18953953
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=0.26............. Loss: 0.11418468, mean(E): -21.78483699-0.00017934j, var(E): 0.16405723
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=0.26............. Loss: -0.07478243, mean(E): -21.77431426-0.01217598j, var(E): 0.23463477
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=0.26............. Loss: -0.06499136, mean(E): -21.75650471-0.02371967j, var(E): 0.27202498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=0.26............. Loss: -0.03879081, mean(E): -21.78434685-0.00368315j, var(E): 0.18505894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=0.26............. Loss: -0.14267907, mean(E): -21.78000861-0.00198758j, var(E): 0.15518279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=0.26............. Loss: -0.63021329, mean(E): -21.69471538-0.02133179j, var(E): 0.63100251
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=0.26............. Loss: 0.12297362, mean(E): -21.75243542+0.00589924j, var(E): 0.25308172
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=0.26............. Loss: 0.15505091, mean(E): -21.79283926+0.00202445j, var(E): 0.23134192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=0.26............. Loss: 0.23839670, mean(E): -21.84743955-0.01757065j, var(E): 0.21738464
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=0.26............. Loss: -0.29574309, mean(E): -21.70895218+0.00412895j, var(E): 0.48885865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=0.27............. Loss: -0.40499404, mean(E): -21.69520488-0.01117058j, var(E): 0.26933424
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=0.26............. Loss: 0.14579576, mean(E): -21.80390746-0.00821671j, var(E): 0.28093315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=0.26............. Loss: 0.15621718, mean(E): -21.78644066-0.00799599j, var(E): 0.25034279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=0.26............. Loss: -0.08095440, mean(E): -21.74174923-0.00303091j, var(E): 0.24311880
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=0.26............. Loss: -0.43327409, mean(E): -21.74017848-0.00329969j, var(E): 0.55065699
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=0.26............. Loss: -0.08488745, mean(E): -21.76445150-0.00897718j, var(E): 0.39845350
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=0.26............. Loss: 0.18311752, mean(E): -21.76719292+0.01372529j, var(E): 0.18860757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=0.26............. Loss: -0.05706075, mean(E): -21.74826383+0.00536817j, var(E): 0.21398153
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=0.26............. Loss: 0.38528971, mean(E): -21.83982070+0.00186520j, var(E): 0.52492472
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=0.26............. Loss: -0.30217846, mean(E): -21.78647982+0.01585966j, var(E): 0.83116110
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=0.26............. Loss: 0.32212146, mean(E): -21.79259931+0.01791067j, var(E): 0.22336036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=0.26............. Loss: -0.05081778, mean(E): -21.73142572+0.02058349j, var(E): 0.52410395
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=0.26............. Loss: -0.57476797, mean(E): -21.70761262-0.02340536j, var(E): 0.53605445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=0.27............. Loss: -0.49519631, mean(E): -21.63718673-0.00215799j, var(E): 0.54548566
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=0.26............. Loss: 0.15614448, mean(E): -21.74728927+0.00296425j, var(E): 0.53799064
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=0.26............. Loss: 0.08377361, mean(E): -21.79688646+0.00111607j, var(E): 0.34019726
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=0.26............. Loss: 0.26773036, mean(E): -21.84122125-0.02535396j, var(E): 0.34503960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=0.26............. Loss: -0.12130365, mean(E): -21.72054475+0.01026592j, var(E): 0.38411192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=0.26............. Loss: 0.11258992, mean(E): -21.79741567-0.00425467j, var(E): 0.38176601
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=0.26............. Loss: 0.01633226, mean(E): -21.79296452-0.00214104j, var(E): 0.18344731
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(20.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=0.26............. Loss: -0.22737643, mean(E): -21.72725099+0.00131340j, var(E): 0.18508292
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=0.26............. Loss: 0.19291299, mean(E): -21.78756627-0.01833613j, var(E): 0.27269453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=0.26............. Loss: -0.37678074, mean(E): -21.71901281-0.01110297j, var(E): 0.33716372
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=0.26............. Loss: 0.05623622, mean(E): -21.77883641-0.00723886j, var(E): 0.16090866
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=0.27............. Loss: -0.69890108, mean(E): -21.71285731+0.01323874j, var(E): 0.65496002
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=0.26............. Loss: -0.17187524, mean(E): -21.78357879+0.00622470j, var(E): 0.73367892
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=0.27............. Loss: 0.04984966, mean(E): -21.80898694+0.00064821j, var(E): 0.25076613
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=0.26............. Loss: -0.06760157, mean(E): -21.75651724+0.01383343j, var(E): 0.50876629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=0.26............. Loss: -0.12218053, mean(E): -21.72090867+0.00738399j, var(E): 0.46847245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=0.26............. Loss: -0.17640896, mean(E): -21.72075867+0.01942489j, var(E): 0.30636685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=0.26............. Loss: -0.01858470, mean(E): -21.76542352-0.01193733j, var(E): 0.33064805
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=0.26............. Loss: 0.22395545, mean(E): -21.79888502-0.02475177j, var(E): 0.22819763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=0.26............. Loss: 0.37861350, mean(E): -21.83030880+0.01037347j, var(E): 0.56267948
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=0.26............. Loss: -0.47937438, mean(E): -21.70493394-0.01245501j, var(E): 0.40227603
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=0.26............. Loss: 0.09485058, mean(E): -21.74829094-0.00709949j, var(E): 0.23345533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=0.26............. Loss: -0.23001802, mean(E): -21.71628565-0.00841401j, var(E): 0.23505842
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=0.27............. Loss: 0.03551893, mean(E): -21.76916152+0.00588643j, var(E): 0.31267906
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=0.27............. Loss: -0.26172415, mean(E): -21.72005955-0.00589981j, var(E): 0.17280688
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=0.26............. Loss: -0.30768893, mean(E): -21.74002516-0.00643317j, var(E): 0.28575292
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=0.26............. Loss: 0.27538501, mean(E): -21.80837283-0.01844259j, var(E): 0.48451000
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=0.26............. Loss: 0.16715705, mean(E): -21.81887115-0.00395159j, var(E): 0.25879996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=0.26............. Loss: 0.16183931, mean(E): -21.76036844+0.00559407j, var(E): 0.11886657
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=0.26............. Loss: 0.05941767, mean(E): -21.75683696+0.00247416j, var(E): 0.13508496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=0.26............. Loss: -0.08717285, mean(E): -21.74898968-0.01390303j, var(E): 0.27543213
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=0.26............. Loss: 0.02839250, mean(E): -21.78031384+0.00621329j, var(E): 0.19685434
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=0.26............. Loss: 0.11534371, mean(E): -21.77210104+0.01325425j, var(E): 0.68753049
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=0.26............. Loss: -0.07981398, mean(E): -21.78091893+0.00614591j, var(E): 0.22256111
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=0.26............. Loss: 0.24184197, mean(E): -21.81567557-0.02319415j, var(E): 0.19670548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=0.26............. Loss: -0.39940461, mean(E): -21.73673215+0.01382730j, var(E): 0.41380927
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=0.26............. Loss: 0.54454749, mean(E): -21.84323111-0.00631832j, var(E): 0.25718538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=0.26............. Loss: -0.80419923, mean(E): -21.65967715+0.01969906j, var(E): 0.91978180
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=0.26............. Loss: 0.16942691, mean(E): -21.81646913+0.00638158j, var(E): 0.26473657
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=0.26............. Loss: 0.52197918, mean(E): -21.85943291-0.00408014j, var(E): 1.03769088
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=0.26............. Loss: 0.01242372, mean(E): -21.79669761-0.00222574j, var(E): 0.56506293
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=0.26............. Loss: 0.21463656, mean(E): -21.82697846-0.01515279j, var(E): 0.44610001
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=0.27............. Loss: 0.31957649, mean(E): -21.82646780+0.00860252j, var(E): 0.26012227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=0.26............. Loss: 0.24079441, mean(E): -21.78429897-0.00779404j, var(E): 0.37474201
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=0.27............. Loss: 0.09265451, mean(E): -21.79041389-0.00571816j, var(E): 0.15184259
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=0.26............. Loss: -0.01200325, mean(E): -21.76282975+0.00551118j, var(E): 0.37335995
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=0.26............. Loss: 0.20588460, mean(E): -21.76917017-0.00173661j, var(E): 0.42812168
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=0.26............. Loss: 0.01859014, mean(E): -21.77786937+0.00980581j, var(E): 0.23529261
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=0.26............. Loss: 0.17067733, mean(E): -21.79246684-0.00380961j, var(E): 0.38315934
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=0.26............. Loss: 0.08987591, mean(E): -21.78631750+0.00725356j, var(E): 0.25176400
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=0.26............. Loss: 0.40480236, mean(E): -21.83403067-0.01885810j, var(E): 0.24260063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=0.26............. Loss: 0.66525589, mean(E): -21.85310668+0.00645167j, var(E): 1.26578711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=0.26............. Loss: 0.02333431, mean(E): -21.75414432-0.00494747j, var(E): 0.21396512
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=0.26............. Loss: 0.06148558, mean(E): -21.78437010+0.00560221j, var(E): 0.22380360
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=0.26............. Loss: -0.31336231, mean(E): -21.71833262-0.00452185j, var(E): 0.24928938
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=0.26............. Loss: 0.17202032, mean(E): -21.82478521-0.00249627j, var(E): 0.20143624
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=0.26............. Loss: -0.20685166, mean(E): -21.78602141-0.00226034j, var(E): 0.32068538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=0.26............. Loss: -0.03126199, mean(E): -21.73889440+0.00102162j, var(E): 0.18228508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=0.26............. Loss: -0.11339612, mean(E): -21.74079966+0.00417564j, var(E): 0.18171480
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=0.26............. Loss: -0.03716713, mean(E): -21.77302877-0.00789845j, var(E): 0.30639716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=0.26............. Loss: 0.37620863, mean(E): -21.86909839+0.00714036j, var(E): 0.20541633
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=0.27............. Loss: -0.52969842, mean(E): -21.75379246-0.00875154j, var(E): 0.47068377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=0.26............. Loss: 0.03718213, mean(E): -21.76502990-0.00744219j, var(E): 0.19845535
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=0.26............. Loss: -0.20203810, mean(E): -21.71918781+0.00566932j, var(E): 0.15504016
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=0.26............. Loss: 0.09504098, mean(E): -21.77069947+0.01864243j, var(E): 0.13795639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=0.26............. Loss: 0.09154083, mean(E): -21.76678636+0.00347558j, var(E): 0.17206235
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=0.26............. Loss: 0.00542888, mean(E): -21.72858337-0.00707774j, var(E): 0.17472853
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=0.26............. Loss: 0.21245806, mean(E): -21.81768589-0.00435757j, var(E): 0.32623047
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=0.27............. Loss: 0.17285074, mean(E): -21.77362576-0.01187358j, var(E): 0.38046668
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=0.26............. Loss: -0.12686945, mean(E): -21.72646737+0.00550503j, var(E): 0.16469132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=0.26............. Loss: -0.04807078, mean(E): -21.70848000+0.01139401j, var(E): 0.71121685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=0.26............. Loss: 0.11207930, mean(E): -21.78061721+0.00831950j, var(E): 0.30151561
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=0.26............. Loss: -0.09074860, mean(E): -21.80271939-0.00717348j, var(E): 0.44966881
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=0.26............. Loss: -0.04539098, mean(E): -21.77470537-0.00625407j, var(E): 0.40641183
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=0.26............. Loss: 0.22749576, mean(E): -21.82279982+0.01528687j, var(E): 0.21067612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=0.26............. Loss: 0.08088578, mean(E): -21.75421603+0.01233740j, var(E): 0.24705415
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=0.26............. Loss: 0.00450775, mean(E): -21.77183091+0.00275107j, var(E): 0.20539346
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=0.26............. Loss: -0.17514426, mean(E): -21.71708579-0.00377237j, var(E): 0.51969084
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=0.26............. Loss: -0.17934657, mean(E): -21.75228152-0.00068415j, var(E): 0.36490848
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=0.26............. Loss: 0.22625983, mean(E): -21.79088945-0.02473112j, var(E): 0.23252339
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=0.27............. Loss: 0.09529190, mean(E): -21.77719607+0.00538147j, var(E): 0.19227018
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=0.26............. Loss: -0.06554992, mean(E): -21.76642367-0.02105050j, var(E): 0.18200083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=0.26............. Loss: -0.09144948, mean(E): -21.76303130+0.00311479j, var(E): 0.20520524
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=0.26............. Loss: -0.19491145, mean(E): -21.71289562+0.01063847j, var(E): 0.22924815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=0.26............. Loss: -0.38358460, mean(E): -21.69929508-0.01473811j, var(E): 0.33562375
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=0.26............. Loss: 0.10369155, mean(E): -21.79477062-0.00860564j, var(E): 0.23985062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=0.26............. Loss: 0.00898789, mean(E): -21.78245865-0.00018955j, var(E): 0.22265022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=0.26............. Loss: 0.00772009, mean(E): -21.76833147-0.01980133j, var(E): 0.16442023
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(21.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=0.26............. Loss: 0.09375882, mean(E): -21.80425577-0.00243096j, var(E): 0.14635192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=0.26............. Loss: 0.09416726, mean(E): -21.81570942+0.00226712j, var(E): 0.22735340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=0.27............. Loss: -0.03123186, mean(E): -21.79874877+0.00479316j, var(E): 0.33660889
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=0.27............. Loss: -0.05718411, mean(E): -21.76523375-0.02301483j, var(E): 0.21128231
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=0.26............. Loss: -0.03901297, mean(E): -21.76364484-0.00886836j, var(E): 0.61440175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=0.26............. Loss: -0.10107317, mean(E): -21.73321259-0.01385488j, var(E): 0.26575368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=0.26............. Loss: -0.18407689, mean(E): -21.77332917+0.00482597j, var(E): 0.16707242
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=0.26............. Loss: -0.04258269, mean(E): -21.73696997-0.01245754j, var(E): 0.40887803
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=0.26............. Loss: -0.19236752, mean(E): -21.74456451-0.00844573j, var(E): 0.24697843
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=0.26............. Loss: 0.05854246, mean(E): -21.82004933-0.00443897j, var(E): 0.44565288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=0.26............. Loss: -0.40888496, mean(E): -21.75789870+0.00322320j, var(E): 0.44216346
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=0.27............. Loss: -0.18695447, mean(E): -21.74682083-0.00844162j, var(E): 0.26871353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=0.26............. Loss: 0.15891281, mean(E): -21.76151740-0.00465822j, var(E): 0.27523607
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=0.26............. Loss: 0.01837392, mean(E): -21.78011145+0.01339157j, var(E): 0.13865972
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=0.26............. Loss: 0.04065855, mean(E): -21.79508173+0.00041282j, var(E): 0.23791243
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=0.27............. Loss: -0.06563775, mean(E): -21.75951981-0.00813764j, var(E): 0.17162220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=0.26............. Loss: -0.14326505, mean(E): -21.77186966-0.01586761j, var(E): 0.15974529
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=0.26............. Loss: -0.01004354, mean(E): -21.76348532+0.02527060j, var(E): 0.12629879
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=0.26............. Loss: -0.18202731, mean(E): -21.74455323+0.00468993j, var(E): 0.22882777
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=0.26............. Loss: -0.26094508, mean(E): -21.74815712-0.00778837j, var(E): 0.21567774
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=0.26............. Loss: -0.13450407, mean(E): -21.75196962-0.00264919j, var(E): 0.16250416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=0.26............. Loss: 0.22613960, mean(E): -21.78613711-0.00475151j, var(E): 0.26587097
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=0.26............. Loss: 0.88432947, mean(E): -21.86895959+0.00816962j, var(E): 1.29124427
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=0.26............. Loss: -0.10363193, mean(E): -21.75760327+0.00512050j, var(E): 0.15756983
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=0.26............. Loss: -0.25663759, mean(E): -21.68434345+0.00926509j, var(E): 0.36208055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=0.26............. Loss: 0.04840825, mean(E): -21.77396644-0.00104919j, var(E): 0.17497237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=0.26............. Loss: 0.08729106, mean(E): -21.75531164-0.00263742j, var(E): 0.19018991
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=0.26............. Loss: 0.22003964, mean(E): -21.82850064-0.00142961j, var(E): 0.15250225
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=0.26............. Loss: -0.01818413, mean(E): -21.79397895-0.00797188j, var(E): 0.18469230
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=0.26............. Loss: -0.07546527, mean(E): -21.79075890+0.00757108j, var(E): 0.21384431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=0.26............. Loss: 0.07881416, mean(E): -21.77883035-0.00070240j, var(E): 0.20752890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=0.26............. Loss: 0.05242983, mean(E): -21.80408590+0.00661757j, var(E): 0.15061429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=0.26............. Loss: -0.39220747, mean(E): -21.71879764+0.00377847j, var(E): 0.45773766
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=0.26............. Loss: -0.34010381, mean(E): -21.74628456+0.00708614j, var(E): 0.22462862
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=0.26............. Loss: 0.12225604, mean(E): -21.80454622-0.00365993j, var(E): 0.15944170
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=0.26............. Loss: 0.41483473, mean(E): -21.84971657-0.01418229j, var(E): 0.18802696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=0.27............. Loss: 0.00699111, mean(E): -21.77549838-0.00267547j, var(E): 0.21224867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=0.26............. Loss: 0.12242073, mean(E): -21.80546219-0.00224694j, var(E): 0.37993123
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=0.26............. Loss: -0.53159471, mean(E): -21.71519481-0.00816564j, var(E): 0.37044040
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=0.26............. Loss: -0.10058396, mean(E): -21.74013687-0.01160214j, var(E): 0.23004171
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=0.26............. Loss: -0.01601353, mean(E): -21.77201807-0.00423593j, var(E): 0.24817668
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=0.26............. Loss: 0.21136218, mean(E): -21.79695507-0.01004724j, var(E): 0.20554372
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=0.26............. Loss: -0.24100947, mean(E): -21.73490880+0.01518651j, var(E): 0.35663326
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=0.26............. Loss: -0.31521814, mean(E): -21.75804760-0.01863453j, var(E): 0.29848070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=0.26............. Loss: 0.17394986, mean(E): -21.76735021+0.01003130j, var(E): 0.19355095
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=0.26............. Loss: 0.06681197, mean(E): -21.75591320-0.01001143j, var(E): 0.11017633
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=0.26............. Loss: -0.10496855, mean(E): -21.75724959+0.00136524j, var(E): 0.17242174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=0.26............. Loss: 0.01105374, mean(E): -21.74953450-0.00236174j, var(E): 0.18109181
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=0.26............. Loss: -0.12449478, mean(E): -21.68944253+0.01966284j, var(E): 0.39315616
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=0.26............. Loss: 0.01117486, mean(E): -21.83241103+0.00168306j, var(E): 0.16242122
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=0.26............. Loss: -0.45694656, mean(E): -21.74295030+0.00633656j, var(E): 0.22901220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=0.26............. Loss: -0.02650971, mean(E): -21.78019525+0.00277391j, var(E): 0.22049491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=0.26............. Loss: -0.05291724, mean(E): -21.79552483-0.01219815j, var(E): 0.30465815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=0.26............. Loss: -0.03692782, mean(E): -21.75635963-0.00454722j, var(E): 0.27763928
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=0.26............. Loss: -0.00711542, mean(E): -21.77090608-0.00403070j, var(E): 0.17220201
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=0.26............. Loss: -0.00347169, mean(E): -21.76695688-0.01421228j, var(E): 0.12847193
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=0.26............. Loss: 0.06339490, mean(E): -21.78032133-0.00835274j, var(E): 0.13268067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=0.26............. Loss: 0.21931313, mean(E): -21.78602627-0.00052232j, var(E): 0.31516967
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=0.26............. Loss: 0.32745714, mean(E): -21.81587481-0.02728117j, var(E): 0.25864016
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=0.26............. Loss: 0.06377130, mean(E): -21.81845170-0.00257734j, var(E): 0.28080294
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=0.26............. Loss: 0.13176941, mean(E): -21.81071179-0.00482635j, var(E): 0.13212909
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=0.26............. Loss: -0.14545498, mean(E): -21.73247618-0.01634218j, var(E): 0.15537508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=0.26............. Loss: 0.13969640, mean(E): -21.79837732+0.00297237j, var(E): 0.24837052
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=0.26............. Loss: 0.04614032, mean(E): -21.79411498+0.00233679j, var(E): 0.28372330
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=0.26............. Loss: 0.05202682, mean(E): -21.77623974-0.00127320j, var(E): 0.11584978
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=0.26............. Loss: -0.19621559, mean(E): -21.72336268+0.00101880j, var(E): 0.12741041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=0.26............. Loss: 0.28156034, mean(E): -21.81795333-0.00409104j, var(E): 0.26408713
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=0.26............. Loss: 0.49895192, mean(E): -21.87477671-0.00400816j, var(E): 0.44101711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=0.26............. Loss: -0.12121141, mean(E): -21.74179561+0.00774944j, var(E): 0.20029295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=0.26............. Loss: 0.13170376, mean(E): -21.79096838+0.02461051j, var(E): 0.28954739
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=0.26............. Loss: -0.11713915, mean(E): -21.76149032+0.00246853j, var(E): 0.18405777
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=0.26............. Loss: -0.00734522, mean(E): -21.77117703+0.00162807j, var(E): 0.12161560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=0.27............. Loss: 0.20329133, mean(E): -21.80599485-0.00232623j, var(E): 0.18194247
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=0.27............. Loss: -0.02725811, mean(E): -21.78819953+0.00045905j, var(E): 0.12104083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=0.27............. Loss: 0.07927361, mean(E): -21.80109033+0.00604759j, var(E): 0.23812361
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=0.26............. Loss: 0.18148690, mean(E): -21.81619696-0.00465709j, var(E): 0.35450827
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=0.26............. Loss: -0.23976806, mean(E): -21.71833072+0.00051583j, var(E): 0.33455062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=0.26............. Loss: 0.20349563, mean(E): -21.77386798-0.00510740j, var(E): 0.19832032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=0.26............. Loss: 0.17276002, mean(E): -21.81510431-0.01313116j, var(E): 0.22094756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=0.26............. Loss: 0.09704169, mean(E): -21.81040968-0.00745299j, var(E): 0.13994866
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=0.26............. Loss: -0.06576394, mean(E): -21.76814399-0.00823482j, var(E): 0.13671972
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=0.26............. Loss: -0.24047825, mean(E): -21.78835566+0.01500407j, var(E): 0.21268555
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=0.26............. Loss: -0.01703569, mean(E): -21.78368934-0.00390552j, var(E): 0.15266091
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=0.26............. Loss: 0.00296784, mean(E): -21.74798979+0.00163972j, var(E): 0.15736249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=0.26............. Loss: 0.05652957, mean(E): -21.77361372-0.00620548j, var(E): 0.14637739
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=0.26............. Loss: 0.14653399, mean(E): -21.77998849+0.00541909j, var(E): 0.64042988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=0.26............. Loss: 0.32025521, mean(E): -21.81575551+0.00395543j, var(E): 0.19157798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=0.26............. Loss: 0.10191416, mean(E): -21.81815057-0.00863399j, var(E): 0.13845193
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=0.27............. Loss: -0.14663889, mean(E): -21.77124741-0.00279790j, var(E): 0.27280627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=0.26............. Loss: -0.15059115, mean(E): -21.76337394-0.00601608j, var(E): 0.29335857
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=0.26............. Loss: 0.00452204, mean(E): -21.79947756-0.00718204j, var(E): 0.14203837
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=0.27............. Loss: 0.02481237, mean(E): -21.78576101-0.00596270j, var(E): 0.26303186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=0.26............. Loss: -0.31196118, mean(E): -21.74994773+0.00394755j, var(E): 0.13473441
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=0.27............. Loss: 0.04433760, mean(E): -21.81819742-0.00277924j, var(E): 0.10521947
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=0.26............. Loss: 0.07902568, mean(E): -21.81697982+0.01884498j, var(E): 0.11087026
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=0.26............. Loss: -0.00132587, mean(E): -21.77478464+0.00684868j, var(E): 0.05638350
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=0.27............. Loss: 0.06466481, mean(E): -21.77480163+0.00193272j, var(E): 0.04817756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=0.26............. Loss: -0.13183157, mean(E): -21.73908002+0.00552116j, var(E): 0.18161777
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=0.26............. Loss: -0.05252352, mean(E): -21.77518610-0.01272176j, var(E): 0.09941237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=0.26............. Loss: 0.14402357, mean(E): -21.82858506-0.00087363j, var(E): 0.11292741
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=0.26............. Loss: -0.08979122, mean(E): -21.74797965-0.00323525j, var(E): 0.12342628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=0.26............. Loss: 0.30671534, mean(E): -21.80393205-0.00656565j, var(E): 0.14015227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=0.26............. Loss: -0.12485526, mean(E): -21.76081433+0.00109729j, var(E): 0.24631743
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=0.26............. Loss: -0.02880755, mean(E): -21.76858489-0.00917229j, var(E): 0.13550253
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=0.26............. Loss: 0.26366327, mean(E): -21.81919751+0.00559548j, var(E): 0.13388903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=0.27............. Loss: 0.02326862, mean(E): -21.78307026+0.00923212j, var(E): 0.07321217
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=0.26............. Loss: -0.37946570, mean(E): -21.76556366+0.00836352j, var(E): 0.23383776
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=0.26............. Loss: 0.10666158, mean(E): -21.79834501-0.00279885j, var(E): 0.12117070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(22.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=0.26............. Loss: -0.03167210, mean(E): -21.79320111+0.00044666j, var(E): 0.07966564
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=0.26............. Loss: 0.00530510, mean(E): -21.79310349-0.00217145j, var(E): 0.11519642
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=0.27............. Loss: -0.44493553, mean(E): -21.73309325+0.00285128j, var(E): 0.26248373
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=0.26............. Loss: 0.46219425, mean(E): -21.83622639+0.00554730j, var(E): 0.28574598
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=0.26............. Loss: 0.08520520, mean(E): -21.76683162-0.00596342j, var(E): 0.08097207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=0.26............. Loss: -0.11221907, mean(E): -21.76701714-0.00751089j, var(E): 0.08745879
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=0.26............. Loss: 0.04898120, mean(E): -21.76733909+0.00266971j, var(E): 0.11354668
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=0.26............. Loss: 0.04910338, mean(E): -21.79447758-0.01445814j, var(E): 0.04525322
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=0.26............. Loss: -0.25613184, mean(E): -21.75300164-0.00075647j, var(E): 0.11772641
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=0.26............. Loss: -0.09896385, mean(E): -21.76567729-0.00276155j, var(E): 0.11156182
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=0.26............. Loss: -0.10668142, mean(E): -21.79079321+0.00276543j, var(E): 0.06614675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=0.26............. Loss: 0.07162466, mean(E): -21.80175676+0.00686444j, var(E): 0.06902903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=0.26............. Loss: 0.01972441, mean(E): -21.81595126-0.00694075j, var(E): 0.08963247
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=0.26............. Loss: -0.13508757, mean(E): -21.75670199-0.00387337j, var(E): 0.09189121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=0.26............. Loss: 0.06686249, mean(E): -21.79064589-0.00070964j, var(E): 0.21190179
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=0.26............. Loss: -0.06083594, mean(E): -21.78375388-0.00540999j, var(E): 0.22357852
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=0.26............. Loss: 0.22317212, mean(E): -21.82262475+0.00033276j, var(E): 0.14584534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=0.26............. Loss: 0.07219798, mean(E): -21.78275467-0.01013313j, var(E): 0.11776450
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=0.26............. Loss: -0.06926177, mean(E): -21.78776819-0.00939904j, var(E): 0.28531986
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=0.26............. Loss: -0.10041532, mean(E): -21.79743478+0.00072294j, var(E): 0.22365062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=0.26............. Loss: -0.09151907, mean(E): -21.75590284+0.00093720j, var(E): 0.16551965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=0.27............. Loss: -0.17358923, mean(E): -21.78059805-0.00605619j, var(E): 0.27485700
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=0.26............. Loss: -0.06273298, mean(E): -21.76717842+0.01012204j, var(E): 0.11876737
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=0.26............. Loss: 0.24002077, mean(E): -21.81595465-0.00761072j, var(E): 0.14475173
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=0.26............. Loss: -0.49318925, mean(E): -21.73126807-0.00799708j, var(E): 0.22494962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=0.26............. Loss: -0.35656000, mean(E): -21.74487519-0.00441343j, var(E): 0.14911522
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=0.26............. Loss: 0.06198057, mean(E): -21.79852267+0.00191925j, var(E): 0.09359889
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=0.26............. Loss: 0.04803223, mean(E): -21.79271287-0.00389379j, var(E): 0.06245613
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=0.26............. Loss: 0.39496593, mean(E): -21.82235958-0.00882509j, var(E): 1.15131898
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=0.26............. Loss: 0.16198767, mean(E): -21.79514040-0.00294957j, var(E): 0.15566792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=0.26............. Loss: 0.38270398, mean(E): -21.83311043-0.00034507j, var(E): 0.29153563
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=0.26............. Loss: 0.05566092, mean(E): -21.79937586-0.00381269j, var(E): 0.06214590
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=0.26............. Loss: 0.67996636, mean(E): -21.87083447+0.00058163j, var(E): 0.46094810
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=0.26............. Loss: -0.20930092, mean(E): -21.77555252-0.00537729j, var(E): 0.26099557
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=0.27............. Loss: -0.36753526, mean(E): -21.72523278-0.00930525j, var(E): 0.39910903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=0.26............. Loss: -0.00261004, mean(E): -21.79639381-0.00171869j, var(E): 0.05870662
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=0.27............. Loss: 0.25283362, mean(E): -21.82517425-0.00447300j, var(E): 0.21622339
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=0.26............. Loss: 0.11446686, mean(E): -21.78232226-0.00452393j, var(E): 0.11229635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=0.26............. Loss: 0.15369930, mean(E): -21.80876884-0.00240554j, var(E): 0.22895483
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=0.26............. Loss: -0.03623183, mean(E): -21.78481602-0.00569825j, var(E): 0.10527561
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=0.27............. Loss: 0.37217811, mean(E): -21.82282982-0.00319508j, var(E): 0.94659201
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=0.26............. Loss: -0.12482736, mean(E): -21.77112524+0.00516919j, var(E): 0.13802317
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=0.26............. Loss: -0.07874069, mean(E): -21.76476005-0.00448915j, var(E): 0.16360728
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=0.26............. Loss: 0.12817196, mean(E): -21.81769832-0.00343158j, var(E): 0.09575495
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=0.27............. Loss: -0.03006009, mean(E): -21.79044357-0.00312223j, var(E): 0.08246387
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=0.26............. Loss: -0.05505942, mean(E): -21.76428650+0.00185669j, var(E): 0.08036774
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=0.26............. Loss: 0.03685580, mean(E): -21.78027427-0.00432874j, var(E): 0.23668739
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=0.26............. Loss: 0.26264580, mean(E): -21.82806392-0.00001800j, var(E): 0.14847221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=0.27............. Loss: 0.08277373, mean(E): -21.81216431-0.00484370j, var(E): 0.07219163
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=0.26............. Loss: -0.04761110, mean(E): -21.78383717-0.00685104j, var(E): 0.09846246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=0.26............. Loss: 0.09160812, mean(E): -21.80030832+0.00593620j, var(E): 0.16197395
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=0.26............. Loss: 0.09798412, mean(E): -21.79875747-0.00601579j, var(E): 0.07708643
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=0.26............. Loss: -0.05843433, mean(E): -21.78781806+0.00065094j, var(E): 0.24031549
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=0.27............. Loss: -0.09006693, mean(E): -21.77835937-0.00288182j, var(E): 0.13439760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=0.26............. Loss: -0.10086116, mean(E): -21.77454103-0.00445113j, var(E): 0.19109342
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=0.26............. Loss: 0.15547326, mean(E): -21.81159361+0.00087959j, var(E): 0.07230967
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=0.26............. Loss: -0.12416514, mean(E): -21.73774544-0.00388475j, var(E): 0.05396518
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=0.26............. Loss: 0.19105827, mean(E): -21.80512760-0.00429963j, var(E): 0.11033622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=0.26............. Loss: 0.12066224, mean(E): -21.79318165+0.00272743j, var(E): 0.13727828
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=0.27............. Loss: 0.17397773, mean(E): -21.81437867+0.00909194j, var(E): 0.09996121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=0.26............. Loss: 0.16036152, mean(E): -21.80781346+0.00032162j, var(E): 0.08980148
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=0.26............. Loss: 0.11197532, mean(E): -21.78994557-0.00122697j, var(E): 0.21428781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=0.26............. Loss: 0.09386673, mean(E): -21.78464414+0.00877520j, var(E): 0.03507086
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=0.26............. Loss: -0.00268936, mean(E): -21.78046800-0.00293519j, var(E): 0.30262119
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=0.26............. Loss: 0.07632685, mean(E): -21.79323973-0.00221732j, var(E): 0.05720622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=0.26............. Loss: -0.13952603, mean(E): -21.76255037+0.00355367j, var(E): 0.13334343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=0.27............. Loss: 0.11442044, mean(E): -21.81105015+0.00553532j, var(E): 0.08833832
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=0.26............. Loss: -0.33477979, mean(E): -21.75810791-0.00221357j, var(E): 0.17438504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=0.27............. Loss: -0.05274328, mean(E): -21.79397106+0.00110649j, var(E): 0.08947986
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=0.26............. Loss: 0.08545923, mean(E): -21.81496571+0.00569399j, var(E): 0.07895479
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=0.26............. Loss: -0.18950264, mean(E): -21.75870653-0.00343240j, var(E): 0.17353416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=0.26............. Loss: -0.08055809, mean(E): -21.76833000+0.00243607j, var(E): 0.06753946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=0.26............. Loss: -0.01158432, mean(E): -21.79482746-0.00844575j, var(E): 0.20056306
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=0.26............. Loss: -0.17717519, mean(E): -21.75572827-0.00807652j, var(E): 0.10890504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=0.26............. Loss: -0.32406736, mean(E): -21.73664311+0.00448819j, var(E): 0.17168591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=0.26............. Loss: 0.24352456, mean(E): -21.81334960-0.00507607j, var(E): 0.18058440
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=0.26............. Loss: -0.20306863, mean(E): -21.77067543+0.00669694j, var(E): 0.13322399
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=0.26............. Loss: 0.11584359, mean(E): -21.83797895+0.00063817j, var(E): 0.17736155
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=0.27............. Loss: -0.09301929, mean(E): -21.74353587-0.00813540j, var(E): 0.13162057
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=0.26............. Loss: -0.37160199, mean(E): -21.73889792-0.00177904j, var(E): 0.32683146
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=0.26............. Loss: -0.06004662, mean(E): -21.77777569-0.00517278j, var(E): 0.05481976
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=0.26............. Loss: 0.02879494, mean(E): -21.76624549-0.00305409j, var(E): 0.05655744
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=0.26............. Loss: -0.27190831, mean(E): -21.76310234-0.00792763j, var(E): 0.23635023
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=0.26............. Loss: -0.21862931, mean(E): -21.75808018+0.00359194j, var(E): 0.16564204
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=0.26............. Loss: -0.13179818, mean(E): -21.77666903+0.00132304j, var(E): 0.19653906
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=0.26............. Loss: -0.15320425, mean(E): -21.77606140-0.01026952j, var(E): 0.09394486
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=0.26............. Loss: -0.25892415, mean(E): -21.76193092-0.00375421j, var(E): 0.10224433
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=0.26............. Loss: 0.00540061, mean(E): -21.79372752+0.00430649j, var(E): 0.07556978
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=0.26............. Loss: 0.08877409, mean(E): -21.80989399-0.00220030j, var(E): 0.24800526
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=0.26............. Loss: 0.18370833, mean(E): -21.79553130-0.00109182j, var(E): 0.07126073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=0.26............. Loss: -0.24847128, mean(E): -21.74702402-0.00096910j, var(E): 0.19392038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=0.26............. Loss: 0.02865700, mean(E): -21.81840868-0.00257676j, var(E): 0.18164606
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=0.26............. Loss: -0.00605272, mean(E): -21.77957028-0.00713042j, var(E): 0.05767974
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=0.26............. Loss: 0.08567941, mean(E): -21.78433455-0.00674162j, var(E): 0.10498588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=0.26............. Loss: 0.09646922, mean(E): -21.80120972+0.00137990j, var(E): 0.06558477
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=0.26............. Loss: -0.16212251, mean(E): -21.77353117+0.00340233j, var(E): 0.13026685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=0.26............. Loss: -0.06263845, mean(E): -21.78745292+0.00043393j, var(E): 0.11485928
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=0.27............. Loss: 0.17059633, mean(E): -21.82025384-0.00055626j, var(E): 0.07434181
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=0.26............. Loss: -0.12024916, mean(E): -21.76713827+0.00026605j, var(E): 0.06717748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=0.26............. Loss: 0.04886267, mean(E): -21.80260066+0.00199594j, var(E): 0.06810296
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=0.27............. Loss: 0.14092857, mean(E): -21.79926489+0.00512137j, var(E): 0.06899720
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=0.26............. Loss: -0.16994954, mean(E): -21.77119594-0.00329421j, var(E): 0.20389472
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=0.26............. Loss: 0.07308744, mean(E): -21.79031904+0.00423578j, var(E): 0.15497412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=0.26............. Loss: 0.02548374, mean(E): -21.78667346-0.00428773j, var(E): 0.07619143
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=0.26............. Loss: 0.00409945, mean(E): -21.81346246-0.00453972j, var(E): 0.07739563
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=0.26............. Loss: -0.12069643, mean(E): -21.77300315-0.00829072j, var(E): 0.22034660
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=0.26............. Loss: 0.08484950, mean(E): -21.82603356+0.00735037j, var(E): 0.11087037
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=0.26............. Loss: -0.07537762, mean(E): -21.77174378+0.00467550j, var(E): 0.09787861
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=0.26............. Loss: -0.20572525, mean(E): -21.77372104+0.00739480j, var(E): 0.08482101
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=0.26............. Loss: -0.19324641, mean(E): -21.77070746-0.00396449j, var(E): 0.33563902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=0.26............. Loss: 0.12470802, mean(E): -21.80123436+0.00325786j, var(E): 0.14937948
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=0.26............. Loss: -0.17330353, mean(E): -21.78430368+0.00466608j, var(E): 0.25629473
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=0.26............. Loss: 0.24910788, mean(E): -21.84380396-0.00743481j, var(E): 0.24149402
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=0.26............. Loss: -0.08895459, mean(E): -21.78421324+0.00162675j, var(E): 0.13437849
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=0.26............. Loss: -0.22177979, mean(E): -21.77517095-0.00491165j, var(E): 0.10304635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=0.27............. Loss: 0.32524310, mean(E): -21.83909844-0.00322866j, var(E): 0.29627805
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=0.27............. Loss: -0.02923147, mean(E): -21.79438764-0.00800056j, var(E): 0.06862828
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=0.26............. Loss: -0.13043729, mean(E): -21.75384944+0.00172295j, var(E): 0.04869690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=0.26............. Loss: 0.00587437, mean(E): -21.76952500-0.00216839j, var(E): 0.13099046
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=0.26............. Loss: -0.14568318, mean(E): -21.78595810+0.01072947j, var(E): 0.08080667
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=0.27............. Loss: -0.17791999, mean(E): -21.73916421-0.00194463j, var(E): 0.11955239
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=0.26............. Loss: -0.02943090, mean(E): -21.75608606+0.00450522j, var(E): 0.10945522
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=0.27............. Loss: 0.05614419, mean(E): -21.80868022-0.00213639j, var(E): 0.05964381
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=0.26............. Loss: -0.00977271, mean(E): -21.79309049+0.00090225j, var(E): 0.08452042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=0.26............. Loss: -0.04974095, mean(E): -21.79492257+0.00167544j, var(E): 0.06038313
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=0.26............. Loss: -0.14961009, mean(E): -21.77098049-0.00505744j, var(E): 0.12663807
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=0.27............. Loss: -0.10027786, mean(E): -21.76034881+0.00256719j, var(E): 0.09588649
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=0.26............. Loss: 0.02005108, mean(E): -21.81365611-0.00067168j, var(E): 0.06324315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=0.26............. Loss: -0.16582309, mean(E): -21.75211890+0.00032977j, var(E): 0.08266023
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=0.26............. Loss: 0.15675778, mean(E): -21.82151664-0.00054341j, var(E): 0.08076834
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=0.26............. Loss: 0.07502522, mean(E): -21.80143271-0.00239061j, var(E): 0.03987743
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=0.26............. Loss: -0.03236802, mean(E): -21.80064410+0.00563876j, var(E): 0.05019260
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=0.26............. Loss: -0.17217540, mean(E): -21.76393538-0.00384608j, var(E): 0.07453377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=0.26............. Loss: 0.14769688, mean(E): -21.82005000+0.00334060j, var(E): 0.05746422
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=0.26............. Loss: -0.10152390, mean(E): -21.75881812+0.00187106j, var(E): 0.06837553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=0.26............. Loss: -0.14917064, mean(E): -21.77171113+0.00258277j, var(E): 0.07064605
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=0.26............. Loss: 0.01033638, mean(E): -21.78813255-0.00247350j, var(E): 0.06844478
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=0.26............. Loss: -0.12447151, mean(E): -21.76614195+0.00473905j, var(E): 0.08541581
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=0.26............. Loss: 0.04662794, mean(E): -21.81988734+0.00109929j, var(E): 0.14274315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=0.27............. Loss: -0.07411715, mean(E): -21.79060832+0.00264046j, var(E): 0.13624711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=0.26............. Loss: 0.37481207, mean(E): -21.84495097+0.00605238j, var(E): 0.37838414
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=0.26............. Loss: 0.09606401, mean(E): -21.81695315-0.00035891j, var(E): 0.06870419
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=0.26............. Loss: -0.03197389, mean(E): -21.79044271+0.00315704j, var(E): 0.07406927
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=0.26............. Loss: 0.11659955, mean(E): -21.81580651+0.00087198j, var(E): 0.07854780
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=0.26............. Loss: 0.00106035, mean(E): -21.79364405-0.00186617j, var(E): 0.02539353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=0.26............. Loss: 0.02990212, mean(E): -21.81660798-0.00096815j, var(E): 0.06399159
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=0.27............. Loss: 0.04349250, mean(E): -21.79642106-0.00376479j, var(E): 0.02457865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=0.26............. Loss: 0.02338728, mean(E): -21.79797638-0.00823650j, var(E): 0.09029868
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=0.26............. Loss: 0.09977379, mean(E): -21.82054820+0.00397507j, var(E): 0.10088929
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=0.26............. Loss: -0.17530773, mean(E): -21.75857702-0.00528239j, var(E): 0.07238695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=0.26............. Loss: -0.08386661, mean(E): -21.76658675-0.00238139j, var(E): 0.07437065
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=0.26............. Loss: 0.29188338, mean(E): -21.81983823-0.00339120j, var(E): 0.12516814
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=0.26............. Loss: 0.01508658, mean(E): -21.79239374-0.00277724j, var(E): 0.07976354
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=0.26............. Loss: -0.05485061, mean(E): -21.79165647+0.00109014j, var(E): 0.05188486
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=0.26............. Loss: 0.28069587, mean(E): -21.83149811-0.00215265j, var(E): 0.11774519
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=0.26............. Loss: -0.07235145, mean(E): -21.78389912+0.00439404j, var(E): 0.07793004
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=0.26............. Loss: -0.09802526, mean(E): -21.78515002+0.00315137j, var(E): 0.07855964
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=0.26............. Loss: 0.10775767, mean(E): -21.81620758+0.00196649j, var(E): 0.15584615
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=0.26............. Loss: -0.00927494, mean(E): -21.80200952-0.00081694j, var(E): 0.02563106
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=0.26............. Loss: -0.58149763, mean(E): -21.73152709+0.00148438j, var(E): 0.43314320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=0.26............. Loss: 0.23134400, mean(E): -21.81290773-0.00098298j, var(E): 0.05119876
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=0.26............. Loss: -0.46545019, mean(E): -21.73194134-0.00307495j, var(E): 0.25892972
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=0.26............. Loss: -0.01010152, mean(E): -21.77986237+0.00510345j, var(E): 0.05234037
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=0.26............. Loss: -0.06005707, mean(E): -21.77488066+0.00017800j, var(E): 0.04930201
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=0.26............. Loss: 0.17425621, mean(E): -21.83923232-0.00203405j, var(E): 0.17052078
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=0.26............. Loss: -0.05829374, mean(E): -21.77429670-0.00196896j, var(E): 0.10029709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=0.26............. Loss: -0.16608862, mean(E): -21.76497356-0.00511766j, var(E): 0.34440318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=0.26............. Loss: -0.06191001, mean(E): -21.76811932-0.00039893j, var(E): 0.05604200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=0.26............. Loss: -0.17921547, mean(E): -21.77839458+0.00679858j, var(E): 0.33173763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=0.26............. Loss: 0.00505641, mean(E): -21.80344502+0.00118897j, var(E): 0.02844313
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=0.26............. Loss: 0.10062811, mean(E): -21.80475254-0.00277666j, var(E): 0.08042893
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=0.26............. Loss: -0.30123490, mean(E): -21.74890996+0.00483341j, var(E): 0.11392276
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=0.26............. Loss: 0.12224757, mean(E): -21.78376655-0.00420684j, var(E): 0.09454919
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=0.26............. Loss: -0.07745813, mean(E): -21.78097266-0.00415014j, var(E): 0.08544768
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=0.27............. Loss: -0.18738694, mean(E): -21.75527515-0.00063697j, var(E): 0.06222426
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=0.26............. Loss: -0.20071565, mean(E): -21.75836397-0.00404326j, var(E): 0.07909769
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=0.26............. Loss: 0.07148446, mean(E): -21.79631420+0.00420633j, var(E): 0.06729911
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=0.27............. Loss: -0.00150854, mean(E): -21.78768846-0.01056425j, var(E): 0.07819088
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=0.27............. Loss: 0.18028713, mean(E): -21.81211795+0.00300891j, var(E): 0.06076785
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=0.26............. Loss: -0.06078545, mean(E): -21.79328248+0.00255107j, var(E): 0.05129110
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=0.26............. Loss: -0.31164459, mean(E): -21.73387409+0.00114603j, var(E): 0.10628760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=0.26............. Loss: 0.07091564, mean(E): -21.75863661-0.00458467j, var(E): 0.12939882
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=0.26............. Loss: -0.09640312, mean(E): -21.75781667-0.00126444j, var(E): 0.08483080
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=0.26............. Loss: 0.25540427, mean(E): -21.80603829+0.00186238j, var(E): 0.30316069
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=0.29............. Loss: 0.19524554, mean(E): -21.81412126+0.00449106j, var(E): 0.08322099
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=0.26............. Loss: 0.41680724, mean(E): -21.83089789+0.00022442j, var(E): 0.25794865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=0.26............. Loss: 0.04158091, mean(E): -21.81814160-0.00399621j, var(E): 0.09624307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=0.26............. Loss: -0.01100510, mean(E): -21.78304320+0.00460864j, var(E): 0.11960737
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=0.26............. Loss: 0.03005746, mean(E): -21.77595569-0.00231001j, var(E): 0.06431648
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=0.26............. Loss: 0.23818955, mean(E): -21.82786343-0.00581550j, var(E): 0.06624001
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=0.26............. Loss: 0.00727380, mean(E): -21.81249041-0.00111424j, var(E): 0.08045484
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=0.26............. Loss: -0.03652335, mean(E): -21.78196561+0.00107195j, var(E): 0.13472875
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=0.26............. Loss: -0.07394544, mean(E): -21.78810147-0.00830437j, var(E): 0.04474892
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=0.27............. Loss: 0.05526517, mean(E): -21.79896272-0.00271985j, var(E): 0.03445130
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=0.26............. Loss: -0.04867418, mean(E): -21.78772607-0.00593360j, var(E): 0.02894553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=0.27............. Loss: 0.19573057, mean(E): -21.82688240+0.00228869j, var(E): 0.27653191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=0.27............. Loss: -0.17983622, mean(E): -21.75743232-0.00154954j, var(E): 0.11954325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=0.26............. Loss: -0.02103088, mean(E): -21.80379302+0.00620320j, var(E): 0.05457652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=0.26............. Loss: -0.13526784, mean(E): -21.77561734-0.00409972j, var(E): 0.12557809
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=0.27............. Loss: 0.07550684, mean(E): -21.79681966-0.00230603j, var(E): 0.11809214
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=0.26............. Loss: -0.04432684, mean(E): -21.79020569+0.00603043j, var(E): 0.06165438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=0.26............. Loss: -0.12116667, mean(E): -21.78141877-0.00478638j, var(E): 0.29629962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=0.27............. Loss: 0.19891105, mean(E): -21.82342899-0.00656326j, var(E): 0.09426536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=0.27............. Loss: -0.22982135, mean(E): -21.78186327+0.00276260j, var(E): 0.11567039
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=0.26............. Loss: -0.16607060, mean(E): -21.77661379+0.00255712j, var(E): 0.09595394
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=0.27............. Loss: 0.35968964, mean(E): -21.84473533-0.00147733j, var(E): 0.21880029
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=0.27............. Loss: 0.25858704, mean(E): -21.82996043-0.00060437j, var(E): 0.25967844
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=0.26............. Loss: -0.16049068, mean(E): -21.78119614-0.00483318j, var(E): 0.14141060
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=0.26............. Loss: 0.13712234, mean(E): -21.80397699-0.00022506j, var(E): 0.03332570
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=0.26............. Loss: 0.06205928, mean(E): -21.79164276-0.00161653j, var(E): 0.07620690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=0.26............. Loss: 0.11599949, mean(E): -21.83351113-0.00066413j, var(E): 0.04174253
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=0.26............. Loss: 0.10800743, mean(E): -21.80029449+0.00152035j, var(E): 0.05174678
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=0.26............. Loss: -0.10590917, mean(E): -21.79422796-0.00140510j, var(E): 0.05472594
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=0.26............. Loss: -0.33634997, mean(E): -21.75555856+0.00211024j, var(E): 0.13489067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=0.26............. Loss: -0.13690816, mean(E): -21.77283945+0.00194148j, var(E): 0.05781843
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=0.27............. Loss: 0.41371431, mean(E): -21.84538224-0.00143964j, var(E): 0.17594904
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=0.27............. Loss: 0.01257267, mean(E): -21.79776567-0.00344270j, var(E): 0.06367308
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=0.26............. Loss: -0.13159124, mean(E): -21.78849524+0.00809935j, var(E): 0.07498945
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=0.26............. Loss: 0.04422010, mean(E): -21.79113869-0.00386624j, var(E): 0.09826757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=0.26............. Loss: 0.19899081, mean(E): -21.81347303-0.00188002j, var(E): 0.13535908
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=0.26............. Loss: 0.46746598, mean(E): -21.85989911+0.00143133j, var(E): 0.16183781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=0.26............. Loss: 0.02908584, mean(E): -21.80531327+0.00465969j, var(E): 0.03386915
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=0.26............. Loss: -0.10400950, mean(E): -21.79189275-0.00104116j, var(E): 0.08569218
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=0.26............. Loss: 0.12578564, mean(E): -21.81290560-0.00342453j, var(E): 0.06236119
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=0.26............. Loss: 0.09957873, mean(E): -21.82147874-0.00430713j, var(E): 0.06254759
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=0.26............. Loss: -0.02863080, mean(E): -21.76686247+0.00533595j, var(E): 0.05535375
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=0.26............. Loss: -0.41416582, mean(E): -21.72691387+0.00208380j, var(E): 0.14503591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=0.26............. Loss: 0.09979545, mean(E): -21.81121747+0.00345337j, var(E): 0.05573528
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=0.26............. Loss: 0.23150211, mean(E): -21.84866897+0.00580290j, var(E): 0.07669815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=0.26............. Loss: 0.25380276, mean(E): -21.84255842-0.00280267j, var(E): 0.15415214
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=0.26............. Loss: -0.14747202, mean(E): -21.76162236-0.00727896j, var(E): 0.14119299
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=0.26............. Loss: -0.16011729, mean(E): -21.78130132-0.00250451j, var(E): 0.50328961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=0.26............. Loss: 0.01144265, mean(E): -21.78447367-0.00105545j, var(E): 0.14284426
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=0.26............. Loss: 0.00706655, mean(E): -21.78941367+0.00291338j, var(E): 0.03102725
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=0.29............. Loss: 0.00389223, mean(E): -21.77414293+0.00325252j, var(E): 0.02148815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=0.27............. Loss: 0.04824043, mean(E): -21.80086632+0.00254266j, var(E): 0.03327518
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=0.26............. Loss: -0.22969804, mean(E): -21.75891369-0.00093826j, var(E): 0.05069000
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=0.26............. Loss: 0.09809805, mean(E): -21.79720045-0.00030715j, var(E): 0.06605845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=0.26............. Loss: -0.16912940, mean(E): -21.77586593-0.00014200j, var(E): 0.09807809
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=0.26............. Loss: 0.16869433, mean(E): -21.82066423-0.00052704j, var(E): 0.13909851
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=0.26............. Loss: -0.12698800, mean(E): -21.78681645+0.00202969j, var(E): 0.14372039
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=0.26............. Loss: -0.07132153, mean(E): -21.77306820-0.00468104j, var(E): 0.08074994
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=0.26............. Loss: -0.02469794, mean(E): -21.77829616+0.00019235j, var(E): 0.09211800
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=0.26............. Loss: -0.05834049, mean(E): -21.78357374-0.00489217j, var(E): 0.05548976
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=0.26............. Loss: -0.12755401, mean(E): -21.77392615-0.00156814j, var(E): 0.20542153
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=0.26............. Loss: -0.05421432, mean(E): -21.78816914-0.00116729j, var(E): 0.05163567
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=0.26............. Loss: 0.05117625, mean(E): -21.81909427-0.00248293j, var(E): 0.03776960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=0.26............. Loss: -0.06063265, mean(E): -21.79065347-0.00208756j, var(E): 0.08568977
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=0.26............. Loss: 0.00378180, mean(E): -21.79255615+0.00191995j, var(E): 0.04850117
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=0.26............. Loss: 0.21689481, mean(E): -21.81464466-0.00172260j, var(E): 0.09579775
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=0.26............. Loss: -0.10186294, mean(E): -21.77529157-0.00706899j, var(E): 0.09929620
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=0.26............. Loss: -0.16167678, mean(E): -21.76142894+0.00419867j, var(E): 0.07837962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=0.26............. Loss: -0.05906806, mean(E): -21.78220793+0.00030602j, var(E): 0.05526730
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=0.27............. Loss: -0.03662116, mean(E): -21.79573715-0.00042116j, var(E): 0.08055189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=0.26............. Loss: 0.16895732, mean(E): -21.80215121+0.00438364j, var(E): 0.13247817
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=0.26............. Loss: 0.17734160, mean(E): -21.82975107+0.00301070j, var(E): 0.09532995
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=0.26............. Loss: -0.25266315, mean(E): -21.75315163-0.00036682j, var(E): 0.08715282
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=0.27............. Loss: -0.04401365, mean(E): -21.78811329+0.00020048j, var(E): 0.10441045
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=0.29............. Loss: -0.00753489, mean(E): -21.78699869+0.00666244j, var(E): 0.04334964
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=0.27............. Loss: -0.00796326, mean(E): -21.81083592-0.00259237j, var(E): 0.09398318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=0.26............. Loss: 0.24850790, mean(E): -21.84666647-0.00143158j, var(E): 0.10304224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=0.26............. Loss: -0.09570083, mean(E): -21.76993213-0.00332609j, var(E): 0.09679939
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=0.27............. Loss: -0.08250076, mean(E): -21.77101880-0.00323090j, var(E): 0.06917034
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=0.27............. Loss: 0.06240521, mean(E): -21.79193455+0.00007523j, var(E): 0.07083775
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=0.26............. Loss: -0.04948864, mean(E): -21.79446194+0.00007724j, var(E): 0.05020439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=0.27............. Loss: -0.13136748, mean(E): -21.76463278+0.00054247j, var(E): 0.09944160
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=0.27............. Loss: 0.41511524, mean(E): -21.84142788-0.00375713j, var(E): 0.17889955
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=0.27............. Loss: 0.16962339, mean(E): -21.82361082-0.00303366j, var(E): 0.06250679
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=0.27............. Loss: 0.08465235, mean(E): -21.80843018+0.00017931j, var(E): 0.03101907
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=0.26............. Loss: -0.16918774, mean(E): -21.77489585-0.00202139j, var(E): 0.06544204
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=0.26............. Loss: -0.11162171, mean(E): -21.76884892+0.00163880j, var(E): 0.07359801
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=0.27............. Loss: -0.14207990, mean(E): -21.77905603-0.00036188j, var(E): 0.07758108
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(23.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=0.27............. Loss: -0.00866471, mean(E): -21.79193419-0.00573641j, var(E): 0.08526527
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=0.26............. Loss: 0.08165677, mean(E): -21.80841516-0.00443678j, var(E): 0.04285455
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=0.26............. Loss: -0.09107819, mean(E): -21.77212454-0.00274242j, var(E): 0.08418554
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=0.27............. Loss: 0.04715101, mean(E): -21.79932142-0.00173780j, var(E): 0.03160285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=0.26............. Loss: -0.11467076, mean(E): -21.77303077-0.00051363j, var(E): 0.04284574
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=0.26............. Loss: 0.10073346, mean(E): -21.80170501+0.00295693j, var(E): 0.04731328
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=0.26............. Loss: -0.18641445, mean(E): -21.78369580+0.00085554j, var(E): 0.20816543
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=0.26............. Loss: -0.00372641, mean(E): -21.79709681+0.00119086j, var(E): 0.01866886
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=0.26............. Loss: 0.03083346, mean(E): -21.79386709+0.00026022j, var(E): 0.04779183
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=0.26............. Loss: 0.16860793, mean(E): -21.82495322-0.00593006j, var(E): 0.09116671
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=0.26............. Loss: -0.00719795, mean(E): -21.78910013-0.00051055j, var(E): 0.04973634
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=0.27............. Loss: -0.06703242, mean(E): -21.78509718-0.00010997j, var(E): 0.05726644
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=0.26............. Loss: -0.14799055, mean(E): -21.78036165+0.00105276j, var(E): 0.06331018
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=0.26............. Loss: 0.07175510, mean(E): -21.81398646+0.00149655j, var(E): 0.03458431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=0.27............. Loss: -0.07812808, mean(E): -21.76557218+0.00006138j, var(E): 0.03358111
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=0.26............. Loss: 0.42929271, mean(E): -21.82974684+0.00233408j, var(E): 0.49621377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=0.26............. Loss: -0.01498661, mean(E): -21.79524662+0.00123207j, var(E): 0.02755082
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=0.27............. Loss: -0.06922903, mean(E): -21.77905091-0.00154582j, var(E): 0.05135036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=0.26............. Loss: 0.09130152, mean(E): -21.81084572+0.00149250j, var(E): 0.05768889
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=0.27............. Loss: -0.00173848, mean(E): -21.79361539+0.00536850j, var(E): 0.01922626
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=0.26............. Loss: -0.22691301, mean(E): -21.75205789+0.00061454j, var(E): 0.15374779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=0.26............. Loss: -0.03398266, mean(E): -21.78312058-0.00157792j, var(E): 0.06426126
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=0.26............. Loss: -0.23755312, mean(E): -21.77442589+0.00086067j, var(E): 0.12072040
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=0.26............. Loss: 0.03695852, mean(E): -21.80007015-0.00497881j, var(E): 0.04899281
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=0.26............. Loss: -0.02656207, mean(E): -21.77700377+0.00539276j, var(E): 0.03953734
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=0.26............. Loss: -0.05707273, mean(E): -21.77931445+0.00207368j, var(E): 0.04355711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=0.26............. Loss: -0.02843423, mean(E): -21.78761336+0.00156713j, var(E): 0.05414632
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=0.26............. Loss: -0.02782750, mean(E): -21.79412295+0.00367330j, var(E): 0.06651586
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=0.26............. Loss: -0.09455799, mean(E): -21.78618187-0.00477679j, var(E): 0.03749267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=0.26............. Loss: 0.10077593, mean(E): -21.82261505-0.00372211j, var(E): 0.05474670
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=0.26............. Loss: 0.22304658, mean(E): -21.81496459-0.00004332j, var(E): 0.41548502
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=0.26............. Loss: -0.10170990, mean(E): -21.77981861-0.00363824j, var(E): 0.16498534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=0.26............. Loss: 0.02595074, mean(E): -21.79117892-0.00320411j, var(E): 0.05179147
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=0.26............. Loss: -0.18941369, mean(E): -21.76689277+0.00007518j, var(E): 0.05120650
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=0.26............. Loss: -0.24755312, mean(E): -21.75807320-0.00033237j, var(E): 0.14878073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=0.26............. Loss: -0.02656709, mean(E): -21.79580248+0.00059629j, var(E): 0.04522837
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=0.26............. Loss: 0.07691816, mean(E): -21.80459080+0.00368096j, var(E): 0.04894172
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=0.26............. Loss: 0.10883453, mean(E): -21.81557664+0.00361940j, var(E): 0.09256070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=0.27............. Loss: -0.15560378, mean(E): -21.77891279-0.00499086j, var(E): 0.09940732
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=0.26............. Loss: 0.18277172, mean(E): -21.82481462+0.00157692j, var(E): 0.11344313
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=0.26............. Loss: 0.11457670, mean(E): -21.81071310-0.00351076j, var(E): 0.03325681
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=0.26............. Loss: 0.22397155, mean(E): -21.81994115-0.00538640j, var(E): 0.12731482
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=0.26............. Loss: -0.07132505, mean(E): -21.79840569-0.00193583j, var(E): 0.06283422
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=0.26............. Loss: -0.01058467, mean(E): -21.79416325+0.00310914j, var(E): 0.02557063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=0.26............. Loss: -0.04027824, mean(E): -21.78166582+0.00027101j, var(E): 0.06373246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=0.26............. Loss: 0.17457375, mean(E): -21.82056585-0.00438815j, var(E): 0.07735274
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=0.26............. Loss: -0.03131860, mean(E): -21.79382854+0.00006264j, var(E): 0.04041081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=0.26............. Loss: -0.01726312, mean(E): -21.79563131-0.00684344j, var(E): 0.02864648
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=0.26............. Loss: 0.11152719, mean(E): -21.80364454-0.00488095j, var(E): 0.05508731
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=0.26............. Loss: -0.12426263, mean(E): -21.77368646+0.00236671j, var(E): 0.06126211
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=0.26............. Loss: -0.03870613, mean(E): -21.79759485+0.00124512j, var(E): 0.12556949
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=0.26............. Loss: 0.02393280, mean(E): -21.79654401+0.00018750j, var(E): 0.03776197
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=0.26............. Loss: 0.02594935, mean(E): -21.79589549+0.00023359j, var(E): 0.01779644
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=0.26............. Loss: 0.15298195, mean(E): -21.82277769+0.00185798j, var(E): 0.04885743
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=0.26............. Loss: 0.06093418, mean(E): -21.80474523-0.00118434j, var(E): 0.06342639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=0.26............. Loss: -0.02645313, mean(E): -21.77580182-0.00203573j, var(E): 0.04846315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=0.26............. Loss: 0.58020603, mean(E): -21.85756317+0.00259378j, var(E): 0.37848007
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=0.27............. Loss: 0.23556092, mean(E): -21.82089540-0.00800279j, var(E): 0.28168348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=0.27............. Loss: -0.46991851, mean(E): -21.74552638-0.00152627j, var(E): 0.26898864
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=0.26............. Loss: 0.04968692, mean(E): -21.79267223-0.00038024j, var(E): 0.02168762
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=0.26............. Loss: 0.11216380, mean(E): -21.80961242-0.00644037j, var(E): 0.09569467
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=0.26............. Loss: 0.03818150, mean(E): -21.80011617+0.00384157j, var(E): 0.02684174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=0.26............. Loss: 0.06780589, mean(E): -21.80133274+0.00442004j, var(E): 0.04975769
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=0.26............. Loss: 0.01617985, mean(E): -21.80403859+0.00308365j, var(E): 0.09104157
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=0.26............. Loss: 0.01455293, mean(E): -21.80076567+0.00549391j, var(E): 0.03946735
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=0.26............. Loss: -0.17286056, mean(E): -21.76231886+0.00230580j, var(E): 0.07360307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=0.27............. Loss: 0.02108894, mean(E): -21.79685538-0.00018351j, var(E): 0.14605217
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=0.27............. Loss: 0.17025519, mean(E): -21.81231491+0.00057504j, var(E): 0.09134725
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=0.26............. Loss: 0.16887255, mean(E): -21.83095301-0.00008012j, var(E): 0.09852605
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=0.26............. Loss: 0.07877019, mean(E): -21.78654053-0.00263891j, var(E): 0.04443425
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=0.26............. Loss: 0.09071070, mean(E): -21.80308040+0.00107348j, var(E): 0.04006163
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=0.26............. Loss: 0.05875810, mean(E): -21.79984905-0.00536875j, var(E): 0.04757353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=0.26............. Loss: -0.00635519, mean(E): -21.79168170-0.00038414j, var(E): 0.07639074
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=0.26............. Loss: -0.05228074, mean(E): -21.79693546+0.00086524j, var(E): 0.02418907
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=0.26............. Loss: -0.09532801, mean(E): -21.79239810-0.00489176j, var(E): 0.04637359
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=0.26............. Loss: -0.02646217, mean(E): -21.79682617-0.00385653j, var(E): 0.04372942
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=0.27............. Loss: 0.08028246, mean(E): -21.78486279+0.00081153j, var(E): 0.05837566
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=0.26............. Loss: -0.00373932, mean(E): -21.79279564+0.00044734j, var(E): 0.07970103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=0.26............. Loss: -0.08804600, mean(E): -21.78142399-0.00202376j, var(E): 0.09713143
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=0.26............. Loss: -0.10966419, mean(E): -21.77635048+0.00023889j, var(E): 0.18189100
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=0.26............. Loss: -0.10191338, mean(E): -21.78890597+0.00063361j, var(E): 0.03858232
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=0.26............. Loss: 0.08221248, mean(E): -21.80265282-0.00186499j, var(E): 0.05831414
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=0.26............. Loss: -0.06278277, mean(E): -21.79380186+0.00173331j, var(E): 0.09656315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=0.26............. Loss: 0.11066100, mean(E): -21.85148795-0.00052690j, var(E): 0.06105718
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=0.26............. Loss: -0.14270000, mean(E): -21.76940548+0.00211968j, var(E): 0.06668364
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=0.26............. Loss: -0.05797507, mean(E): -21.77475430+0.00148363j, var(E): 0.06510749
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=0.26............. Loss: 0.03165120, mean(E): -21.81244957+0.00565136j, var(E): 0.01508938
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=0.26............. Loss: -0.15753035, mean(E): -21.77673148+0.00010781j, var(E): 0.09711833
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=0.27............. Loss: 0.11586707, mean(E): -21.81608669+0.00220250j, var(E): 0.08113844
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=0.26............. Loss: 0.05750211, mean(E): -21.82699127+0.00008083j, var(E): 0.06204923
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=0.27............. Loss: 0.03275749, mean(E): -21.82279752+0.00060445j, var(E): 0.06975987
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=0.27............. Loss: -0.02352917, mean(E): -21.80722748+0.00065302j, var(E): 0.01812989
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=0.26............. Loss: 0.11921522, mean(E): -21.81468944+0.00222647j, var(E): 0.10138998
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=0.26............. Loss: 0.07690170, mean(E): -21.81491467+0.00146463j, var(E): 0.03160831
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=0.26............. Loss: -0.00859589, mean(E): -21.80892693+0.00302709j, var(E): 0.02614645
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=0.26............. Loss: -0.09469049, mean(E): -21.78770927+0.00066903j, var(E): 0.04757820
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=0.26............. Loss: -0.10155756, mean(E): -21.79024251+0.00046336j, var(E): 0.04230965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=0.26............. Loss: -0.05398376, mean(E): -21.77805306-0.00087274j, var(E): 0.11425996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=0.27............. Loss: -0.33128128, mean(E): -21.75273567+0.00423508j, var(E): 0.15730421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=0.26............. Loss: -0.06273904, mean(E): -21.77512193-0.00045469j, var(E): 0.13642670
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=0.26............. Loss: 0.06910299, mean(E): -21.81248011-0.00043727j, var(E): 0.02137215
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=0.26............. Loss: -0.22765798, mean(E): -21.77420517+0.00189811j, var(E): 0.14736424
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=0.26............. Loss: -0.00567661, mean(E): -21.78419465+0.00116122j, var(E): 0.09864340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=0.26............. Loss: -0.01604066, mean(E): -21.78900161+0.00028097j, var(E): 0.12040638
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=0.26............. Loss: 0.00529020, mean(E): -21.79175258+0.00017817j, var(E): 0.02518266
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=0.27............. Loss: -0.07758556, mean(E): -21.78376345+0.00270587j, var(E): 0.05092614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=0.27............. Loss: -0.08320516, mean(E): -21.76507910+0.00265966j, var(E): 0.05076321
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=0.27............. Loss: -0.01911200, mean(E): -21.79125620+0.00464290j, var(E): 0.06991928
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=0.27............. Loss: -0.04793548, mean(E): -21.78643107+0.00419774j, var(E): 0.04877617
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=0.27............. Loss: -0.16988627, mean(E): -21.79843657-0.00196271j, var(E): 0.09526431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=0.26............. Loss: 0.18154645, mean(E): -21.81005904-0.00016809j, var(E): 0.08303704
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=0.26............. Loss: 0.10874351, mean(E): -21.81110827-0.00024286j, var(E): 0.06440199
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=0.27............. Loss: 0.12449612, mean(E): -21.81400885+0.00001806j, var(E): 0.07612246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=0.26............. Loss: -0.00573184, mean(E): -21.78917186-0.00171140j, var(E): 0.03923148
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=0.27............. Loss: -0.10328122, mean(E): -21.77465028+0.00248793j, var(E): 0.03354124
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=0.26............. Loss: 0.13059370, mean(E): -21.81164033+0.00556692j, var(E): 0.06695708
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=0.26............. Loss: 0.05404103, mean(E): -21.78525404-0.00173837j, var(E): 0.05355355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=0.27............. Loss: 0.09693482, mean(E): -21.81312364+0.00142409j, var(E): 0.02135420
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=0.27............. Loss: 0.18720116, mean(E): -21.80928707+0.00063421j, var(E): 0.17833489
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=0.26............. Loss: -0.09152923, mean(E): -21.76634376-0.00052624j, var(E): 0.05379161
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=0.27............. Loss: -0.13078010, mean(E): -21.78128668+0.00196350j, var(E): 0.11571043
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=0.26............. Loss: 0.08673608, mean(E): -21.81210310+0.00464026j, var(E): 0.06965203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=0.27............. Loss: -0.11529880, mean(E): -21.79637840+0.00340730j, var(E): 0.23626447
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=0.26............. Loss: -0.34334951, mean(E): -21.75025568+0.00257856j, var(E): 0.08287622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=0.27............. Loss: 0.02991763, mean(E): -21.79329058+0.00006305j, var(E): 0.01570545
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=0.27............. Loss: 0.00001642, mean(E): -21.79369238-0.00585910j, var(E): 0.11736661
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=0.26............. Loss: -0.06882260, mean(E): -21.76934219-0.00013603j, var(E): 0.07642038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=0.26............. Loss: -0.03353053, mean(E): -21.78614016-0.00302025j, var(E): 0.04821934
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=0.26............. Loss: 0.25327314, mean(E): -21.82723766-0.00093002j, var(E): 0.14906728
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=0.26............. Loss: 0.01846339, mean(E): -21.80740108-0.00208644j, var(E): 0.03309571
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=0.27............. Loss: -0.01061145, mean(E): -21.78947534-0.00108583j, var(E): 0.04094358
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=0.26............. Loss: 0.10052094, mean(E): -21.81085866-0.00302952j, var(E): 0.06389043
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=0.27............. Loss: -0.12037836, mean(E): -21.78338582-0.00166824j, var(E): 0.05846965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=0.27............. Loss: 0.12389605, mean(E): -21.80201503+0.00054684j, var(E): 0.03230787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=0.27............. Loss: 0.57243138, mean(E): -21.87940892+0.00175775j, var(E): 0.30256865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=0.27............. Loss: 0.13162013, mean(E): -21.82391897+0.00110927j, var(E): 0.04505434
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=0.26............. Loss: -0.08530686, mean(E): -21.79363497-0.00059767j, var(E): 0.07374507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=0.27............. Loss: -0.36831015, mean(E): -21.76136279+0.00436241j, var(E): 0.22816540
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=0.26............. Loss: -0.15050812, mean(E): -21.77849566-0.00037835j, var(E): 0.11330033
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=0.27............. Loss: -0.08595480, mean(E): -21.77140652+0.00175949j, var(E): 0.05450118
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=0.27............. Loss: -0.20395103, mean(E): -21.76556400-0.00376978j, var(E): 0.10738024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=0.26............. Loss: -0.00560238, mean(E): -21.79249294+0.00392994j, var(E): 0.02306543
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=0.27............. Loss: 0.13685852, mean(E): -21.81807174+0.00192399j, var(E): 0.05379491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=0.27............. Loss: 0.01835118, mean(E): -21.79939217-0.00104313j, var(E): 0.08651226
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=0.27............. Loss: -0.16731923, mean(E): -21.76518934+0.00177742j, var(E): 0.05059965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=0.26............. Loss: -0.09185634, mean(E): -21.77808029-0.00182661j, var(E): 0.03279189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=0.27............. Loss: -0.13452641, mean(E): -21.77033940+0.00212818j, var(E): 0.05065672
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=0.27............. Loss: 0.02400938, mean(E): -21.80285524+0.00452619j, var(E): 0.06001537
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=0.27............. Loss: 0.10588147, mean(E): -21.80213846+0.00100950j, var(E): 0.03207293
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=0.27............. Loss: 0.32135679, mean(E): -21.82593598-0.00202332j, var(E): 0.33299032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=0.27............. Loss: 0.02732277, mean(E): -21.79943309+0.00141395j, var(E): 0.04798143
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=0.27............. Loss: 0.05414168, mean(E): -21.80010881+0.00243653j, var(E): 0.02661743
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=0.27............. Loss: 0.12638647, mean(E): -21.80561808+0.00056959j, var(E): 0.13303358
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=0.27............. Loss: -0.01542697, mean(E): -21.79416806+0.00085171j, var(E): 0.03397620
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=0.27............. Loss: 0.09240985, mean(E): -21.80399704-0.00148440j, var(E): 0.03523042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=0.27............. Loss: 0.10084594, mean(E): -21.81842155-0.00199743j, var(E): 0.05125357
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=0.27............. Loss: -0.03718271, mean(E): -21.78330703+0.00083973j, var(E): 0.08325368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=0.27............. Loss: -0.01450298, mean(E): -21.78596041+0.00439914j, var(E): 0.05480649
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=0.27............. Loss: 0.05961162, mean(E): -21.80888199+0.00571481j, var(E): 0.03007014
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=0.27............. Loss: -0.01298330, mean(E): -21.78153680-0.00102320j, var(E): 0.02740791
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=0.27............. Loss: -0.10822425, mean(E): -21.78155968+0.00473920j, var(E): 0.05052859
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=0.27............. Loss: -0.08110525, mean(E): -21.79179530+0.00036121j, var(E): 0.02676905
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=0.27............. Loss: -0.17139254, mean(E): -21.78523803+0.00327061j, var(E): 0.09487885
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=0.27............. Loss: 0.15200134, mean(E): -21.82028679-0.00338388j, var(E): 0.06825321
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=0.26............. Loss: -0.03139928, mean(E): -21.79091661+0.00056902j, var(E): 0.02817588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=0.26............. Loss: 0.24641221, mean(E): -21.83881970-0.00126521j, var(E): 0.10167399
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=0.26............. Loss: 0.12705041, mean(E): -21.81415985-0.00012762j, var(E): 0.06214377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=0.27............. Loss: 0.01067300, mean(E): -21.79272617+0.00223392j, var(E): 0.10273205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=0.26............. Loss: -0.17994792, mean(E): -21.75928167-0.00010951j, var(E): 0.08856599
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=0.26............. Loss: -0.05429397, mean(E): -21.80612008+0.00080973j, var(E): 0.03947548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=0.27............. Loss: -0.01356946, mean(E): -21.79162628-0.00036297j, var(E): 0.05303158
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=0.27............. Loss: 0.10020215, mean(E): -21.80766293+0.00604873j, var(E): 0.05319326
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=0.26............. Loss: 0.14581815, mean(E): -21.83035747-0.00147908j, var(E): 0.08452508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=0.26............. Loss: 0.01408391, mean(E): -21.81565053+0.00062085j, var(E): 0.02250887
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=0.27............. Loss: 0.11895236, mean(E): -21.81390108+0.00202652j, var(E): 0.03736681
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=0.26............. Loss: -0.18254063, mean(E): -21.77121072-0.00110677j, var(E): 0.05895036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=0.27............. Loss: 0.25993192, mean(E): -21.81216070+0.00078827j, var(E): 0.33668936
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=0.27............. Loss: 0.01571843, mean(E): -21.80285108-0.00046781j, var(E): 0.07774672
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=0.26............. Loss: 0.04196137, mean(E): -21.80653608+0.00254238j, var(E): 0.05328611
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=0.26............. Loss: -0.20269917, mean(E): -21.75378710+0.00236603j, var(E): 0.37959830
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=0.27............. Loss: -0.12337582, mean(E): -21.78806281+0.00240130j, var(E): 0.08421237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=0.27............. Loss: 0.03334714, mean(E): -21.80249842+0.00051452j, var(E): 0.11044150
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=0.26............. Loss: -0.04178507, mean(E): -21.79106576-0.00059379j, var(E): 0.05699922
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=0.27............. Loss: -0.01438113, mean(E): -21.79019972-0.00094096j, var(E): 0.07015591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=0.26............. Loss: 0.17593942, mean(E): -21.82766576+0.00046517j, var(E): 0.11681851
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=0.26............. Loss: 0.25220805, mean(E): -21.82007085-0.00383703j, var(E): 0.06415259
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=0.27............. Loss: -0.08642987, mean(E): -21.78145771+0.00467133j, var(E): 0.03661937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=0.26............. Loss: 0.07807534, mean(E): -21.81032816+0.00112235j, var(E): 0.05099914
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=0.27............. Loss: 0.03811783, mean(E): -21.79058974+0.00228326j, var(E): 0.03254344
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=0.27............. Loss: 0.07179538, mean(E): -21.80479547-0.00248743j, var(E): 0.01980848
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=0.26............. Loss: 0.02689980, mean(E): -21.81186601+0.00085166j, var(E): 0.04113629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=0.26............. Loss: 0.30005670, mean(E): -21.83188870+0.00094409j, var(E): 0.12825189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=0.27............. Loss: -0.02455143, mean(E): -21.79450662+0.00035199j, var(E): 0.02365871
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=0.27............. Loss: 0.26823532, mean(E): -21.83645588-0.00238526j, var(E): 0.13962227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=0.27............. Loss: -0.25304046, mean(E): -21.77389347+0.00441271j, var(E): 0.06203720
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=0.26............. Loss: -0.07213335, mean(E): -21.79432999+0.00217637j, var(E): 0.12704114
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=0.26............. Loss: 0.08197041, mean(E): -21.82068000+0.00020735j, var(E): 0.04429635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=0.26............. Loss: -0.15813443, mean(E): -21.75568453-0.00279751j, var(E): 0.04022485
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=0.27............. Loss: 0.11588576, mean(E): -21.81320497+0.00167050j, var(E): 0.03468015
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=0.27............. Loss: 0.08335842, mean(E): -21.80307945+0.00627102j, var(E): 0.04573842
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=0.27............. Loss: -0.10226866, mean(E): -21.76842640+0.00414451j, var(E): 0.02373495
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=0.27............. Loss: 0.01123546, mean(E): -21.79629830+0.00218528j, var(E): 0.04028052
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=0.27............. Loss: 0.06569731, mean(E): -21.81047576-0.00044160j, var(E): 0.02664622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=0.26............. Loss: -0.13840793, mean(E): -21.77874604-0.00051227j, var(E): 0.06015541
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=0.27............. Loss: -0.05402753, mean(E): -21.77302356-0.00333142j, var(E): 0.02230530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=0.27............. Loss: -0.06765876, mean(E): -21.78332791-0.00415314j, var(E): 0.02888838
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=0.26............. Loss: 0.23201612, mean(E): -21.81339854+0.00046380j, var(E): 0.09073076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=0.27............. Loss: -0.11032998, mean(E): -21.78814124+0.00030315j, var(E): 0.07576035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=0.26............. Loss: -0.30903491, mean(E): -21.76757703-0.00084375j, var(E): 0.36096672
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=0.26............. Loss: 0.03933230, mean(E): -21.79612796-0.00209811j, var(E): 0.01997470
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=0.27............. Loss: 0.08524559, mean(E): -21.81123354-0.00014047j, var(E): 0.03204500
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=0.26............. Loss: 0.00686216, mean(E): -21.78870222-0.00165467j, var(E): 0.07271936
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=0.26............. Loss: -0.01639760, mean(E): -21.79621694+0.00001058j, var(E): 0.02454145
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=0.26............. Loss: -0.08087999, mean(E): -21.79257772-0.00092038j, var(E): 0.02835650
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=0.26............. Loss: -0.02730741, mean(E): -21.79125840+0.00073688j, var(E): 0.07827670
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=0.26............. Loss: 0.11692627, mean(E): -21.82764781-0.00133308j, var(E): 0.03202933
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=0.27............. Loss: 0.14248540, mean(E): -21.81158621+0.00052662j, var(E): 0.03579807
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=0.26............. Loss: -0.13897821, mean(E): -21.77409060-0.00049998j, var(E): 0.04544762
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=0.26............. Loss: 0.30193859, mean(E): -21.81227288-0.00357653j, var(E): 0.34412439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=0.27............. Loss: 0.02451418, mean(E): -21.80027007+0.00125845j, var(E): 0.01925230
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=0.27............. Loss: 0.28258799, mean(E): -21.84143645-0.00020216j, var(E): 0.07176801
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=0.27............. Loss: 0.01339399, mean(E): -21.80180309-0.00079641j, var(E): 0.02142097
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=0.27............. Loss: 0.04559878, mean(E): -21.80292194-0.00046177j, var(E): 0.02372601
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=0.26............. Loss: 0.19616455, mean(E): -21.82781077-0.00177315j, var(E): 0.10115593
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=0.26............. Loss: 0.01465951, mean(E): -21.79687702+0.00166577j, var(E): 0.05341688
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=0.27............. Loss: -0.23459747, mean(E): -21.75928710-0.00275528j, var(E): 0.05968661
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=0.27............. Loss: -0.42817932, mean(E): -21.75565188+0.00024490j, var(E): 0.23283528
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=0.26............. Loss: 0.17701792, mean(E): -21.82986434-0.00078488j, var(E): 0.08381751
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=0.26............. Loss: -0.34527183, mean(E): -21.77694346-0.00070677j, var(E): 0.18215493
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=0.26............. Loss: 0.05823225, mean(E): -21.79749117+0.00026133j, var(E): 0.03069221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=0.27............. Loss: -0.03977265, mean(E): -21.80276127-0.00180346j, var(E): 0.03717196
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=0.26............. Loss: 0.02299127, mean(E): -21.78630952+0.00186755j, var(E): 0.05697962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=0.26............. Loss: -0.17878047, mean(E): -21.76279076-0.00289325j, var(E): 0.05691808
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=0.27............. Loss: 0.00478368, mean(E): -21.79418726+0.00169400j, var(E): 0.04052679
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=0.27............. Loss: 0.15295648, mean(E): -21.81120747+0.00125605j, var(E): 0.03840627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=0.26............. Loss: -0.08554748, mean(E): -21.77873052-0.00009374j, var(E): 0.05559792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=0.27............. Loss: 0.01566559, mean(E): -21.80167416+0.00091791j, var(E): 0.02789927
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=0.26............. Loss: -0.00619018, mean(E): -21.78920073-0.00051894j, var(E): 0.04959431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=0.26............. Loss: -0.05615423, mean(E): -21.80412917+0.00020674j, var(E): 0.14258232
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=0.26............. Loss: -0.03971790, mean(E): -21.78468993-0.00231899j, var(E): 0.04560700
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=0.26............. Loss: -0.10008277, mean(E): -21.78580530+0.00000401j, var(E): 0.04712090
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=0.26............. Loss: -0.06987049, mean(E): -21.80677931-0.00141583j, var(E): 0.05217334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=0.27............. Loss: -0.08571692, mean(E): -21.79253790-0.00463483j, var(E): 0.03898946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=0.26............. Loss: -0.44700592, mean(E): -21.72054579-0.00069565j, var(E): 0.09981410
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=0.27............. Loss: -0.26539134, mean(E): -21.74783593+0.00036872j, var(E): 0.10109030
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=0.27............. Loss: -0.00430519, mean(E): -21.78918266+0.00045409j, var(E): 0.01534039
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=0.27............. Loss: -0.45734667, mean(E): -21.75354398+0.00022567j, var(E): 0.51622011
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=0.27............. Loss: 0.35603940, mean(E): -21.79331384+0.00033997j, var(E): 0.62753114
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=0.27............. Loss: 0.02607699, mean(E): -21.78772725+0.00007798j, var(E): 0.07929294
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=0.27............. Loss: 0.04206681, mean(E): -21.80372202-0.00077613j, var(E): 0.05134966
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=0.26............. Loss: 0.02741814, mean(E): -21.82653369-0.00009242j, var(E): 0.16174905
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=0.27............. Loss: -0.22083361, mean(E): -21.75336843-0.00193613j, var(E): 0.10698145
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=0.27............. Loss: 0.01360855, mean(E): -21.80291858+0.00286668j, var(E): 0.04793391
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=0.26............. Loss: -0.01938076, mean(E): -21.79879666-0.00029922j, var(E): 0.04548993
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=0.26............. Loss: 0.02148556, mean(E): -21.79436359-0.00102678j, var(E): 0.05749200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=0.26............. Loss: -0.01300421, mean(E): -21.79198102-0.00022281j, var(E): 0.04567100
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=0.26............. Loss: 0.01800344, mean(E): -21.78305487-0.00238665j, var(E): 0.04372032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=0.26............. Loss: 0.00556334, mean(E): -21.79403260-0.00210148j, var(E): 0.02462191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=0.27............. Loss: -0.02170283, mean(E): -21.78608401-0.00162176j, var(E): 0.04834237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=0.26............. Loss: 0.23484302, mean(E): -21.81542808+0.00035693j, var(E): 0.14107941
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=0.26............. Loss: -0.23057902, mean(E): -21.78199045-0.00286527j, var(E): 0.15333946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=0.26............. Loss: -0.04106816, mean(E): -21.77696065+0.00104939j, var(E): 0.06280690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=0.27............. Loss: 0.12664144, mean(E): -21.80390269+0.00015468j, var(E): 0.05640318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=0.26............. Loss: -0.05492413, mean(E): -21.78804747+0.00251834j, var(E): 0.05766964
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=0.26............. Loss: -0.06952702, mean(E): -21.78888359+0.00163296j, var(E): 0.04227158
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=0.27............. Loss: -0.03043168, mean(E): -21.80260943+0.00072941j, var(E): 0.03423139
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=0.27............. Loss: -0.05160463, mean(E): -21.78523569+0.00011600j, var(E): 0.05493787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=0.27............. Loss: -0.09409133, mean(E): -21.78730750-0.00174059j, var(E): 0.08291006
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=0.27............. Loss: -0.05951686, mean(E): -21.78290763-0.00013127j, var(E): 0.05814389
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=0.26............. Loss: -0.11374054, mean(E): -21.78161556-0.00043901j, var(E): 0.05570216
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=0.26............. Loss: -0.07679187, mean(E): -21.78748302+0.00078959j, var(E): 0.02506085
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=0.27............. Loss: -0.21031174, mean(E): -21.77829075+0.00111117j, var(E): 0.10674026
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=0.26............. Loss: 0.19597118, mean(E): -21.83637756-0.00262540j, var(E): 0.34532624
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=0.27............. Loss: -0.25195771, mean(E): -21.75817410-0.00061191j, var(E): 0.10423988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=0.27............. Loss: 0.11660661, mean(E): -21.82704635-0.00162293j, var(E): 0.03544325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=0.26............. Loss: -0.17313860, mean(E): -21.77648714+0.00207461j, var(E): 0.05392186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=0.26............. Loss: -0.06469871, mean(E): -21.79559402-0.00227638j, var(E): 0.03439719
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=0.27............. Loss: 0.06102504, mean(E): -21.80163270-0.00090923j, var(E): 0.01959341
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=0.26............. Loss: 0.01205965, mean(E): -21.80442882+0.00181122j, var(E): 0.03343529
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=0.26............. Loss: -0.08767263, mean(E): -21.78245719+0.00082704j, var(E): 0.02265796
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=0.26............. Loss: -0.22786716, mean(E): -21.77434818+0.00084896j, var(E): 0.14661133
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=0.26............. Loss: -0.09224039, mean(E): -21.77786768+0.00049972j, var(E): 0.07950614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=0.26............. Loss: 0.02334675, mean(E): -21.79559510+0.00150100j, var(E): 0.06441664
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=0.26............. Loss: -0.10050517, mean(E): -21.78611306+0.00263233j, var(E): 0.03852497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=0.27............. Loss: 0.25512835, mean(E): -21.82674576-0.00024190j, var(E): 0.11338013
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=0.27............. Loss: 0.01718282, mean(E): -21.79909598+0.00206402j, var(E): 0.04352878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=0.26............. Loss: -0.07667291, mean(E): -21.78848042-0.00071839j, var(E): 0.03473793
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=0.27............. Loss: 0.13477671, mean(E): -21.81782470-0.00079557j, var(E): 0.04340351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=0.26............. Loss: 0.03510824, mean(E): -21.79756207-0.00150075j, var(E): 0.01675967
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=0.26............. Loss: -0.05588275, mean(E): -21.78441770+0.00014630j, var(E): 0.04985388
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=0.26............. Loss: -0.02261978, mean(E): -21.79856746+0.00029435j, var(E): 0.01748162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=0.3............. Loss: 0.08601242, mean(E): -21.81087226+0.00006920j, var(E): 0.02322074
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=0.27............. Loss: 0.01181422, mean(E): -21.80295258+0.00043290j, var(E): 0.06991169
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=0.27............. Loss: -0.13250295, mean(E): -21.78657789+0.00141849j, var(E): 0.08794889
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=0.26............. Loss: 0.04973584, mean(E): -21.79302946+0.00129884j, var(E): 0.02448470
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=0.26............. Loss: -0.06322265, mean(E): -21.78157636-0.00029400j, var(E): 0.04231228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=0.27............. Loss: -0.15027619, mean(E): -21.76851658-0.00236387j, var(E): 0.08362837
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=0.26............. Loss: -0.00922807, mean(E): -21.80872623+0.00131904j, var(E): 0.04449051
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=0.27............. Loss: 0.21368612, mean(E): -21.84752258+0.00170389j, var(E): 0.09241633
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=0.26............. Loss: 0.06636548, mean(E): -21.82948258-0.00142214j, var(E): 0.05308036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=0.27............. Loss: -0.11301765, mean(E): -21.78309065-0.00090055j, var(E): 0.08925223
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=0.27............. Loss: -0.16454419, mean(E): -21.78417709+0.00085313j, var(E): 0.06738611
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=0.27............. Loss: -0.23368452, mean(E): -21.74262336-0.00032605j, var(E): 0.27592127
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=0.26............. Loss: 0.08779597, mean(E): -21.81096373-0.00009828j, var(E): 0.02954120
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=0.26............. Loss: 0.06623727, mean(E): -21.79656306+0.00118243j, var(E): 0.06043060
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=0.26............. Loss: -0.09962490, mean(E): -21.79428029+0.00127190j, var(E): 0.04662222
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=0.27............. Loss: -0.15367620, mean(E): -21.77506173+0.00153361j, var(E): 0.03983537
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=0.26............. Loss: -0.13369395, mean(E): -21.77963611-0.00122859j, var(E): 0.10844651
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=0.26............. Loss: 0.04785610, mean(E): -21.81470682-0.00079584j, var(E): 0.03588262
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=0.26............. Loss: -0.17422602, mean(E): -21.76544058-0.00232067j, var(E): 0.04959386
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=0.27............. Loss: -0.07053455, mean(E): -21.79186522-0.00024405j, var(E): 0.04706236
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=0.27............. Loss: 0.35215684, mean(E): -21.83033180+0.00006694j, var(E): 0.34581083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=0.27............. Loss: 0.16432620, mean(E): -21.80810654-0.00025328j, var(E): 0.06465632
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=0.27............. Loss: -0.01694505, mean(E): -21.77189811+0.00110554j, var(E): 0.03413506
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=0.27............. Loss: 0.05883034, mean(E): -21.80525549+0.00174254j, var(E): 0.03225101
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=0.27............. Loss: -0.05376192, mean(E): -21.79686387-0.00006222j, var(E): 0.04088038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=0.27............. Loss: -0.08834343, mean(E): -21.79915598+0.00232812j, var(E): 0.03465735
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=0.27............. Loss: 0.07104147, mean(E): -21.79375504+0.00016113j, var(E): 0.03990719
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=0.27............. Loss: 0.00331871, mean(E): -21.80054584+0.00233217j, var(E): 0.01690630
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=0.27............. Loss: -0.11064183, mean(E): -21.76831653+0.00144514j, var(E): 0.07586118
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=0.27............. Loss: -0.10253114, mean(E): -21.76792930-0.00209809j, var(E): 0.28017845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=0.27............. Loss: 0.08239686, mean(E): -21.80235973-0.00036514j, var(E): 0.02274924
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=0.27............. Loss: 0.19884329, mean(E): -21.84382915+0.00162723j, var(E): 0.18795703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=0.27............. Loss: -0.26178395, mean(E): -21.77036023+0.00254035j, var(E): 0.09198220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=0.27............. Loss: 0.02743994, mean(E): -21.80717216+0.00133495j, var(E): 0.01714975
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=0.27............. Loss: 0.02380952, mean(E): -21.80706948-0.00113149j, var(E): 0.02859196
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=0.27............. Loss: -0.14431136, mean(E): -21.77782538-0.00080712j, var(E): 0.03984343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=0.27............. Loss: 0.06309782, mean(E): -21.80234041-0.00042203j, var(E): 0.02354073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=0.27............. Loss: -0.04520541, mean(E): -21.79367697+0.00032747j, var(E): 0.04137466
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=0.27............. Loss: -0.04360781, mean(E): -21.77904909-0.00274210j, var(E): 0.06671459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=0.27............. Loss: 0.04462112, mean(E): -21.80252482+0.00112278j, var(E): 0.03128999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=0.27............. Loss: -0.00778158, mean(E): -21.80179207-0.00043999j, var(E): 0.02433336
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=0.26............. Loss: -0.01572274, mean(E): -21.80250195+0.00129165j, var(E): 0.03970180
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=0.26............. Loss: -0.02841571, mean(E): -21.78151569+0.00015370j, var(E): 0.02632783
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=0.26............. Loss: -0.05000668, mean(E): -21.79549590+0.00071531j, var(E): 0.03714274
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=0.27............. Loss: -0.24678907, mean(E): -21.74578865+0.00105640j, var(E): 0.07385598
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=0.26............. Loss: -0.03427860, mean(E): -21.78661339+0.00014427j, var(E): 0.15479493
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=0.26............. Loss: 0.06708494, mean(E): -21.79176757-0.00103830j, var(E): 0.01893020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=0.27............. Loss: 0.03867774, mean(E): -21.80418931-0.00050633j, var(E): 0.02448553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=0.27............. Loss: -0.14162569, mean(E): -21.78694922+0.00045283j, var(E): 0.09453867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=0.27............. Loss: 0.12639419, mean(E): -21.80400691+0.00054588j, var(E): 0.06364612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=0.27............. Loss: -0.02781053, mean(E): -21.80366013-0.00048113j, var(E): 0.02424596
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=0.27............. Loss: -0.23916904, mean(E): -21.77823716-0.00049371j, var(E): 0.05889652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=0.27............. Loss: -0.09027931, mean(E): -21.78071138+0.00114929j, var(E): 0.04409267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=0.29............. Loss: 0.02531487, mean(E): -21.79404922+0.00083316j, var(E): 0.02158340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=0.26............. Loss: 0.10690291, mean(E): -21.81637436+0.00004367j, var(E): 0.05901323
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=0.27............. Loss: 0.01956952, mean(E): -21.80414436-0.00210508j, var(E): 0.03298985
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=0.26............. Loss: 0.10552549, mean(E): -21.81868605+0.00132900j, var(E): 0.07053699
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=0.27............. Loss: 0.26187924, mean(E): -21.84010501+0.00225537j, var(E): 0.11277207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=0.27............. Loss: -0.13685964, mean(E): -21.78733068-0.00018177j, var(E): 0.06142982
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=0.27............. Loss: 0.23006567, mean(E): -21.83032571-0.00066425j, var(E): 0.11645029
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=0.27............. Loss: 0.06349073, mean(E): -21.80354079+0.00067757j, var(E): 0.02867474
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=0.27............. Loss: -0.15119356, mean(E): -21.77751500+0.00008914j, var(E): 0.14092806
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=0.26............. Loss: 0.04561439, mean(E): -21.79968013-0.00207181j, var(E): 0.14375500
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=0.27............. Loss: -0.03487302, mean(E): -21.80531896-0.00061893j, var(E): 0.10845454
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=0.27............. Loss: -0.11332319, mean(E): -21.77760080+0.00089630j, var(E): 0.11928459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=0.27............. Loss: -0.00004652, mean(E): -21.79974340+0.00126805j, var(E): 0.03961307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=0.27............. Loss: 0.00419505, mean(E): -21.80311824+0.00010786j, var(E): 0.01404046
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=0.26............. Loss: 0.00670158, mean(E): -21.80345722-0.00109656j, var(E): 0.03804315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=0.26............. Loss: -0.03961736, mean(E): -21.78729105+0.00022532j, var(E): 0.03142097
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=0.27............. Loss: -0.03538361, mean(E): -21.78907128-0.00036195j, var(E): 0.06058569
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=0.27............. Loss: 0.09440843, mean(E): -21.80635082+0.00115347j, var(E): 0.02074371
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=0.27............. Loss: -0.10862349, mean(E): -21.77962771-0.00014386j, var(E): 0.03851520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=0.27............. Loss: 0.00590516, mean(E): -21.80002572-0.00018917j, var(E): 0.11375239
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=0.26............. Loss: -0.08583208, mean(E): -21.79180246+0.00104128j, var(E): 0.04562319
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=0.27............. Loss: -0.10688296, mean(E): -21.79550189-0.00023640j, var(E): 0.05201694
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=0.26............. Loss: 0.35975245, mean(E): -21.84707838-0.00036253j, var(E): 0.18925816
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=0.27............. Loss: 0.05384232, mean(E): -21.78059747+0.00086929j, var(E): 0.04564614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=0.27............. Loss: 0.14319809, mean(E): -21.82219638+0.00000114j, var(E): 0.09912286
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=0.26............. Loss: 0.25965883, mean(E): -21.84424569+0.00030597j, var(E): 0.11015654
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=0.27............. Loss: -0.08948854, mean(E): -21.78798567+0.00086715j, var(E): 0.03383994
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=0.27............. Loss: -0.05886377, mean(E): -21.78955431-0.00027935j, var(E): 0.03342797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=0.27............. Loss: 0.19898918, mean(E): -21.81954034-0.00020303j, var(E): 0.06656900
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=0.26............. Loss: 0.02935592, mean(E): -21.79149333+0.00085725j, var(E): 0.08537055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=0.27............. Loss: 0.02826741, mean(E): -21.79786783-0.00157711j, var(E): 0.01306075
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=0.27............. Loss: -0.09336371, mean(E): -21.78537079-0.00162268j, var(E): 0.03555081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=0.27............. Loss: 0.02189205, mean(E): -21.80604343-0.00086346j, var(E): 0.01376020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=0.26............. Loss: -0.21228801, mean(E): -21.77898701+0.00030406j, var(E): 0.26458214
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=0.26............. Loss: -0.13284265, mean(E): -21.77963252-0.00112335j, var(E): 0.09062354
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=0.26............. Loss: -0.02718461, mean(E): -21.79522520-0.00165937j, var(E): 0.01384376
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=0.27............. Loss: -0.03520068, mean(E): -21.79646763+0.00043701j, var(E): 0.04267110
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=0.27............. Loss: -0.06381852, mean(E): -21.79004028-0.00091159j, var(E): 0.02744514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=0.26............. Loss: 0.16725203, mean(E): -21.82232261+0.00155752j, var(E): 0.06916875
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=0.27............. Loss: -0.05246589, mean(E): -21.76994433-0.00023569j, var(E): 0.02521145
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=0.27............. Loss: -0.27686446, mean(E): -21.76032263+0.00055084j, var(E): 0.09874065
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=0.26............. Loss: 0.07187443, mean(E): -21.81390109+0.00180120j, var(E): 0.03451122
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=0.27............. Loss: -0.00148379, mean(E): -21.81035407-0.00012428j, var(E): 0.01384722
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=0.27............. Loss: -0.02035636, mean(E): -21.78023223-0.00014674j, var(E): 0.03215697
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=0.27............. Loss: 0.07220914, mean(E): -21.79941416+0.00063868j, var(E): 0.03103884
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=0.26............. Loss: -0.00094670, mean(E): -21.78434355-0.00037637j, var(E): 0.03757202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=0.27............. Loss: 0.15902990, mean(E): -21.82128757+0.00032181j, var(E): 0.02650098
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=0.27............. Loss: 0.10607622, mean(E): -21.81720394-0.00156609j, var(E): 0.02100531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=0.26............. Loss: 0.13560781, mean(E): -21.81981044+0.00001339j, var(E): 0.03973270
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=0.27............. Loss: -0.03978720, mean(E): -21.79538332+0.00007660j, var(E): 0.01771324
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=0.26............. Loss: 0.02506149, mean(E): -21.79796491+0.00074757j, var(E): 0.01369343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=0.26............. Loss: -0.03893827, mean(E): -21.79656541-0.00116901j, var(E): 0.03665666
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=0.26............. Loss: -0.01488484, mean(E): -21.79908187-0.00014427j, var(E): 0.02889459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=0.26............. Loss: 0.11748000, mean(E): -21.81655167+0.00000339j, var(E): 0.05300869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=0.26............. Loss: -0.00856056, mean(E): -21.79132296-0.00058931j, var(E): 0.02670212
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=0.27............. Loss: -0.06850921, mean(E): -21.79829753-0.00088875j, var(E): 0.03530653
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=0.27............. Loss: 0.11662817, mean(E): -21.81941885-0.00009405j, var(E): 0.02520996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=0.26............. Loss: -0.11844084, mean(E): -21.77172937-0.00060741j, var(E): 0.04781132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=0.27............. Loss: 0.06439191, mean(E): -21.80483833-0.00009116j, var(E): 0.04442209
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=0.26............. Loss: 0.04757001, mean(E): -21.80757264-0.00105206j, var(E): 0.03873365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=0.27............. Loss: -0.16619272, mean(E): -21.77694656+0.00050589j, var(E): 0.10311087
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=0.27............. Loss: -0.05601931, mean(E): -21.77268228-0.00153484j, var(E): 0.01005793
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=0.27............. Loss: 0.06002118, mean(E): -21.80066862+0.00015592j, var(E): 0.01270182
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=0.27............. Loss: -0.05583003, mean(E): -21.79500699-0.00076503j, var(E): 0.03426335
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=0.27............. Loss: -0.07640585, mean(E): -21.79643138+0.00053974j, var(E): 0.03801266
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=0.27............. Loss: 0.17551925, mean(E): -21.82455396-0.00050049j, var(E): 0.03377888
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=0.27............. Loss: -0.09259062, mean(E): -21.78955549+0.00119880j, var(E): 0.01634376
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=0.27............. Loss: 0.15076927, mean(E): -21.82307233-0.00040684j, var(E): 0.03894023
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=0.27............. Loss: 0.23589203, mean(E): -21.82792713+0.00028408j, var(E): 0.20381502
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=0.27............. Loss: -0.05185677, mean(E): -21.79265916+0.00109657j, var(E): 0.02464461
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=0.27............. Loss: -0.05601022, mean(E): -21.78525539+0.00077209j, var(E): 0.02409335
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=0.26............. Loss: -0.05986092, mean(E): -21.78224040+0.00044986j, var(E): 0.06090797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=0.27............. Loss: 0.12518934, mean(E): -21.80694185+0.00058987j, var(E): 0.04343536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=0.27............. Loss: 0.01571051, mean(E): -21.79642017+0.00078597j, var(E): 0.00878784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=0.27............. Loss: -0.38768640, mean(E): -21.73979056-0.00091385j, var(E): 0.13016545
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=0.27............. Loss: 0.10095446, mean(E): -21.81149159-0.00032454j, var(E): 0.03613952
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=0.26............. Loss: 0.06113415, mean(E): -21.79827640+0.00021665j, var(E): 0.06410989
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=0.27............. Loss: 0.03088943, mean(E): -21.80529357+0.00008801j, var(E): 0.01986529
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=0.27............. Loss: -0.02348460, mean(E): -21.79407866-0.00029311j, var(E): 0.02722003
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=0.27............. Loss: 0.08761844, mean(E): -21.80812202-0.00036775j, var(E): 0.05169367
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=0.26............. Loss: -0.09599963, mean(E): -21.79226893-0.00047237j, var(E): 0.02681746
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=0.27............. Loss: 0.21016131, mean(E): -21.83068294-0.00016165j, var(E): 0.06107953
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=0.27............. Loss: -0.02158201, mean(E): -21.79429006-0.00012989j, var(E): 0.00825559
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=0.27............. Loss: 0.13470253, mean(E): -21.83059801+0.00034844j, var(E): 0.05989536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=0.26............. Loss: 1.36278148, mean(E): -21.89093823+0.00055157j, var(E): 1.47875093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=0.27............. Loss: 0.04426679, mean(E): -21.80372453-0.00049786j, var(E): 0.03404703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=0.26............. Loss: -0.02761430, mean(E): -21.78525475+0.00054217j, var(E): 0.04177786
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=0.27............. Loss: -0.16644477, mean(E): -21.76908064-0.00094509j, var(E): 0.11399498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=0.26............. Loss: 0.13262487, mean(E): -21.81993565-0.00077556j, var(E): 0.09017345
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=0.27............. Loss: -0.28454773, mean(E): -21.75742384+0.00020598j, var(E): 0.09963579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=0.26............. Loss: 0.09065524, mean(E): -21.80238600+0.00005699j, var(E): 0.05927283
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=0.27............. Loss: 0.10231463, mean(E): -21.81504860+0.00047950j, var(E): 0.02573661
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=0.27............. Loss: -0.14668442, mean(E): -21.77693204+0.00025154j, var(E): 0.03031353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=0.27............. Loss: 0.01801545, mean(E): -21.81103741+0.00076937j, var(E): 0.03991023
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=0.27............. Loss: 0.25157088, mean(E): -21.82245087+0.00092101j, var(E): 0.13023159
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=0.27............. Loss: 0.00529925, mean(E): -21.80106911-0.00062709j, var(E): 0.01798215
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=0.27............. Loss: -0.15814424, mean(E): -21.78239305-0.00029842j, var(E): 0.12831014
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=0.27............. Loss: -0.03285433, mean(E): -21.79243167-0.00032788j, var(E): 0.02891375
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=0.27............. Loss: -0.16131627, mean(E): -21.77993126-0.00095969j, var(E): 0.09719379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=0.26............. Loss: -0.07582972, mean(E): -21.78865760-0.00016086j, var(E): 0.03864858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=0.27............. Loss: 0.01805018, mean(E): -21.80302416-0.00015218j, var(E): 0.00964103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=0.26............. Loss: 0.07915994, mean(E): -21.80208031-0.00007371j, var(E): 0.03579124
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=0.27............. Loss: -0.15663457, mean(E): -21.78371828+0.00050941j, var(E): 0.03357103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=0.27............. Loss: -0.17291603, mean(E): -21.77842384-0.00027920j, var(E): 0.03416299
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=0.26............. Loss: 0.10727950, mean(E): -21.80776028-0.00043987j, var(E): 0.04403705
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=0.26............. Loss: 0.05597675, mean(E): -21.79554055+0.00032506j, var(E): 0.01151019
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=0.27............. Loss: -0.10331677, mean(E): -21.79669390-0.00037991j, var(E): 0.04379898
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=0.27............. Loss: -0.25667517, mean(E): -21.77273903+0.00049224j, var(E): 0.09894363
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=0.27............. Loss: -0.00132443, mean(E): -21.79857463-0.00043123j, var(E): 0.04946758
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=0.26............. Loss: -0.00516799, mean(E): -21.80345405+0.00042676j, var(E): 0.04508348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=0.27............. Loss: -0.30504496, mean(E): -21.75097013+0.00000670j, var(E): 0.21370151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=0.27............. Loss: -0.12880592, mean(E): -21.78140322+0.00010319j, var(E): 0.02029240
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=0.27............. Loss: 0.02509670, mean(E): -21.79919004-0.00078534j, var(E): 0.02821018
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=0.27............. Loss: -0.01368463, mean(E): -21.80111415-0.00025624j, var(E): 0.02447885
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=0.26............. Loss: 0.07900295, mean(E): -21.80811700+0.00103374j, var(E): 0.02712193
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=0.27............. Loss: 0.01358538, mean(E): -21.78726859-0.00017648j, var(E): 0.07716531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=0.26............. Loss: -0.11679949, mean(E): -21.77341001-0.00078788j, var(E): 0.06236098
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=0.27............. Loss: 0.04469936, mean(E): -21.80947811-0.00129173j, var(E): 0.02581560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=0.27............. Loss: 0.04078019, mean(E): -21.79880880-0.00015750j, var(E): 0.04424412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=0.27............. Loss: -0.06109551, mean(E): -21.79116226+0.00025207j, var(E): 0.03041536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=0.27............. Loss: 0.05702621, mean(E): -21.79545090+0.00093844j, var(E): 0.07986926
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=0.27............. Loss: -0.01430806, mean(E): -21.79493185-0.00055094j, var(E): 0.06813925
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=0.27............. Loss: -0.03104151, mean(E): -21.79268824+0.00041382j, var(E): 0.02522473
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=0.27............. Loss: 0.08000068, mean(E): -21.79446754-0.00129257j, var(E): 0.04973170
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=0.27............. Loss: 0.01264248, mean(E): -21.79706745-0.00007091j, var(E): 0.04288162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=0.27............. Loss: 0.03096254, mean(E): -21.80158488-0.00115128j, var(E): 0.02545657
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=0.27............. Loss: 0.17705935, mean(E): -21.82034106+0.00156922j, var(E): 0.05762890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=0.27............. Loss: 0.10568185, mean(E): -21.81275772-0.00028806j, var(E): 0.03420930
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=0.27............. Loss: 0.11384950, mean(E): -21.81016956+0.00026981j, var(E): 0.06682615
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=0.27............. Loss: 0.07057890, mean(E): -21.80948875-0.00076472j, var(E): 0.03277549
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=0.27............. Loss: -0.01009387, mean(E): -21.78351035-0.00027800j, var(E): 0.01879534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=0.27............. Loss: 0.01584798, mean(E): -21.80560018+0.00068308j, var(E): 0.04803119
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=0.27............. Loss: 0.05217500, mean(E): -21.79623662-0.00058150j, var(E): 0.03999412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=0.27............. Loss: 0.11451455, mean(E): -21.81593699-0.00010197j, var(E): 0.04181507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=0.27............. Loss: 0.20602154, mean(E): -21.82651479-0.00012083j, var(E): 0.04915684
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=0.27............. Loss: -0.08316469, mean(E): -21.79396208-0.00002602j, var(E): 0.02327013
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=0.27............. Loss: 0.10890151, mean(E): -21.81437612-0.00005787j, var(E): 0.04174598
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=0.27............. Loss: -0.10930415, mean(E): -21.77191882+0.00049870j, var(E): 0.03622573
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=0.27............. Loss: -0.09917843, mean(E): -21.78693091-0.00007126j, var(E): 0.02911141
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=0.27............. Loss: -0.20322032, mean(E): -21.78942963+0.00037767j, var(E): 0.07647379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=0.27............. Loss: -0.01862734, mean(E): -21.79511450-0.00006367j, var(E): 0.02442804
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=0.27............. Loss: -0.08223039, mean(E): -21.77845802+0.00033775j, var(E): 0.03089239
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=0.27............. Loss: 0.04559860, mean(E): -21.81181049+0.00020342j, var(E): 0.18889099
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=0.27............. Loss: 0.18337739, mean(E): -21.81448439-0.00076349j, var(E): 0.14918349
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=0.27............. Loss: -0.00433077, mean(E): -21.79958641+0.00026161j, var(E): 0.03176982
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=0.27............. Loss: 0.01181277, mean(E): -21.79645305-0.00036552j, var(E): 0.11903402
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=0.27............. Loss: -0.19145115, mean(E): -21.75753216+0.00010261j, var(E): 0.07409119
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=0.27............. Loss: -0.19580542, mean(E): -21.76765532-0.00006836j, var(E): 0.07287164
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=0.27............. Loss: 0.01995145, mean(E): -21.79687615+0.00021660j, var(E): 0.01690020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=0.27............. Loss: -0.01052077, mean(E): -21.79809756+0.00031349j, var(E): 0.04113655
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=0.27............. Loss: -0.08874831, mean(E): -21.80382342+0.00018054j, var(E): 0.03378024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=0.27............. Loss: 0.13848648, mean(E): -21.81518749+0.00110636j, var(E): 0.08834915
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=0.27............. Loss: 0.08328932, mean(E): -21.80399153+0.00042599j, var(E): 0.06286047
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=0.27............. Loss: -0.02817038, mean(E): -21.79710113-0.00042267j, var(E): 0.02987263
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=0.27............. Loss: -0.13438407, mean(E): -21.77612622-0.00013871j, var(E): 0.03312632
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=0.27............. Loss: -0.03689506, mean(E): -21.79176806-0.00034906j, var(E): 0.03068195
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=0.27............. Loss: 0.05643873, mean(E): -21.80780918+0.00010939j, var(E): 0.01876753
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=0.27............. Loss: -0.01251719, mean(E): -21.80248785+0.00006719j, var(E): 0.05140385
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=0.27............. Loss: 0.01470154, mean(E): -21.80373172-0.00024059j, var(E): 0.00882206
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=0.27............. Loss: 0.04539048, mean(E): -21.81641097-0.00033128j, var(E): 0.00740131
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=0.31............. Loss: -0.01482760, mean(E): -21.79661944-0.00004702j, var(E): 0.01004625
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=0.27............. Loss: 0.02708345, mean(E): -21.80430699-0.00036325j, var(E): 0.00949743
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=0.27............. Loss: 0.03376382, mean(E): -21.80288965-0.00035433j, var(E): 0.02416010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=0.27............. Loss: 0.06523428, mean(E): -21.79728086+0.00016529j, var(E): 0.03230466
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=0.27............. Loss: 0.04773571, mean(E): -21.81353015-0.00006953j, var(E): 0.03120390
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=0.27............. Loss: -0.09513590, mean(E): -21.78517249-0.00029489j, var(E): 0.03534483
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=0.27............. Loss: -0.01645631, mean(E): -21.80248737+0.00019391j, var(E): 0.04803028
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=0.27............. Loss: -0.02750853, mean(E): -21.80029731-0.00018814j, var(E): 0.01737327
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=0.27............. Loss: 0.00653235, mean(E): -21.80322802-0.00019456j, var(E): 0.03527742
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=0.27............. Loss: 0.00864847, mean(E): -21.79306839+0.00043308j, var(E): 0.08533347
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=0.27............. Loss: 0.02181068, mean(E): -21.79564440-0.00008046j, var(E): 0.02309417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=0.27............. Loss: 0.06759637, mean(E): -21.82133860-0.00051914j, var(E): 0.02607303
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=0.27............. Loss: 0.01595894, mean(E): -21.80742703-0.00033036j, var(E): 0.03392010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=0.27............. Loss: 0.10424329, mean(E): -21.79859713+0.00038194j, var(E): 0.12044674
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=0.27............. Loss: 0.19687050, mean(E): -21.82584333+0.00017487j, var(E): 0.07687639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=0.27............. Loss: -0.03782209, mean(E): -21.79651516-0.00002601j, var(E): 0.03568897
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=0.27............. Loss: 0.01070792, mean(E): -21.80143243+0.00004388j, var(E): 0.03732237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=0.27............. Loss: 0.06185149, mean(E): -21.80600581+0.00080262j, var(E): 0.01214346
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=0.27............. Loss: 0.07290031, mean(E): -21.80946832-0.00063601j, var(E): 0.04492748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=0.27............. Loss: 0.23559012, mean(E): -21.82330844-0.00013541j, var(E): 0.16612542
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=0.27............. Loss: -0.11598014, mean(E): -21.78636430+0.00049023j, var(E): 0.05885298
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=0.27............. Loss: -0.10443800, mean(E): -21.78010292+0.00079279j, var(E): 0.05713934
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=0.27............. Loss: 0.02183744, mean(E): -21.80026748-0.00052310j, var(E): 0.03820655
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=0.27............. Loss: -0.36601084, mean(E): -21.76129569-0.00010902j, var(E): 0.09493091
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=0.27............. Loss: -0.02967763, mean(E): -21.78725306-0.00089666j, var(E): 0.03185533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=0.27............. Loss: -0.04995286, mean(E): -21.77743106+0.00026340j, var(E): 0.02891797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=0.27............. Loss: 0.01347839, mean(E): -21.80711138+0.00028937j, var(E): 0.05213231
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=0.27............. Loss: -0.09164768, mean(E): -21.78861599-0.00011785j, var(E): 0.03697078
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=0.27............. Loss: 0.01467772, mean(E): -21.79864429-0.00090465j, var(E): 0.01074021
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=0.27............. Loss: 0.07746931, mean(E): -21.81141779-0.00019875j, var(E): 0.03830070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=0.27............. Loss: 0.03095870, mean(E): -21.80532056-0.00005355j, var(E): 0.02512210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=0.27............. Loss: 0.04436094, mean(E): -21.80708197-0.00032973j, var(E): 0.03194209
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=0.27............. Loss: -0.10430090, mean(E): -21.78279492+0.00016325j, var(E): 0.04778750
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=0.27............. Loss: 0.13505707, mean(E): -21.81474573-0.00021883j, var(E): 0.04402125
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=0.27............. Loss: 0.01726538, mean(E): -21.79308837+0.00010917j, var(E): 0.02127479
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=0.27............. Loss: 0.03609186, mean(E): -21.79161967+0.00020356j, var(E): 0.02199562
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=0.27............. Loss: -0.02165710, mean(E): -21.78870102+0.00019212j, var(E): 0.02931383
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=0.27............. Loss: -0.04671207, mean(E): -21.79362842-0.00016617j, var(E): 0.04458761
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=0.27............. Loss: -0.24901838, mean(E): -21.78261087-0.00004934j, var(E): 0.05233567
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=0.27............. Loss: -0.13404697, mean(E): -21.78161835+0.00023099j, var(E): 0.06256662
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=0.27............. Loss: -0.04623912, mean(E): -21.79408605+0.00023929j, var(E): 0.03544782
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=0.27............. Loss: -0.20131491, mean(E): -21.78013885+0.00048863j, var(E): 0.22002814
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=0.27............. Loss: -0.00207998, mean(E): -21.80103444+0.00037431j, var(E): 0.01958226
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=0.27............. Loss: -0.19096553, mean(E): -21.78028070-0.00029887j, var(E): 0.15688346
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=0.27............. Loss: 0.08670599, mean(E): -21.80609011-0.00023591j, var(E): 0.01426067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=0.27............. Loss: -0.10882721, mean(E): -21.79000493-0.00011269j, var(E): 0.05547055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=0.27............. Loss: 0.00251748, mean(E): -21.79579653+0.00032542j, var(E): 0.01908189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=0.27............. Loss: 0.01121770, mean(E): -21.78227347+0.00092157j, var(E): 0.08562614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=0.27............. Loss: -0.04191336, mean(E): -21.80682445-0.00006611j, var(E): 0.04912708
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=0.27............. Loss: -0.11721036, mean(E): -21.78054456-0.00014506j, var(E): 0.07271121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=0.27............. Loss: 0.19808650, mean(E): -21.82223121-0.00047586j, var(E): 0.05066492
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=0.27............. Loss: 0.00686563, mean(E): -21.80421993+0.00031000j, var(E): 0.01732130
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=0.27............. Loss: 0.02616176, mean(E): -21.81245447+0.00211694j, var(E): 0.08318189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=0.27............. Loss: -0.03775747, mean(E): -21.79932636+0.00072014j, var(E): 0.03161940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=0.27............. Loss: 0.03564704, mean(E): -21.80328398-0.00017019j, var(E): 0.03551535
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=0.27............. Loss: -0.00579537, mean(E): -21.80108559+0.00001108j, var(E): 0.02124543
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=0.27............. Loss: 0.10174928, mean(E): -21.80993661+0.00041193j, var(E): 0.06504216
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=0.27............. Loss: -0.01823174, mean(E): -21.79278061+0.00108459j, var(E): 0.01902950
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=0.27............. Loss: 0.03212040, mean(E): -21.79988764-0.00005059j, var(E): 0.04429673
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=0.27............. Loss: -0.09752902, mean(E): -21.78952630-0.00116184j, var(E): 0.04673706
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=0.27............. Loss: 0.09512406, mean(E): -21.79184496+0.00023117j, var(E): 0.05908998
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=0.27............. Loss: -0.00207408, mean(E): -21.80090168+0.00006800j, var(E): 0.05727006
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=0.27............. Loss: -0.03444478, mean(E): -21.79208788-0.00001349j, var(E): 0.21135543
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=0.27............. Loss: -0.13950171, mean(E): -21.78159108-0.00009726j, var(E): 0.06619435
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(24.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=0.27............. Loss: -0.11617485, mean(E): -21.78496409-0.00104331j, var(E): 0.03079570
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=0.27............. Loss: 0.34124780, mean(E): -21.84796186+0.00003415j, var(E): 0.12258351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=0.27............. Loss: -0.06208599, mean(E): -21.79456566+0.00063094j, var(E): 0.02751662
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=0.27............. Loss: -0.05269920, mean(E): -21.80568428+0.00048747j, var(E): 0.03486475
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=0.27............. Loss: -0.01996026, mean(E): -21.80321481+0.00043157j, var(E): 0.01345835
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=0.27............. Loss: -0.05116496, mean(E): -21.79542291-0.00210583j, var(E): 0.02909558
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=0.27............. Loss: 0.08594403, mean(E): -21.81087023-0.00266090j, var(E): 0.04773421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=0.27............. Loss: -0.00709489, mean(E): -21.79517873+0.00104510j, var(E): 0.01047873
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=0.27............. Loss: 0.03933744, mean(E): -21.79928002-0.00079079j, var(E): 0.04576701
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=0.27............. Loss: 0.67979203, mean(E): -21.87393547+0.00006397j, var(E): 0.88691032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=0.27............. Loss: 0.01525335, mean(E): -21.80228010+0.00042812j, var(E): 0.03656619
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=0.27............. Loss: -0.25635453, mean(E): -21.77621643-0.00111276j, var(E): 0.13151094
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=0.27............. Loss: -0.05821422, mean(E): -21.78620352+0.00061901j, var(E): 0.02900849
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=0.27............. Loss: -0.09870278, mean(E): -21.78034670-0.00044962j, var(E): 0.06825740
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=0.27............. Loss: -0.05260084, mean(E): -21.78474549+0.00034393j, var(E): 0.02328794
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=0.27............. Loss: 0.05504584, mean(E): -21.80415302-0.00126696j, var(E): 0.01728124
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=0.27............. Loss: 0.01776543, mean(E): -21.80999402+0.00177088j, var(E): 0.00845704
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=0.27............. Loss: 0.21006597, mean(E): -21.82355123+0.00101410j, var(E): 0.14065792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=0.27............. Loss: 0.01711219, mean(E): -21.80469018-0.00045675j, var(E): 0.01515577
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=0.27............. Loss: -0.09966243, mean(E): -21.79333254+0.00320993j, var(E): 0.05100803
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=0.27............. Loss: 0.06572305, mean(E): -21.81042435-0.00089447j, var(E): 0.02703189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=0.27............. Loss: 0.03027646, mean(E): -21.81244455+0.00006162j, var(E): 0.03043438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=0.27............. Loss: 0.01670726, mean(E): -21.79521662+0.00033246j, var(E): 0.03289230
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=0.27............. Loss: -0.19533477, mean(E): -21.76395755-0.00047353j, var(E): 0.10047488
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=0.27............. Loss: 0.04673492, mean(E): -21.79425000+0.00049955j, var(E): 0.02103412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=0.27............. Loss: 0.00267721, mean(E): -21.78891769-0.00000357j, var(E): 0.01482902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=0.27............. Loss: -0.02351235, mean(E): -21.77917430-0.00083374j, var(E): 0.04545628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=0.27............. Loss: 0.13418461, mean(E): -21.81269132-0.00057081j, var(E): 0.06498636
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=0.27............. Loss: 0.08756105, mean(E): -21.80674522-0.00004231j, var(E): 0.03314874
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=0.27............. Loss: -0.03085978, mean(E): -21.79662176+0.00080289j, var(E): 0.03093121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=0.27............. Loss: -0.15115457, mean(E): -21.77633941+0.00070044j, var(E): 0.03556576
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=0.27............. Loss: -0.01715302, mean(E): -21.78681553+0.00006581j, var(E): 0.03141124
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=0.27............. Loss: 0.11827417, mean(E): -21.80454059+0.00017125j, var(E): 0.05865395
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=0.27............. Loss: -0.00799939, mean(E): -21.81663332+0.00066481j, var(E): 0.02527147
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=0.27............. Loss: -0.10136905, mean(E): -21.77012586+0.00012181j, var(E): 0.03876327
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=0.27............. Loss: -0.05340536, mean(E): -21.79443950+0.00083168j, var(E): 0.04068011
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=0.27............. Loss: -0.08266813, mean(E): -21.78752123-0.00035232j, var(E): 0.06648251
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=0.27............. Loss: 0.10002080, mean(E): -21.82188422+0.00028004j, var(E): 0.07331620
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=0.27............. Loss: 0.10436269, mean(E): -21.80550389-0.00024781j, var(E): 0.08775331
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=0.27............. Loss: -0.09496460, mean(E): -21.78873178+0.00060025j, var(E): 0.04424484
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=0.27............. Loss: -0.04160157, mean(E): -21.79423769-0.00022949j, var(E): 0.01148505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=0.27............. Loss: 0.06111245, mean(E): -21.79309085+0.00094843j, var(E): 0.04375949
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=0.27............. Loss: -0.04875769, mean(E): -21.77138720-0.00105590j, var(E): 0.01917727
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=0.3............. Loss: 0.57933729, mean(E): -21.85778199+0.00000755j, var(E): 0.54356978
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=0.27............. Loss: -0.08986988, mean(E): -21.78580492+0.00029425j, var(E): 0.04368790
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=0.27............. Loss: 0.01793085, mean(E): -21.80166713-0.00015585j, var(E): 0.01632686
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=0.27............. Loss: 0.10942260, mean(E): -21.80404249-0.00024538j, var(E): 0.05465678
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=0.27............. Loss: 0.06849588, mean(E): -21.79397794-0.00038162j, var(E): 0.15990227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=0.27............. Loss: -0.10306633, mean(E): -21.77188866-0.00015832j, var(E): 0.02215139
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=0.27............. Loss: -0.07293913, mean(E): -21.79958135-0.00002293j, var(E): 0.02039530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=0.27............. Loss: -0.03455602, mean(E): -21.78349502-0.00020000j, var(E): 0.01196465
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=0.27............. Loss: 0.15085694, mean(E): -21.81560438+0.00034559j, var(E): 0.18632300
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=0.27............. Loss: -0.04258501, mean(E): -21.79251187+0.00011160j, var(E): 0.03045315
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=0.27............. Loss: -0.15980120, mean(E): -21.77521857-0.00026452j, var(E): 0.10156710
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=0.27............. Loss: 0.06075393, mean(E): -21.80120564-0.00101839j, var(E): 0.04175076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=0.27............. Loss: 0.02530230, mean(E): -21.79216233+0.00003170j, var(E): 0.01345848
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=0.27............. Loss: -0.03704037, mean(E): -21.79473839+0.00095929j, var(E): 0.02368252
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=0.27............. Loss: 0.01680726, mean(E): -21.80846303+0.00047406j, var(E): 0.01252619
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=0.27............. Loss: -0.13334177, mean(E): -21.77953768-0.00010539j, var(E): 0.02993068
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=0.27............. Loss: -0.29278810, mean(E): -21.76248024+0.00033699j, var(E): 0.16182969
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=0.27............. Loss: -0.08484548, mean(E): -21.78995873-0.00014357j, var(E): 0.02156174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=0.27............. Loss: 0.23604238, mean(E): -21.82486597+0.00184609j, var(E): 0.10832191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=0.27............. Loss: -0.09876194, mean(E): -21.79028819-0.00129428j, var(E): 0.18618330
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=0.27............. Loss: 0.16299920, mean(E): -21.82215894+0.00003917j, var(E): 0.09879631
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=0.27............. Loss: 0.05651082, mean(E): -21.81109959+0.00057986j, var(E): 0.01249916
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=0.5............. Loss: -0.22990373, mean(E): -21.76561074-0.00037622j, var(E): 0.08034486
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=0.27............. Loss: -0.02371507, mean(E): -21.78964217-0.00066175j, var(E): 0.06146692
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=0.27............. Loss: 0.05713331, mean(E): -21.81581759-0.00067846j, var(E): 0.03020183
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=0.27............. Loss: 0.00679228, mean(E): -21.81348203-0.00027398j, var(E): 0.02422789
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=0.27............. Loss: -0.00768073, mean(E): -21.81830846-0.00170744j, var(E): 0.05176348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=0.27............. Loss: 0.03841683, mean(E): -21.80962849-0.00125227j, var(E): 0.07436305
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=0.27............. Loss: -0.42052658, mean(E): -21.75142973+0.00070388j, var(E): 0.13957202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=0.27............. Loss: 0.06173825, mean(E): -21.81859034+0.00105535j, var(E): 0.02397056
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=0.27............. Loss: 0.03411167, mean(E): -21.79380955-0.00154753j, var(E): 0.02446438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=0.27............. Loss: 1.27665869, mean(E): -21.90916974+0.00011505j, var(E): 2.25230508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=0.27............. Loss: 0.02271452, mean(E): -21.81317256-0.00026557j, var(E): 0.03180724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=0.27............. Loss: -0.08565220, mean(E): -21.80434863+0.00064427j, var(E): 0.06906779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=0.27............. Loss: -0.03728840, mean(E): -21.80189613+0.00012592j, var(E): 0.03288360
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=0.27............. Loss: 0.01643255, mean(E): -21.80238009+0.00052765j, var(E): 0.02359658
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=0.27............. Loss: 0.02236381, mean(E): -21.79236110-0.00026951j, var(E): 0.01905405
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=0.27............. Loss: -0.01532359, mean(E): -21.79409126-0.00031584j, var(E): 0.01873575
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=0.27............. Loss: -0.06555303, mean(E): -21.78448398+0.00012324j, var(E): 0.03782295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=0.27............. Loss: 0.06487888, mean(E): -21.81082690+0.00041432j, var(E): 0.02191774
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=0.27............. Loss: -0.06247822, mean(E): -21.78978007+0.00024357j, var(E): 0.03131899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=0.27............. Loss: -0.02318959, mean(E): -21.79076466+0.00025398j, var(E): 0.02671081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=0.27............. Loss: -0.05289778, mean(E): -21.78595159-0.00070944j, var(E): 0.03537030
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=0.27............. Loss: -0.16932979, mean(E): -21.78291901-0.00037486j, var(E): 0.03184988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=0.27............. Loss: -0.08909700, mean(E): -21.79253557+0.00096530j, var(E): 0.02638650
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=0.27............. Loss: 0.14507649, mean(E): -21.82115682-0.00038027j, var(E): 0.06936593
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=0.27............. Loss: -0.02458504, mean(E): -21.79874469+0.00012526j, var(E): 0.02341836
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=0.27............. Loss: 0.00372276, mean(E): -21.78473243-0.00046099j, var(E): 0.12708860
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=0.27............. Loss: -0.22599066, mean(E): -21.76020208-0.00004654j, var(E): 0.05289937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=0.27............. Loss: -0.03109117, mean(E): -21.77937148+0.00037246j, var(E): 0.03891965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=0.27............. Loss: -0.01526620, mean(E): -21.78854961-0.00029682j, var(E): 0.02441507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=0.27............. Loss: 0.09353674, mean(E): -21.82193417+0.00224333j, var(E): 0.02883962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=0.27............. Loss: 0.03571214, mean(E): -21.80844877+0.00025908j, var(E): 0.01964819
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=0.27............. Loss: 0.04816322, mean(E): -21.81019763+0.00105903j, var(E): 0.01856490
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=0.27............. Loss: -0.14893898, mean(E): -21.77175036+0.00009949j, var(E): 0.05216092
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=0.27............. Loss: 0.01362994, mean(E): -21.80512888-0.00089760j, var(E): 0.01748961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=0.27............. Loss: 0.03446931, mean(E): -21.80558079+0.00075847j, var(E): 0.02838617
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=0.27............. Loss: -0.12042087, mean(E): -21.78624458-0.00118462j, var(E): 0.03883104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=0.27............. Loss: -0.08589981, mean(E): -21.79863643+0.00036584j, var(E): 0.20425914
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=0.27............. Loss: 0.04776598, mean(E): -21.79932194+0.00104963j, var(E): 0.03755186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=0.27............. Loss: -0.13684349, mean(E): -21.77849274+0.00099035j, var(E): 0.03033622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=0.27............. Loss: 0.03465198, mean(E): -21.80769640-0.00073300j, var(E): 0.02839738
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=0.27............. Loss: 0.09518124, mean(E): -21.80441730+0.00028301j, var(E): 0.08205965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=0.27............. Loss: -0.13893100, mean(E): -21.77246993+0.00115075j, var(E): 0.03515331
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=0.27............. Loss: 0.21070946, mean(E): -21.83282611-0.00059591j, var(E): 0.08951721
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=0.27............. Loss: 0.03579300, mean(E): -21.79675004+0.00093347j, var(E): 0.01041450
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=0.27............. Loss: 0.01210738, mean(E): -21.80043919+0.00044762j, var(E): 0.01629464
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=0.27............. Loss: -0.04332206, mean(E): -21.78938742-0.00190685j, var(E): 0.01812489
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=0.27............. Loss: -0.26321348, mean(E): -21.76569135+0.00074278j, var(E): 0.06279053
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=0.27............. Loss: -0.01522504, mean(E): -21.79209899-0.00079820j, var(E): 0.02375722
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=0.27............. Loss: 0.07148632, mean(E): -21.80445038+0.00084822j, var(E): 0.01939063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=0.27............. Loss: -0.08384781, mean(E): -21.79356224+0.00076491j, var(E): 0.03222227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=0.27............. Loss: -0.14122862, mean(E): -21.77170281+0.00018048j, var(E): 0.06293391
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=0.27............. Loss: 0.02030537, mean(E): -21.80366953-0.00003461j, var(E): 0.00652558
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=0.27............. Loss: 0.01070744, mean(E): -21.81693406+0.00036321j, var(E): 0.04345081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=0.27............. Loss: 0.06547111, mean(E): -21.81635957-0.00070951j, var(E): 0.10709136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=0.27............. Loss: -0.07933287, mean(E): -21.78462762+0.00012709j, var(E): 0.03612860
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=0.27............. Loss: 0.03052996, mean(E): -21.79179982+0.00006577j, var(E): 0.07229571
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=0.27............. Loss: -0.14358546, mean(E): -21.77525687+0.00047620j, var(E): 0.14271275
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=0.27............. Loss: 0.03469079, mean(E): -21.81188166+0.00046409j, var(E): 0.02884287
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=0.27............. Loss: 0.04473591, mean(E): -21.80162562-0.00082688j, var(E): 0.04065628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=0.27............. Loss: -0.48974130, mean(E): -21.74470922-0.00022396j, var(E): 0.20049267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=0.27............. Loss: 0.01221280, mean(E): -21.81581957+0.00004652j, var(E): 0.02264653
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=0.3............. Loss: 0.13522800, mean(E): -21.81254530-0.00017935j, var(E): 0.05781086
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=0.27............. Loss: 0.78050692, mean(E): -21.86959983+0.00052179j, var(E): 0.75070469
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=0.27............. Loss: 0.10030899, mean(E): -21.80205223+0.00025504j, var(E): 0.04931333
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=0.27............. Loss: 0.02746146, mean(E): -21.79617998-0.00037631j, var(E): 0.03303579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=0.27............. Loss: 0.25640315, mean(E): -21.83217144+0.00028339j, var(E): 0.13041525
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=0.27............. Loss: 0.06217006, mean(E): -21.80580987+0.00013544j, var(E): 0.02549769
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=0.27............. Loss: -0.03727019, mean(E): -21.80081868+0.00038498j, var(E): 0.03104441
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=0.27............. Loss: 0.13429627, mean(E): -21.82505343+0.00029604j, var(E): 0.03096587
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=0.27............. Loss: -0.00379403, mean(E): -21.79660285+0.00013444j, var(E): 0.03256067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=0.27............. Loss: 0.13679008, mean(E): -21.80361839-0.00014194j, var(E): 0.06740875
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=0.27............. Loss: 0.06905936, mean(E): -21.81375561-0.00030488j, var(E): 0.03403091
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=0.27............. Loss: -0.07216988, mean(E): -21.79959302+0.00021493j, var(E): 0.02320446
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=0.27............. Loss: -0.10786704, mean(E): -21.79004460+0.00003681j, var(E): 0.02871203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=0.27............. Loss: -0.00054742, mean(E): -21.80486985+0.00007238j, var(E): 0.01582849
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=0.27............. Loss: -0.17445686, mean(E): -21.76919885-0.00005453j, var(E): 0.04425358
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=0.27............. Loss: 0.20622828, mean(E): -21.81623449+0.00016596j, var(E): 0.04531366
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=0.27............. Loss: -0.04803885, mean(E): -21.79522508-0.00009463j, var(E): 0.02199442
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=0.27............. Loss: -0.17610064, mean(E): -21.77053804-0.00009503j, var(E): 0.02657024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=0.27............. Loss: -0.18402987, mean(E): -21.76632167-0.00024053j, var(E): 0.08231251
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=0.27............. Loss: -0.15425284, mean(E): -21.77003836+0.00026370j, var(E): 0.05854284
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=0.27............. Loss: 0.07700032, mean(E): -21.81034021-0.00014757j, var(E): 0.01510831
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=0.27............. Loss: 0.00626989, mean(E): -21.79393570-0.00015143j, var(E): 0.01955010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=0.27............. Loss: -0.20055451, mean(E): -21.76404120-0.00006581j, var(E): 0.13149063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=0.27............. Loss: -0.02356732, mean(E): -21.79085666+0.00025773j, var(E): 0.01794694
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=0.27............. Loss: -0.02277478, mean(E): -21.79546021+0.00024554j, var(E): 0.03488083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=0.27............. Loss: -0.00769509, mean(E): -21.80163673+0.00019882j, var(E): 0.04602323
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=0.27............. Loss: 0.06265574, mean(E): -21.79990918+0.00012719j, var(E): 0.01137975
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=0.27............. Loss: 0.06333250, mean(E): -21.79599543+0.00037987j, var(E): 0.04068915
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=0.27............. Loss: -0.06812761, mean(E): -21.79338205-0.00095785j, var(E): 0.01952798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=0.27............. Loss: 0.04199416, mean(E): -21.80885576+0.00012182j, var(E): 0.02321970
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=0.27............. Loss: 0.16002694, mean(E): -21.79599574-0.00145810j, var(E): 0.04103109
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=0.27............. Loss: -0.04698964, mean(E): -21.78264565+0.00096474j, var(E): 0.02685205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=0.27............. Loss: 0.00128009, mean(E): -21.79954387-0.00114362j, var(E): 0.01760832
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=0.27............. Loss: -0.18322715, mean(E): -21.77405101-0.00072578j, var(E): 0.13854892
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=0.27............. Loss: 0.08044586, mean(E): -21.81071579-0.00044522j, var(E): 0.03892096
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=0.27............. Loss: 0.04073395, mean(E): -21.79921333+0.00072512j, var(E): 0.02610175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=0.27............. Loss: -0.17126651, mean(E): -21.77532799+0.00002148j, var(E): 0.07989578
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=0.27............. Loss: 0.06392889, mean(E): -21.80210205-0.00088164j, var(E): 0.01771458
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=0.27............. Loss: 0.01815503, mean(E): -21.80534595+0.00058462j, var(E): 0.02135645
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=0.27............. Loss: 0.12658121, mean(E): -21.81538880-0.00047709j, var(E): 0.04958207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=0.27............. Loss: 0.15015973, mean(E): -21.82132104+0.00073781j, var(E): 0.04930763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=0.27............. Loss: -0.10372787, mean(E): -21.78696616+0.00004128j, var(E): 0.05596865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=0.27............. Loss: -0.02698952, mean(E): -21.79900511+0.00056831j, var(E): 0.08348608
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=0.27............. Loss: 0.09752782, mean(E): -21.81867798-0.00103853j, var(E): 0.02794071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=0.27............. Loss: -0.02609338, mean(E): -21.79879979-0.00109396j, var(E): 0.02031150
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=0.27............. Loss: -0.03883498, mean(E): -21.79633742-0.00040538j, var(E): 0.07180936
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=0.27............. Loss: 0.08856670, mean(E): -21.80580710+0.00125899j, var(E): 0.03561580
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=0.27............. Loss: 0.03124536, mean(E): -21.80235646+0.00027827j, var(E): 0.02310087
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=0.27............. Loss: 0.03551236, mean(E): -21.80509807-0.00032464j, var(E): 0.02029162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=0.27............. Loss: -0.03715319, mean(E): -21.78989126+0.00177369j, var(E): 0.02941881
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=0.27............. Loss: -0.08238348, mean(E): -21.79982644+0.00009600j, var(E): 0.02406808
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=0.27............. Loss: -0.22161584, mean(E): -21.77525812-0.00242922j, var(E): 0.11805971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=0.27............. Loss: -0.64318013, mean(E): -21.72240451-0.00004349j, var(E): 0.44667545
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=0.27............. Loss: -0.00331073, mean(E): -21.79958796+0.00044583j, var(E): 0.02135401
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=0.27............. Loss: -0.07683283, mean(E): -21.78309230+0.00069519j, var(E): 0.02970863
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=0.27............. Loss: 0.16804278, mean(E): -21.82391534+0.00032922j, var(E): 0.04346125
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=0.27............. Loss: 0.02139979, mean(E): -21.80562965+0.00014429j, var(E): 0.03091132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=0.27............. Loss: -0.02222265, mean(E): -21.79409184-0.00049796j, var(E): 0.04814488
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=0.27............. Loss: 0.05503982, mean(E): -21.79735788+0.00021551j, var(E): 0.09583429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=0.27............. Loss: -0.07478599, mean(E): -21.78332333+0.00106349j, var(E): 0.01544656
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=0.27............. Loss: -0.00089550, mean(E): -21.79727354-0.00147585j, var(E): 0.00738506
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=0.27............. Loss: -0.31268133, mean(E): -21.77776075+0.00080478j, var(E): 0.09352181
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=0.27............. Loss: 0.03373632, mean(E): -21.79317691-0.00020348j, var(E): 0.02962496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=0.27............. Loss: 0.06228504, mean(E): -21.80029059-0.00018714j, var(E): 0.04624847
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=0.27............. Loss: 0.28631783, mean(E): -21.80840867+0.00044286j, var(E): 0.18317075
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=0.27............. Loss: 0.01076768, mean(E): -21.79360986+0.00040802j, var(E): 0.06391301
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=0.27............. Loss: 0.01326563, mean(E): -21.80719443+0.00038432j, var(E): 0.03743600
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=0.27............. Loss: -0.05982815, mean(E): -21.78003233+0.00143534j, var(E): 0.03501757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=0.27............. Loss: -0.12955689, mean(E): -21.78804426-0.00036143j, var(E): 0.04224911
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=0.27............. Loss: -0.06294592, mean(E): -21.79802035-0.00215910j, var(E): 0.04886243
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=0.27............. Loss: 0.10306909, mean(E): -21.80352070+0.00026753j, var(E): 0.02580649
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=0.27............. Loss: -0.11091999, mean(E): -21.78440784-0.00048936j, var(E): 0.07225489
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=0.27............. Loss: 0.02915273, mean(E): -21.79997767+0.00010174j, var(E): 0.02699890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=0.27............. Loss: 0.08663292, mean(E): -21.81022700-0.00017546j, var(E): 0.03927971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=0.27............. Loss: -0.03832284, mean(E): -21.77824213+0.00018664j, var(E): 0.02029417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=0.27............. Loss: -0.01565347, mean(E): -21.79896911+0.00003930j, var(E): 0.02085695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=0.27............. Loss: -0.00640038, mean(E): -21.80116057+0.00108171j, var(E): 0.01240821
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=0.27............. Loss: 0.05428529, mean(E): -21.81175393-0.00054713j, var(E): 0.02591599
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=0.27............. Loss: 0.00333296, mean(E): -21.79727338+0.00050701j, var(E): 0.01842845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=0.27............. Loss: 0.04654318, mean(E): -21.78932163+0.00073771j, var(E): 0.07666555
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=0.27............. Loss: 0.03635287, mean(E): -21.79301462-0.00034025j, var(E): 0.03595351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=0.27............. Loss: -0.04558678, mean(E): -21.80068533-0.00000443j, var(E): 0.02859468
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=0.27............. Loss: -0.03263302, mean(E): -21.78245203-0.00045514j, var(E): 0.01806944
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=0.27............. Loss: 0.10158203, mean(E): -21.81562609-0.00015770j, var(E): 0.02371312
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=0.27............. Loss: 0.04782982, mean(E): -21.80047697-0.00101262j, var(E): 0.01839985
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=0.27............. Loss: -0.04536152, mean(E): -21.78930368+0.00041194j, var(E): 0.01847802
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=0.27............. Loss: -0.00450111, mean(E): -21.80140540+0.00044927j, var(E): 0.01711598
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=0.27............. Loss: -0.12239736, mean(E): -21.78474192-0.00094822j, var(E): 0.02679778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=0.27............. Loss: 0.07992378, mean(E): -21.80508074-0.00082463j, var(E): 0.04505778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=0.27............. Loss: 0.10769263, mean(E): -21.80677170+0.00002935j, var(E): 0.15633560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=0.27............. Loss: 0.09823305, mean(E): -21.81389139+0.00063312j, var(E): 0.02826923
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=0.27............. Loss: -0.01900703, mean(E): -21.79731458-0.00034937j, var(E): 0.01231786
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=0.27............. Loss: -0.00134430, mean(E): -21.82220706-0.00052897j, var(E): 0.03328899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=0.27............. Loss: 0.02812616, mean(E): -21.79546996+0.00053361j, var(E): 0.03094407
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=0.27............. Loss: 0.00879977, mean(E): -21.79988599-0.00027202j, var(E): 0.04493525
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=0.27............. Loss: 0.09455444, mean(E): -21.80019585-0.00075027j, var(E): 0.05713643
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=0.27............. Loss: 0.06829759, mean(E): -21.80294659-0.00049614j, var(E): 0.02340961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=0.27............. Loss: 0.14740205, mean(E): -21.81695684-0.00028864j, var(E): 0.05649456
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=0.27............. Loss: 0.18193309, mean(E): -21.82675743+0.00001824j, var(E): 0.13559565
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=0.27............. Loss: 0.07559265, mean(E): -21.81305484+0.00028281j, var(E): 0.02880357
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=0.27............. Loss: -0.06783154, mean(E): -21.78373545+0.00140974j, var(E): 0.00920212
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=0.27............. Loss: -0.01345729, mean(E): -21.79892684+0.00028464j, var(E): 0.01653688
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=0.27............. Loss: 0.02239288, mean(E): -21.79370783+0.00027937j, var(E): 0.08628783
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=0.27............. Loss: -0.11116498, mean(E): -21.79040786-0.00002669j, var(E): 0.03345396
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=0.27............. Loss: -0.00304243, mean(E): -21.81607977-0.00007177j, var(E): 0.01782734
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=0.27............. Loss: -0.00194175, mean(E): -21.80234715-0.00002092j, var(E): 0.01955958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=0.27............. Loss: -0.01311952, mean(E): -21.80371775+0.00012972j, var(E): 0.04869562
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=0.27............. Loss: -0.01660752, mean(E): -21.79781209+0.00003159j, var(E): 0.02574394
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=0.27............. Loss: 0.04896960, mean(E): -21.80613514-0.00027846j, var(E): 0.01259453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=0.27............. Loss: 0.06997165, mean(E): -21.81709154-0.00016075j, var(E): 0.04049764
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=0.27............. Loss: -0.10108733, mean(E): -21.78547411-0.00015814j, var(E): 0.03849329
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=0.27............. Loss: -0.02335453, mean(E): -21.79005826+0.00005839j, var(E): 0.01577715
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=0.27............. Loss: 0.03920221, mean(E): -21.80787069+0.00019403j, var(E): 0.00974340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=0.27............. Loss: -0.00812145, mean(E): -21.79346595+0.00017221j, var(E): 0.01391054
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=0.27............. Loss: -0.04884218, mean(E): -21.79400256-0.00019424j, var(E): 0.01959138
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=0.27............. Loss: 0.01934259, mean(E): -21.80489510-0.00005954j, var(E): 0.01743047
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=0.27............. Loss: 0.01692686, mean(E): -21.80934143+0.00025070j, var(E): 0.01670250
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=0.27............. Loss: -0.01541737, mean(E): -21.79883174-0.00024261j, var(E): 0.01141353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=0.27............. Loss: -0.04201846, mean(E): -21.79550476-0.00047595j, var(E): 0.02378220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=0.27............. Loss: 0.01356118, mean(E): -21.80114595-0.00000158j, var(E): 0.01349100
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=0.27............. Loss: -0.04254823, mean(E): -21.79250849-0.00003350j, var(E): 0.02227646
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=0.27............. Loss: -0.02425150, mean(E): -21.79301990+0.00011740j, var(E): 0.00666285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=0.27............. Loss: -0.02391386, mean(E): -21.79531158+0.00001116j, var(E): 0.01700467
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=0.27............. Loss: -0.11171171, mean(E): -21.78120805-0.00000781j, var(E): 0.03265907
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=0.27............. Loss: 0.04682143, mean(E): -21.80238511-0.00005611j, var(E): 0.01611443
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=0.27............. Loss: -0.02002774, mean(E): -21.78332989+0.00013317j, var(E): 0.01216602
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=0.27............. Loss: -0.18942399, mean(E): -21.78147678+0.00003210j, var(E): 0.03723429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=0.27............. Loss: -0.22112420, mean(E): -21.77585669-0.00004258j, var(E): 0.04687786
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=0.27............. Loss: 0.05692534, mean(E): -21.81231190-0.00018506j, var(E): 0.03356081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=0.27............. Loss: 0.01499590, mean(E): -21.80776522+0.00000287j, var(E): 0.02013610
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=0.27............. Loss: 0.00630323, mean(E): -21.80333760-0.00003763j, var(E): 0.02557690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=0.27............. Loss: -0.06233599, mean(E): -21.79348176+0.00033384j, var(E): 0.02043022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=0.27............. Loss: -0.09589990, mean(E): -21.78743174+0.00008702j, var(E): 0.02068613
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=0.27............. Loss: 0.07213929, mean(E): -21.80267831+0.00007271j, var(E): 0.02644121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=0.27............. Loss: -0.05677092, mean(E): -21.78546556+0.00002147j, var(E): 0.02272684
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=0.27............. Loss: -0.01245959, mean(E): -21.80009596-0.00020449j, var(E): 0.01959478
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=0.27............. Loss: 0.03148794, mean(E): -21.80342342+0.00037441j, var(E): 0.01017754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=0.27............. Loss: -0.02707760, mean(E): -21.80092877+0.00009837j, var(E): 0.02577692
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=0.27............. Loss: 0.02737997, mean(E): -21.79195686+0.00039511j, var(E): 0.01076971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=0.27............. Loss: -0.15864889, mean(E): -21.78882661+0.00031458j, var(E): 0.03787039
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=0.27............. Loss: 0.01741100, mean(E): -21.80436589+0.00030413j, var(E): 0.01355208
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=0.27............. Loss: 0.04107719, mean(E): -21.81547816+0.00027525j, var(E): 0.02421799
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=0.27............. Loss: 0.05456388, mean(E): -21.81442027-0.00015811j, var(E): 0.04145833
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=0.27............. Loss: 0.06719642, mean(E): -21.81451080+0.00017276j, var(E): 0.01711140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=0.27............. Loss: -0.03470027, mean(E): -21.79481115+0.00014705j, var(E): 0.04197478
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=0.27............. Loss: 0.05133295, mean(E): -21.80521996+0.00009140j, var(E): 0.02164717
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=0.27............. Loss: 0.25854180, mean(E): -21.82083182+0.00003133j, var(E): 0.11822458
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=0.27............. Loss: -0.02839862, mean(E): -21.80603904+0.00012515j, var(E): 0.02820773
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=0.27............. Loss: -0.03324714, mean(E): -21.80294667+0.00017034j, var(E): 0.02381837
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=0.27............. Loss: 0.02022079, mean(E): -21.79574318+0.00014625j, var(E): 0.01463549
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=0.27............. Loss: -0.02165090, mean(E): -21.80293451-0.00000837j, var(E): 0.03012582
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=0.27............. Loss: 0.16989343, mean(E): -21.82445049-0.00037848j, var(E): 0.08447834
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=0.27............. Loss: -0.03269102, mean(E): -21.79075754-0.00032336j, var(E): 0.02277745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=0.27............. Loss: 0.14087815, mean(E): -21.82097915-0.00031155j, var(E): 0.04060166
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=0.26............. Loss: -0.19259280, mean(E): -21.78371673-0.00024722j, var(E): 0.04440188
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=0.26............. Loss: -0.10749096, mean(E): -21.77393913+0.00037091j, var(E): 0.01523761
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=0.26............. Loss: -0.01033981, mean(E): -21.79480606-0.00018036j, var(E): 0.02083609
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=0.26............. Loss: 0.06949042, mean(E): -21.80882096+0.00009321j, var(E): 0.02619322
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=0.27............. Loss: -0.01968978, mean(E): -21.79295972+0.00007525j, var(E): 0.01291910
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=0.26............. Loss: -0.01508984, mean(E): -21.79294913+0.00073695j, var(E): 0.01225365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=0.26............. Loss: -0.03977439, mean(E): -21.79527894+0.00011428j, var(E): 0.01300984
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=0.26............. Loss: 0.05042917, mean(E): -21.80844222-0.00014593j, var(E): 0.01886703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=0.26............. Loss: 0.07429425, mean(E): -21.80947169+0.00082696j, var(E): 0.02620556
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=0.27............. Loss: -0.00736249, mean(E): -21.80540935+0.00037083j, var(E): 0.01067840
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=0.26............. Loss: -0.06760143, mean(E): -21.79182525-0.00016964j, var(E): 0.02893234
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=0.26............. Loss: 0.05275770, mean(E): -21.80847838-0.00000091j, var(E): 0.04640558
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=0.27............. Loss: -0.06088707, mean(E): -21.79850492+0.00047094j, var(E): 0.01600064
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=0.27............. Loss: 0.00043125, mean(E): -21.78232960+0.00067595j, var(E): 0.06609429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=0.27............. Loss: -0.00318869, mean(E): -21.81150683-0.00154556j, var(E): 0.01720756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=0.27............. Loss: 0.08344359, mean(E): -21.80980296+0.00067950j, var(E): 0.02591777
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=0.27............. Loss: -0.05770753, mean(E): -21.79273494-0.00071575j, var(E): 0.01769031
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=0.26............. Loss: 0.01813637, mean(E): -21.80088674-0.00079960j, var(E): 0.01358322
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=0.27............. Loss: -0.05116875, mean(E): -21.79661319+0.00058582j, var(E): 0.06601520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=0.27............. Loss: 0.02724402, mean(E): -21.79735701-0.00108356j, var(E): 0.01840896
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=0.27............. Loss: -0.00243811, mean(E): -21.79066472+0.00223042j, var(E): 0.02884210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=0.27............. Loss: -0.43783060, mean(E): -21.74769200-0.00052907j, var(E): 0.18575249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=0.27............. Loss: -0.01702926, mean(E): -21.78663774+0.00155930j, var(E): 0.01829271
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=0.27............. Loss: 0.31032299, mean(E): -21.83884195-0.00047679j, var(E): 0.16494690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=0.27............. Loss: -0.10218878, mean(E): -21.79309583+0.00058154j, var(E): 0.06240435
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=0.26............. Loss: 0.03073926, mean(E): -21.80535505+0.00120227j, var(E): 0.02365741
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=0.27............. Loss: 0.04705930, mean(E): -21.81757293+0.00147687j, var(E): 0.02437363
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=0.26............. Loss: -0.15119397, mean(E): -21.79016894-0.00135941j, var(E): 0.07588920
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=0.27............. Loss: 0.07003781, mean(E): -21.79929767+0.00061691j, var(E): 0.13023839
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=0.27............. Loss: -0.14375480, mean(E): -21.76814028+0.00068371j, var(E): 0.09913640
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=0.26............. Loss: -0.10785490, mean(E): -21.78140722-0.00036548j, var(E): 0.06075831
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=0.27............. Loss: 0.04691055, mean(E): -21.80207963-0.00043074j, var(E): 0.03124918
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=0.27............. Loss: 0.02723249, mean(E): -21.80331362+0.00032439j, var(E): 0.01184197
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=0.27............. Loss: 0.06814373, mean(E): -21.80547601+0.00000222j, var(E): 0.01522914
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=0.27............. Loss: 0.02699249, mean(E): -21.80011375-0.00007873j, var(E): 0.01320169
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=0.27............. Loss: 0.17957891, mean(E): -21.82039916-0.00096478j, var(E): 0.03279162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=0.27............. Loss: -0.02058908, mean(E): -21.79492524-0.00092213j, var(E): 0.01368534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=0.27............. Loss: -0.11988517, mean(E): -21.76743247+0.00020978j, var(E): 0.04038070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=0.26............. Loss: 0.22409684, mean(E): -21.81805727-0.00073080j, var(E): 0.06075518
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=0.27............. Loss: 0.06969495, mean(E): -21.80820571-0.00027483j, var(E): 0.02988692
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=0.26............. Loss: 0.07695964, mean(E): -21.80790482-0.00053381j, var(E): 0.03871939
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=0.27............. Loss: 0.04401697, mean(E): -21.80137308-0.00006958j, var(E): 0.01713345
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=0.27............. Loss: 0.12069206, mean(E): -21.82030559+0.00043601j, var(E): 0.02471273
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=0.27............. Loss: 0.28890209, mean(E): -21.82722769-0.00034159j, var(E): 0.16757179
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=0.27............. Loss: 0.02902647, mean(E): -21.79558683+0.00013343j, var(E): 0.01690267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=0.26............. Loss: -0.02173844, mean(E): -21.79886044+0.00032496j, var(E): 0.01104542
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=0.26............. Loss: 0.02433641, mean(E): -21.80100967-0.00012016j, var(E): 0.01846975
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=0.27............. Loss: -0.00005453, mean(E): -21.79129512-0.00004946j, var(E): 0.03495224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=0.27............. Loss: -0.03925991, mean(E): -21.78886817-0.00021584j, var(E): 0.03828787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=0.27............. Loss: -0.01911025, mean(E): -21.79771449+0.00020552j, var(E): 0.01679989
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=0.27............. Loss: -0.16374727, mean(E): -21.77405334-0.00003112j, var(E): 0.03770613
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=0.27............. Loss: 0.02062451, mean(E): -21.79955244+0.00004343j, var(E): 0.05353290
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=0.26............. Loss: 0.05182485, mean(E): -21.80124719+0.00082139j, var(E): 0.03767109
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=0.26............. Loss: -0.24487734, mean(E): -21.76848928-0.00034397j, var(E): 0.08367646
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=0.26............. Loss: 0.03158591, mean(E): -21.80756897-0.00044706j, var(E): 0.00725642
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=0.27............. Loss: 0.07756158, mean(E): -21.82062917-0.00028175j, var(E): 0.02504827
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=0.27............. Loss: 0.02170346, mean(E): -21.79826892-0.00014414j, var(E): 0.02210913
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=0.26............. Loss: -0.02083788, mean(E): -21.79583972+0.00020338j, var(E): 0.01208910
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=0.26............. Loss: -0.02726865, mean(E): -21.79615325-0.00004775j, var(E): 0.01640958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=0.27............. Loss: -0.20932346, mean(E): -21.77885047+0.00089894j, var(E): 0.10296246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=0.27............. Loss: 0.02001408, mean(E): -21.79285974+0.00073815j, var(E): 0.03211015
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=0.26............. Loss: -0.03052603, mean(E): -21.79246810-0.00001612j, var(E): 0.01467943
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=0.27............. Loss: -0.10327270, mean(E): -21.78859494-0.00043615j, var(E): 0.03934932
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=0.26............. Loss: -0.07525390, mean(E): -21.79349147+0.00006264j, var(E): 0.05908810
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=0.26............. Loss: 0.09434018, mean(E): -21.81378675+0.00098327j, var(E): 0.01829369
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=0.26............. Loss: -0.12470959, mean(E): -21.79174643-0.00030491j, var(E): 0.05720872
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=0.26............. Loss: 0.06774620, mean(E): -21.81013923-0.00060845j, var(E): 0.01301444
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=0.27............. Loss: 0.03959731, mean(E): -21.80790621+0.00049476j, var(E): 0.03345056
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=0.26............. Loss: -0.08335402, mean(E): -21.78672832+0.00043913j, var(E): 0.07278826
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=0.26............. Loss: 0.03159477, mean(E): -21.80981409-0.00093336j, var(E): 0.00921317
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=0.27............. Loss: -0.03635104, mean(E): -21.79960414-0.00015543j, var(E): 0.03141548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=0.27............. Loss: -0.02006151, mean(E): -21.79500434+0.00074601j, var(E): 0.00997234
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=0.27............. Loss: 0.00149525, mean(E): -21.79947216-0.00035921j, var(E): 0.02189344
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=0.27............. Loss: -0.05170779, mean(E): -21.80019201+0.00029751j, var(E): 0.04263136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=0.27............. Loss: 0.03555098, mean(E): -21.80765370+0.00008950j, var(E): 0.01457321
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=0.27............. Loss: -0.03398879, mean(E): -21.79516918-0.00031516j, var(E): 0.06369716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=0.27............. Loss: 0.04306914, mean(E): -21.81093947+0.00004170j, var(E): 0.02094844
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=0.27............. Loss: 0.08203088, mean(E): -21.80782679-0.00081095j, var(E): 0.04939610
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=0.27............. Loss: 0.19219070, mean(E): -21.83171246-0.00008492j, var(E): 0.05956379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=0.27............. Loss: -0.01644213, mean(E): -21.79548930+0.00058646j, var(E): 0.03813407
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=0.27............. Loss: -0.14409227, mean(E): -21.77146969+0.00017753j, var(E): 0.08132221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=0.27............. Loss: 0.49774531, mean(E): -21.85501619-0.00098269j, var(E): 0.20480365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=0.27............. Loss: 0.04151842, mean(E): -21.79132212+0.00000374j, var(E): 0.01516568
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=0.26............. Loss: -0.03614184, mean(E): -21.78525172-0.00042716j, var(E): 0.02060200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=0.27............. Loss: 0.05500299, mean(E): -21.80553920-0.00041800j, var(E): 0.02541178
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=0.27............. Loss: 0.00592406, mean(E): -21.81735808+0.00007322j, var(E): 0.01521709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=0.27............. Loss: 0.07930017, mean(E): -21.81418883-0.00073573j, var(E): 0.02170601
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=0.27............. Loss: -0.06938055, mean(E): -21.80101453+0.00015791j, var(E): 0.03262919
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=0.27............. Loss: -0.12517179, mean(E): -21.78515376+0.00041062j, var(E): 0.03729848
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=0.27............. Loss: -0.07104789, mean(E): -21.77725242-0.00018595j, var(E): 0.03419003
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=0.27............. Loss: 0.00691740, mean(E): -21.80224108+0.00010274j, var(E): 0.01323716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=0.27............. Loss: -0.07371373, mean(E): -21.79262763-0.00012336j, var(E): 0.02010184
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=0.27............. Loss: 0.01029120, mean(E): -21.80428388-0.00016556j, var(E): 0.01607760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=0.27............. Loss: 0.03336854, mean(E): -21.80132647+0.00167150j, var(E): 0.01931768
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=0.27............. Loss: 0.11869022, mean(E): -21.81886220+0.00114788j, var(E): 0.04657067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=0.27............. Loss: 0.02817860, mean(E): -21.81141880-0.00130333j, var(E): 0.03359445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=0.27............. Loss: 0.04914765, mean(E): -21.80964850-0.00112289j, var(E): 0.06116815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=0.27............. Loss: 0.05463709, mean(E): -21.80337866-0.00080337j, var(E): 0.03369279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=0.27............. Loss: 0.10056528, mean(E): -21.80421927+0.00263623j, var(E): 0.02343996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=0.27............. Loss: 0.15608830, mean(E): -21.80989577+0.00067906j, var(E): 0.05382059
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=0.27............. Loss: 0.05330460, mean(E): -21.80225537-0.00162309j, var(E): 0.01292439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=0.27............. Loss: -0.05318968, mean(E): -21.78536263+0.00018070j, var(E): 0.01495682
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=0.27............. Loss: 0.00728455, mean(E): -21.79530693-0.00148726j, var(E): 0.02326659
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=0.27............. Loss: -0.00791418, mean(E): -21.79557483+0.00093759j, var(E): 0.01102475
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=0.27............. Loss: 0.10238324, mean(E): -21.81469243-0.00095718j, var(E): 0.08014297
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=0.26............. Loss: -0.02297832, mean(E): -21.79538094+0.00002271j, var(E): 0.02337383
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=0.27............. Loss: -0.04426410, mean(E): -21.79569773+0.00019142j, var(E): 0.03940510
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=0.27............. Loss: 0.14785362, mean(E): -21.82079280+0.00063324j, var(E): 0.06664270
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=0.27............. Loss: -0.01130557, mean(E): -21.80040989+0.00014499j, var(E): 0.03744705
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=0.27............. Loss: 0.01260915, mean(E): -21.80189550+0.00030847j, var(E): 0.02934132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=0.27............. Loss: -0.03422421, mean(E): -21.80034422-0.00003496j, var(E): 0.02068243
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=0.27............. Loss: 0.00895253, mean(E): -21.80410975+0.00012205j, var(E): 0.02297127
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=0.27............. Loss: 0.70654777, mean(E): -21.85334982-0.00042953j, var(E): 0.43096145
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=0.27............. Loss: 0.04678789, mean(E): -21.79689843+0.00127273j, var(E): 0.04004904
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=0.27............. Loss: -0.05248772, mean(E): -21.79162914-0.00089105j, var(E): 0.02329511
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=0.27............. Loss: 0.00372954, mean(E): -21.81148097+0.00069094j, var(E): 0.02946423
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=0.27............. Loss: 0.00467578, mean(E): -21.79394505-0.00034347j, var(E): 0.05474219
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=0.27............. Loss: -0.01825687, mean(E): -21.80155644+0.00006434j, var(E): 0.01265409
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=0.27............. Loss: 0.02894573, mean(E): -21.80315410+0.00022957j, var(E): 0.05919136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=0.27............. Loss: 0.03672452, mean(E): -21.80857955-0.00027528j, var(E): 0.05122509
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=0.27............. Loss: 0.10405102, mean(E): -21.81467890-0.00067802j, var(E): 0.02519248
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=0.27............. Loss: -0.05583495, mean(E): -21.78970159-0.00004870j, var(E): 0.06926607
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=0.27............. Loss: -0.05728830, mean(E): -21.78289067+0.00089540j, var(E): 0.02966086
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=0.27............. Loss: -0.13764158, mean(E): -21.79467147+0.00017069j, var(E): 0.03653676
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=0.27............. Loss: 0.02846468, mean(E): -21.78847654+0.00016268j, var(E): 0.03008858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=0.27............. Loss: -0.07477516, mean(E): -21.78771961+0.00019754j, var(E): 0.04943229
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=0.26............. Loss: -0.03107353, mean(E): -21.79621623+0.00022543j, var(E): 0.12272390
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=0.27............. Loss: 0.06749541, mean(E): -21.80550217-0.00008793j, var(E): 0.01768314
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=0.27............. Loss: 0.09263788, mean(E): -21.81894721-0.00081760j, var(E): 0.01908541
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=0.26............. Loss: -0.12542190, mean(E): -21.78946154+0.00028795j, var(E): 0.04803082
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=0.27............. Loss: -0.08416725, mean(E): -21.80178174+0.00031954j, var(E): 0.05577716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=0.27............. Loss: -0.01798675, mean(E): -21.79241944+0.00015518j, var(E): 0.01502116
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=0.27............. Loss: -0.05917292, mean(E): -21.79436368+0.00046755j, var(E): 0.01548057
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=0.27............. Loss: -0.01999707, mean(E): -21.80530616-0.00023898j, var(E): 0.02878421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=0.27............. Loss: -0.05450797, mean(E): -21.79080229+0.00017809j, var(E): 0.00948041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=0.26............. Loss: -0.05639690, mean(E): -21.79630299+0.00040408j, var(E): 0.01300369
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=0.26............. Loss: -0.01452254, mean(E): -21.79736465+0.00033316j, var(E): 0.01347761
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=0.26............. Loss: -0.01198438, mean(E): -21.79721260+0.00016342j, var(E): 0.00550060
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=0.27............. Loss: 0.08498440, mean(E): -21.79290316+0.00063421j, var(E): 0.06078158
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=0.27............. Loss: 0.16404491, mean(E): -21.81264285-0.00032894j, var(E): 0.02685798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=0.26............. Loss: 0.04212119, mean(E): -21.81516903+0.00033845j, var(E): 0.01825413
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=0.27............. Loss: -0.16171330, mean(E): -21.77748624-0.00079758j, var(E): 0.03438790
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=0.27............. Loss: 0.02766289, mean(E): -21.80319521+0.00052035j, var(E): 0.01154803
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=0.27............. Loss: -0.07547463, mean(E): -21.78768696-0.00007367j, var(E): 0.06494344
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=0.27............. Loss: -0.00932829, mean(E): -21.79317282-0.00077597j, var(E): 0.00749295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=0.27............. Loss: 0.05930912, mean(E): -21.80478966+0.00032136j, var(E): 0.01950472
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=0.26............. Loss: -0.00473871, mean(E): -21.78645096-0.00020784j, var(E): 0.00769457
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=0.27............. Loss: 0.08219554, mean(E): -21.80661197-0.00011844j, var(E): 0.01384001
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=0.27............. Loss: 0.21698651, mean(E): -21.82319171-0.00000042j, var(E): 0.05074016
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=0.27............. Loss: 0.00551674, mean(E): -21.80279840+0.00031208j, var(E): 0.00750160
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=0.27............. Loss: -0.06378181, mean(E): -21.78756008+0.00022376j, var(E): 0.02527156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=0.26............. Loss: -0.02931157, mean(E): -21.79391597+0.00005850j, var(E): 0.03277327
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=0.26............. Loss: 0.11480616, mean(E): -21.81698270+0.00010852j, var(E): 0.07254283
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=0.27............. Loss: 0.02028683, mean(E): -21.79581603+0.00009464j, var(E): 0.00917781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=0.27............. Loss: 0.15517047, mean(E): -21.83132361-0.00025274j, var(E): 0.02924021
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=0.27............. Loss: -0.14107569, mean(E): -21.77264182-0.00013346j, var(E): 0.13006801
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=0.27............. Loss: -0.03527453, mean(E): -21.79056929-0.00010978j, var(E): 0.01666039
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=0.27............. Loss: 0.09853217, mean(E): -21.81501395-0.00014509j, var(E): 0.05361857
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=0.26............. Loss: 0.02770236, mean(E): -21.81041492+0.00042665j, var(E): 0.01570493
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=0.26............. Loss: -0.03633201, mean(E): -21.79299385+0.00011807j, var(E): 0.01395356
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=0.27............. Loss: 0.06949438, mean(E): -21.80367343-0.00041306j, var(E): 0.02421851
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=0.27............. Loss: -0.01640070, mean(E): -21.80270146+0.00025686j, var(E): 0.01591520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=0.27............. Loss: -0.12547849, mean(E): -21.78454139-0.00031028j, var(E): 0.06633509
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=0.26............. Loss: 0.00857731, mean(E): -21.80586945+0.00006144j, var(E): 0.00906138
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=0.26............. Loss: -0.13366060, mean(E): -21.77659888+0.00022864j, var(E): 0.04894165
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=0.26............. Loss: 0.00755446, mean(E): -21.79398691+0.00021869j, var(E): 0.01528200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=0.27............. Loss: 0.12429460, mean(E): -21.82209411+0.00043294j, var(E): 0.04167503
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=0.27............. Loss: 0.06182539, mean(E): -21.80878706-0.00015940j, var(E): 0.01253253
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=0.27............. Loss: -0.07803016, mean(E): -21.80078413-0.00043571j, var(E): 0.02096496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=0.27............. Loss: 0.93216398, mean(E): -21.88654478+0.00049305j, var(E): 1.57412706
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=0.26............. Loss: -0.09500496, mean(E): -21.79141869-0.00000466j, var(E): 0.03120156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=0.27............. Loss: 0.07678821, mean(E): -21.81020368-0.00009324j, var(E): 0.03059806
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=0.27............. Loss: 0.03795824, mean(E): -21.80459309+0.00027282j, var(E): 0.01719047
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=0.27............. Loss: -0.01337680, mean(E): -21.79860066+0.00007711j, var(E): 0.01369096
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=0.26............. Loss: 0.01745519, mean(E): -21.79844290+0.00005018j, var(E): 0.02206133
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=0.27............. Loss: 0.01377502, mean(E): -21.79893356-0.00008238j, var(E): 0.03168760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=0.27............. Loss: 0.02729458, mean(E): -21.80518698-0.00009956j, var(E): 0.01037969
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=0.27............. Loss: 0.00326636, mean(E): -21.80631836-0.00087056j, var(E): 0.01583709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=0.26............. Loss: 0.06032308, mean(E): -21.81777039-0.00009416j, var(E): 0.02091904
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=0.26............. Loss: -0.02977805, mean(E): -21.79349266-0.00263755j, var(E): 0.02003715
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=0.26............. Loss: -0.01863152, mean(E): -21.79455301+0.00006679j, var(E): 0.01180068
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=0.27............. Loss: -0.07855619, mean(E): -21.77937029-0.00123464j, var(E): 0.03949883
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=0.27............. Loss: -0.00628159, mean(E): -21.80027797-0.00027280j, var(E): 0.01931733
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=0.27............. Loss: 0.04415174, mean(E): -21.82876703-0.00087484j, var(E): 0.02664876
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=0.27............. Loss: -0.00317577, mean(E): -21.79284213-0.00026321j, var(E): 0.01092928
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=0.26............. Loss: -0.02912354, mean(E): -21.81188522-0.00020375j, var(E): 0.02158188
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=0.27............. Loss: -0.06652626, mean(E): -21.79062716-0.00071904j, var(E): 0.03104572
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=0.27............. Loss: 0.10852059, mean(E): -21.81321707+0.00000823j, var(E): 0.02305514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=0.27............. Loss: -0.03378457, mean(E): -21.79350763-0.00014890j, var(E): 0.02269554
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=0.27............. Loss: 0.07525849, mean(E): -21.80664380+0.00017217j, var(E): 0.03706584
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=0.27............. Loss: 0.08289594, mean(E): -21.81576407-0.00045477j, var(E): 0.02306781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=0.27............. Loss: 0.17935747, mean(E): -21.82679341-0.00001461j, var(E): 0.05757644
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=0.27............. Loss: 0.06620772, mean(E): -21.81194112+0.00145115j, var(E): 0.03654161
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=0.27............. Loss: 0.12010134, mean(E): -21.80486902+0.00085853j, var(E): 0.03828514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=0.27............. Loss: -0.11873231, mean(E): -21.78305699-0.00136919j, var(E): 0.05055265
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=0.27............. Loss: -0.02951401, mean(E): -21.79863095+0.00245147j, var(E): 0.02588452
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=0.27............. Loss: 0.01503030, mean(E): -21.80430481-0.00164377j, var(E): 0.01431537
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=0.27............. Loss: 0.03511033, mean(E): -21.80318919-0.00011457j, var(E): 0.03912416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=0.27............. Loss: 0.09275508, mean(E): -21.80707099+0.00145052j, var(E): 0.02642748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=0.27............. Loss: -0.08473705, mean(E): -21.79348421+0.00066702j, var(E): 0.02189664
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=0.26............. Loss: -0.07347597, mean(E): -21.78404957+0.00049152j, var(E): 0.01396254
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=0.26............. Loss: -0.13118011, mean(E): -21.79349281+0.00052087j, var(E): 0.07108540
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=0.27............. Loss: -0.11284114, mean(E): -21.80002147+0.00023760j, var(E): 0.16432799
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=0.27............. Loss: -0.05008586, mean(E): -21.79064195+0.00008138j, var(E): 0.01575960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=0.26............. Loss: -0.05098617, mean(E): -21.79639581-0.00010531j, var(E): 0.02245372
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=0.27............. Loss: -0.08288940, mean(E): -21.77953404-0.00119123j, var(E): 0.01559113
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=0.27............. Loss: -0.07629758, mean(E): -21.77783909+0.00060817j, var(E): 0.01653733
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=0.27............. Loss: -0.07343222, mean(E): -21.78109971-0.00017296j, var(E): 0.03174804
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=0.27............. Loss: 0.04361588, mean(E): -21.79799900+0.00013540j, var(E): 0.02131305
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=0.27............. Loss: 0.01111803, mean(E): -21.79591917-0.00013038j, var(E): 0.01978307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=0.27............. Loss: -0.00151005, mean(E): -21.79270027-0.00028662j, var(E): 0.01384522
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=0.27............. Loss: -0.01422903, mean(E): -21.79535427+0.00033615j, var(E): 0.01575726
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=0.26............. Loss: 0.07192969, mean(E): -21.80617700-0.00022213j, var(E): 0.01251073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=0.27............. Loss: -0.05015003, mean(E): -21.79139300-0.00039919j, var(E): 0.03644507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=0.27............. Loss: -0.09945391, mean(E): -21.77109270+0.00051315j, var(E): 0.03645999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=0.27............. Loss: 0.01683237, mean(E): -21.79282764-0.00004828j, var(E): 0.01245858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=0.26............. Loss: -0.04065226, mean(E): -21.78551455-0.00045064j, var(E): 0.01067041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=0.27............. Loss: -0.03510387, mean(E): -21.78796615+0.00014901j, var(E): 0.02040547
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=0.26............. Loss: -0.01874634, mean(E): -21.80307117-0.00010617j, var(E): 0.01252257
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=0.26............. Loss: 0.15058113, mean(E): -21.82211020-0.00013516j, var(E): 0.03180520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=0.26............. Loss: 0.02728925, mean(E): -21.80364939-0.00011744j, var(E): 0.01215246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=0.27............. Loss: -0.01302855, mean(E): -21.79414011-0.00012460j, var(E): 0.01827024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=0.27............. Loss: 0.04110758, mean(E): -21.79410297+0.00006146j, var(E): 0.03331758
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=0.27............. Loss: -0.00228992, mean(E): -21.78501272-0.00003692j, var(E): 0.00973271
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=0.27............. Loss: 0.00242482, mean(E): -21.79096447-0.00018083j, var(E): 0.01188973
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=0.27............. Loss: 0.04004556, mean(E): -21.80014747-0.00001005j, var(E): 0.01464249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=0.27............. Loss: 0.11716242, mean(E): -21.80505012+0.00007277j, var(E): 0.01888387
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=0.27............. Loss: 0.03561106, mean(E): -21.80423530+0.00003974j, var(E): 0.01739268
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=0.26............. Loss: -0.04164309, mean(E): -21.79043614+0.00003640j, var(E): 0.02020931
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=0.27............. Loss: 0.06480657, mean(E): -21.80794005-0.00001890j, var(E): 0.02867868
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=0.26............. Loss: -0.02328527, mean(E): -21.79540671+0.00000211j, var(E): 0.02006447
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=0.27............. Loss: -0.15372082, mean(E): -21.78528412-0.00002114j, var(E): 0.02561433
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=0.27............. Loss: -0.12451519, mean(E): -21.79851890+0.00000238j, var(E): 0.05332452
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=0.27............. Loss: 0.05859764, mean(E): -21.81624995-0.00001488j, var(E): 0.03211384
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=0.26............. Loss: -0.16929690, mean(E): -21.77976314-0.00001336j, var(E): 0.08871970
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=0.27............. Loss: 0.03424092, mean(E): -21.80578767+0.00009134j, var(E): 0.01244627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=0.27............. Loss: -0.00503795, mean(E): -21.81170118+0.00012480j, var(E): 0.02118792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=0.27............. Loss: -0.20379446, mean(E): -21.77899983+0.00003348j, var(E): 0.05628578
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=0.27............. Loss: -0.02038196, mean(E): -21.80161538-0.00002851j, var(E): 0.01878214
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=0.27............. Loss: 0.02663845, mean(E): -21.80742125+0.00018333j, var(E): 0.03211405
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=0.28............. Loss: -0.01263050, mean(E): -21.80577380-0.00049081j, var(E): 0.00648335
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=0.27............. Loss: -0.01596235, mean(E): -21.80177085-0.00012053j, var(E): 0.01554390
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=0.27............. Loss: 0.07278471, mean(E): -21.80937489-0.00001936j, var(E): 0.02827691
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=0.27............. Loss: -0.01236605, mean(E): -21.80462935+0.00009081j, var(E): 0.01123696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=0.27............. Loss: -0.01150758, mean(E): -21.79308775-0.00017887j, var(E): 0.03091509
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=0.27............. Loss: -0.21129275, mean(E): -21.77475166-0.00007866j, var(E): 0.04296379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=0.27............. Loss: 0.00134134, mean(E): -21.80475977-0.00013912j, var(E): 0.07122325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=0.27............. Loss: -0.00942509, mean(E): -21.79259039-0.00004243j, var(E): 0.05471298
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=0.27............. Loss: -0.15202115, mean(E): -21.78571853+0.00019805j, var(E): 0.03576642
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=0.27............. Loss: -0.19309805, mean(E): -21.77716794-0.00007699j, var(E): 0.07662232
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=0.27............. Loss: 0.03423412, mean(E): -21.79669053+0.00002994j, var(E): 0.01248902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=0.27............. Loss: -0.05130017, mean(E): -21.79599467+0.00004747j, var(E): 0.01264689
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=0.27............. Loss: 0.06009668, mean(E): -21.80517806-0.00006789j, var(E): 0.02001352
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=0.27............. Loss: -0.00892804, mean(E): -21.78817768+0.00028457j, var(E): 0.00566170
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=0.27............. Loss: -0.02897933, mean(E): -21.80235751-0.00037486j, var(E): 0.01614074
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=0.27............. Loss: -0.18731794, mean(E): -21.77752992+0.00014786j, var(E): 0.04317829
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=0.26............. Loss: -0.00220330, mean(E): -21.80259623+0.00014242j, var(E): 0.01705904
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=0.27............. Loss: 0.00963300, mean(E): -21.80942974+0.00017301j, var(E): 0.01935603
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=0.26............. Loss: 0.00229819, mean(E): -21.78007091+0.00002063j, var(E): 0.04085491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=0.26............. Loss: -0.09238016, mean(E): -21.78419427+0.00024202j, var(E): 0.01809595
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=0.27............. Loss: -0.13952391, mean(E): -21.78180809-0.00036678j, var(E): 0.07113745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=0.27............. Loss: -0.01199020, mean(E): -21.79631139+0.00009179j, var(E): 0.01146790
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=0.27............. Loss: -0.08363617, mean(E): -21.77448057-0.00018920j, var(E): 0.02487907
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=0.26............. Loss: -0.25474739, mean(E): -21.78344315-0.00008002j, var(E): 0.12420348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=0.27............. Loss: 0.04191197, mean(E): -21.80050727+0.00015003j, var(E): 0.01452104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=0.27............. Loss: 0.04444598, mean(E): -21.80373941-0.00021631j, var(E): 0.01952171
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=0.27............. Loss: 0.21943097, mean(E): -21.82710703+0.00003829j, var(E): 0.10611790
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=0.27............. Loss: 0.12724884, mean(E): -21.81701708-0.00020557j, var(E): 0.03603031
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=0.27............. Loss: 0.05129741, mean(E): -21.80247388-0.00044217j, var(E): 0.01892168
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=0.27............. Loss: 0.01205730, mean(E): -21.79779936+0.00002152j, var(E): 0.02504454
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=0.27............. Loss: -0.14418139, mean(E): -21.77729865+0.00060535j, var(E): 0.03043833
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=0.27............. Loss: -0.08505872, mean(E): -21.78592514+0.00006172j, var(E): 0.01771675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=0.27............. Loss: -0.01765737, mean(E): -21.79776107+0.00042342j, var(E): 0.01208103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=0.27............. Loss: -0.05254260, mean(E): -21.79152240-0.00032029j, var(E): 0.02617577
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=0.27............. Loss: 0.09071194, mean(E): -21.81454215-0.00076225j, var(E): 0.01889376
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=0.27............. Loss: -0.01734366, mean(E): -21.79864605+0.00004491j, var(E): 0.00776619
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=0.27............. Loss: 0.00393522, mean(E): -21.78050778-0.00059371j, var(E): 0.05454148
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=0.27............. Loss: -0.10050755, mean(E): -21.78772041+0.00124888j, var(E): 0.07269334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=0.27............. Loss: 0.10141207, mean(E): -21.81600457-0.00110176j, var(E): 0.01491930
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=0.27............. Loss: -0.02567919, mean(E): -21.79269361-0.00057988j, var(E): 0.02555516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=0.27............. Loss: 0.01105435, mean(E): -21.79788646+0.00103060j, var(E): 0.02291449
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=0.27............. Loss: -0.27994768, mean(E): -21.76813974+0.00102963j, var(E): 0.16700371
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=0.27............. Loss: -0.01092952, mean(E): -21.79167394-0.00112718j, var(E): 0.01350866
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=0.27............. Loss: -0.13495658, mean(E): -21.78533160+0.00116498j, var(E): 0.05362228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=0.27............. Loss: 0.03078159, mean(E): -21.80418736-0.00122901j, var(E): 0.03986498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=0.27............. Loss: 0.24305612, mean(E): -21.82770598+0.00203517j, var(E): 0.07562285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=0.27............. Loss: -0.01124922, mean(E): -21.79167633+0.00021890j, var(E): 0.01343846
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=0.27............. Loss: 0.05306398, mean(E): -21.80897120-0.00164093j, var(E): 0.02116317
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=0.27............. Loss: -0.03600877, mean(E): -21.79662127-0.00015603j, var(E): 0.01666947
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=0.27............. Loss: -0.16122377, mean(E): -21.77772229+0.00033920j, var(E): 0.03730013
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=0.27............. Loss: -0.05108950, mean(E): -21.79235033+0.00090132j, var(E): 0.01169470
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=0.27............. Loss: 0.00500312, mean(E): -21.80152666+0.00025663j, var(E): 0.04963759
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=0.27............. Loss: -0.01115248, mean(E): -21.79981301+0.00035745j, var(E): 0.01438002
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=0.27............. Loss: 0.00872037, mean(E): -21.78454476-0.00032627j, var(E): 0.10018521
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=0.27............. Loss: -0.00085635, mean(E): -21.79895912+0.00122691j, var(E): 0.01144288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=0.27............. Loss: -0.02641853, mean(E): -21.79813423-0.00077542j, var(E): 0.01967978
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=0.27............. Loss: 0.12242334, mean(E): -21.82058724+0.00017470j, var(E): 0.08566239
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=0.27............. Loss: 0.05307721, mean(E): -21.80217058-0.00014116j, var(E): 0.04604766
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=0.27............. Loss: 0.05709346, mean(E): -21.80208775+0.00019013j, var(E): 0.01550838
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=0.27............. Loss: -0.13420324, mean(E): -21.77461826-0.00044872j, var(E): 0.02426620
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=0.27............. Loss: 0.01160406, mean(E): -21.80011045+0.00034854j, var(E): 0.01507835
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=0.27............. Loss: -0.06913893, mean(E): -21.79072001-0.00007426j, var(E): 0.01683000
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=0.27............. Loss: -0.01177835, mean(E): -21.79825954+0.00017958j, var(E): 0.01788635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=0.27............. Loss: 0.09648269, mean(E): -21.80488522+0.00027768j, var(E): 0.02888134
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=0.27............. Loss: -0.37669435, mean(E): -21.76049813+0.00024396j, var(E): 0.29145667
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=0.27............. Loss: 0.00015853, mean(E): -21.80088878+0.00020632j, var(E): 0.02835130
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=0.27............. Loss: 0.03534611, mean(E): -21.80501592+0.00008407j, var(E): 0.01624264
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=0.27............. Loss: 0.18654972, mean(E): -21.82283858+0.00022297j, var(E): 0.06664521
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=0.27............. Loss: -0.28844623, mean(E): -21.75754515-0.00012347j, var(E): 0.13205741
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=0.27............. Loss: -0.05449679, mean(E): -21.80818226+0.00031263j, var(E): 0.03599723
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=0.27............. Loss: 0.11321873, mean(E): -21.80924772+0.00005194j, var(E): 0.04951952
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=0.27............. Loss: -0.01471793, mean(E): -21.80068616-0.00004899j, var(E): 0.01140951
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=0.27............. Loss: -0.06114623, mean(E): -21.79913042+0.00030674j, var(E): 0.01200809
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=0.27............. Loss: 0.00797181, mean(E): -21.80005288-0.00006533j, var(E): 0.01555062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=0.27............. Loss: 0.06087741, mean(E): -21.80891491-0.00001535j, var(E): 0.01919969
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=0.27............. Loss: 0.01358827, mean(E): -21.80245607-0.00000487j, var(E): 0.04160865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=0.27............. Loss: 0.03075945, mean(E): -21.80593075-0.00010224j, var(E): 0.01370755
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=0.27............. Loss: -0.09559386, mean(E): -21.77558765-0.00020154j, var(E): 0.02357045
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=0.27............. Loss: 0.06755506, mean(E): -21.81052060-0.00007315j, var(E): 0.06173579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=0.27............. Loss: 0.09206881, mean(E): -21.80887285+0.00002277j, var(E): 0.01360085
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(25.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=0.27............. Loss: 0.01558977, mean(E): -21.80172577+0.00021232j, var(E): 0.00551905
