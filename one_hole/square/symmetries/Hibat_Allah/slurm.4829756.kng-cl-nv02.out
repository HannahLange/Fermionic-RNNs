/var/spool/slurmd/job4829756/slurm_script: line 14: ../../ML_Environment/bin/activate: No such file or directory
1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, Nx=4, Ny=4, U=1.0, antisym=0.0, bounds=1, boundsx=0, boundsy=0, density=1.0, hd=70, load_model=0, sym=0.0, t=3.0)
4x4_qubits/periodic/Jp=1.0Jz=1.0t=0.0den=1.00/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=2.05............. Loss: -0.79348570, mean(E): -0.32850594+0.00141499j, var(E): 1.09895192
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=0.2............. Loss: -1.33968426, mean(E): -0.62097164-0.08268389j, var(E): 1.84890141
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=0.2............. Loss: -0.52458274, mean(E): -6.25899039+0.02549535j, var(E): 2.96096600
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=0.2............. Loss: 1.13544232, mean(E): -7.02210252+0.00281982j, var(E): 3.13641520
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=0.2............. Loss: 2.55123337, mean(E): -9.13059597-0.20887523j, var(E): 5.30450337
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=0.2............. Loss: -1.74264467, mean(E): -10.49277947-0.16792104j, var(E): 4.56816322
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=0.2............. Loss: -5.70015098, mean(E): -11.64103279-0.11749734j, var(E): 7.76211770
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=0.2............. Loss: 2.19129143, mean(E): -12.79936862-0.15464903j, var(E): 12.78980401
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=0.2............. Loss: -5.29186487, mean(E): -13.69791380-0.06178896j, var(E): 6.15363481
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=0.2............. Loss: -3.76127486, mean(E): -13.67295141-0.23834887j, var(E): 5.31039057
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=0.2............. Loss: 0.00698508, mean(E): -14.23674888-0.13357497j, var(E): 5.95960402
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=0.2............. Loss: -1.27242764, mean(E): -14.56920892-0.21348534j, var(E): 9.06479086
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=0.2............. Loss: -0.74706258, mean(E): -14.87669887-0.28906619j, var(E): 13.81437938
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=0.2............. Loss: -2.88235831, mean(E): -15.21543825-0.15849084j, var(E): 6.63603139
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=0.2............. Loss: -4.20842634, mean(E): -13.79681145-0.13282089j, var(E): 6.65261251
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=0.2............. Loss: -3.91061252, mean(E): -14.57566634+0.08344493j, var(E): 8.04707062
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=0.2............. Loss: -1.95735460, mean(E): -14.87072926-0.10060297j, var(E): 7.88512211
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=0.2............. Loss: -1.72414181, mean(E): -15.48703638+0.00591201j, var(E): 5.96692043
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=0.2............. Loss: -1.25475024, mean(E): -15.63224211+0.12934831j, var(E): 5.07915321
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=0.2............. Loss: 0.51298079, mean(E): -16.22980623-0.08148282j, var(E): 4.16302334
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=0.2............. Loss: 9.52619555, mean(E): -16.92612067-0.03452146j, var(E): 44.41554895
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=0.2............. Loss: -4.05064083, mean(E): -16.35248581-0.11060016j, var(E): 10.68201580
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=0.2............. Loss: -0.37085150, mean(E): -16.36190084-0.05828863j, var(E): 3.28235467
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=0.2............. Loss: 2.18228719, mean(E): -16.63615870-0.03434553j, var(E): 5.48214938
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=0.2............. Loss: -1.96588808, mean(E): -16.39760597-0.10789116j, var(E): 2.77460671
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=0.2............. Loss: -1.28907923, mean(E): -16.54523781-0.02776714j, var(E): 3.00999992
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=0.2............. Loss: -1.40157026, mean(E): -16.57584672-0.08905789j, var(E): 4.17722228
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=0.2............. Loss: -0.08710446, mean(E): -16.54133988+0.06492984j, var(E): 2.31579222
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=0.2............. Loss: 0.44262652, mean(E): -16.89753554+0.03120093j, var(E): 6.48916167
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=0.2............. Loss: 0.76453868, mean(E): -16.82138813+0.17133205j, var(E): 2.25632588
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=0.2............. Loss: -1.20626099, mean(E): -16.45245256-0.15060249j, var(E): 2.88994286
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=0.2............. Loss: -0.48488953, mean(E): -16.70498150-0.05953950j, var(E): 1.76971317
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=0.2............. Loss: -3.94070609, mean(E): -16.46491744-0.13613818j, var(E): 2.16227428
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=0.2............. Loss: -1.02899182, mean(E): -16.66533543+0.01704078j, var(E): 2.96940016
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=0.2............. Loss: -1.85040362, mean(E): -16.68551150-0.19447265j, var(E): 2.91159246
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=0.2............. Loss: -4.23886842, mean(E): -16.69909966-0.13135691j, var(E): 2.98382918
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=0.2............. Loss: 0.60943602, mean(E): -16.83546835-0.08582129j, var(E): 3.11905039
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=0.2............. Loss: 0.54949481, mean(E): -16.91870592-0.05928031j, var(E): 1.72438541
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=0.2............. Loss: -2.29507000, mean(E): -16.88530743+0.01741304j, var(E): 4.23455094
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=0.2............. Loss: -0.59126173, mean(E): -16.71058238-0.18754685j, var(E): 12.39980564
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=0.2............. Loss: -0.15354946, mean(E): -16.66978681-0.13932539j, var(E): 3.80189729
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=0.2............. Loss: -3.29363241, mean(E): -16.27909834-0.06646936j, var(E): 2.14339459
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=0.2............. Loss: -0.96684293, mean(E): -16.92074039-0.31850888j, var(E): 10.24062282
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=0.2............. Loss: 1.34002919, mean(E): -16.77049587-0.07000011j, var(E): 3.36259688
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=0.2............. Loss: -1.86723699, mean(E): -16.57639938-0.26417734j, var(E): 3.21076367
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=0.2............. Loss: -0.18679470, mean(E): -16.68337957-0.17043013j, var(E): 2.16650385
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=0.2............. Loss: -0.36260424, mean(E): -16.51553138-0.21375720j, var(E): 3.68727652
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=0.2............. Loss: -5.61536023, mean(E): -15.68518776+0.17479581j, var(E): 7.28274864
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=0.2............. Loss: -3.87280606, mean(E): -16.33774966+0.22201730j, var(E): 4.70866266
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=0.2............. Loss: -0.05602484, mean(E): -16.76293076-0.11560987j, var(E): 4.65010061
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=0.2............. Loss: -0.92213020, mean(E): -16.58236950+0.15325420j, var(E): 4.48692537
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=0.2............. Loss: -1.82218992, mean(E): -16.70669666+0.19752905j, var(E): 3.62811349
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=0.2............. Loss: -1.58549612, mean(E): -16.66283699+0.00012035j, var(E): 2.79505330
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=0.2............. Loss: -0.23043706, mean(E): -16.73291670+0.03899867j, var(E): 1.94266691
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=0.2............. Loss: 1.41768910, mean(E): -17.00448320-0.10633557j, var(E): 2.59321872
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=0.2............. Loss: -1.30958799, mean(E): -16.65431150+0.02754258j, var(E): 1.85654052
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=0.2............. Loss: 1.22275755, mean(E): -16.86605038+0.06331963j, var(E): 2.52813995
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=0.2............. Loss: 0.42465816, mean(E): -16.81038826-0.06923860j, var(E): 1.52326054
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=0.2............. Loss: -2.10363261, mean(E): -17.23436158+0.24235685j, var(E): 3.27117137
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=0.2............. Loss: 0.38355408, mean(E): -17.04722148+0.17128836j, var(E): 4.55725267
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=0.2............. Loss: -0.05435184, mean(E): -17.15290684+0.15824917j, var(E): 8.01999954
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=0.2............. Loss: 0.84035981, mean(E): -17.12975532+0.04002048j, var(E): 1.71636126
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=0.2............. Loss: -0.15327174, mean(E): -17.09130654+0.15508706j, var(E): 1.04830198
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=0.2............. Loss: -2.12265681, mean(E): -17.10976941-0.02873661j, var(E): 0.92939760
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=0.2............. Loss: -0.36808155, mean(E): -17.00528601+0.12421452j, var(E): 2.02517384
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=0.2............. Loss: -2.47976840, mean(E): -17.09882273+0.12933938j, var(E): 1.84752355
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=0.2............. Loss: 1.49185476, mean(E): -17.05026782+0.10311536j, var(E): 1.18655316
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=0.2............. Loss: -0.43946089, mean(E): -17.13282009+0.13628590j, var(E): 0.55504688
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=0.2............. Loss: -0.30722315, mean(E): -17.14255979+0.20541813j, var(E): 0.79241425
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=0.2............. Loss: -0.68667661, mean(E): -17.09151179+0.02015355j, var(E): 7.42529649
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=0.2............. Loss: 1.41525333, mean(E): -17.20941193+0.02465906j, var(E): 1.16772461
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=0.2............. Loss: -2.31468162, mean(E): -17.17515839-0.01109952j, var(E): 0.61421249
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=0.2............. Loss: 4.26671147, mean(E): -17.42180371-0.08801210j, var(E): 9.94572206
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=0.2............. Loss: -0.25517835, mean(E): -17.05951965-0.13062444j, var(E): 1.71485086
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=0.2............. Loss: 0.27018929, mean(E): -17.11819392-0.12957051j, var(E): 1.98293542
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=0.2............. Loss: -0.07405892, mean(E): -17.26201161-0.02261163j, var(E): 0.63022536
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=0.2............. Loss: -0.38162211, mean(E): -17.22573960+0.12474776j, var(E): 1.00955570
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=0.2............. Loss: -0.89574001, mean(E): -17.24295425+0.05833987j, var(E): 0.40719451
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=0.2............. Loss: 0.99855866, mean(E): -17.18925178+0.14738598j, var(E): 0.92435453
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=0.2............. Loss: -2.14986804, mean(E): -17.21902374+0.10933208j, var(E): 0.68618987
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=0.2............. Loss: 0.43466732, mean(E): -17.18136383+0.12814487j, var(E): 1.68919429
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=0.2............. Loss: 0.04780805, mean(E): -16.76572634+0.35531668j, var(E): 29.28781411
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=0.2............. Loss: -0.29509217, mean(E): -17.10902799+0.11630821j, var(E): 1.50235142
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=0.2............. Loss: -0.86606375, mean(E): -17.25636819+0.22805585j, var(E): 0.64110744
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=0.2............. Loss: -0.99340900, mean(E): -17.33076284+0.09215173j, var(E): 1.39574659
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=0.2............. Loss: -1.08863375, mean(E): -17.20353831+0.07722422j, var(E): 0.95870879
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=0.2............. Loss: 1.35690410, mean(E): -17.33027843-0.10399194j, var(E): 3.81154272
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=0.2............. Loss: -1.60077747, mean(E): -17.32868650+0.02592905j, var(E): 0.53427531
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=0.2............. Loss: -0.29770570, mean(E): -17.27869341-0.03450321j, var(E): 0.58585788
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=0.2............. Loss: -1.68777351, mean(E): -17.31157560-0.05417046j, var(E): 2.11321844
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=0.2............. Loss: 1.52305448, mean(E): -17.22571023+0.02242431j, var(E): 1.02217060
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=0.2............. Loss: -2.15054874, mean(E): -17.03091618+0.08033402j, var(E): 1.12416021
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=0.2............. Loss: -2.96920835, mean(E): -16.79950152-0.12058869j, var(E): 3.06089566
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=0.2............. Loss: 2.01194489, mean(E): -16.98153725-0.05548159j, var(E): 1.94469887
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=0.2............. Loss: 0.61503061, mean(E): -17.17471107+0.06288596j, var(E): 3.48665125
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=0.2............. Loss: -0.81433123, mean(E): -17.27953479+0.01998040j, var(E): 1.43062959
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=0.2............. Loss: -2.85212554, mean(E): -17.10807474-0.11418238j, var(E): 1.61958900
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=0.2............. Loss: -3.08788268, mean(E): -17.15974703-0.20499903j, var(E): 3.23032596
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=0.2............. Loss: -0.69317718, mean(E): -16.83980874+0.02123501j, var(E): 2.18704756
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=0.2............. Loss: 0.57828305, mean(E): -17.17777976-0.05486069j, var(E): 0.90319316
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=0.2............. Loss: 1.31394834, mean(E): -17.21519955+0.06844640j, var(E): 0.79681970
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=0.2............. Loss: -0.66045907, mean(E): -17.27930656+0.08176717j, var(E): 0.72618501
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=0.2............. Loss: -3.44243364, mean(E): -16.87287457+0.25074042j, var(E): 2.81873126
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=0.2............. Loss: 1.23290226, mean(E): -17.12685033+0.30436370j, var(E): 1.14818708
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=0.2............. Loss: -2.23900581, mean(E): -17.11529668+0.23041068j, var(E): 1.94807339
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=0.2............. Loss: 0.34933262, mean(E): -17.14623220+0.13165774j, var(E): 0.65576531
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=0.2............. Loss: -1.44118526, mean(E): -17.17817429+0.03017920j, var(E): 0.73447176
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=0.2............. Loss: 0.23110624, mean(E): -17.27412384-0.19214419j, var(E): 1.08779346
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=0.2............. Loss: -3.09182582, mean(E): -17.24181191-0.11191257j, var(E): 1.83553553
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=0.2............. Loss: -4.51756491, mean(E): -16.89426184+0.01690341j, var(E): 5.25787632
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=0.2............. Loss: -0.03869095, mean(E): -17.21449012+0.03978622j, var(E): 0.84051221
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=0.2............. Loss: -0.37826261, mean(E): -17.30238190+0.14453771j, var(E): 1.87264236
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=0.2............. Loss: 0.27822516, mean(E): -17.25612484+0.02614517j, var(E): 0.83660548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=0.2............. Loss: -1.58880255, mean(E): -17.22758044-0.10676314j, var(E): 1.43137286
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=0.2............. Loss: -1.60987546, mean(E): -17.37774255-0.15267466j, var(E): 5.82791850
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=0.2............. Loss: -2.57697473, mean(E): -17.26933501-0.14431620j, var(E): 1.34709723
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=0.2............. Loss: 2.66260592, mean(E): -17.24778235-0.03108173j, var(E): 0.59105968
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=0.2............. Loss: -3.05054230, mean(E): -17.07364734+0.11927013j, var(E): 2.93489012
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=0.2............. Loss: -0.33409611, mean(E): -17.16927511-0.11809098j, var(E): 1.48051438
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=0.2............. Loss: 0.50124188, mean(E): -17.35682341-0.16611561j, var(E): 1.06858001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=0.2............. Loss: -0.41191484, mean(E): -17.31089645-0.03585315j, var(E): 0.58758606
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=0.2............. Loss: -2.82000102, mean(E): -17.25275615+0.22785661j, var(E): 5.86773803
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=0.2............. Loss: -2.62784065, mean(E): -17.23056999+0.01019447j, var(E): 0.53857688
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=0.2............. Loss: -0.97043617, mean(E): -17.19163639+0.17106310j, var(E): 3.61269174
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=0.2............. Loss: -1.95608590, mean(E): -17.16480990-0.05147801j, var(E): 1.69354431
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=0.2............. Loss: -0.49625249, mean(E): -17.18615018+0.07581952j, var(E): 0.58067898
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=0.2............. Loss: -0.11962988, mean(E): -17.23320243-0.07495759j, var(E): 0.64710879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=0.2............. Loss: 1.43197042, mean(E): -17.24482645+0.14784411j, var(E): 0.48468261
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=0.2............. Loss: 0.51606961, mean(E): -17.23590076-0.20925856j, var(E): 7.61281916
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=0.2............. Loss: 1.61683466, mean(E): -17.25572164-0.15328890j, var(E): 0.92611043
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=0.2............. Loss: -1.12624974, mean(E): -17.28379372+0.00451210j, var(E): 1.88393324
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=0.2............. Loss: -1.38235145, mean(E): -17.23983148+0.11081778j, var(E): 0.42050765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=0.2............. Loss: 1.56472210, mean(E): -17.29312616-0.04441331j, var(E): 0.63546318
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=0.2............. Loss: -0.39201809, mean(E): -17.37163892-0.11285317j, var(E): 0.61191988
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=0.2............. Loss: 1.10262525, mean(E): -17.48966181-0.24511562j, var(E): 6.46100948
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=0.2............. Loss: 2.46107638, mean(E): -17.54522158-0.03717473j, var(E): 6.80936380
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=0.2............. Loss: 0.41919768, mean(E): -17.38714136+0.08584568j, var(E): 4.75664153
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=0.2............. Loss: -0.18740802, mean(E): -17.36335096+0.04706692j, var(E): 1.29659600
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=0.2............. Loss: -0.29147573, mean(E): -17.27442750-0.21056398j, var(E): 0.92028225
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=0.2............. Loss: -0.93537402, mean(E): -17.37580975-0.04259596j, var(E): 0.48704697
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=0.2............. Loss: -2.11777686, mean(E): -17.38310910+0.02472442j, var(E): 2.28062456
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=0.2............. Loss: 0.21584080, mean(E): -17.48099460+0.06085560j, var(E): 2.11443746
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=0.2............. Loss: -4.63034449, mean(E): -17.42184824+0.09812425j, var(E): 1.68418590
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=0.2............. Loss: 1.22091482, mean(E): -17.32975873+0.10586778j, var(E): 0.83026205
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=0.2............. Loss: -3.73796816, mean(E): -17.30424687-0.04042111j, var(E): 5.08634676
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=0.2............. Loss: -1.17729927, mean(E): -17.40656450+0.02388236j, var(E): 1.42290583
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=0.2............. Loss: -0.95820701, mean(E): -17.39195743+0.04000577j, var(E): 0.68775314
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=0.2............. Loss: 0.08093075, mean(E): -17.37386224+0.11129494j, var(E): 0.79359677
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=0.2............. Loss: -2.98038499, mean(E): -17.26998803+0.20156059j, var(E): 3.58290588
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=0.2............. Loss: 1.81388828, mean(E): -17.15808301+0.00540665j, var(E): 0.78508309
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=0.2............. Loss: -1.54496376, mean(E): -17.02358788+0.17844911j, var(E): 2.04698013
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=0.2............. Loss: 0.84916147, mean(E): -17.05986827+0.06856654j, var(E): 1.37498452
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=0.2............. Loss: 2.43152717, mean(E): -17.04570090-0.13676809j, var(E): 1.48496090
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=0.2............. Loss: 4.39425202, mean(E): -17.32761924-0.19737392j, var(E): 4.74212656
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=0.2............. Loss: 2.00718805, mean(E): -17.29138495-0.10575393j, var(E): 1.07496931
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=0.2............. Loss: 0.65192287, mean(E): -17.21602729-0.03062160j, var(E): 0.54627108
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=0.2............. Loss: -2.54597756, mean(E): -17.19127829+0.08803614j, var(E): 11.95427757
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=0.2............. Loss: -0.07466463, mean(E): -17.25889976+0.11168877j, var(E): 0.47729813
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=0.2............. Loss: -6.51457962, mean(E): -17.17917222+0.27437891j, var(E): 5.43420405
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=0.2............. Loss: -2.53520583, mean(E): -17.27854206+0.18026483j, var(E): 0.69947794
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=0.2............. Loss: -0.97881002, mean(E): -17.18147161+0.12572052j, var(E): 2.59355079
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=0.2............. Loss: -0.40765418, mean(E): -17.33618058+0.10839258j, var(E): 0.53898431
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=0.2............. Loss: -0.16519170, mean(E): -17.40990856+0.15785279j, var(E): 0.45240199
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=0.2............. Loss: -2.30709635, mean(E): -17.22782552+0.15811694j, var(E): 4.96162778
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=0.2............. Loss: -1.54379280, mean(E): -17.10039755+0.11370550j, var(E): 3.48431994
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=0.2............. Loss: -3.13394271, mean(E): -17.18800926+0.16102233j, var(E): 1.39903384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=0.2............. Loss: -1.85233071, mean(E): -17.24257232+0.26700721j, var(E): 0.59878033
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=0.2............. Loss: -2.29766194, mean(E): -17.26800328+0.03439286j, var(E): 2.99289807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=0.2............. Loss: -3.21569040, mean(E): -17.24121369+0.10431206j, var(E): 4.24782587
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=0.2............. Loss: -1.34942005, mean(E): -17.29582609+0.39903086j, var(E): 1.08926380
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=0.2............. Loss: 0.19088033, mean(E): -17.35803106-0.07650231j, var(E): 1.46731710
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=0.2............. Loss: -0.05095044, mean(E): -17.38742618+0.07953275j, var(E): 0.79948617
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=0.2............. Loss: 0.42336435, mean(E): -17.46559897+0.23739272j, var(E): 0.73203952
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=0.2............. Loss: -3.03583372, mean(E): -17.45578079+0.16660565j, var(E): 0.41995254
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=0.2............. Loss: 0.49627220, mean(E): -17.46002198+0.13616245j, var(E): 0.67021312
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=0.2............. Loss: -0.74165945, mean(E): -17.35567515+0.12292964j, var(E): 0.62836534
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=0.2............. Loss: -0.53190319, mean(E): -17.27335241+0.25990878j, var(E): 0.77136943
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=0.2............. Loss: -0.16119388, mean(E): -17.43809154+0.24073640j, var(E): 0.38957437
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=0.2............. Loss: 0.15566601, mean(E): -17.31659311+0.19116486j, var(E): 0.45937568
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=0.2............. Loss: -2.11578538, mean(E): -17.43613604+0.26760656j, var(E): 3.70243072
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=0.2............. Loss: 1.68641644, mean(E): -17.37828629+0.11999153j, var(E): 0.57202170
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=0.2............. Loss: -2.17270051, mean(E): -17.34568216+0.18648367j, var(E): 1.29359672
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=0.2............. Loss: 7.77171361, mean(E): -17.33895638+0.09973447j, var(E): 3.07155838
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=0.2............. Loss: -5.37592093, mean(E): -17.29520320-0.00369764j, var(E): 2.99351275
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=0.2............. Loss: 4.75714917, mean(E): -17.11640732+0.08052930j, var(E): 1.98383562
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=0.2............. Loss: -5.29189874, mean(E): -17.31040700+0.25004302j, var(E): 1.79499568
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=0.2............. Loss: -1.76984689, mean(E): -17.36351967+0.37259323j, var(E): 1.26964733
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=0.2............. Loss: -1.54969799, mean(E): -17.39791055+0.16354130j, var(E): 0.41975575
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=0.2............. Loss: 6.12963904, mean(E): -17.35084585-0.19374075j, var(E): 6.57987396
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=0.2............. Loss: 2.00057445, mean(E): -17.26554308-0.09117490j, var(E): 1.05650172
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=0.2............. Loss: -0.77729443, mean(E): -17.33687221+0.06456676j, var(E): 0.56384785
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=0.2............. Loss: -1.72288786, mean(E): -17.28813543-0.03900103j, var(E): 0.74739255
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=0.2............. Loss: -2.02540453, mean(E): -17.25159371+0.03510251j, var(E): 0.54542971
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=0.2............. Loss: -2.40649682, mean(E): -17.19636332+0.04021048j, var(E): 2.02205880
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=0.2............. Loss: 0.79418731, mean(E): -17.17696787-0.02332851j, var(E): 2.29764482
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=0.2............. Loss: -3.18217694, mean(E): -17.22201490+0.20862364j, var(E): 0.99377151
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=0.2............. Loss: 1.08796553, mean(E): -17.22617812+0.11079129j, var(E): 0.82621110
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=0.2............. Loss: -1.65474660, mean(E): -17.31209714+0.09663285j, var(E): 0.62875932
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=0.2............. Loss: -2.99918001, mean(E): -17.22245683+0.19586365j, var(E): 0.91714728
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=0.2............. Loss: -5.29496589, mean(E): -17.04776078+0.24299259j, var(E): 3.75584953
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=0.2............. Loss: -9.35385905, mean(E): -16.92790802+0.01478618j, var(E): 9.60995259
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=0.2............. Loss: 3.63366481, mean(E): -16.20659329+0.20308297j, var(E): 5.66014130
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=0.2............. Loss: -15.94013587, mean(E): -16.35445273+0.59323125j, var(E): 4.12957845
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=0.2............. Loss: 3.70580464, mean(E): -16.81834972-0.27448413j, var(E): 1.26137178
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=0.2............. Loss: -6.59700922, mean(E): -16.97645232-0.07937784j, var(E): 1.46338524
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=0.2............. Loss: 3.03563739, mean(E): -16.93270262-0.14980621j, var(E): 2.20749398
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=0.2............. Loss: 3.75597633, mean(E): -16.99343104+0.02376591j, var(E): 2.13080637
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=0.2............. Loss: 3.44002199, mean(E): -17.12613174+0.20540352j, var(E): 1.77003812
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=0.2............. Loss: -1.95976403, mean(E): -17.11591221+0.28920931j, var(E): 2.11352776
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=0.2............. Loss: 3.08532657, mean(E): -17.25415708-0.03505510j, var(E): 1.56286643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=0.21............. Loss: -4.86586318, mean(E): -17.23024241+0.33236298j, var(E): 0.99708063
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=0.2............. Loss: 6.69797342, mean(E): -17.44464146+0.00059943j, var(E): 9.32529957
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=0.2............. Loss: -2.35716473, mean(E): -17.32836093+0.21775581j, var(E): 2.40412119
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=0.2............. Loss: 5.01569061, mean(E): -17.37019968+0.12884938j, var(E): 1.18545952
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=0.2............. Loss: 6.72476218, mean(E): -17.19246280-0.19569255j, var(E): 8.70749115
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=0.2............. Loss: -0.72451591, mean(E): -17.07202941-0.03888701j, var(E): 1.30776354
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=0.2............. Loss: -2.72744279, mean(E): -17.15987457+0.05101915j, var(E): 0.59258481
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=0.2............. Loss: 1.66230550, mean(E): -17.19051009+0.12115626j, var(E): 0.45803228
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=0.2............. Loss: 3.05211080, mean(E): -17.18642968+0.15007277j, var(E): 9.75530532
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=0.2............. Loss: 1.54920671, mean(E): -17.16021056+0.24799764j, var(E): 1.11694346
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=0.2............. Loss: -1.10290496, mean(E): -17.19537411+0.35764908j, var(E): 1.14678695
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=0.2............. Loss: 0.01399453, mean(E): -17.23817140+0.42785805j, var(E): 2.05866900
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=0.2............. Loss: 1.18036925, mean(E): -17.20953427+0.25015422j, var(E): 0.73541235
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=0.2............. Loss: 0.27201886, mean(E): -17.34981008+0.30438535j, var(E): 0.55840164
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=0.2............. Loss: 1.01342316, mean(E): -17.34023631+0.24627587j, var(E): 0.27761777
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=0.2............. Loss: 3.40525658, mean(E): -17.33997055+0.13150941j, var(E): 0.59023435
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=0.2............. Loss: -0.14711305, mean(E): -17.39447726+0.17742552j, var(E): 0.66930917
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=0.2............. Loss: 2.22567730, mean(E): -17.44134885+0.11041251j, var(E): 2.10156751
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=0.2............. Loss: -1.09877622, mean(E): -17.34600584-0.09617668j, var(E): 0.97961061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=0.2............. Loss: 2.51971384, mean(E): -17.36999471-0.03188607j, var(E): 0.95956943
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=0.2............. Loss: 0.37626386, mean(E): -17.41722017-0.06100492j, var(E): 0.85180749
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=0.2............. Loss: -0.28718266, mean(E): -17.34273916+0.02124284j, var(E): 0.88779520
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=0.2............. Loss: 0.36919081, mean(E): -17.40322091+0.09681196j, var(E): 0.61373921
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=0.2............. Loss: -1.58302928, mean(E): -17.29023951-0.01085500j, var(E): 2.77867708
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=0.2............. Loss: 0.92396753, mean(E): -17.40124571+0.14152885j, var(E): 0.55363191
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=0.2............. Loss: -2.33798292, mean(E): -17.44868761+0.22961744j, var(E): 1.32741797
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=0.2............. Loss: 0.75713722, mean(E): -17.38324596+0.20302042j, var(E): 0.67658685
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=0.2............. Loss: -1.18610681, mean(E): -17.41692480+0.04817240j, var(E): 1.15286275
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=0.2............. Loss: 2.73391393, mean(E): -17.35308627-0.00527593j, var(E): 1.05948226
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=0.2............. Loss: -3.31865237, mean(E): -17.29568510+0.00637984j, var(E): 3.25949172
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=0.2............. Loss: 1.68650674, mean(E): -17.51413327+0.07482207j, var(E): 0.36347159
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=0.2............. Loss: 0.03336829, mean(E): -17.54427425-0.08171800j, var(E): 1.21915001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=0.2............. Loss: -0.30895660, mean(E): -17.54517542+0.04355329j, var(E): 0.24770363
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=0.2............. Loss: 3.38701078, mean(E): -17.46093223+0.20304429j, var(E): 12.03086896
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=0.2............. Loss: 0.06197751, mean(E): -17.56064199+0.10985872j, var(E): 0.44989146
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=0.2............. Loss: -0.26572179, mean(E): -17.54940773-0.01394748j, var(E): 0.76776372
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=0.2............. Loss: 1.32878329, mean(E): -17.62842764-0.02910374j, var(E): 1.25753654
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=0.2............. Loss: 0.77615221, mean(E): -17.55035506+0.14291357j, var(E): 1.48581330
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=0.2............. Loss: -0.05267086, mean(E): -17.49082388+0.07059037j, var(E): 0.16124066
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=0.2............. Loss: 2.13050942, mean(E): -17.77462188+0.03035492j, var(E): 13.76692123
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=0.2............. Loss: -0.07486474, mean(E): -17.52354939+0.03686215j, var(E): 0.93939303
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=0.2............. Loss: -0.75869951, mean(E): -17.50118970+0.06815802j, var(E): 1.46819338
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=0.2............. Loss: 0.15156819, mean(E): -17.51451156+0.24434648j, var(E): 0.25792826
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=0.2............. Loss: -0.89364221, mean(E): -17.52798414+0.14353577j, var(E): 0.24621561
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=0.2............. Loss: 2.97960443, mean(E): -17.51680425-0.03430455j, var(E): 1.43893003
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=0.2............. Loss: -1.03979043, mean(E): -17.50612296+0.15033404j, var(E): 0.57360624
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=0.2............. Loss: -0.59678863, mean(E): -17.54439508+0.17090087j, var(E): 1.84478668
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=0.2............. Loss: 0.74281337, mean(E): -17.61490827+0.06886006j, var(E): 2.03107123
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=0.2............. Loss: 4.69345687, mean(E): -17.37681629-0.05117428j, var(E): 2.55060115
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=0.2............. Loss: -2.97558795, mean(E): -17.45053493+0.07566599j, var(E): 0.53898484
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=0.2............. Loss: 0.17034305, mean(E): -17.50034526+0.04998586j, var(E): 0.72396297
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=0.2............. Loss: 0.65490104, mean(E): -17.52889126+0.13170224j, var(E): 0.82824808
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=0.2............. Loss: 1.41289357, mean(E): -17.60004172+0.13880212j, var(E): 1.46575726
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=0.2............. Loss: -1.83958380, mean(E): -17.45444190+0.27476101j, var(E): 1.02744847
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=0.2............. Loss: 1.27035739, mean(E): -17.51144813+0.19857515j, var(E): 0.86159908
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=0.2............. Loss: 0.55122336, mean(E): -17.62131198+0.11215588j, var(E): 1.46325922
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=0.2............. Loss: -0.51035853, mean(E): -17.48868628+0.02832310j, var(E): 0.31594839
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=0.2............. Loss: -1.61067208, mean(E): -17.42836590+0.15086642j, var(E): 0.81103790
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=0.2............. Loss: 1.86549647, mean(E): -17.55951690+0.10212867j, var(E): 2.13937568
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=0.2............. Loss: 0.15433800, mean(E): -17.56886859-0.01674588j, var(E): 2.06342294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=0.2............. Loss: -0.51722624, mean(E): -17.60917353+0.22297323j, var(E): 1.18407230
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=0.2............. Loss: -1.98614462, mean(E): -17.55399001-0.06189084j, var(E): 2.85463237
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=0.2............. Loss: 2.35236024, mean(E): -17.62933146-0.01997811j, var(E): 1.77949361
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=0.2............. Loss: -2.28276585, mean(E): -17.59568331+0.10084728j, var(E): 0.89916757
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(21.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=0.2............. Loss: 0.42523884, mean(E): -17.53950712+0.17965845j, var(E): 1.42421539
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=0.2............. Loss: 0.86399775, mean(E): -17.54660141+0.03254949j, var(E): 0.52031123
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=0.2............. Loss: 1.11647973, mean(E): -17.51179666+0.10218498j, var(E): 0.24563542
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=0.2............. Loss: -2.27181272, mean(E): -17.32727423+0.16531769j, var(E): 2.36931753
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=0.2............. Loss: -2.64579791, mean(E): -17.34335280+0.31590913j, var(E): 1.45191478
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=0.2............. Loss: -3.46883490, mean(E): -17.44004412-0.02387525j, var(E): 1.96478834
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=0.2............. Loss: -0.21465804, mean(E): -17.41105197-0.00516390j, var(E): 0.65321307
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=0.2............. Loss: -0.76243733, mean(E): -17.39233882+0.06158419j, var(E): 2.05371808
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=0.2............. Loss: -4.88956272, mean(E): -17.41207290+0.24331087j, var(E): 0.94695147
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=0.2............. Loss: 0.47639651, mean(E): -17.39499265-0.09465837j, var(E): 0.65521699
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=0.2............. Loss: -10.36938867, mean(E): -17.18818578-0.04291833j, var(E): 3.07128878
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=0.2............. Loss: -3.24003221, mean(E): -17.11111439+0.14296659j, var(E): 2.51199615
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=0.2............. Loss: -3.33541214, mean(E): -17.11394563-0.02597383j, var(E): 3.02886417
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=0.2............. Loss: 6.29351869, mean(E): -16.91345446-0.08841233j, var(E): 3.13253639
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=0.2............. Loss: 6.00211757, mean(E): -16.85832439-0.23253584j, var(E): 1.79140229
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=0.2............. Loss: -2.47162299, mean(E): -17.03921760-0.19618698j, var(E): 2.32592737
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=0.2............. Loss: -7.19038423, mean(E): -16.90999503-0.03751076j, var(E): 1.11093184
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=0.2............. Loss: 3.96269374, mean(E): -17.12396861+0.04716936j, var(E): 5.10091751
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=0.2............. Loss: -1.57977168, mean(E): -17.03516605-0.10791129j, var(E): 4.84225823
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=0.2............. Loss: 2.61729050, mean(E): -17.09007875-0.32523315j, var(E): 0.89181584
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=0.2............. Loss: -0.13108834, mean(E): -16.97045123-0.23605923j, var(E): 0.77882472
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=0.2............. Loss: -10.94049525, mean(E): -17.10483623-0.00664299j, var(E): 2.31918053
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=0.2............. Loss: -10.31876701, mean(E): -16.12423193+0.14120515j, var(E): 4.67152021
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=0.2............. Loss: -7.23521323, mean(E): -16.53990145-0.18230095j, var(E): 3.23579291
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(22.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=0.2............. Loss: 6.72070766, mean(E): -16.27434093-0.00161104j, var(E): 2.60012197
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=0.2............. Loss: -2.14238042, mean(E): -16.23033775+0.00017732j, var(E): 3.68321513
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=0.2............. Loss: -16.65682808, mean(E): -16.22442064-0.15509091j, var(E): 2.88056350
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=0.2............. Loss: 10.76270235, mean(E): -16.10675205+0.28741316j, var(E): 11.42804516
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=0.2............. Loss: 9.69906856, mean(E): -16.42539498-0.23794122j, var(E): 11.31807568
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=0.2............. Loss: -8.62885556, mean(E): -16.26177006-0.06611265j, var(E): 1.09468758
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=0.2............. Loss: -4.75988182, mean(E): -16.42419473-0.00790809j, var(E): 1.11981359
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=0.2............. Loss: 2.56976158, mean(E): -16.40547864-0.07328450j, var(E): 2.14910324
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=0.2............. Loss: -1.09873642, mean(E): -16.33795291-0.01257473j, var(E): 1.72995528
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=0.2............. Loss: -0.61772852, mean(E): -16.49370928+0.04425133j, var(E): 0.77405825
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=0.2............. Loss: 1.86355381, mean(E): -16.45491596+0.15005362j, var(E): 0.34251508
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=0.2............. Loss: -1.23238357, mean(E): -16.44102393-0.10969095j, var(E): 2.75016908
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=0.2............. Loss: -11.18481873, mean(E): -16.46163551+0.05077373j, var(E): 0.82431330
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=0.2............. Loss: 5.19082257, mean(E): -16.48516255-0.10668358j, var(E): 0.56953684
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=0.2............. Loss: -11.66702127, mean(E): -16.51865838+0.14737663j, var(E): 0.61966041
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=0.2............. Loss: -14.18992015, mean(E): -16.17250289+0.01376007j, var(E): 1.59163768
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=0.2............. Loss: -4.87870985, mean(E): -16.37650803+0.03844042j, var(E): 1.43381415
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=0.2............. Loss: -6.86703577, mean(E): -14.92271100-0.27110690j, var(E): 4.95574083
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=0.2............. Loss: 19.83038380, mean(E): -15.69700467+0.25886494j, var(E): 6.26564533
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=0.2............. Loss: -14.96385657, mean(E): -15.70060692-0.30865739j, var(E): 6.10064510
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(23.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=0.2............. Loss: -9.82025489, mean(E): -15.91141206-0.04290458j, var(E): 4.55527481
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=0.2............. Loss: -13.87370037, mean(E): -15.92463395-0.16678938j, var(E): 14.29986601
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=0.2............. Loss: -0.64336042, mean(E): -16.34515511+0.03662812j, var(E): 2.69331474
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=0.2............. Loss: -14.89721121, mean(E): -16.45560972-0.12822148j, var(E): 1.71943522
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=0.2............. Loss: 1.90008349, mean(E): -16.25949395-0.03820525j, var(E): 2.21556192
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=0.2............. Loss: -1.18424240, mean(E): -16.42725257-0.21930019j, var(E): 0.58180939
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=0.2............. Loss: 8.02143991, mean(E): -16.37129652-0.42434749j, var(E): 2.54758251
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(24.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=0.2............. Loss: -1.73181416, mean(E): -11.96686146-0.01605524j, var(E): 2.43162337
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=0.2............. Loss: 1.90878441, mean(E): -11.11012856-0.03064406j, var(E): 5.71054318
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(25.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=0.2............. Loss: -0.79550844, mean(E): -11.09919850+0.01157299j, var(E): 5.39888992
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=0.2............. Loss: -2.36239599, mean(E): -11.05490165-0.02662797j, var(E): 5.02360781
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=0.2............. Loss: -3.04597606, mean(E): -11.03795660-0.05086954j, var(E): 4.56734773
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=0.2............. Loss: -1.17781195, mean(E): -10.99583192+0.02582613j, var(E): 4.04622166
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=0.2............. Loss: -3.40527129, mean(E): -11.14653506-0.01330289j, var(E): 3.94193583
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=0.2............. Loss: -2.00508265, mean(E): -10.85061305+0.06143614j, var(E): 4.80688735
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=0.2............. Loss: 2.16514059, mean(E): -11.04633917+0.16929373j, var(E): 9.39501603
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=0.2............. Loss: -3.55906958, mean(E): -10.74413087-0.00416055j, var(E): 5.09522690
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=0.2............. Loss: -1.38034307, mean(E): -11.02632853+0.01182584j, var(E): 4.62658023
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=0.2............. Loss: -3.20574346, mean(E): -10.88750360-0.09227175j, var(E): 6.14165208
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=0.2............. Loss: 1.29197742, mean(E): -10.91123602-0.24345680j, var(E): 19.28016653
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=0.2............. Loss: -2.54762666, mean(E): -11.01861304-0.01470842j, var(E): 4.06925470
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=0.2............. Loss: -3.52186893, mean(E): -10.98131562-0.01215911j, var(E): 4.46948120
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=0.2............. Loss: -2.78377640, mean(E): -11.02522349-0.03331348j, var(E): 5.09955634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=0.21............. Loss: -3.25206161, mean(E): -11.15610074+0.09321647j, var(E): 4.47704725
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=0.21............. Loss: -2.53681664, mean(E): -10.88739026-0.02217693j, var(E): 4.75631443
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=0.21............. Loss: -0.18597255, mean(E): -10.91221986+0.10045002j, var(E): 4.12469222
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=0.21............. Loss: -2.19543653, mean(E): -10.86013610+0.00363092j, var(E): 4.75481729
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=0.2............. Loss: -1.07232302, mean(E): -11.18482559-0.04362617j, var(E): 4.47150916
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=0.2............. Loss: -2.84262186, mean(E): -10.95624436-0.03480329j, var(E): 4.65847064
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=0.2............. Loss: -1.91411494, mean(E): -10.93022803+0.10176064j, var(E): 4.91523764
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=0.2............. Loss: -1.70725037, mean(E): -11.05671488+0.05559617j, var(E): 4.66076894
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=0.2............. Loss: 3.09048311, mean(E): -10.88931008-0.01406013j, var(E): 6.40210495
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=0.2............. Loss: -2.20901508, mean(E): -11.00840121+0.01228407j, var(E): 5.00420424
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=0.2............. Loss: -3.76725059, mean(E): -11.29398683-0.00626287j, var(E): 3.95657788
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=0.2............. Loss: -2.64018416, mean(E): -10.93198840+0.04677734j, var(E): 4.47334327
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=0.2............. Loss: 2.88136169, mean(E): -10.86353867+0.12208625j, var(E): 5.12509332
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=0.2............. Loss: -0.36425556, mean(E): -10.93971686+0.05582641j, var(E): 5.26325744
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=0.2............. Loss: -1.49485196, mean(E): -10.74912598+0.00177110j, var(E): 5.53210641
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=0.2............. Loss: -3.51062646, mean(E): -10.89713584-0.09903170j, var(E): 5.24833108
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=0.21............. Loss: -2.33823564, mean(E): -11.20386425-0.06117119j, var(E): 3.63360135
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=0.21............. Loss: -1.22023517, mean(E): -11.27803169-0.11319438j, var(E): 15.23069100
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=0.21............. Loss: -1.23273237, mean(E): -10.99873242-0.01710883j, var(E): 4.43091897
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=0.2............. Loss: -2.86477605, mean(E): -10.99370799+0.05798894j, var(E): 4.88654979
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=0.2............. Loss: -0.02293037, mean(E): -11.08482605-0.02337832j, var(E): 7.20539783
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=0.2............. Loss: -1.29132334, mean(E): -11.15883634-0.00771059j, var(E): 4.06889404
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=0.2............. Loss: -1.33183969, mean(E): -10.98117973+0.16541856j, var(E): 6.36708931
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=0.2............. Loss: -1.21832896, mean(E): -10.97010403+0.06257219j, var(E): 6.37801999
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=0.2............. Loss: -1.18629537, mean(E): -10.89739987+0.00561969j, var(E): 4.70029571
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=0.2............. Loss: -0.23833957, mean(E): -10.85520828+0.00171467j, var(E): 6.62285615
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=0.2............. Loss: -1.47867450, mean(E): -10.91536400+0.01077351j, var(E): 4.73850668
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=0.2............. Loss: -3.37397293, mean(E): -10.85536014+0.07108727j, var(E): 5.76112067
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=0.2............. Loss: -1.85413267, mean(E): -10.94568110+0.09098529j, var(E): 5.46135548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=0.2............. Loss: -1.94807292, mean(E): -11.11895021+0.00859104j, var(E): 4.73922270
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=0.2............. Loss: -1.85859055, mean(E): -11.06709010-0.03593479j, var(E): 4.28258124
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=0.2............. Loss: -1.89443919, mean(E): -10.85174664+0.03552996j, var(E): 4.53730967
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=0.2............. Loss: -1.49701767, mean(E): -10.71239128+0.07201286j, var(E): 4.76260598
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=0.2............. Loss: -2.03971578, mean(E): -11.04712835+0.07096704j, var(E): 4.42857915
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=0.2............. Loss: -3.14249505, mean(E): -10.87722409-0.01277894j, var(E): 4.66617827
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=0.2............. Loss: -1.13543891, mean(E): -10.88259568+0.06341195j, var(E): 4.56920049
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=0.2............. Loss: -11.31177519, mean(E): -10.91199060-0.19652535j, var(E): 12.30979946
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=0.2............. Loss: -6.81039113, mean(E): -11.17924630-0.21276630j, var(E): 10.41389736
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=0.2............. Loss: -1.25805136, mean(E): -11.07036018+0.01325481j, var(E): 4.11593527
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=0.2............. Loss: -0.02266865, mean(E): -10.99045360+0.10006999j, var(E): 4.75089868
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=0.2............. Loss: -2.23076795, mean(E): -10.99845945+0.00548390j, var(E): 4.42418682
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=0.2............. Loss: -0.65810256, mean(E): -10.86621497+0.11568957j, var(E): 4.23783817
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=0.2............. Loss: -4.60129113, mean(E): -10.96144155-0.04943836j, var(E): 4.76066226
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=0.2............. Loss: -2.23174697, mean(E): -11.00607047+0.03489940j, var(E): 4.84658797
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=0.2............. Loss: -4.40016087, mean(E): -11.12187284+0.01407437j, var(E): 4.49419085
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=0.2............. Loss: 0.12852814, mean(E): -11.14964610+0.03505236j, var(E): 4.17541650
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=0.2............. Loss: -1.67468822, mean(E): -11.04569435+0.10251378j, var(E): 4.60399698
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=0.2............. Loss: -4.55440260, mean(E): -10.95613828-0.04632075j, var(E): 4.66633066
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=0.2............. Loss: -1.08770573, mean(E): -11.05475254-0.00048616j, var(E): 5.01716819
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=0.2............. Loss: -2.41716349, mean(E): -10.98080392+0.03672360j, var(E): 5.99850583
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=0.2............. Loss: -1.79370717, mean(E): -11.25075185-0.02208864j, var(E): 3.81488844
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=0.2............. Loss: -1.43547943, mean(E): -11.15154437-0.01621671j, var(E): 4.56574263
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=0.2............. Loss: -2.66194638, mean(E): -11.17814637+0.03127035j, var(E): 4.39594075
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=0.2............. Loss: -2.39506580, mean(E): -11.04878846-0.01850374j, var(E): 4.89649731
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=0.2............. Loss: -4.82679430, mean(E): -11.03954307-0.18282771j, var(E): 8.23035856
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=0.2............. Loss: -2.33523702, mean(E): -10.91545671+0.03419816j, var(E): 5.05631653
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=0.2............. Loss: -2.34284640, mean(E): -11.01576155-0.00667992j, var(E): 4.82370369
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=0.2............. Loss: -3.06485654, mean(E): -11.27772342-0.04028275j, var(E): 5.19695215
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=0.2............. Loss: -1.52909447, mean(E): -10.80284567-0.04980123j, var(E): 5.07080567
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=0.2............. Loss: -2.83047150, mean(E): -10.93448205-0.03693589j, var(E): 4.73248115
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=0.2............. Loss: -2.67827723, mean(E): -11.20857147+0.01202094j, var(E): 4.08770755
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=0.2............. Loss: -2.84182439, mean(E): -10.94119056+0.10901131j, var(E): 4.25813644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=0.2............. Loss: -3.39618546, mean(E): -11.13158556+0.04751347j, var(E): 4.26424239
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=0.2............. Loss: -2.55774750, mean(E): -10.86139342+0.04134351j, var(E): 4.98084439
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=0.2............. Loss: -0.41153130, mean(E): -11.29337255-0.15681117j, var(E): 6.41042587
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=0.2............. Loss: -5.42527016, mean(E): -11.04069048-0.02187712j, var(E): 5.48348280
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=0.2............. Loss: -3.67545939, mean(E): -11.03832104-0.12731900j, var(E): 4.45438195
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=0.2............. Loss: -2.37095434, mean(E): -11.46000017+0.01873234j, var(E): 3.48347193
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=0.2............. Loss: -2.34046031, mean(E): -11.32349238-0.07544600j, var(E): 3.67146033
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=0.21............. Loss: -3.52201897, mean(E): -10.92151837-0.02798631j, var(E): 4.71809007
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=0.2............. Loss: -2.38229284, mean(E): -11.05256109-0.00460678j, var(E): 6.57256717
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=0.2............. Loss: -1.85430719, mean(E): -11.05814441+0.01918418j, var(E): 4.25951651
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=0.2............. Loss: -3.63399509, mean(E): -10.95951829-0.05056662j, var(E): 4.77316078
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=0.2............. Loss: -0.54964699, mean(E): -11.12168030-0.07617651j, var(E): 4.30298793
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=0.2............. Loss: -3.85544403, mean(E): -11.33697952+0.01883506j, var(E): 4.25461555
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=0.2............. Loss: -1.01984073, mean(E): -11.08599740-0.03063467j, var(E): 6.06507496
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=0.2............. Loss: -1.39549472, mean(E): -11.18835536-0.02159482j, var(E): 4.77339056
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=0.2............. Loss: 1.53968979, mean(E): -11.13928668+0.07343267j, var(E): 5.81308155
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=0.2............. Loss: -0.74147424, mean(E): -11.07902235+0.06806123j, var(E): 11.36888754
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=0.2............. Loss: -2.35721698, mean(E): -11.06366818-0.03102956j, var(E): 5.58062626
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=0.2............. Loss: -3.21628401, mean(E): -11.37642581-0.05770522j, var(E): 3.89440704
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=0.2............. Loss: 0.16697131, mean(E): -11.40629703-0.00775239j, var(E): 4.08335899
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=0.2............. Loss: -1.26414295, mean(E): -11.05096491+0.03460212j, var(E): 4.04957339
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=0.2............. Loss: -1.90693888, mean(E): -11.13091883+0.03785547j, var(E): 5.21406228
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=0.2............. Loss: -2.21223492, mean(E): -11.02001673-0.06133945j, var(E): 4.86091950
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=0.2............. Loss: -3.26719640, mean(E): -11.18288598-0.02472261j, var(E): 5.29420796
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=0.2............. Loss: -3.15975247, mean(E): -11.11523289-0.00058562j, var(E): 6.08496916
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=0.2............. Loss: -3.41325026, mean(E): -11.19393701+0.07646064j, var(E): 4.33561644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=0.2............. Loss: -3.33850391, mean(E): -11.04883473-0.04547438j, var(E): 4.16414286
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=0.2............. Loss: -1.65403328, mean(E): -11.14647067-0.05177109j, var(E): 4.15494249
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=0.2............. Loss: -2.38143746, mean(E): -11.00267909-0.01304017j, var(E): 4.56293909
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=0.2............. Loss: -1.98833904, mean(E): -11.03036265+0.01364250j, var(E): 4.65106121
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=0.2............. Loss: -2.83895142, mean(E): -11.11003093+0.01263433j, var(E): 4.61668663
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=0.2............. Loss: -2.29197089, mean(E): -11.18594498+0.01231662j, var(E): 5.15487851
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=0.2............. Loss: -4.43902708, mean(E): -11.27678656-0.01223659j, var(E): 4.38541598
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=0.2............. Loss: -2.58315474, mean(E): -10.89284481+0.12553410j, var(E): 6.47994670
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=0.2............. Loss: -2.73274014, mean(E): -11.35769119-0.04581642j, var(E): 4.33406077
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=0.2............. Loss: -3.03242427, mean(E): -11.25767200+0.00270268j, var(E): 4.23589682
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=0.2............. Loss: -2.63660049, mean(E): -11.00209713-0.07695708j, var(E): 5.87216028
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=0.2............. Loss: -1.22611466, mean(E): -11.13604413+0.00930945j, var(E): 4.29704311
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=0.2............. Loss: -0.11014060, mean(E): -11.37035937+0.03197683j, var(E): 4.54722075
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=0.2............. Loss: -0.95189035, mean(E): -11.20724680+0.12950197j, var(E): 4.30723595
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=0.2............. Loss: -2.78576833, mean(E): -11.52370199-0.03183087j, var(E): 3.25779294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=0.2............. Loss: -2.25332969, mean(E): -11.25289490-0.02658380j, var(E): 4.92019402
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=0.2............. Loss: -3.08445113, mean(E): -11.38787993+0.01391755j, var(E): 3.92637620
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=0.2............. Loss: -1.74693148, mean(E): -11.22718021+0.02431283j, var(E): 4.31945742
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=0.2............. Loss: -3.79767235, mean(E): -11.25286821-0.04115263j, var(E): 4.23731488
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=0.2............. Loss: -0.19878756, mean(E): -11.06781565-0.00323091j, var(E): 4.68900050
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=0.2............. Loss: -0.06636751, mean(E): -11.50231249-0.24655511j, var(E): 5.96824656
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=0.2............. Loss: -3.47565322, mean(E): -11.21368317-0.03778845j, var(E): 4.06728967
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=0.2............. Loss: -2.82065568, mean(E): -11.20758219+0.00767095j, var(E): 4.54442307
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=0.2............. Loss: 0.86606681, mean(E): -11.58641727+0.02372380j, var(E): 3.42749227
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=0.2............. Loss: -3.64379906, mean(E): -11.08106642-0.09889028j, var(E): 13.55411200
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=0.2............. Loss: 0.67228081, mean(E): -11.42542550-0.18650239j, var(E): 4.61136865
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=0.2............. Loss: -1.67161993, mean(E): -11.42864196-0.06257230j, var(E): 4.22351039
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=0.2............. Loss: -2.32210597, mean(E): -11.11336345+0.09489014j, var(E): 5.03371248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=0.2............. Loss: -3.96345450, mean(E): -11.24244669-0.07821225j, var(E): 3.73351182
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=0.2............. Loss: -2.95337865, mean(E): -11.43901361-0.03095309j, var(E): 3.20161751
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=0.2............. Loss: 0.96462697, mean(E): -11.26484838+0.02924542j, var(E): 4.96821554
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=0.2............. Loss: -2.23536912, mean(E): -11.35790656-0.02022082j, var(E): 4.04414913
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=0.2............. Loss: 1.22919809, mean(E): -11.47180109+0.04316530j, var(E): 4.05994968
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=0.2............. Loss: -1.88004000, mean(E): -11.19015225+0.01576654j, var(E): 5.84476150
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=0.2............. Loss: -1.85845113, mean(E): -11.29103643-0.02553913j, var(E): 5.16792037
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=0.2............. Loss: 3.25605987, mean(E): -11.36205025-0.05446576j, var(E): 6.57234998
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=0.2............. Loss: 0.59880173, mean(E): -11.04376971+0.06725038j, var(E): 4.57967553
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=0.2............. Loss: -4.09208131, mean(E): -11.42495557-0.04126900j, var(E): 3.44475812
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=0.2............. Loss: -3.62906148, mean(E): -11.27068108-0.03693304j, var(E): 3.99403271
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=0.2............. Loss: -1.40386731, mean(E): -11.24512477+0.12099432j, var(E): 3.83213161
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=0.2............. Loss: -2.84170056, mean(E): -11.32304914+0.02963463j, var(E): 4.09623046
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=0.2............. Loss: -2.18456310, mean(E): -11.48555387-0.02115754j, var(E): 3.51208508
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=0.2............. Loss: -1.35712849, mean(E): -11.41729979-0.05850527j, var(E): 5.13310624
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=0.2............. Loss: -2.28045449, mean(E): -11.16759509-0.06416435j, var(E): 4.84201001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=0.2............. Loss: -2.31603924, mean(E): -11.57832470-0.10006361j, var(E): 5.41529108
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=0.2............. Loss: 1.16607785, mean(E): -11.42253529+0.14662555j, var(E): 5.35234339
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=0.2............. Loss: -0.25780234, mean(E): -11.32170028+0.03792261j, var(E): 4.19583922
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=0.2............. Loss: -2.79428891, mean(E): -11.23539747-0.02278575j, var(E): 5.38966635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=0.2............. Loss: -0.97622647, mean(E): -11.34434226-0.01134592j, var(E): 4.43077365
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=0.2............. Loss: 2.31151187, mean(E): -11.34113542-0.04359753j, var(E): 5.85428793
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=0.21............. Loss: -3.24155084, mean(E): -11.37455307-0.02853137j, var(E): 3.88217260
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=0.2............. Loss: -1.71856261, mean(E): -11.16204094+0.06288041j, var(E): 4.17263526
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=0.2............. Loss: -1.47640784, mean(E): -11.43457614+0.00732248j, var(E): 3.75623045
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=0.2............. Loss: -0.27798662, mean(E): -11.39881676+0.05051539j, var(E): 4.19730461
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=0.2............. Loss: -0.72620088, mean(E): -11.27177896+0.02102802j, var(E): 3.96598233
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=0.2............. Loss: -2.35983663, mean(E): -11.12306513-0.03405951j, var(E): 5.31856448
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=0.2............. Loss: -1.72052445, mean(E): -11.30041010+0.13901107j, var(E): 4.85540635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=0.2............. Loss: 0.73463411, mean(E): -11.58540148+0.04152714j, var(E): 3.91766128
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=0.2............. Loss: -2.84073384, mean(E): -11.34984756+0.06135783j, var(E): 5.05258259
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=0.2............. Loss: -2.93930001, mean(E): -11.11895712+0.00338296j, var(E): 4.31518943
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=0.2............. Loss: -0.51531624, mean(E): -11.51580742-0.00387496j, var(E): 3.56389514
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=0.2............. Loss: -3.88331733, mean(E): -11.52554116-0.06055487j, var(E): 3.86888002
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=0.2............. Loss: 1.22957293, mean(E): -11.18092613+0.05062993j, var(E): 5.40613396
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=0.2............. Loss: -2.69110233, mean(E): -11.45380242+0.01487112j, var(E): 3.78437696
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=0.2............. Loss: 0.20329351, mean(E): -11.33823552+0.00043808j, var(E): 4.73077653
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=0.2............. Loss: -1.95968807, mean(E): -11.37078650+0.02272946j, var(E): 3.41200031
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=0.2............. Loss: -1.76822732, mean(E): -11.33411044-0.03223238j, var(E): 3.61419048
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=0.2............. Loss: -5.66478253, mean(E): -11.48873153+0.02190470j, var(E): 3.78620728
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=0.2............. Loss: 2.31971097, mean(E): -11.22486081+0.05424222j, var(E): 3.85699355
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=0.2............. Loss: -0.60578475, mean(E): -11.15698917+0.02285452j, var(E): 4.84900800
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=0.2............. Loss: -3.83868200, mean(E): -11.33387712-0.08034532j, var(E): 3.81611696
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=0.2............. Loss: 0.86233414, mean(E): -11.34518259-0.02781875j, var(E): 6.16896932
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=0.2............. Loss: -2.02613320, mean(E): -11.38048255+0.00109460j, var(E): 3.59528168
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=0.2............. Loss: -2.39372728, mean(E): -11.49289950+0.02344809j, var(E): 3.08324417
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=0.2............. Loss: -2.74596452, mean(E): -11.28522336-0.02466123j, var(E): 4.83036944
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=0.2............. Loss: -2.03169514, mean(E): -11.43033545-0.00482565j, var(E): 5.17300190
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=0.2............. Loss: -0.65662719, mean(E): -11.31684178+0.00165278j, var(E): 4.22141551
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=0.2............. Loss: -0.71741296, mean(E): -11.31139708+0.03052097j, var(E): 4.40152360
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=0.2............. Loss: -1.35718319, mean(E): -11.08881756+0.01970089j, var(E): 5.44058255
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=0.2............. Loss: -1.67437921, mean(E): -11.30607457+0.02093245j, var(E): 3.65572711
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=0.2............. Loss: -3.81344124, mean(E): -11.01672115-0.07032984j, var(E): 6.95453779
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=0.2............. Loss: -1.33022028, mean(E): -11.30439156-0.04660129j, var(E): 4.52503628
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=0.2............. Loss: -2.18493130, mean(E): -10.95729885+0.03895125j, var(E): 4.56873942
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=0.2............. Loss: -2.61628062, mean(E): -11.66357087-0.01455674j, var(E): 2.94441030
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=0.2............. Loss: -1.39945150, mean(E): -11.47498740+0.08120409j, var(E): 10.01052752
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=0.2............. Loss: -2.44814968, mean(E): -11.47926382-0.04240203j, var(E): 3.18046902
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=0.2............. Loss: -4.16317855, mean(E): -11.31442531-0.00121246j, var(E): 4.77544705
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=0.2............. Loss: -0.42571383, mean(E): -11.17640165+0.03159531j, var(E): 5.28424022
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=0.2............. Loss: -3.21628439, mean(E): -11.18968453-0.01129207j, var(E): 4.24955135
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=0.2............. Loss: 3.81067987, mean(E): -11.23241021-0.09561202j, var(E): 5.77658976
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=0.21............. Loss: 0.78272611, mean(E): -11.25236616+0.01131934j, var(E): 4.58068835
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=0.2............. Loss: -0.43075771, mean(E): -11.48822569+0.07821913j, var(E): 4.20316471
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=0.2............. Loss: -1.28305219, mean(E): -11.48988679+0.03957555j, var(E): 3.30374857
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=0.2............. Loss: -2.93864294, mean(E): -11.30688280-0.07694054j, var(E): 4.09916742
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=0.2............. Loss: -2.24349840, mean(E): -11.20185633-0.05241250j, var(E): 5.76007343
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=0.2............. Loss: -1.31766367, mean(E): -11.34507338-0.03446759j, var(E): 3.87083483
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=0.2............. Loss: -1.65384844, mean(E): -11.33531603+0.01733262j, var(E): 3.55005861
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=0.2............. Loss: -2.07233452, mean(E): -11.51442194-0.01730301j, var(E): 2.79064042
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=0.2............. Loss: -6.15104203, mean(E): -11.43378388-0.17407582j, var(E): 5.77225033
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=0.2............. Loss: -2.31591634, mean(E): -11.41053577-0.06519181j, var(E): 5.11043748
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=0.2............. Loss: -1.29655418, mean(E): -11.15843287+0.14984879j, var(E): 5.50655923
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=0.2............. Loss: -2.63442386, mean(E): -11.52722187+0.10082205j, var(E): 4.00281777
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=0.2............. Loss: -3.34316356, mean(E): -11.29171563-0.09092185j, var(E): 4.17149154
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=0.2............. Loss: 1.69858236, mean(E): -11.37646198+0.07685995j, var(E): 4.46749769
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=0.21............. Loss: -1.25345497, mean(E): -11.38548253+0.09214721j, var(E): 5.34900406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=0.21............. Loss: -1.98334868, mean(E): -11.46015856+0.02289427j, var(E): 3.95767551
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=0.2............. Loss: -3.33807061, mean(E): -11.48481651-0.04855355j, var(E): 3.28618616
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=0.2............. Loss: -0.88003133, mean(E): -11.34245712+0.03701404j, var(E): 4.25450073
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=0.2............. Loss: -0.94035254, mean(E): -11.24776552+0.08994790j, var(E): 7.98763722
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=0.21............. Loss: -4.21797503, mean(E): -11.33920791-0.00927105j, var(E): 4.80680087
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=0.2............. Loss: -2.53989263, mean(E): -11.36452185-0.04944356j, var(E): 3.62238126
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=0.2............. Loss: -3.00554575, mean(E): -11.39061718-0.04922962j, var(E): 4.97840789
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=0.2............. Loss: -2.80339615, mean(E): -11.30592521-0.04655885j, var(E): 4.28069825
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=0.2............. Loss: -3.30445025, mean(E): -11.31673977-0.02267265j, var(E): 3.43987782
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=0.2............. Loss: -2.01400549, mean(E): -11.62969394-0.12734181j, var(E): 3.07549368
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=0.2............. Loss: -2.98391474, mean(E): -11.33191036-0.02997591j, var(E): 3.80622586
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=0.2............. Loss: -1.57638938, mean(E): -11.46008255+0.01684776j, var(E): 4.34988223
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=0.2............. Loss: -2.56397278, mean(E): -11.37787279+0.11853392j, var(E): 4.39775763
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=0.2............. Loss: -1.26658777, mean(E): -11.27014284+0.06322498j, var(E): 4.80400571
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=0.2............. Loss: -3.90112850, mean(E): -11.33464134-0.05147457j, var(E): 3.39085344
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=0.21............. Loss: -2.88527480, mean(E): -11.44397212-0.03612205j, var(E): 3.83196175
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=0.2............. Loss: -2.38619580, mean(E): -11.51043197+0.02732203j, var(E): 5.87595974
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=0.21............. Loss: -2.02530718, mean(E): -11.04236445+0.06446970j, var(E): 4.79488101
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=0.2............. Loss: -3.45797931, mean(E): -11.01184024-0.03436954j, var(E): 4.54282942
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=0.2............. Loss: -2.35132613, mean(E): -11.51898645-0.05251819j, var(E): 4.82002791
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=0.2............. Loss: -2.90664724, mean(E): -11.41599737+0.03690239j, var(E): 3.61867523
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=0.2............. Loss: -2.82952108, mean(E): -11.32188866-0.09417044j, var(E): 3.89063817
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=0.2............. Loss: -2.00286231, mean(E): -11.44186313+0.03228123j, var(E): 3.88854373
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=0.2............. Loss: -2.79668539, mean(E): -11.45846962-0.00634877j, var(E): 2.95059248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=0.2............. Loss: -3.79633376, mean(E): -11.27717319-0.06589402j, var(E): 5.11782221
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=0.2............. Loss: -0.31194057, mean(E): -11.35187227+0.03175920j, var(E): 4.43172081
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=0.2............. Loss: -3.64541303, mean(E): -11.37320365-0.04801997j, var(E): 4.27043722
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=0.2............. Loss: -2.79066604, mean(E): -11.24982846-0.00694376j, var(E): 3.72979566
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=0.2............. Loss: -1.77594429, mean(E): -11.32200570+0.00801152j, var(E): 4.43789994
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=0.2............. Loss: -2.86545968, mean(E): -11.39762860-0.03481638j, var(E): 3.63739954
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=0.2............. Loss: -2.92016551, mean(E): -11.42425231+0.06781903j, var(E): 3.82829874
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=0.2............. Loss: -2.33289663, mean(E): -11.32009068-0.03865614j, var(E): 3.77306009
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=0.2............. Loss: 0.77050410, mean(E): -11.48271998+0.08203976j, var(E): 4.16426497
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=0.2............. Loss: -2.57261156, mean(E): -11.26510105-0.04873417j, var(E): 3.84392600
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=0.21............. Loss: 0.50233781, mean(E): -11.49191930-0.07186329j, var(E): 5.75453848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=0.2............. Loss: -3.28314433, mean(E): -11.33338701+0.03336646j, var(E): 3.27753006
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=0.21............. Loss: -3.78688041, mean(E): -11.27324989-0.02940696j, var(E): 3.66666261
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=0.2............. Loss: 1.01967639, mean(E): -11.31309519+0.00542314j, var(E): 6.08179923
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=0.2............. Loss: -5.19669207, mean(E): -11.39370340-0.00435495j, var(E): 5.62453413
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=0.2............. Loss: -1.85021333, mean(E): -11.52842726-0.03348179j, var(E): 3.44697300
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=0.2............. Loss: -4.33198979, mean(E): -11.24002104-0.12265105j, var(E): 5.16932399
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=0.21............. Loss: -0.83913179, mean(E): -11.43301573+0.07672075j, var(E): 4.22729408
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=0.2............. Loss: 0.49592031, mean(E): -11.10379324-0.05979865j, var(E): 5.59168795
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=0.2............. Loss: -2.12316205, mean(E): -11.36845044-0.01481141j, var(E): 4.29243244
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=0.21............. Loss: -1.98969285, mean(E): -11.47210015+0.06983691j, var(E): 3.41706891
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=0.2............. Loss: -1.74970270, mean(E): -11.46990219-0.01352564j, var(E): 3.74743955
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=0.2............. Loss: -0.78654696, mean(E): -11.35437687+0.03127310j, var(E): 4.70525954
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=0.21............. Loss: -1.94445765, mean(E): -11.24703807-0.05617174j, var(E): 4.17381093
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=0.2............. Loss: -1.59219761, mean(E): -11.30243890+0.11826863j, var(E): 4.10591878
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=0.2............. Loss: -4.72587697, mean(E): -11.27980120-0.05107691j, var(E): 4.08395647
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=0.2............. Loss: -0.86976630, mean(E): -11.75807859-0.02947223j, var(E): 2.97179758
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=0.2............. Loss: -2.45627460, mean(E): -11.22872259+0.09726164j, var(E): 4.92517332
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=0.2............. Loss: -2.54257776, mean(E): -11.32364694+0.11102500j, var(E): 4.95149904
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=0.21............. Loss: -1.72727330, mean(E): -11.34570219+0.00670025j, var(E): 4.01373250
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=0.2............. Loss: -4.64621256, mean(E): -11.54532209+0.04918508j, var(E): 3.24635646
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=0.21............. Loss: -4.12427474, mean(E): -11.44410742+0.02512538j, var(E): 3.35058795
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=0.2............. Loss: -10.49169067, mean(E): -10.51746394+0.14919065j, var(E): 162.94516140
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=0.2............. Loss: -2.58310278, mean(E): -11.38694358+0.01546980j, var(E): 3.52441739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=0.21............. Loss: -2.18962091, mean(E): -11.56857898-0.05080511j, var(E): 3.52849039
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=0.21............. Loss: -0.11759095, mean(E): -11.35289225-0.02007386j, var(E): 3.63820678
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=0.2............. Loss: -1.22104034, mean(E): -11.54267797+0.00641664j, var(E): 2.85287164
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=0.2............. Loss: -2.63846605, mean(E): -11.34941855-0.06438075j, var(E): 3.78529296
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=0.21............. Loss: -5.01079188, mean(E): -11.15844509+0.06970846j, var(E): 6.23344216
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=0.2............. Loss: -2.61455291, mean(E): -11.54577929-0.07019877j, var(E): 2.93283807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=0.2............. Loss: -3.07729417, mean(E): -11.45429880-0.07504731j, var(E): 3.96685551
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=0.21............. Loss: -3.01863297, mean(E): -11.49084285-0.07252346j, var(E): 3.02407907
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=0.2............. Loss: -2.95807489, mean(E): -11.58735031+0.05697969j, var(E): 2.94284499
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=0.21............. Loss: -3.51455699, mean(E): -11.28927459+0.02805897j, var(E): 4.57355835
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=0.2............. Loss: -3.57411910, mean(E): -11.53279062-0.11195025j, var(E): 4.75230448
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=0.2............. Loss: -5.85589099, mean(E): -11.46146448-0.08148204j, var(E): 5.34898202
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=0.2............. Loss: -1.58875883, mean(E): -11.61640700+0.10829682j, var(E): 3.98802571
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=0.2............. Loss: -1.92869816, mean(E): -11.29460348-0.03399541j, var(E): 3.64393197
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=0.21............. Loss: -5.83327444, mean(E): -11.24646270-0.11254484j, var(E): 12.91528246
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=0.2............. Loss: -3.53584447, mean(E): -11.54021142-0.07568671j, var(E): 4.70578806
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=0.2............. Loss: -3.62445213, mean(E): -11.04758503+0.03682263j, var(E): 5.11968596
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=0.2............. Loss: -3.53263175, mean(E): -11.47475318+0.09033447j, var(E): 4.74797676
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=0.21............. Loss: -4.24418668, mean(E): -11.38921251+0.00105223j, var(E): 3.77783183
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=0.2............. Loss: -3.80895391, mean(E): -11.13631829-0.00265863j, var(E): 4.59205054
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=0.2............. Loss: -0.06193434, mean(E): -11.29042733-0.02942425j, var(E): 5.11726857
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=0.2............. Loss: -5.26490610, mean(E): -11.42353649+0.05415703j, var(E): 3.72788368
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=0.21............. Loss: -2.77731118, mean(E): -11.25664954+0.03196537j, var(E): 4.65489406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=0.2............. Loss: -3.66978512, mean(E): -11.20618001+0.04400594j, var(E): 5.50343482
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=0.2............. Loss: 0.25195092, mean(E): -11.41843953+0.11274704j, var(E): 5.97807267
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=0.2............. Loss: -3.19698813, mean(E): -11.52543003-0.04233606j, var(E): 3.59689630
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=0.2............. Loss: -0.61479360, mean(E): -11.39144689-0.01860463j, var(E): 4.02420994
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=0.2............. Loss: -3.21080819, mean(E): -11.53780306-0.04819155j, var(E): 3.17326601
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=0.2............. Loss: -1.85225026, mean(E): -11.45088671+0.03017555j, var(E): 4.21708504
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=0.2............. Loss: -2.99360031, mean(E): -11.29359742+0.02661486j, var(E): 4.26181638
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=0.2............. Loss: -4.70758247, mean(E): -11.57941892-0.04572516j, var(E): 3.67808546
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=0.2............. Loss: -1.60223251, mean(E): -11.44374957-0.00470567j, var(E): 4.03181782
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=0.2............. Loss: -3.51148654, mean(E): -11.40813876+0.02625918j, var(E): 3.36120458
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=0.2............. Loss: -4.16033802, mean(E): -11.42786302-0.02031140j, var(E): 3.62795248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=0.2............. Loss: -2.38644288, mean(E): -11.12265519+0.01790211j, var(E): 4.07927179
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=0.2............. Loss: -1.68319261, mean(E): -11.48255570+0.00024951j, var(E): 3.23849056
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=0.2............. Loss: -0.40087264, mean(E): -11.36595881+0.09716365j, var(E): 5.52296679
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=0.2............. Loss: 0.98814435, mean(E): -11.28735768+0.08043769j, var(E): 5.00853696
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=0.2............. Loss: -2.96281462, mean(E): -11.29346917+0.04312065j, var(E): 5.06693548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=0.2............. Loss: -3.84249422, mean(E): -11.37296264+0.02584920j, var(E): 4.35618457
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=0.2............. Loss: -4.46367960, mean(E): -11.25322510+0.02671676j, var(E): 4.44762195
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=0.2............. Loss: -2.20243495, mean(E): -11.29393444-0.02237609j, var(E): 3.82278864
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=0.2............. Loss: -1.72232661, mean(E): -11.48851064-0.01199761j, var(E): 3.45161430
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=0.2............. Loss: 0.11753979, mean(E): -11.35597020+0.04003011j, var(E): 4.72573258
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=0.2............. Loss: -3.58078314, mean(E): -11.66763994-0.02038417j, var(E): 4.61902547
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=0.2............. Loss: -2.05051203, mean(E): -11.15123205+0.04244178j, var(E): 5.13901323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=0.2............. Loss: -2.06187892, mean(E): -11.46577029+0.07605636j, var(E): 4.21240528
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=0.2............. Loss: -2.39129046, mean(E): -11.40486547-0.05383741j, var(E): 4.00382824
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=0.2............. Loss: -3.29407980, mean(E): -11.59780369-0.03036649j, var(E): 2.81973724
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=0.2............. Loss: -4.17069981, mean(E): -11.30854517-0.03290272j, var(E): 4.01572887
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=0.2............. Loss: -3.02690961, mean(E): -11.33189614-0.06212417j, var(E): 5.71272442
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=0.2............. Loss: -1.71442084, mean(E): -11.61231108+0.02116697j, var(E): 3.12860034
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=0.2............. Loss: -3.33683451, mean(E): -11.26393792+0.00100995j, var(E): 4.03348503
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=0.2............. Loss: -1.10740991, mean(E): -11.26244594+0.01927951j, var(E): 4.13868065
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=0.2............. Loss: -3.84489530, mean(E): -11.39811047+0.01167811j, var(E): 3.82888151
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=0.2............. Loss: -2.72119490, mean(E): -11.45501508+0.11586686j, var(E): 4.31408531
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=0.2............. Loss: -2.37918193, mean(E): -11.37550697+0.05564559j, var(E): 3.86699640
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=0.2............. Loss: 0.21709293, mean(E): -11.28879166+0.09948984j, var(E): 5.19167050
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=0.2............. Loss: -1.20202563, mean(E): -11.41370954+0.01947091j, var(E): 3.48078229
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=0.2............. Loss: 9.31135907, mean(E): -11.15531038-0.19921715j, var(E): 17.24805307
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=0.2............. Loss: -1.53491356, mean(E): -11.45642735-0.01680292j, var(E): 3.37481256
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=0.2............. Loss: -1.57489341, mean(E): -11.33812085+0.03532734j, var(E): 3.93694984
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=0.2............. Loss: -4.66038872, mean(E): -11.39969102-0.02579000j, var(E): 3.96453185
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=0.2............. Loss: -1.50804363, mean(E): -11.54017113+0.04542589j, var(E): 5.05804421
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=0.2............. Loss: -2.80995508, mean(E): -11.24693968+0.05767240j, var(E): 4.67459989
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=0.2............. Loss: -1.97601138, mean(E): -11.43612996+0.03209543j, var(E): 4.06170771
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=0.2............. Loss: -2.84487111, mean(E): -11.57905542+0.02820278j, var(E): 2.78565116
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=0.2............. Loss: -3.43479960, mean(E): -11.56654563-0.04188376j, var(E): 3.98695460
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=0.2............. Loss: -5.39377587, mean(E): -11.52155604-0.06078238j, var(E): 4.68284534
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=0.2............. Loss: -3.28322418, mean(E): -11.55546868-0.03520161j, var(E): 3.24347933
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=0.2............. Loss: -1.66324918, mean(E): -11.52663585-0.00177912j, var(E): 3.45822366
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=0.2............. Loss: 0.16076170, mean(E): -11.32294070+0.03462798j, var(E): 4.25690636
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=0.21............. Loss: -1.59356941, mean(E): -11.34383517-0.00092842j, var(E): 5.05372289
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=0.21............. Loss: -1.07406701, mean(E): -11.60009921+0.00234818j, var(E): 3.13023512
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=0.21............. Loss: -0.46490925, mean(E): -11.25606105+0.07360901j, var(E): 4.04817821
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=0.21............. Loss: -1.71921758, mean(E): -11.37783563-0.05344456j, var(E): 3.62637986
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=0.2............. Loss: -1.14407090, mean(E): -11.43965263-0.04700856j, var(E): 3.97925186
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=0.21............. Loss: -5.02091808, mean(E): -11.50653025-0.10743460j, var(E): 4.17622546
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=0.2............. Loss: -1.65896917, mean(E): -11.37698951+0.03463437j, var(E): 4.26099258
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=0.2............. Loss: -2.64963018, mean(E): -11.38794347+0.00200527j, var(E): 3.54532590
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=0.2............. Loss: -0.36992551, mean(E): -11.44742492-0.07366181j, var(E): 5.58556126
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=0.2............. Loss: -3.46324021, mean(E): -11.50637917+0.07439038j, var(E): 3.55428080
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=0.2............. Loss: -2.11128276, mean(E): -11.44826963-0.05291776j, var(E): 4.08954008
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=0.2............. Loss: 6.40988195, mean(E): -11.63409000-0.32584393j, var(E): 16.63402263
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=0.2............. Loss: -1.09183860, mean(E): -11.50751543-0.07709539j, var(E): 4.26225758
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=0.2............. Loss: -4.13546222, mean(E): -11.54245768-0.11324808j, var(E): 4.60369142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=0.21............. Loss: -2.93520123, mean(E): -11.43767073+0.01894505j, var(E): 4.09991560
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=0.21............. Loss: 1.68545460, mean(E): -11.47565667+0.10747663j, var(E): 4.60051178
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=0.21............. Loss: -3.04935998, mean(E): -11.55447396-0.03120101j, var(E): 3.29200842
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=0.21............. Loss: -3.71887239, mean(E): -11.26927346+0.12099931j, var(E): 5.60918634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=0.21............. Loss: 0.84608266, mean(E): -11.45926601+0.08764301j, var(E): 4.57608406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=0.21............. Loss: -0.96576650, mean(E): -11.50556243+0.06316785j, var(E): 3.76557102
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=0.21............. Loss: -3.57454108, mean(E): -11.50505207+0.00142434j, var(E): 5.93851114
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=0.21............. Loss: -1.72296059, mean(E): -11.53241282-0.01587342j, var(E): 3.31693999
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=0.21............. Loss: -1.72537574, mean(E): -11.53938031-0.00258642j, var(E): 3.21699100
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=0.21............. Loss: -5.20568383, mean(E): -11.50951192-0.00822956j, var(E): 4.42085239
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=0.21............. Loss: -4.78665897, mean(E): -11.30362508-0.02920302j, var(E): 4.48071734
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=0.21............. Loss: -0.90380389, mean(E): -11.59855102-0.00520822j, var(E): 2.97719339
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=0.21............. Loss: -3.19213464, mean(E): -11.70579757-0.02051311j, var(E): 3.28544601
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=0.21............. Loss: -1.34999402, mean(E): -11.39543899+0.00454401j, var(E): 3.91372041
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=0.21............. Loss: -2.37008520, mean(E): -11.34897750-0.05742906j, var(E): 5.37553241
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=0.21............. Loss: -0.13038692, mean(E): -11.74917796-0.01292625j, var(E): 3.44396097
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=0.21............. Loss: -2.16891895, mean(E): -11.52477734-0.04981301j, var(E): 4.23718190
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=0.21............. Loss: 1.21211598, mean(E): -11.31759777+0.06965918j, var(E): 5.65100099
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=0.21............. Loss: -3.77010638, mean(E): -11.39166023-0.06474094j, var(E): 5.58969185
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=0.21............. Loss: -2.69528700, mean(E): -11.60048050-0.05174960j, var(E): 4.46053448
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=0.21............. Loss: -2.00679430, mean(E): -11.63693043-0.00320957j, var(E): 3.61626577
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=0.21............. Loss: -0.77198279, mean(E): -11.70996006-0.00816774j, var(E): 3.09933027
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=0.21............. Loss: -0.99598424, mean(E): -11.42300254+0.11670955j, var(E): 4.74036717
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=0.21............. Loss: -3.58696441, mean(E): -11.12212400-0.00807402j, var(E): 4.36617081
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=0.21............. Loss: -1.93681992, mean(E): -11.40523619-0.04110650j, var(E): 3.56551905
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=0.21............. Loss: -2.09070686, mean(E): -11.49337426+0.07318693j, var(E): 3.85281521
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=0.21............. Loss: -2.49434766, mean(E): -11.29577713-0.03876257j, var(E): 5.20580582
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=0.21............. Loss: -0.27240807, mean(E): -11.27896543+0.05895650j, var(E): 5.20727836
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=0.21............. Loss: 7.13766295, mean(E): -11.66066575-0.25479047j, var(E): 16.17900173
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=0.2............. Loss: -3.57561453, mean(E): -11.47941364-0.01937384j, var(E): 3.63451139
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=0.2............. Loss: -1.03128951, mean(E): -11.59936790-0.01835822j, var(E): 4.96409264
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=0.2............. Loss: -2.76072910, mean(E): -11.36086698+0.03286004j, var(E): 3.91210943
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=0.2............. Loss: -3.48356710, mean(E): -11.56032989-0.05405854j, var(E): 3.42086722
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=0.2............. Loss: -1.60714120, mean(E): -11.63944324-0.05950218j, var(E): 3.24988373
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=0.2............. Loss: -3.35618248, mean(E): -11.28881909+0.03059279j, var(E): 4.09481671
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=0.2............. Loss: -1.09832933, mean(E): -11.43302492-0.01932907j, var(E): 3.33550745
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=0.2............. Loss: -2.18579654, mean(E): -11.53287631-0.00804125j, var(E): 3.15565561
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=0.2............. Loss: 0.43672148, mean(E): -11.51733518+0.04992944j, var(E): 5.83045758
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=0.2............. Loss: -4.94630207, mean(E): -11.60293607-0.06796628j, var(E): 4.02534488
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=0.2............. Loss: -0.00338160, mean(E): -11.26333559+0.03415754j, var(E): 4.63062739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=0.2............. Loss: -2.87328522, mean(E): -11.63831916+0.03606646j, var(E): 2.50948528
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=0.2............. Loss: -4.21219593, mean(E): -11.23275250-0.01406035j, var(E): 4.05646360
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=0.2............. Loss: -2.39984100, mean(E): -11.56009602-0.02631229j, var(E): 3.10239833
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=0.21............. Loss: -4.46890964, mean(E): -11.30836006-0.05733186j, var(E): 3.67128081
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=0.2............. Loss: -2.17750730, mean(E): -11.39467314-0.00351215j, var(E): 3.51570586
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=0.2............. Loss: -1.33336681, mean(E): -11.41175304+0.01225231j, var(E): 4.02017059
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=0.2............. Loss: -2.73423134, mean(E): -11.55773599-0.10171417j, var(E): 4.10609298
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=0.2............. Loss: 0.23905757, mean(E): -11.37926034+0.02394601j, var(E): 4.21570357
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=0.21............. Loss: -5.71121653, mean(E): -11.37929469-0.02390824j, var(E): 4.64015511
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=0.2............. Loss: -5.35387340, mean(E): -11.30049722+0.03319383j, var(E): 5.82387169
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=0.2............. Loss: -2.42538624, mean(E): -11.29700168+0.02174490j, var(E): 4.41961718
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=0.2............. Loss: -2.74267466, mean(E): -11.61213917-0.06683085j, var(E): 2.76800380
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=0.2............. Loss: -2.98777008, mean(E): -10.96187105+0.13063014j, var(E): 8.00407966
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=0.2............. Loss: -1.58245422, mean(E): -11.42829195-0.07129008j, var(E): 3.95243123
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=0.2............. Loss: -1.49084980, mean(E): -11.54558163+0.01003701j, var(E): 4.04656096
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=0.2............. Loss: -0.92883872, mean(E): -11.42794644-0.04610546j, var(E): 3.50618042
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=0.2............. Loss: -3.10323932, mean(E): -11.53641786-0.08420417j, var(E): 3.42312590
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=0.2............. Loss: -1.85816360, mean(E): -11.44691793-0.04059204j, var(E): 4.32226560
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=0.2............. Loss: -1.69508689, mean(E): -11.26593180+0.05863849j, var(E): 5.37327087
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=0.2............. Loss: -1.51868059, mean(E): -11.38544245-0.04132703j, var(E): 3.82173580
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=0.2............. Loss: -3.07529960, mean(E): -11.16640207+0.04415718j, var(E): 4.25747808
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=0.2............. Loss: -2.34620119, mean(E): -11.55090264-0.05481137j, var(E): 3.89163110
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=0.2............. Loss: -2.60729148, mean(E): -11.24037154+0.00361098j, var(E): 3.88886399
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=0.2............. Loss: -2.66799833, mean(E): -11.38651613+0.17867090j, var(E): 4.45457411
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=0.2............. Loss: -1.67132007, mean(E): -11.14789601+0.01601000j, var(E): 6.13782540
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=0.2............. Loss: -1.60681885, mean(E): -11.38331355+0.04088696j, var(E): 3.67505149
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=0.2............. Loss: -0.31729193, mean(E): -11.64546327+0.01572991j, var(E): 3.85265696
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=0.2............. Loss: -1.96552045, mean(E): -11.52759263+0.00719121j, var(E): 3.38391742
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=0.2............. Loss: -5.36970668, mean(E): -11.47745622-0.13880892j, var(E): 4.06575924
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=0.2............. Loss: -3.28494493, mean(E): -11.60767621+0.02338447j, var(E): 3.13237156
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=0.2............. Loss: -3.60162935, mean(E): -11.37192785+0.00180884j, var(E): 5.12373491
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=0.2............. Loss: -5.83039553, mean(E): -11.60108027-0.01066873j, var(E): 3.45626636
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=0.2............. Loss: -0.76123578, mean(E): -11.38031504+0.02913726j, var(E): 3.87508881
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=0.2............. Loss: 5.13519103, mean(E): -11.25523506+0.12725395j, var(E): 17.66808848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=0.2............. Loss: -5.98923038, mean(E): -11.14972364-0.11040914j, var(E): 6.94923537
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=0.2............. Loss: -2.44422768, mean(E): -11.36523164+0.08588391j, var(E): 4.14240294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=0.2............. Loss: 1.60690470, mean(E): -11.16022321-0.00617794j, var(E): 7.17005851
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=0.2............. Loss: -3.66598335, mean(E): -11.60795043-0.07682351j, var(E): 3.69806460
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=0.21............. Loss: -3.15885208, mean(E): -11.57112390-0.01056014j, var(E): 2.76611801
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=0.21............. Loss: -1.70680949, mean(E): -11.38081148-0.00368035j, var(E): 3.90097881
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=0.21............. Loss: -3.64533326, mean(E): -11.44696788-0.08523159j, var(E): 3.81414621
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=0.21............. Loss: -1.72446617, mean(E): -11.73305322-0.03687320j, var(E): 2.25192132
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=0.2............. Loss: -2.05084677, mean(E): -11.07673573+0.00101837j, var(E): 5.67476157
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=0.2............. Loss: -2.07750228, mean(E): -11.38333182+0.03718494j, var(E): 5.29695240
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=0.2............. Loss: -3.96723384, mean(E): -11.49845396+0.02851165j, var(E): 4.80060052
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=0.2............. Loss: -3.05578415, mean(E): -11.50741618-0.00765352j, var(E): 4.79012580
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=0.2............. Loss: -1.63782410, mean(E): -11.41736500-0.03479556j, var(E): 3.86433802
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=0.2............. Loss: 1.10449932, mean(E): -11.48575810+0.06132328j, var(E): 8.07033173
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=0.2............. Loss: -0.44770975, mean(E): -11.48495476+0.04138448j, var(E): 3.84327889
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=0.2............. Loss: -0.89724285, mean(E): -11.55174413+0.01505901j, var(E): 3.27709315
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=0.2............. Loss: -4.11062375, mean(E): -11.55001831-0.08912151j, var(E): 4.27445176
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=0.2............. Loss: -3.36766435, mean(E): -11.45478498-0.05542814j, var(E): 3.19326159
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=0.2............. Loss: -2.04627120, mean(E): -11.54029300+0.02671395j, var(E): 3.49629908
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=0.2............. Loss: -3.20294863, mean(E): -11.47388995+0.04497777j, var(E): 3.12259411
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=0.21............. Loss: 3.71531773, mean(E): -11.66289783-0.01753204j, var(E): 5.72859909
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=0.21............. Loss: 1.12177539, mean(E): -11.20301136+0.01864654j, var(E): 5.71973222
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=0.21............. Loss: -3.73001710, mean(E): -11.60218132-0.04780262j, var(E): 3.73571262
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=0.2............. Loss: -3.10989456, mean(E): -11.55207994-0.02392760j, var(E): 4.56202917
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=0.2............. Loss: -2.00858844, mean(E): -11.72444285-0.04029268j, var(E): 3.17583026
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=0.2............. Loss: -2.55960359, mean(E): -11.41585018-0.03523184j, var(E): 5.43533846
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=0.2............. Loss: -2.13639249, mean(E): -11.30561318-0.03922531j, var(E): 5.28363292
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=0.21............. Loss: -1.22312450, mean(E): -11.20691098+0.02725267j, var(E): 6.24081578
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=0.2............. Loss: -2.73722558, mean(E): -11.40926931-0.04036367j, var(E): 3.94828596
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=0.2............. Loss: -1.46630444, mean(E): -11.38435414+0.01454227j, var(E): 4.15768932
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=0.2............. Loss: -2.36188535, mean(E): -11.41340174-0.07578489j, var(E): 3.49265160
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=0.21............. Loss: -1.94466589, mean(E): -11.37356932-0.07331071j, var(E): 3.57140611
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=0.2............. Loss: -3.10848384, mean(E): -11.19848958+0.07497318j, var(E): 4.88525467
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=0.2............. Loss: -3.24662260, mean(E): -11.43492810+0.04897480j, var(E): 4.86164087
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=0.21............. Loss: 0.84975184, mean(E): -11.41496028+0.01421290j, var(E): 4.03789047
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=0.21............. Loss: 0.66318563, mean(E): -11.42736240+0.01372309j, var(E): 4.51434716
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=0.21............. Loss: -1.83891054, mean(E): -11.41344007-0.05712740j, var(E): 4.68888402
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=0.21............. Loss: -1.32318919, mean(E): -11.57585978-0.03308098j, var(E): 3.37386575
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=0.21............. Loss: 8.94420156, mean(E): -11.62510531-0.22561337j, var(E): 16.18406606
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=0.21............. Loss: -1.17167887, mean(E): -11.34140799-0.05333213j, var(E): 4.93420429
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=0.21............. Loss: -2.52138525, mean(E): -11.21375696-0.04922915j, var(E): 4.57598822
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=0.21............. Loss: -2.50331769, mean(E): -11.32564395+0.02177515j, var(E): 3.70211378
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=0.21............. Loss: -0.05305667, mean(E): -11.40574771+0.06727747j, var(E): 4.99488256
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=0.21............. Loss: -1.23061565, mean(E): -11.51539183+0.04001052j, var(E): 4.48642335
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=0.21............. Loss: 1.45839547, mean(E): -11.42083637+0.03710423j, var(E): 4.94061484
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=0.21............. Loss: -0.24242474, mean(E): -11.38227605+0.01959253j, var(E): 3.61517549
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=0.21............. Loss: -1.95300523, mean(E): -11.41304319-0.04855398j, var(E): 4.18209598
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=0.21............. Loss: -4.67871584, mean(E): -11.61442374-0.09182460j, var(E): 4.91297769
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=0.21............. Loss: -2.69773618, mean(E): -11.52859652-0.06760556j, var(E): 4.23228968
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=0.21............. Loss: -1.39531935, mean(E): -11.66904978+0.03409915j, var(E): 2.84345008
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=0.21............. Loss: -0.94809383, mean(E): -11.46274904+0.01265842j, var(E): 4.25035335
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=0.21............. Loss: 2.90559448, mean(E): -11.46775997+0.05240702j, var(E): 5.55107680
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=0.21............. Loss: -2.66434577, mean(E): -11.31180696+0.10152227j, var(E): 3.50642267
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=0.21............. Loss: -1.88845643, mean(E): -11.53841051-0.00784772j, var(E): 3.69580725
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=0.21............. Loss: -1.51200072, mean(E): -11.51252517+0.04047699j, var(E): 3.26421927
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=0.21............. Loss: -2.92962903, mean(E): -11.50986760+0.07895574j, var(E): 3.65435386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=0.21............. Loss: -1.23611516, mean(E): -11.29786404+0.04338019j, var(E): 3.88878447
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=0.21............. Loss: -1.64896272, mean(E): -11.32978721+0.05332756j, var(E): 4.04824389
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=0.21............. Loss: -1.97111624, mean(E): -11.56399325+0.00683456j, var(E): 3.97991734
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=0.21............. Loss: -0.73391457, mean(E): -11.45800875+0.07757653j, var(E): 4.65942882
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=0.21............. Loss: 2.33981111, mean(E): -11.43324851+0.02711168j, var(E): 5.98677147
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=0.21............. Loss: -0.05137852, mean(E): -11.55332212-0.01495453j, var(E): 6.90862473
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=0.21............. Loss: -2.50436679, mean(E): -11.52383330-0.06404824j, var(E): 3.57117879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=0.21............. Loss: -3.33940429, mean(E): -11.19868772-0.04295177j, var(E): 4.36605602
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=0.21............. Loss: -1.66624016, mean(E): -11.55467054-0.03920598j, var(E): 4.25882670
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=0.21............. Loss: 9.05675710, mean(E): -11.48781990-0.18670281j, var(E): 16.63712607
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=0.21............. Loss: -2.00343223, mean(E): -11.42685212+0.04844439j, var(E): 3.33526582
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=0.21............. Loss: -2.48568867, mean(E): -11.09839477+0.14087858j, var(E): 5.66493398
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=0.21............. Loss: -1.02700878, mean(E): -11.52962255+0.09416475j, var(E): 4.05021703
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=0.21............. Loss: -2.34495158, mean(E): -11.50283001-0.15131361j, var(E): 3.98977003
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=0.21............. Loss: -1.91243661, mean(E): -11.57834363+0.01196870j, var(E): 3.10368903
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=0.2............. Loss: -2.90125691, mean(E): -11.48397434-0.02268780j, var(E): 3.29146613
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=0.2............. Loss: -3.63530451, mean(E): -11.18211789-0.05476400j, var(E): 4.93791959
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=0.2............. Loss: -1.52953094, mean(E): -11.35001533+0.01437419j, var(E): 6.40436414
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=0.2............. Loss: 3.46747258, mean(E): -11.84938896-0.12880787j, var(E): 4.16237034
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=0.2............. Loss: -2.91197466, mean(E): -11.65802361-0.05358691j, var(E): 2.60058773
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=0.2............. Loss: -2.61340025, mean(E): -11.40286500+0.00047299j, var(E): 3.68164544
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=0.2............. Loss: -2.19446426, mean(E): -11.26531482+0.11650499j, var(E): 4.19515759
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=0.2............. Loss: 0.16286669, mean(E): -11.27889868+0.10491688j, var(E): 4.50764337
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=0.2............. Loss: -1.79626236, mean(E): -11.38712324-0.04072545j, var(E): 3.36085560
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=0.2............. Loss: -2.17194664, mean(E): -11.35256052-0.00953789j, var(E): 3.84169990
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=0.2............. Loss: -1.45554002, mean(E): -11.31934298+0.03123074j, var(E): 5.49578623
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=0.2............. Loss: -2.93714194, mean(E): -11.51921778-0.05475423j, var(E): 3.19208359
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=0.2............. Loss: -4.77463468, mean(E): -11.45928743-0.07175158j, var(E): 3.97459747
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=0.2............. Loss: -0.66593612, mean(E): -11.49341382+0.05052795j, var(E): 3.57912171
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=0.2............. Loss: -4.05442918, mean(E): -11.52696178-0.17450434j, var(E): 4.86330778
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=0.21............. Loss: -4.36890488, mean(E): -11.34719732-0.10794802j, var(E): 6.36398742
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=0.2............. Loss: -1.67904171, mean(E): -11.57077676+0.02246462j, var(E): 3.51103109
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=0.21............. Loss: -2.21445450, mean(E): -11.63976917-0.05539119j, var(E): 2.96339948
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=0.2............. Loss: -2.96839376, mean(E): -11.49366864-0.00346491j, var(E): 3.46097631
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=0.2............. Loss: -1.25092893, mean(E): -11.54892562+0.02314912j, var(E): 3.66812768
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=0.21............. Loss: 0.25481257, mean(E): -11.37672283+0.07377900j, var(E): 4.57387643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=0.21............. Loss: -4.49293839, mean(E): -11.43835964-0.03089440j, var(E): 4.59111592
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=0.21............. Loss: -2.42594643, mean(E): -11.61899462+0.01059119j, var(E): 3.23550384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=0.21............. Loss: -0.14230902, mean(E): -11.88818565-0.01757813j, var(E): 24.85218738
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=0.21............. Loss: -1.60024054, mean(E): -11.34364672+0.00358278j, var(E): 4.02839226
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=0.21............. Loss: 0.65898877, mean(E): -11.50372889+0.00167044j, var(E): 4.19831046
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=0.21............. Loss: -4.09498448, mean(E): -11.60874576-0.09074092j, var(E): 3.94684748
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=0.21............. Loss: -2.85819604, mean(E): -11.43492490-0.07026735j, var(E): 3.25132691
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=0.21............. Loss: 1.37040806, mean(E): -11.71387206+0.10251012j, var(E): 2.98113613
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=0.21............. Loss: -4.88347796, mean(E): -11.14034191-0.00228248j, var(E): 4.72269690
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=0.21............. Loss: -2.02378907, mean(E): -11.27639698+0.02047627j, var(E): 6.17466903
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=0.21............. Loss: -3.84669680, mean(E): -11.49553899-0.13686615j, var(E): 6.26165141
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=0.21............. Loss: -2.33162356, mean(E): -11.30815095+0.11895561j, var(E): 10.36748027
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=0.21............. Loss: -4.87438914, mean(E): -11.40853524+0.04573171j, var(E): 3.44231733
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=0.21............. Loss: -1.09292143, mean(E): -11.49991544-0.00891339j, var(E): 3.39874781
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=0.2............. Loss: -4.51621672, mean(E): -11.33143208+0.08400462j, var(E): 10.64528418
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=0.2............. Loss: -2.38332368, mean(E): -11.43834349-0.07773770j, var(E): 3.89735759
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=0.2............. Loss: -5.82696795, mean(E): -11.53171831-0.10152436j, var(E): 5.21583529
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=0.2............. Loss: -3.89487157, mean(E): -11.74073168-0.09156423j, var(E): 3.62654234
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=0.2............. Loss: -13.45099498, mean(E): -11.33338618+0.14037452j, var(E): 8.85436897
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=0.2............. Loss: -3.57947609, mean(E): -11.41541011+0.07991553j, var(E): 4.41370528
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=0.2............. Loss: -2.05755021, mean(E): -11.36039206-0.01734424j, var(E): 5.01475392
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=0.2............. Loss: -3.70715111, mean(E): -11.46966021-0.16970152j, var(E): 4.37603204
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=0.2............. Loss: -2.71402417, mean(E): -11.24758232+0.06356448j, var(E): 4.77672666
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=0.2............. Loss: -4.39818739, mean(E): -11.41977661-0.02881117j, var(E): 3.93361922
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=0.2............. Loss: -1.85261359, mean(E): -11.47583090+0.03083503j, var(E): 3.78672796
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=0.2............. Loss: -0.75734616, mean(E): -11.40155904+0.05102949j, var(E): 4.57807888
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=0.2............. Loss: -1.83154030, mean(E): -11.33059370-0.00251097j, var(E): 4.12946024
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=0.2............. Loss: -2.20096644, mean(E): -11.38286803+0.00217105j, var(E): 3.56057697
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=0.2............. Loss: -5.98402764, mean(E): -11.55393875-0.02125689j, var(E): 3.08071142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=0.2............. Loss: -0.95528578, mean(E): -11.39983300+0.03356006j, var(E): 3.63887825
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=0.2............. Loss: 1.07750390, mean(E): -11.57102995-0.10002467j, var(E): 5.06766029
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=0.21............. Loss: -3.31275889, mean(E): -11.47950757-0.03680957j, var(E): 2.96985076
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=0.2............. Loss: -0.94634349, mean(E): -11.62185237-0.00665361j, var(E): 3.76185363
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=0.2............. Loss: 0.08146087, mean(E): -11.65496294+0.04894927j, var(E): 6.10985153
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=0.2............. Loss: -3.94053559, mean(E): -11.31761891+0.05971704j, var(E): 4.67453779
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=0.2............. Loss: -2.00241542, mean(E): -11.33445484-0.02230870j, var(E): 3.69743450
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=0.2............. Loss: -3.98828767, mean(E): -11.59821709-0.08453790j, var(E): 4.35666677
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=0.2............. Loss: -0.95696614, mean(E): -11.41626467-0.05440489j, var(E): 4.19371491
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=0.2............. Loss: -2.83027487, mean(E): -11.55172584+0.02182586j, var(E): 4.19466670
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=0.2............. Loss: -3.35120460, mean(E): -11.53116389-0.09027485j, var(E): 3.06886385
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=0.2............. Loss: -2.18062219, mean(E): -11.42911351+0.08990714j, var(E): 3.81446746
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=0.2............. Loss: -2.02987734, mean(E): -11.63394060+0.00495112j, var(E): 3.03916849
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=0.2............. Loss: -4.78015378, mean(E): -11.72985618-0.11366006j, var(E): 4.40934319
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=0.2............. Loss: 0.72141614, mean(E): -11.39880250+0.01928010j, var(E): 4.99543087
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=0.2............. Loss: 1.26359315, mean(E): -11.32242842-0.04586392j, var(E): 5.36974555
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=0.2............. Loss: -3.43941032, mean(E): -11.56319962-0.07291215j, var(E): 4.08326299
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=0.2............. Loss: -0.44879675, mean(E): -11.52896577+0.10515066j, var(E): 3.82329901
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=0.2............. Loss: 0.08946268, mean(E): -11.44903762+0.03774358j, var(E): 4.41715662
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=0.2............. Loss: -3.08784039, mean(E): -11.34643200-0.00074477j, var(E): 5.21656595
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=0.2............. Loss: -3.14222115, mean(E): -11.33851307+0.01217342j, var(E): 4.01458397
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=0.2............. Loss: -2.44115408, mean(E): -11.32062554-0.03355102j, var(E): 4.12007886
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=0.2............. Loss: -2.19916831, mean(E): -11.56918724-0.04108376j, var(E): 4.25720475
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=0.2............. Loss: -2.72088231, mean(E): -11.51800215-0.03298125j, var(E): 3.82271953
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=0.2............. Loss: -0.53561257, mean(E): -11.52572133-0.00246767j, var(E): 3.58508603
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=0.2............. Loss: -2.72013347, mean(E): -11.52679426+0.03326330j, var(E): 3.52807248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=0.2............. Loss: -2.15498645, mean(E): -11.49934343-0.02182490j, var(E): 3.06458503
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=0.2............. Loss: -1.73523151, mean(E): -11.53323825+0.02316156j, var(E): 3.93658992
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=0.2............. Loss: 0.56931613, mean(E): -11.59229644+0.11537684j, var(E): 6.02521159
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=0.2............. Loss: -0.75152706, mean(E): -11.50549714+0.02160032j, var(E): 3.44868474
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=0.2............. Loss: -0.10616573, mean(E): -11.74168136+0.04864725j, var(E): 2.59600984
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=0.2............. Loss: -0.69215875, mean(E): -11.33451092+0.05493736j, var(E): 3.92301673
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=0.2............. Loss: -4.51042406, mean(E): -11.28868246+0.09439859j, var(E): 5.94432208
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=0.2............. Loss: -2.36463044, mean(E): -11.47571323-0.01801744j, var(E): 3.39977063
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=0.2............. Loss: -3.05905500, mean(E): -11.60528344-0.11484941j, var(E): 4.31383883
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=0.2............. Loss: -2.70630065, mean(E): -11.70988515-0.00527461j, var(E): 3.22284312
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=0.2............. Loss: -1.29562729, mean(E): -11.41548396-0.01802778j, var(E): 3.69843936
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=0.2............. Loss: -1.14640339, mean(E): -11.55681389-0.02962137j, var(E): 3.79023178
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=0.2............. Loss: -2.61886335, mean(E): -11.35560846+0.01395698j, var(E): 3.95438767
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=0.2............. Loss: -2.95735909, mean(E): -11.64530491-0.05406012j, var(E): 3.93774931
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=0.2............. Loss: -4.15639658, mean(E): -11.61067015+0.03667454j, var(E): 3.40796372
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=0.2............. Loss: 8.25217669, mean(E): -11.37882022-0.17238626j, var(E): 15.11587601
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=0.2............. Loss: -1.89382282, mean(E): -11.62651580-0.01584215j, var(E): 3.08298464
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=0.2............. Loss: -1.92011983, mean(E): -11.57202984-0.00579776j, var(E): 2.65092840
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=0.2............. Loss: -2.42761342, mean(E): -11.80389196+0.00877880j, var(E): 3.82790449
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=0.2............. Loss: -1.88352602, mean(E): -11.31792418-0.03126967j, var(E): 3.94858350
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=0.2............. Loss: -2.19418389, mean(E): -11.50790531+0.07414214j, var(E): 3.83241561
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=0.2............. Loss: -2.17437019, mean(E): -11.25801549-0.00841671j, var(E): 3.80305850
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=0.2............. Loss: -1.57268192, mean(E): -11.70021925-0.01931891j, var(E): 2.49043318
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=0.2............. Loss: -2.43916639, mean(E): -11.42094299-0.00006845j, var(E): 3.28121362
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=0.2............. Loss: -1.66659534, mean(E): -11.38484648-0.02229338j, var(E): 3.68455140
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=0.2............. Loss: -3.57768327, mean(E): -11.28202612+0.01875112j, var(E): 8.03584426
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=0.2............. Loss: -3.40701231, mean(E): -11.50354305-0.09698216j, var(E): 2.79134167
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=0.2............. Loss: -2.98505896, mean(E): -11.49647929-0.03929304j, var(E): 3.29899773
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=0.2............. Loss: -1.18683635, mean(E): -11.39249162+0.02828375j, var(E): 3.87233280
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=0.2............. Loss: -3.90899879, mean(E): -11.51097808-0.08548674j, var(E): 3.25248366
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=0.2............. Loss: -1.22639424, mean(E): -11.56890349-0.05738368j, var(E): 3.35605688
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=0.2............. Loss: -3.83331980, mean(E): -11.42605020-0.05178936j, var(E): 3.27986016
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=0.2............. Loss: -3.13456142, mean(E): -11.52294323-0.06965895j, var(E): 4.62794307
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=0.2............. Loss: 1.84269287, mean(E): -11.34024731+0.11079286j, var(E): 4.93568952
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=0.2............. Loss: -0.55349083, mean(E): -11.43074544+0.01265269j, var(E): 4.15007922
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=0.2............. Loss: -1.56101351, mean(E): -11.59232780+0.06762208j, var(E): 3.05268911
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=0.2............. Loss: -3.34424422, mean(E): -11.39696456-0.10756321j, var(E): 5.17255746
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=0.2............. Loss: -4.39189352, mean(E): -11.38335691-0.00604421j, var(E): 3.79990924
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=0.2............. Loss: 3.81736044, mean(E): -11.39691040+0.00324940j, var(E): 5.97054152
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=0.2............. Loss: -1.33342063, mean(E): -11.32173896+0.03433832j, var(E): 3.92416892
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=0.2............. Loss: 0.32437413, mean(E): -11.54680332+0.08133007j, var(E): 4.65209373
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=0.2............. Loss: -2.88818902, mean(E): -11.69124605-0.07247895j, var(E): 3.30288776
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=0.2............. Loss: -1.21017730, mean(E): -11.55356294-0.07340585j, var(E): 4.38768680
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=0.2............. Loss: -6.61631503, mean(E): -11.51965695-0.14767085j, var(E): 5.22293917
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=0.2............. Loss: -3.33524310, mean(E): -11.42311234-0.01289170j, var(E): 3.50483376
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=0.2............. Loss: 0.54092234, mean(E): -11.54419493+0.04395185j, var(E): 3.31590202
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=0.2............. Loss: -1.20028345, mean(E): -11.50336460-0.01108669j, var(E): 3.47188865
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=0.2............. Loss: -5.29344271, mean(E): -11.48553415-0.04996471j, var(E): 4.50607083
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=0.2............. Loss: -0.35734479, mean(E): -11.58469027+0.06896242j, var(E): 3.50856237
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=0.2............. Loss: 0.86153525, mean(E): -11.38370225+0.12264967j, var(E): 4.35818873
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=0.2............. Loss: -3.40317909, mean(E): -11.52674858-0.12071458j, var(E): 10.82370176
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=0.2............. Loss: -0.65492185, mean(E): -11.33518214+0.01231254j, var(E): 5.17644149
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=0.2............. Loss: 3.10468547, mean(E): -11.37470667+0.04450426j, var(E): 5.68069249
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=0.2............. Loss: -2.23465800, mean(E): -11.53597810+0.01558719j, var(E): 3.54272944
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=0.2............. Loss: -2.28612935, mean(E): -11.33317062+0.09328416j, var(E): 4.69885116
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=0.2............. Loss: -2.44470692, mean(E): -11.58426620-0.05623873j, var(E): 3.16815618
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=0.2............. Loss: -2.05083141, mean(E): -11.53194786+0.00130473j, var(E): 2.79843863
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=0.2............. Loss: -2.13965685, mean(E): -11.68635639-0.03510069j, var(E): 3.05810877
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=0.2............. Loss: -1.99613039, mean(E): -11.35779485-0.01054485j, var(E): 4.60408906
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=0.2............. Loss: -3.88669092, mean(E): -11.55219652-0.10105420j, var(E): 3.94667462
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=0.2............. Loss: -2.60632626, mean(E): -11.61456061+0.01099559j, var(E): 2.86672500
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=0.2............. Loss: -2.83903799, mean(E): -11.58500872+0.04171432j, var(E): 3.31578552
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=0.2............. Loss: -2.39451277, mean(E): -11.54985494-0.03512875j, var(E): 3.35253477
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=0.2............. Loss: -4.28349852, mean(E): -11.76320360-0.10344785j, var(E): 3.14882001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=0.2............. Loss: -3.06667255, mean(E): -11.65708522-0.04511379j, var(E): 3.77825248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=0.2............. Loss: -2.93846545, mean(E): -11.28505498+0.01753174j, var(E): 4.68767749
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=0.2............. Loss: -1.26221876, mean(E): -11.65982252+0.00721043j, var(E): 2.98156196
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=0.2............. Loss: -4.32773902, mean(E): -11.42800977+0.12005292j, var(E): 4.92913850
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=0.2............. Loss: -1.22657224, mean(E): -11.53358030+0.01295974j, var(E): 4.16642535
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=0.2............. Loss: -1.00695471, mean(E): -11.52903851+0.01686603j, var(E): 3.35867645
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=0.2............. Loss: -0.39771398, mean(E): -11.38158262+0.03339856j, var(E): 5.19614348
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=0.2............. Loss: -3.17201755, mean(E): -11.42281417-0.05339893j, var(E): 4.93827704
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=0.2............. Loss: -3.84838567, mean(E): -11.54363195-0.02649598j, var(E): 3.25506704
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=0.2............. Loss: -2.09710865, mean(E): -11.51418372-0.11494605j, var(E): 3.60653117
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=0.2............. Loss: -1.19441761, mean(E): -11.57011406-0.05230357j, var(E): 3.16493173
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=0.2............. Loss: -3.53345610, mean(E): -11.48245838-0.02980066j, var(E): 3.50131823
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=0.2............. Loss: -1.49677055, mean(E): -11.49094715+0.08924289j, var(E): 4.81156845
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=0.21............. Loss: -3.62005889, mean(E): -11.27228862+0.00319867j, var(E): 4.31466024
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=0.2............. Loss: -4.31976978, mean(E): -11.15855227+0.01896808j, var(E): 5.17443429
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=0.2............. Loss: -2.28753088, mean(E): -11.63107476-0.02937404j, var(E): 4.27379846
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=0.2............. Loss: -1.73602465, mean(E): -11.46770072-0.02133931j, var(E): 3.74957487
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=0.2............. Loss: -2.79021385, mean(E): -11.48256637-0.02891792j, var(E): 3.73029901
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=0.21............. Loss: -1.84685239, mean(E): -11.50615213-0.02504755j, var(E): 4.14199538
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=0.2............. Loss: -3.71959681, mean(E): -11.45474546+0.01962856j, var(E): 3.17136718
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=0.2............. Loss: -2.51342638, mean(E): -11.44814398-0.01464047j, var(E): 4.04189393
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=0.2............. Loss: -4.93538145, mean(E): -11.61638123-0.04852989j, var(E): 2.54717531
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=0.2............. Loss: -2.77958037, mean(E): -11.64528338-0.01228893j, var(E): 2.70531899
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=0.2............. Loss: -0.49497464, mean(E): -11.34131430-0.00783018j, var(E): 4.44310903
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=0.2............. Loss: 0.51215578, mean(E): -11.78431826+0.04915640j, var(E): 5.44263836
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=0.2............. Loss: 2.21914852, mean(E): -11.47129548-0.07467437j, var(E): 5.34252635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=0.2............. Loss: 7.24893384, mean(E): -11.42668202-0.12033653j, var(E): 7.54702803
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=0.2............. Loss: -2.30802119, mean(E): -11.61123031-0.01641403j, var(E): 3.39063500
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=0.2............. Loss: -2.44691950, mean(E): -11.67786245-0.02292966j, var(E): 3.95885348
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=0.2............. Loss: -3.25882094, mean(E): -11.55249016-0.03121363j, var(E): 3.70248711
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=0.2............. Loss: -4.09185495, mean(E): -11.65640547-0.02803539j, var(E): 3.25709913
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=0.2............. Loss: -4.40076069, mean(E): -11.31105514+0.03994784j, var(E): 3.60247859
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=0.2............. Loss: -1.06519044, mean(E): -11.56907520+0.03447114j, var(E): 3.67616228
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=0.2............. Loss: -1.22823602, mean(E): -11.30980030+0.06991979j, var(E): 4.33721390
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=0.2............. Loss: 0.46638501, mean(E): -11.82345499+0.06203138j, var(E): 4.03992577
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=0.2............. Loss: -0.94243815, mean(E): -11.58100922+0.04311563j, var(E): 3.64201426
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=0.2............. Loss: -2.69335045, mean(E): -11.53978209-0.02524942j, var(E): 3.38238154
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=0.2............. Loss: -2.80297245, mean(E): -11.49393759-0.03333193j, var(E): 3.60329857
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=0.2............. Loss: -3.48350411, mean(E): -11.38751000+0.02510090j, var(E): 3.81265731
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=0.2............. Loss: -1.05104382, mean(E): -11.53739264+0.00366234j, var(E): 4.14341562
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=0.2............. Loss: -3.75548515, mean(E): -11.48741335-0.06109701j, var(E): 5.06934921
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=0.2............. Loss: -2.37312699, mean(E): -11.45934621+0.03081429j, var(E): 3.37569640
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=0.2............. Loss: -0.72540546, mean(E): -11.56381082-0.02686475j, var(E): 4.28830951
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=0.2............. Loss: -0.95560563, mean(E): -11.42808701-0.00460823j, var(E): 3.81959228
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=0.2............. Loss: -0.84641924, mean(E): -11.51801876+0.03278036j, var(E): 4.23567162
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=0.2............. Loss: -3.81120902, mean(E): -11.43255400+0.08715791j, var(E): 3.77528330
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=0.2............. Loss: -5.91228342, mean(E): -11.66704471-0.41423499j, var(E): 55.55394824
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=0.2............. Loss: -2.06226834, mean(E): -11.42377503+0.13234885j, var(E): 4.56267691
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=0.2............. Loss: -0.66467924, mean(E): -11.43582119+0.12141670j, var(E): 4.38683208
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=0.2............. Loss: -2.98747534, mean(E): -11.40242269+0.00326892j, var(E): 3.52246033
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=0.2............. Loss: -4.79358679, mean(E): -11.23260163+0.06169549j, var(E): 5.47003488
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=0.2............. Loss: -4.02130399, mean(E): -11.28550129-0.03953408j, var(E): 4.01412147
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=0.2............. Loss: -0.87067693, mean(E): -11.62868119+0.08538947j, var(E): 4.05384549
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=0.2............. Loss: -2.26883937, mean(E): -11.48207658-0.01202739j, var(E): 3.53312135
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=0.2............. Loss: -2.58763474, mean(E): -11.57788457+0.04892516j, var(E): 3.07812065
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=0.2............. Loss: -4.47873282, mean(E): -11.40505197-0.09737757j, var(E): 4.54251105
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=0.2............. Loss: -3.56116249, mean(E): -11.40805140-0.05334655j, var(E): 4.35841315
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=0.2............. Loss: -5.20563464, mean(E): -11.42122998-0.04825957j, var(E): 5.47009868
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=0.2............. Loss: -2.91920619, mean(E): -11.56069017-0.01212533j, var(E): 4.68638344
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=0.2............. Loss: -2.44302895, mean(E): -11.74852278-0.08901309j, var(E): 3.22332795
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=0.2............. Loss: -1.00267704, mean(E): -11.50970297+0.07542609j, var(E): 4.56611225
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=0.2............. Loss: -1.16376301, mean(E): -11.11188273-0.00797342j, var(E): 5.71198928
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=0.2............. Loss: 0.36585822, mean(E): -11.39260565+0.04883042j, var(E): 4.53885428
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=0.2............. Loss: -0.33812908, mean(E): -11.59900733+0.10000705j, var(E): 4.30760419
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=0.2............. Loss: -2.96438432, mean(E): -11.19130199-0.08045556j, var(E): 7.32095362
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=0.2............. Loss: -2.36859663, mean(E): -11.76912115-0.02097393j, var(E): 2.68563318
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=0.2............. Loss: -2.53598176, mean(E): -11.54550255+0.06055670j, var(E): 5.26154717
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=0.2............. Loss: -3.37614241, mean(E): -11.57482556+0.01167522j, var(E): 2.91725813
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=0.2............. Loss: -2.18358332, mean(E): -11.32548442-0.03357736j, var(E): 4.00114732
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=0.2............. Loss: -2.12015923, mean(E): -11.44627862+0.05596478j, var(E): 4.31767094
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=0.2............. Loss: -1.22297449, mean(E): -11.53211756+0.05915223j, var(E): 4.14135011
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=0.2............. Loss: -4.85120156, mean(E): -11.36375108-0.08890855j, var(E): 4.38652879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=0.2............. Loss: -0.31196756, mean(E): -11.61647521+0.05564136j, var(E): 4.12436867
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=0.2............. Loss: -2.75098624, mean(E): -11.60942767-0.00011609j, var(E): 3.53851238
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=0.2............. Loss: -2.54799331, mean(E): -11.52894776-0.09184597j, var(E): 4.44312331
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=0.2............. Loss: -2.91977877, mean(E): -11.53891259-0.09537413j, var(E): 4.62173679
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=0.2............. Loss: 0.70587199, mean(E): -11.77399475+0.04507214j, var(E): 4.06886386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=0.2............. Loss: -1.79755309, mean(E): -11.60480430+0.00928563j, var(E): 3.25364558
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=0.2............. Loss: -3.00013671, mean(E): -11.61590227-0.10091822j, var(E): 3.99808396
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=0.2............. Loss: -4.21267446, mean(E): -11.40776016-0.08800281j, var(E): 4.20850323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=0.2............. Loss: -1.66689075, mean(E): -11.48799733+0.03505983j, var(E): 4.64144720
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=0.2............. Loss: -1.87865670, mean(E): -11.70328404-0.04302335j, var(E): 3.92241997
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=0.2............. Loss: -3.00608356, mean(E): -11.30665886-0.02924885j, var(E): 4.66746334
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=0.2............. Loss: -2.74897866, mean(E): -11.39518393+0.06362027j, var(E): 3.51204977
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=0.2............. Loss: -0.87947943, mean(E): -11.43047239-0.00253109j, var(E): 3.54954085
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=0.2............. Loss: -3.09110096, mean(E): -11.77552065-0.13822089j, var(E): 3.55471001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=0.2............. Loss: -2.52504865, mean(E): -11.37372075-0.04252464j, var(E): 3.61928442
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=0.2............. Loss: -3.17301152, mean(E): -11.76600704-0.04046071j, var(E): 1.89785494
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=0.2............. Loss: -2.75907516, mean(E): -11.56931530-0.03581165j, var(E): 3.77994657
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=0.2............. Loss: -0.32661380, mean(E): -11.37357845+0.03230097j, var(E): 5.16577358
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=0.2............. Loss: -1.47337988, mean(E): -11.56731276-0.00338970j, var(E): 3.37124737
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=0.2............. Loss: -0.43008984, mean(E): -11.31934763+0.01603792j, var(E): 4.07308475
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=0.2............. Loss: -2.19452014, mean(E): -11.75336471-0.00682645j, var(E): 2.46065302
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=0.2............. Loss: -0.55247334, mean(E): -11.38175136+0.09013759j, var(E): 4.62206020
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=0.2............. Loss: -5.18315336, mean(E): -11.41134289-0.06971617j, var(E): 4.62910065
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=0.2............. Loss: -2.69624220, mean(E): -11.50651377-0.02064635j, var(E): 3.82444619
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=0.2............. Loss: -0.90410954, mean(E): -11.75785308-0.01816532j, var(E): 3.18912793
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=0.2............. Loss: -2.06886795, mean(E): -11.64506121-0.04512681j, var(E): 2.57997064
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=0.2............. Loss: -1.56415075, mean(E): -11.61620238+0.08553578j, var(E): 3.14204142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=0.2............. Loss: -3.53540002, mean(E): -11.67474908-0.02049275j, var(E): 4.12493974
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=0.2............. Loss: -3.35130432, mean(E): -11.44721735-0.02693994j, var(E): 3.38577462
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=0.2............. Loss: -2.73045416, mean(E): -11.55575319+0.03778246j, var(E): 2.84558950
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=0.2............. Loss: -4.29216760, mean(E): -11.48814225-0.01167659j, var(E): 3.95550096
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=0.2............. Loss: -1.91906282, mean(E): -11.71975603-0.03705443j, var(E): 2.63345531
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=0.2............. Loss: -2.46911757, mean(E): -11.40056747+0.06205614j, var(E): 4.39129404
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=0.2............. Loss: -2.00615886, mean(E): -11.67397806+0.10585015j, var(E): 3.84031594
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=0.2............. Loss: 3.97624559, mean(E): -11.39236233-0.01268189j, var(E): 5.44266116
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=0.2............. Loss: -2.12536382, mean(E): -11.51545483+0.01814068j, var(E): 4.57576501
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=0.2............. Loss: -1.92585610, mean(E): -11.67406803+0.03375105j, var(E): 3.18688131
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=0.2............. Loss: 0.37493186, mean(E): -11.54490155+0.09575023j, var(E): 4.56305417
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=0.2............. Loss: -4.26002487, mean(E): -11.47165529-0.06587969j, var(E): 4.73754544
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=0.2............. Loss: -0.60469968, mean(E): -11.48401114-0.16021926j, var(E): 6.35691732
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=0.2............. Loss: -3.08206012, mean(E): -11.61522088-0.04951323j, var(E): 3.10396597
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=0.2............. Loss: 0.66133835, mean(E): -11.44235904+0.08835742j, var(E): 4.64959733
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=0.2............. Loss: -2.04342053, mean(E): -11.57150000-0.02061248j, var(E): 3.91671470
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=0.2............. Loss: -2.63074984, mean(E): -11.40543878+0.06866233j, var(E): 3.75084398
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=0.2............. Loss: 0.26380101, mean(E): -11.40040756+0.14159202j, var(E): 5.54379835
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=0.2............. Loss: -1.71635166, mean(E): -11.72793233-0.04322690j, var(E): 2.65088211
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=0.2............. Loss: -2.35618724, mean(E): -11.79528996-0.02955698j, var(E): 2.63883439
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=0.2............. Loss: -3.40497144, mean(E): -11.43568719-0.02330523j, var(E): 4.04843871
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=0.2............. Loss: -1.79831001, mean(E): -11.59074154+0.01951536j, var(E): 3.37152851
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=0.2............. Loss: -4.42812551, mean(E): -11.47207566+0.03410988j, var(E): 3.89005780
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=0.2............. Loss: -0.07629178, mean(E): -11.43863863+0.07353656j, var(E): 5.74911989
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=0.2............. Loss: -5.81499175, mean(E): -11.53396202+0.00502233j, var(E): 3.28811862
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=0.2............. Loss: -2.30145926, mean(E): -11.30294650-0.05853912j, var(E): 4.01904901
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=0.2............. Loss: -0.42803724, mean(E): -11.56797090-0.00988381j, var(E): 3.11019219
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=0.2............. Loss: -0.55599174, mean(E): -11.75212032+0.10621067j, var(E): 3.56409185
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=0.2............. Loss: -1.51204756, mean(E): -11.60713776+0.00626758j, var(E): 3.45063513
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=0.2............. Loss: -6.10956009, mean(E): -11.50067422+0.07878629j, var(E): 3.99268608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=0.2............. Loss: -4.08529314, mean(E): -11.74238813-0.04965466j, var(E): 3.71246293
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=0.2............. Loss: -2.50162498, mean(E): -11.42449114+0.02698053j, var(E): 3.33026207
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=0.2............. Loss: -1.24336909, mean(E): -11.67195165-0.03291882j, var(E): 2.65913189
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=0.2............. Loss: -1.48570395, mean(E): -11.41247683+0.02139670j, var(E): 4.83288039
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=0.2............. Loss: -2.56490601, mean(E): -11.59004745+0.00590946j, var(E): 3.14403536
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=0.2............. Loss: -2.79472070, mean(E): -11.24550591+0.00647805j, var(E): 5.79230058
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=0.2............. Loss: 6.98556844, mean(E): -11.44501276+0.06773780j, var(E): 9.51725630
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=0.2............. Loss: -1.53729845, mean(E): -11.51197276-0.07040821j, var(E): 4.30661791
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=0.2............. Loss: -1.75218600, mean(E): -11.41552416+0.00883932j, var(E): 3.30887350
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=0.2............. Loss: -1.83002479, mean(E): -11.76254457-0.04550017j, var(E): 2.86138647
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=0.2............. Loss: -2.42575975, mean(E): -11.37762092+0.02149414j, var(E): 3.94284881
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=0.2............. Loss: -3.30723919, mean(E): -11.59650443-0.03702775j, var(E): 3.23489971
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=0.2............. Loss: -1.50488076, mean(E): -11.66412804+0.09076703j, var(E): 3.53328041
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=0.2............. Loss: -0.64987402, mean(E): -11.57532475-0.05035888j, var(E): 4.41704969
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=0.2............. Loss: -2.29021352, mean(E): -11.29648102+0.01072085j, var(E): 4.26074382
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=0.21............. Loss: -3.24452084, mean(E): -11.42133505+0.01933345j, var(E): 5.82807410
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=0.2............. Loss: -1.23599113, mean(E): -11.43104755-0.05658102j, var(E): 4.05125960
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=0.2............. Loss: -2.38884202, mean(E): -11.33427890+0.08261065j, var(E): 4.52170090
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=0.2............. Loss: -1.55115432, mean(E): -11.37484628+0.02935245j, var(E): 14.13337836
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=0.2............. Loss: -0.20119186, mean(E): -11.36831328+0.09493510j, var(E): 4.80062197
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=0.21............. Loss: -0.91820519, mean(E): -11.68308088-0.02286327j, var(E): 3.18356629
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=0.2............. Loss: -2.96692457, mean(E): -11.41428409+0.02682758j, var(E): 3.57501270
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=0.2............. Loss: -0.17183974, mean(E): -11.60452685+0.03703174j, var(E): 4.38258599
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=0.2............. Loss: -2.34335221, mean(E): -11.61319906-0.10023457j, var(E): 4.78491454
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=0.2............. Loss: -2.10522708, mean(E): -11.39483961-0.01804896j, var(E): 5.48822643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=0.21............. Loss: -1.03689479, mean(E): -11.70472408+0.07536307j, var(E): 3.28136876
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=0.2............. Loss: -1.02359864, mean(E): -11.72836233-0.06509491j, var(E): 2.98590145
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=0.2............. Loss: 1.54894763, mean(E): -11.57779161+0.06725425j, var(E): 5.40538827
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=0.2............. Loss: -2.46896565, mean(E): -11.54572890+0.05854705j, var(E): 4.81423134
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=0.2............. Loss: 1.52987572, mean(E): -11.39428802-0.03867188j, var(E): 5.32343816
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=0.21............. Loss: 4.57234368, mean(E): -11.62078342+0.14592747j, var(E): 9.15580755
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=0.2............. Loss: -1.39387372, mean(E): -11.59513789+0.09887664j, var(E): 4.08046316
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=0.2............. Loss: -3.62667030, mean(E): -11.63236960-0.09856025j, var(E): 4.16127302
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=0.2............. Loss: 1.78821298, mean(E): -11.67682846-0.11237678j, var(E): 4.26110900
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=0.2............. Loss: -1.66683293, mean(E): -11.74782682-0.07275776j, var(E): 4.66017784
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=0.21............. Loss: -1.72422339, mean(E): -11.57944886-0.00641882j, var(E): 3.71869561
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=0.2............. Loss: -2.90050658, mean(E): -11.35955440+0.04963292j, var(E): 3.91776836
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=0.2............. Loss: 0.21618226, mean(E): -11.49433500+0.11424178j, var(E): 4.11564508
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=0.2............. Loss: -2.34014171, mean(E): -11.40358126+0.03014123j, var(E): 5.30425043
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=0.2............. Loss: -2.31155147, mean(E): -11.58911741+0.00994586j, var(E): 2.69038741
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=0.2............. Loss: -4.01262342, mean(E): -11.46745731-0.03596506j, var(E): 3.77705112
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=0.2............. Loss: -3.00924042, mean(E): -11.71570613-0.04061299j, var(E): 2.47331590
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=0.2............. Loss: 5.72695972, mean(E): -11.55125950-0.06821887j, var(E): 6.03414064
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=0.2............. Loss: -5.56001037, mean(E): -11.54965253-0.05918664j, var(E): 4.59915912
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=0.2............. Loss: 0.17681953, mean(E): -11.45038920+0.06641394j, var(E): 3.62302277
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=0.2............. Loss: 0.26826617, mean(E): -11.54547547+0.11105822j, var(E): 3.54733072
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=0.2............. Loss: -2.22155761, mean(E): -11.54151151+0.09433671j, var(E): 3.57925716
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=0.2............. Loss: -3.30967445, mean(E): -11.59950590+0.04131652j, var(E): 3.72312967
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=0.2............. Loss: -0.38481889, mean(E): -11.68887471-0.06542577j, var(E): 2.99760635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=0.2............. Loss: -0.21949320, mean(E): -11.42301224+0.01463744j, var(E): 5.03734183
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=0.2............. Loss: -1.40448442, mean(E): -11.70808219+0.00426751j, var(E): 2.55441417
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=0.2............. Loss: -1.66758018, mean(E): -11.44339812+0.04937634j, var(E): 3.98503581
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=0.2............. Loss: -0.39764811, mean(E): -11.53393701+0.01849660j, var(E): 3.57501013
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=0.2............. Loss: -2.66723306, mean(E): -11.52900181-0.02437182j, var(E): 3.52247512
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=0.2............. Loss: -2.18983423, mean(E): -11.52191654-0.06245953j, var(E): 5.05971427
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=0.2............. Loss: 0.02769712, mean(E): -11.61258346+0.08914449j, var(E): 3.55208775
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=0.2............. Loss: -4.30256240, mean(E): -11.57702918-0.03008347j, var(E): 3.93232646
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=0.2............. Loss: -3.23129767, mean(E): -11.52885460+0.06385994j, var(E): 3.68545915
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=0.2............. Loss: 0.69036994, mean(E): -11.73831113+0.07952642j, var(E): 5.07487698
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=0.2............. Loss: 2.20079164, mean(E): -11.58194764-0.08222447j, var(E): 5.60408979
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=0.2............. Loss: -4.71250159, mean(E): -11.48420583-0.02130905j, var(E): 3.68636129
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=0.2............. Loss: 2.70899146, mean(E): -11.67777055-0.08887272j, var(E): 4.52711859
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=0.2............. Loss: -1.80982473, mean(E): -11.82419310-0.04460611j, var(E): 2.16346535
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=0.2............. Loss: -3.09487857, mean(E): -11.48627799+0.04909274j, var(E): 3.77910315
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=0.2............. Loss: -2.87307349, mean(E): -11.72779334-0.07162414j, var(E): 4.01066770
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=0.2............. Loss: -1.51459916, mean(E): -11.74110015-0.02141726j, var(E): 2.72077582
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=0.2............. Loss: 2.15379921, mean(E): -11.61558521-0.03981760j, var(E): 4.23186839
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=0.2............. Loss: -1.12452751, mean(E): -11.81723615+0.00126290j, var(E): 2.69439323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=0.2............. Loss: -2.40452382, mean(E): -11.69400347-0.00147815j, var(E): 2.66126485
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=0.2............. Loss: -0.48551912, mean(E): -11.70031879-0.01012406j, var(E): 4.36911416
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=0.2............. Loss: -2.00326018, mean(E): -11.69435323-0.03576881j, var(E): 2.73181526
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=0.2............. Loss: -4.06364967, mean(E): -11.62475565-0.05020503j, var(E): 4.25378634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=0.2............. Loss: -1.88709444, mean(E): -11.60996075-0.03761569j, var(E): 3.84914760
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=0.2............. Loss: -1.87989880, mean(E): -11.53407569+0.01468781j, var(E): 5.24642292
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=0.2............. Loss: -2.99801868, mean(E): -11.74834773-0.07639437j, var(E): 2.73335868
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=0.2............. Loss: -2.77939910, mean(E): -11.60629033-0.01044355j, var(E): 3.55018564
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=0.2............. Loss: -2.22913191, mean(E): -11.76415536-0.00962533j, var(E): 3.21319151
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=0.2............. Loss: 0.81247685, mean(E): -11.75062724+0.07829964j, var(E): 5.02551687
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=0.2............. Loss: -1.60655582, mean(E): -11.56917516+0.02049805j, var(E): 5.73895765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=0.2............. Loss: -3.03018111, mean(E): -11.50047465-0.00121068j, var(E): 3.68391796
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=0.2............. Loss: -0.83767877, mean(E): -11.68775430-0.01880223j, var(E): 3.77365699
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=0.2............. Loss: -0.89652420, mean(E): -11.65252524+0.04282595j, var(E): 2.85409885
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=0.2............. Loss: -2.06462057, mean(E): -11.71822140-0.13413543j, var(E): 2.93206142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=0.2............. Loss: -1.36750428, mean(E): -11.55929898+0.03650285j, var(E): 3.58919137
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=0.2............. Loss: -4.60648174, mean(E): -11.69029972-0.11356473j, var(E): 3.07945833
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=0.2............. Loss: -1.69594428, mean(E): -11.52459534+0.07751885j, var(E): 3.22646767
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=0.2............. Loss: -3.49480814, mean(E): -11.74856149-0.11834084j, var(E): 3.84697095
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=0.2............. Loss: -0.82857938, mean(E): -11.65392954-0.02512194j, var(E): 4.61237634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=0.2............. Loss: -0.32974449, mean(E): -11.60956261+0.09518848j, var(E): 4.61904473
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=0.2............. Loss: -3.50585234, mean(E): -11.64663072-0.04188703j, var(E): 5.78737406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=0.2............. Loss: -1.01276598, mean(E): -11.72356779-0.00110868j, var(E): 2.88792622
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=0.2............. Loss: -2.14703168, mean(E): -11.65751697-0.00817257j, var(E): 2.90482442
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=0.2............. Loss: -1.56219550, mean(E): -11.49835746+0.04035806j, var(E): 3.62078530
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=0.2............. Loss: -2.32150540, mean(E): -11.79849642-0.00283247j, var(E): 2.33842158
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=0.2............. Loss: -4.21756547, mean(E): -11.50911002-0.01915155j, var(E): 4.71637570
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=0.2............. Loss: -0.95710246, mean(E): -11.60058452+0.02572488j, var(E): 2.94226673
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=0.2............. Loss: -0.12493824, mean(E): -11.48912151-0.09833946j, var(E): 5.51039486
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=0.2............. Loss: -1.99023300, mean(E): -11.64324876-0.00648310j, var(E): 4.69929807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=0.2............. Loss: -3.91547119, mean(E): -11.58090000-0.04097746j, var(E): 3.50939791
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=0.2............. Loss: -2.13415368, mean(E): -11.75594463+0.03260045j, var(E): 3.74966680
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=0.2............. Loss: -1.68898209, mean(E): -11.45019922+0.12949356j, var(E): 4.60325611
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=0.2............. Loss: 0.17429518, mean(E): -11.64076522-0.02053025j, var(E): 6.33927365
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=0.2............. Loss: -4.44500017, mean(E): -11.65777405-0.02549537j, var(E): 4.37759989
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=0.2............. Loss: 2.18245760, mean(E): -11.61147335+0.09023055j, var(E): 7.70985456
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=0.2............. Loss: -1.90961211, mean(E): -11.58329593+0.05428423j, var(E): 5.89291923
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=0.2............. Loss: -2.36209578, mean(E): -11.62942673+0.01044061j, var(E): 4.17084675
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=0.2............. Loss: -1.35182207, mean(E): -11.84619538-0.03848548j, var(E): 2.74123500
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=0.2............. Loss: -0.35251526, mean(E): -11.49132360+0.07957550j, var(E): 4.33353239
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=0.2............. Loss: -2.93578236, mean(E): -11.62174905+0.05805203j, var(E): 3.04839935
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=0.2............. Loss: -4.22352812, mean(E): -11.28741451+0.08320623j, var(E): 10.84705093
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=0.2............. Loss: -2.84857068, mean(E): -11.71591427-0.02239416j, var(E): 3.13845687
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=0.2............. Loss: -1.51046031, mean(E): -11.54151406+0.07520125j, var(E): 4.31566102
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=0.2............. Loss: -2.68208049, mean(E): -11.59683240-0.01237149j, var(E): 4.14343064
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=0.2............. Loss: -0.58612647, mean(E): -11.88530492-0.03751695j, var(E): 2.78594952
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=0.2............. Loss: -3.87842428, mean(E): -11.48770170+0.02480509j, var(E): 4.21112260
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=0.2............. Loss: -1.83695563, mean(E): -11.56432071+0.03920994j, var(E): 4.03662954
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=0.2............. Loss: -3.26928902, mean(E): -11.71042981+0.05888190j, var(E): 2.95379142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=0.2............. Loss: 3.29440785, mean(E): -11.63594994+0.03857261j, var(E): 4.82259751
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=0.2............. Loss: -3.51473526, mean(E): -11.62632526+0.03496121j, var(E): 2.92746818
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=0.2............. Loss: -3.16205239, mean(E): -11.59232822+0.01985336j, var(E): 3.60934114
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=0.2............. Loss: -3.07149038, mean(E): -11.60014250-0.04649692j, var(E): 3.33067400
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=0.2............. Loss: -2.22376571, mean(E): -11.82278523-0.00938263j, var(E): 2.52276788
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=0.2............. Loss: -0.99908250, mean(E): -11.75775167+0.02061089j, var(E): 3.24561990
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=0.2............. Loss: 1.24276197, mean(E): -11.77589256+0.09742524j, var(E): 3.61571154
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=0.2............. Loss: -2.37027500, mean(E): -11.62435943+0.08775218j, var(E): 3.83117663
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=0.2............. Loss: -1.66390035, mean(E): -11.69570463+0.00900112j, var(E): 3.09536232
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=0.2............. Loss: -4.46870280, mean(E): -11.38320394-0.02626732j, var(E): 4.99167521
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=0.2............. Loss: -1.84476431, mean(E): -11.63898524-0.02756432j, var(E): 3.89010211
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=0.2............. Loss: -3.56834710, mean(E): -11.61330789+0.05206235j, var(E): 3.83218046
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=0.2............. Loss: -3.32901461, mean(E): -11.76318280+0.02084067j, var(E): 2.69542008
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=0.2............. Loss: 1.08086367, mean(E): -11.71988997-0.14288695j, var(E): 4.47673905
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=0.2............. Loss: -2.20437264, mean(E): -11.68281692-0.01965095j, var(E): 3.07634739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=0.2............. Loss: -2.16759165, mean(E): -11.37867346+0.03473970j, var(E): 6.02011897
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=0.2............. Loss: -4.21516977, mean(E): -11.60862626-0.09970702j, var(E): 3.93548379
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=0.2............. Loss: -0.78796562, mean(E): -11.60131252-0.08023480j, var(E): 4.13228298
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=0.2............. Loss: 0.83696824, mean(E): -11.84357883-0.01224393j, var(E): 4.57862877
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=0.2............. Loss: -2.10156012, mean(E): -11.76108640-0.03580142j, var(E): 2.85486406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=0.2............. Loss: -3.66425535, mean(E): -11.61180361+0.00833176j, var(E): 3.38278337
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=0.2............. Loss: -0.95469672, mean(E): -11.44350420+0.12202517j, var(E): 4.74835333
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=0.2............. Loss: -3.73570318, mean(E): -11.66496258+0.00331803j, var(E): 3.69191987
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=0.2............. Loss: -0.47588070, mean(E): -11.64264845-0.00698912j, var(E): 4.58132000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=0.2............. Loss: -2.22290232, mean(E): -11.72359399+0.07595081j, var(E): 2.69220750
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=0.2............. Loss: -2.00122946, mean(E): -11.49961385-0.02542222j, var(E): 5.73221475
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=0.2............. Loss: -3.38392558, mean(E): -11.59791995-0.04411311j, var(E): 4.40662811
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=0.2............. Loss: -1.56931881, mean(E): -11.62815214+0.03053897j, var(E): 3.21564937
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=0.2............. Loss: -3.56568442, mean(E): -11.80399317+0.00974339j, var(E): 2.93397768
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=0.2............. Loss: -2.87700789, mean(E): -11.78022564+0.03398649j, var(E): 2.30904525
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=0.2............. Loss: -2.82609714, mean(E): -11.85377581-0.02019226j, var(E): 2.03088540
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=0.2............. Loss: -1.73807309, mean(E): -11.63480505+0.04551918j, var(E): 3.74798118
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=0.2............. Loss: -1.14198016, mean(E): -11.55598284+0.09685930j, var(E): 5.56168433
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=0.2............. Loss: -2.17972982, mean(E): -11.58377831+0.01012368j, var(E): 3.88379730
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=0.2............. Loss: -7.40279277, mean(E): -11.89754978-0.40644406j, var(E): 53.96024392
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=0.2............. Loss: -2.76256276, mean(E): -11.58485036+0.05694301j, var(E): 2.80891923
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=0.2............. Loss: -1.87280898, mean(E): -11.59440596+0.01193163j, var(E): 3.31296655
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=0.2............. Loss: -1.44831911, mean(E): -11.62500172+0.03158062j, var(E): 4.46788853
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=0.2............. Loss: -1.80543542, mean(E): -11.74415721-0.01956547j, var(E): 3.04942466
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=0.2............. Loss: -1.77350284, mean(E): -11.67552204+0.03703910j, var(E): 3.42661584
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=0.2............. Loss: -3.30005312, mean(E): -11.52922344+0.00594620j, var(E): 3.33076838
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=0.2............. Loss: -3.10159766, mean(E): -11.69917189-0.09139203j, var(E): 2.48650140
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=0.2............. Loss: -4.14970711, mean(E): -11.64314252-0.06281567j, var(E): 2.98924175
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=0.2............. Loss: -3.16242741, mean(E): -11.68223127+0.13528010j, var(E): 3.91357935
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=0.2............. Loss: -2.61525518, mean(E): -11.75224244-0.03961215j, var(E): 2.74990302
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=0.2............. Loss: -2.54064513, mean(E): -11.70157369+0.01741883j, var(E): 3.51086226
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=0.2............. Loss: -2.20314786, mean(E): -11.81874507-0.03427286j, var(E): 3.14253407
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=0.2............. Loss: -3.54794174, mean(E): -11.58914412-0.01078037j, var(E): 3.73796651
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=0.2............. Loss: -4.01779204, mean(E): -11.51644461-0.04946393j, var(E): 4.03661061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=0.2............. Loss: -3.53679426, mean(E): -11.47373723+0.00354352j, var(E): 4.67372069
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=0.2............. Loss: -0.79392520, mean(E): -11.70233821+0.00448114j, var(E): 3.45387889
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=0.2............. Loss: -2.51246845, mean(E): -11.73899353-0.02844591j, var(E): 3.46153311
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=0.2............. Loss: -4.17949083, mean(E): -11.67729425+0.00453381j, var(E): 3.26501787
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=0.2............. Loss: -1.22599791, mean(E): -11.56240964+0.07454617j, var(E): 3.48225425
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=0.2............. Loss: -1.36641897, mean(E): -11.75726519+0.05698072j, var(E): 3.15103496
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=0.2............. Loss: -1.78311544, mean(E): -11.51919286+0.06959449j, var(E): 5.37013572
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=0.2............. Loss: -5.60959750, mean(E): -11.56948242+0.01094188j, var(E): 3.51327730
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=0.2............. Loss: -2.02192485, mean(E): -11.55807046+0.03823204j, var(E): 3.78041883
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=0.2............. Loss: -2.53747907, mean(E): -11.70704638-0.02304329j, var(E): 2.96724203
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=0.2............. Loss: -1.11889224, mean(E): -11.77729156+0.02088851j, var(E): 2.84475842
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=0.2............. Loss: -1.75368263, mean(E): -11.77877277+0.00606933j, var(E): 2.30487817
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=0.2............. Loss: -3.25534270, mean(E): -11.69286157+0.00863676j, var(E): 3.08046926
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=0.2............. Loss: 0.11711181, mean(E): -11.61557099+0.01884382j, var(E): 5.05938599
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=0.2............. Loss: -0.90000004, mean(E): -11.89731738+0.02271789j, var(E): 2.37521199
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=0.2............. Loss: -2.67684047, mean(E): -11.72946547-0.02197129j, var(E): 2.88826981
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=0.2............. Loss: 3.73333535, mean(E): -11.85723868-0.18824116j, var(E): 8.59514281
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=0.2............. Loss: -2.65267434, mean(E): -11.56901415+0.00975919j, var(E): 3.24267698
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=0.2............. Loss: -4.54298891, mean(E): -11.57013256+0.01056070j, var(E): 4.02900355
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=0.2............. Loss: -5.32606041, mean(E): -12.09287621-0.19537312j, var(E): 22.68768335
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=0.2............. Loss: -4.04626451, mean(E): -11.70590024-0.00440999j, var(E): 5.27793368
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=0.2............. Loss: -1.06850874, mean(E): -11.83959467-0.00417125j, var(E): 2.85726783
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=0.2............. Loss: -5.36457080, mean(E): -11.37669196+0.07885557j, var(E): 5.19027196
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=0.2............. Loss: -2.24008521, mean(E): -11.65051898+0.00940211j, var(E): 3.25139866
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=0.2............. Loss: -3.13678352, mean(E): -11.70813371-0.03427608j, var(E): 2.87624693
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=0.21............. Loss: -3.75597260, mean(E): -11.53215737+0.01305955j, var(E): 3.10717462
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=0.2............. Loss: -1.70242359, mean(E): -11.67837627+0.00818287j, var(E): 4.00762184
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=0.2............. Loss: -0.50514808, mean(E): -11.64321474-0.06405024j, var(E): 3.48138255
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=0.2............. Loss: 0.26743274, mean(E): -11.72328133-0.04014188j, var(E): 3.58812372
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=0.2............. Loss: -0.91946948, mean(E): -11.44489868+0.07474455j, var(E): 4.33521793
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=0.21............. Loss: -3.35135722, mean(E): -11.72733431-0.03059886j, var(E): 3.04514899
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=0.2............. Loss: -3.31486328, mean(E): -11.52480960+0.02055782j, var(E): 4.01589830
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=0.2............. Loss: -2.00032055, mean(E): -11.71702538+0.01811346j, var(E): 3.31847652
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=0.2............. Loss: -2.94183442, mean(E): -11.80926236-0.06315093j, var(E): 4.04360385
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=0.2............. Loss: -3.38151446, mean(E): -11.53384904-0.03469522j, var(E): 3.03464042
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=0.21............. Loss: -4.16213557, mean(E): -11.91742872-0.10288992j, var(E): 3.07390901
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=0.2............. Loss: -1.50498788, mean(E): -11.56326878-0.00712801j, var(E): 3.62212375
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=0.2............. Loss: -4.27681342, mean(E): -11.55297717-0.03689595j, var(E): 4.39731077
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=0.2............. Loss: -3.19383274, mean(E): -11.47429977+0.01169705j, var(E): 4.02165339
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=0.2............. Loss: -1.39771348, mean(E): -11.62670028+0.01874297j, var(E): 3.34998472
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=0.21............. Loss: 0.67444638, mean(E): -11.98588056+0.10290493j, var(E): 3.77178797
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=0.2............. Loss: -2.36964654, mean(E): -11.43119782+0.05198050j, var(E): 4.60914096
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=0.2............. Loss: -2.33477690, mean(E): -11.51309671-0.02832186j, var(E): 4.27303527
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=0.2............. Loss: 0.02072746, mean(E): -11.66065770+0.01107737j, var(E): 3.93585112
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=0.2............. Loss: -2.41170474, mean(E): -11.61542133-0.02535469j, var(E): 3.00955908
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=0.21............. Loss: 0.20109819, mean(E): -11.66429670+0.05769576j, var(E): 4.13110709
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=0.2............. Loss: -3.99502110, mean(E): -11.71468460+0.02619342j, var(E): 4.28193390
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=0.2............. Loss: -3.72369564, mean(E): -11.63095479-0.02940815j, var(E): 3.29905017
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=0.2............. Loss: -4.45146058, mean(E): -11.36369507+0.08269620j, var(E): 12.04428572
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=0.2............. Loss: -2.69300413, mean(E): -11.62946063+0.01259042j, var(E): 3.62661786
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=0.2............. Loss: -2.63119872, mean(E): -11.63382517-0.08453834j, var(E): 4.37612061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=0.2............. Loss: -2.24719813, mean(E): -11.67149182-0.00109206j, var(E): 3.45651756
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=0.2............. Loss: -4.79208737, mean(E): -11.78025982-0.11659447j, var(E): 3.77119256
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=0.2............. Loss: -3.12436598, mean(E): -11.51159361-0.05860204j, var(E): 4.53544214
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=0.2............. Loss: -1.27864781, mean(E): -11.71362230+0.07705563j, var(E): 4.69740661
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=0.2............. Loss: -0.75690920, mean(E): -11.67260030+0.02771950j, var(E): 3.31965803
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=0.2............. Loss: -2.28530493, mean(E): -11.95464192-0.00922410j, var(E): 1.84275168
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=0.2............. Loss: -1.85174553, mean(E): -11.61295573+0.05098164j, var(E): 3.90956807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=0.2............. Loss: -1.25581275, mean(E): -11.72810327+0.07195031j, var(E): 2.60101649
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=0.2............. Loss: -1.78998466, mean(E): -11.65584019+0.04347991j, var(E): 3.90622380
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=0.2............. Loss: -1.96547533, mean(E): -11.75358458-0.01934514j, var(E): 2.91165999
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=0.2............. Loss: -2.44173388, mean(E): -11.67889597-0.05397448j, var(E): 4.90165978
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=0.2............. Loss: -3.39535805, mean(E): -11.72877428+0.00734071j, var(E): 2.83682802
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=0.2............. Loss: 0.99791647, mean(E): -11.62711301+0.10783286j, var(E): 5.16245166
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=0.2............. Loss: -4.98006642, mean(E): -11.65754931+0.04041107j, var(E): 3.42396548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=0.2............. Loss: -1.57423376, mean(E): -11.78608752+0.04063866j, var(E): 4.04584323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=0.2............. Loss: -0.04605822, mean(E): -11.66446782+0.13814727j, var(E): 3.91722360
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=0.2............. Loss: -1.92543386, mean(E): -11.34705565-0.04697281j, var(E): 4.97604592
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=0.2............. Loss: -2.91026383, mean(E): -11.64989392+0.07678610j, var(E): 3.50578716
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=0.2............. Loss: -3.12790794, mean(E): -11.66549699-0.03128055j, var(E): 3.14892477
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=0.2............. Loss: -1.70028749, mean(E): -11.69083552+0.05501047j, var(E): 4.64951576
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=0.2............. Loss: -2.23345776, mean(E): -11.41337292+0.13586715j, var(E): 7.01884909
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=0.2............. Loss: -2.06840190, mean(E): -11.72940286-0.01173745j, var(E): 3.11313631
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=0.2............. Loss: -2.62579996, mean(E): -11.68927266-0.00025284j, var(E): 2.65525550
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=0.2............. Loss: -2.43270249, mean(E): -11.88772009-0.03947185j, var(E): 3.23739085
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=0.2............. Loss: -3.22530683, mean(E): -11.72672567-0.02402488j, var(E): 2.36884412
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=0.2............. Loss: -1.12023040, mean(E): -11.69382065+0.01964166j, var(E): 4.56545169
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=0.2............. Loss: 8.00485345, mean(E): -11.71756231-0.04818994j, var(E): 11.09082989
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=0.2............. Loss: -2.37002158, mean(E): -11.75937557+0.03158917j, var(E): 2.57081291
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=0.2............. Loss: -1.71908054, mean(E): -11.74768429+0.01472896j, var(E): 3.30344232
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=0.2............. Loss: -3.45349732, mean(E): -11.63873669-0.04367194j, var(E): 3.38152396
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=0.2............. Loss: 6.88927432, mean(E): -11.76053534-0.09529103j, var(E): 10.07742557
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=0.2............. Loss: 0.09632855, mean(E): -11.63297701+0.15822952j, var(E): 5.75244618
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=0.2............. Loss: -1.67388194, mean(E): -11.56650101+0.05093663j, var(E): 3.76734089
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=0.2............. Loss: -1.47434177, mean(E): -11.45002287+0.03953732j, var(E): 5.69960874
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=0.2............. Loss: -8.50998858, mean(E): -11.71451810-0.16088128j, var(E): 28.96992321
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=0.2............. Loss: -2.62543403, mean(E): -11.49708197+0.09452681j, var(E): 4.40437127
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=0.2............. Loss: -1.13933934, mean(E): -11.69356961+0.03740783j, var(E): 3.29492230
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=0.2............. Loss: -3.53307761, mean(E): -11.62296341+0.12147560j, var(E): 10.82300176
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=0.2............. Loss: -3.49436329, mean(E): -11.61364795-0.00212160j, var(E): 3.08272446
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=0.2............. Loss: -2.08711861, mean(E): -11.50462601+0.01142797j, var(E): 3.75661248
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=0.2............. Loss: -0.79409920, mean(E): -11.65940258+0.05878943j, var(E): 4.18020417
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=0.2............. Loss: -2.10988813, mean(E): -11.67183643-0.09394465j, var(E): 3.62020777
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=0.2............. Loss: -3.24361291, mean(E): -11.78010518-0.02891010j, var(E): 2.74148200
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=0.2............. Loss: 1.03857043, mean(E): -11.75375835+0.02799769j, var(E): 5.64327800
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=0.2............. Loss: -3.53810804, mean(E): -11.80950449-0.03399951j, var(E): 2.81677351
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=0.2............. Loss: 0.32795922, mean(E): -11.79424895+0.08767725j, var(E): 2.93789353
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=0.2............. Loss: -1.59981681, mean(E): -11.70777316-0.03787326j, var(E): 3.97413355
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=0.2............. Loss: -2.36748259, mean(E): -11.58535577+0.03594340j, var(E): 3.92471242
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=0.2............. Loss: -4.13880935, mean(E): -11.67517749-0.01975133j, var(E): 4.03284808
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=0.2............. Loss: -3.57209790, mean(E): -11.62435614-0.05101310j, var(E): 3.75579874
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=0.2............. Loss: -0.15931618, mean(E): -11.73720849+0.10338963j, var(E): 4.89097893
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=0.2............. Loss: -3.56523255, mean(E): -11.77796810-0.09554958j, var(E): 4.13829052
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=0.2............. Loss: -1.68489625, mean(E): -11.91615806-0.06125584j, var(E): 4.45201016
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=0.2............. Loss: -2.16868674, mean(E): -11.68010608-0.03272209j, var(E): 2.95196714
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=0.2............. Loss: 0.59428504, mean(E): -11.70933209+0.05417606j, var(E): 4.53440996
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=0.2............. Loss: -3.16533580, mean(E): -11.56900148-0.04378124j, var(E): 3.11584953
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=0.2............. Loss: -3.68255236, mean(E): -11.66161953+0.05197598j, var(E): 3.61989134
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=0.2............. Loss: -5.03927664, mean(E): -11.56364321+0.05940697j, var(E): 3.66915789
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=0.2............. Loss: -4.40744213, mean(E): -11.60140479-0.01401003j, var(E): 3.99864715
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=0.2............. Loss: -1.87369563, mean(E): -11.72539038-0.05610018j, var(E): 4.49711501
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=0.2............. Loss: -5.39286091, mean(E): -11.47524903-0.02703809j, var(E): 5.33552979
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=0.2............. Loss: -0.99208186, mean(E): -11.88950376-0.01652238j, var(E): 3.06130179
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=0.2............. Loss: -1.60576078, mean(E): -11.59749432+0.03011785j, var(E): 3.45954287
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=0.2............. Loss: -3.07937017, mean(E): -11.69551271-0.02276634j, var(E): 4.12771537
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=0.2............. Loss: -3.75053387, mean(E): -11.58820037+0.03359668j, var(E): 5.53722384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=0.2............. Loss: -1.13163178, mean(E): -11.89107221+0.00454020j, var(E): 3.48806057
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=0.2............. Loss: -2.67765896, mean(E): -11.73813452+0.06538674j, var(E): 3.16058377
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=0.2............. Loss: -1.64424969, mean(E): -11.65398475+0.01518344j, var(E): 3.45847998
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=0.2............. Loss: -3.56828614, mean(E): -11.51549331+0.03104331j, var(E): 4.08447006
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=0.2............. Loss: -3.48118342, mean(E): -11.88364326-0.07531108j, var(E): 3.34953654
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=0.2............. Loss: -0.99618396, mean(E): -11.56979271+0.10104004j, var(E): 3.79882222
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=0.2............. Loss: 0.91739640, mean(E): -11.77848634+0.12587868j, var(E): 5.38475636
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=0.2............. Loss: -0.66967600, mean(E): -11.91205821+0.12814000j, var(E): 3.00564708
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=0.2............. Loss: -1.45768982, mean(E): -11.58936742-0.03258952j, var(E): 3.60425847
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=0.2............. Loss: -0.95969338, mean(E): -11.75507001-0.02259813j, var(E): 3.88141520
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=0.2............. Loss: -2.14285535, mean(E): -11.84413630-0.03907204j, var(E): 4.76614338
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=0.2............. Loss: -4.79967758, mean(E): -11.60341021+0.02787314j, var(E): 3.44720214
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=0.2............. Loss: -2.80681509, mean(E): -11.84540521-0.02447399j, var(E): 4.48414867
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=0.2............. Loss: 0.37676328, mean(E): -11.63664165+0.00720241j, var(E): 5.55289630
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=0.2............. Loss: -2.11885335, mean(E): -11.81527691-0.02807113j, var(E): 2.74996691
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=0.2............. Loss: -3.84801634, mean(E): -11.84946736-0.00595071j, var(E): 2.46110680
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=0.2............. Loss: -2.08305026, mean(E): -11.70087062+0.01360992j, var(E): 3.24875503
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=0.2............. Loss: -1.02033424, mean(E): -11.70894245+0.01625111j, var(E): 2.85574195
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=0.2............. Loss: -2.68030193, mean(E): -11.67245613+0.08864034j, var(E): 4.12757743
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=0.2............. Loss: -3.12370022, mean(E): -11.70529026+0.01001136j, var(E): 3.24415957
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=0.2............. Loss: -2.80966437, mean(E): -11.71451366+0.00809089j, var(E): 3.05035603
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=0.2............. Loss: -1.97571047, mean(E): -11.59737089+0.07286338j, var(E): 3.91616768
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=0.2............. Loss: -1.10658040, mean(E): -11.52872674+0.02838223j, var(E): 4.57052734
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=0.2............. Loss: -2.44581745, mean(E): -11.70563165+0.02196919j, var(E): 3.44963280
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=0.2............. Loss: -2.54844454, mean(E): -11.65806033+0.01010256j, var(E): 3.96520313
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=0.2............. Loss: -2.98829422, mean(E): -11.61747952+0.01856627j, var(E): 3.22519233
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=0.2............. Loss: -3.87437192, mean(E): -11.74964093+0.01271671j, var(E): 3.19346386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=0.2............. Loss: 1.79535750, mean(E): -11.60702450+0.09175806j, var(E): 5.29742635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=0.2............. Loss: -0.54309574, mean(E): -11.72011607+0.09555441j, var(E): 3.48292294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=0.2............. Loss: -0.50327811, mean(E): -11.70013920+0.08147068j, var(E): 5.25330964
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=0.2............. Loss: -0.08790094, mean(E): -11.69355954-0.05104273j, var(E): 3.77782421
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=0.2............. Loss: -1.48811986, mean(E): -11.57745220+0.03346906j, var(E): 3.40748886
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=0.2............. Loss: -2.83880463, mean(E): -11.64525523+0.01506694j, var(E): 3.52106829
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=0.2............. Loss: -1.96242446, mean(E): -11.72020812-0.03887012j, var(E): 4.02692167
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=0.2............. Loss: -1.99227020, mean(E): -11.64217921-0.05833603j, var(E): 4.55365500
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=0.2............. Loss: -2.31419171, mean(E): -11.61432068+0.00581124j, var(E): 3.79970255
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=0.2............. Loss: 0.20929465, mean(E): -11.72155744+0.07992103j, var(E): 3.30420584
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=0.2............. Loss: -1.64257358, mean(E): -11.86683651+0.02885349j, var(E): 2.71899092
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=0.2............. Loss: -1.31292505, mean(E): -11.72909810+0.10175644j, var(E): 6.92773272
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=0.2............. Loss: -0.38193759, mean(E): -11.75464668+0.05530357j, var(E): 3.01354748
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=0.2............. Loss: -4.50660809, mean(E): -11.52911444+0.06294435j, var(E): 4.60847012
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=0.2............. Loss: -4.01187219, mean(E): -11.58075128+0.01095837j, var(E): 3.26153706
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=0.2............. Loss: -1.35370358, mean(E): -11.92858887+0.01288213j, var(E): 2.63987793
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=0.2............. Loss: -1.41531403, mean(E): -11.61725616+0.03476941j, var(E): 4.89089305
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=0.2............. Loss: -2.38247597, mean(E): -11.78469801+0.02002044j, var(E): 3.12655575
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=0.2............. Loss: 0.60510351, mean(E): -11.92025897+0.09227489j, var(E): 2.97182323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=0.2............. Loss: -4.74764908, mean(E): -11.80754279+0.01636843j, var(E): 2.88512892
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=0.2............. Loss: -2.61374901, mean(E): -11.68524453-0.03281137j, var(E): 3.02812482
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=0.2............. Loss: -1.21649114, mean(E): -11.77799702+0.07028617j, var(E): 3.72430634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=0.2............. Loss: -1.98199800, mean(E): -11.60775962+0.11454844j, var(E): 3.64007225
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=0.2............. Loss: -1.70620722, mean(E): -11.70408256+0.02747864j, var(E): 5.36298197
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=0.2............. Loss: -4.76125343, mean(E): -11.80805754+0.08869809j, var(E): 2.97649696
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=0.2............. Loss: -0.91343436, mean(E): -11.79424961+0.06109332j, var(E): 3.58466508
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=0.2............. Loss: -2.56397097, mean(E): -11.72054329-0.05025238j, var(E): 4.13928180
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=0.2............. Loss: -0.85903881, mean(E): -11.67341904+0.03287786j, var(E): 3.63831567
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=0.2............. Loss: -0.61676452, mean(E): -11.86112758-0.07332672j, var(E): 3.11312180
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=0.2............. Loss: -3.18976270, mean(E): -11.72849570-0.09307407j, var(E): 4.36149107
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=0.2............. Loss: -3.35887134, mean(E): -11.90165530-0.08124672j, var(E): 2.93277369
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=0.2............. Loss: -2.87177094, mean(E): -11.89372249-0.02051788j, var(E): 2.53802707
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=0.2............. Loss: 0.21056445, mean(E): -11.44099875+0.14699582j, var(E): 6.20697532
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=0.2............. Loss: -0.88083693, mean(E): -11.71121390+0.01465930j, var(E): 3.06600110
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=0.2............. Loss: -1.25012273, mean(E): -11.91169565+0.06055128j, var(E): 3.74133367
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=0.2............. Loss: -3.65822569, mean(E): -11.78270417-0.02281601j, var(E): 2.90743323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=0.2............. Loss: -3.37141195, mean(E): -11.78127441-0.03923382j, var(E): 4.06262321
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=0.2............. Loss: -3.58054425, mean(E): -11.67212185-0.02372533j, var(E): 3.49793697
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=0.2............. Loss: -4.54175903, mean(E): -11.70989579-0.04347590j, var(E): 3.28721784
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=0.2............. Loss: -1.28537554, mean(E): -11.76781919+0.00130723j, var(E): 2.84445164
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=0.2............. Loss: -1.74003820, mean(E): -11.83678200+0.00259635j, var(E): 3.57913304
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=0.2............. Loss: -2.74602016, mean(E): -11.86804148-0.00878598j, var(E): 3.48452964
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=0.2............. Loss: -2.36273039, mean(E): -11.91273422-0.02158897j, var(E): 2.90589954
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=0.2............. Loss: -1.92162914, mean(E): -11.80821154+0.01507987j, var(E): 3.34480602
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=0.2............. Loss: -1.75234542, mean(E): -11.75114875+0.05824525j, var(E): 2.90657621
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=0.2............. Loss: -2.48435451, mean(E): -11.58080190-0.02692044j, var(E): 3.16854091
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=0.2............. Loss: 0.38456557, mean(E): -11.90315452+0.08322842j, var(E): 2.96074324
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=0.2............. Loss: -0.95902248, mean(E): -11.93393267+0.05277347j, var(E): 2.62820139
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=0.2............. Loss: -1.37443950, mean(E): -11.87314301-0.04901858j, var(E): 5.46641890
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=0.2............. Loss: -2.19144480, mean(E): -11.68623249-0.02609328j, var(E): 3.09448664
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=0.2............. Loss: 5.15780662, mean(E): -11.95751932-0.16498457j, var(E): 8.04153443
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=0.2............. Loss: -3.43304847, mean(E): -11.77145530-0.08315660j, var(E): 3.47111950
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=0.2............. Loss: -2.54480074, mean(E): -11.80347147+0.02565523j, var(E): 2.68318384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=0.2............. Loss: -3.67642240, mean(E): -11.79488286-0.05724803j, var(E): 3.50777388
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=0.21............. Loss: -3.22297315, mean(E): -11.88886507+0.00437698j, var(E): 2.14025060
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=0.2............. Loss: -3.00236254, mean(E): -11.53342726-0.05613506j, var(E): 4.43379840
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=0.2............. Loss: -0.26948819, mean(E): -11.80103499+0.03772244j, var(E): 2.98563590
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=0.2............. Loss: -1.08280814, mean(E): -11.75691605+0.06316716j, var(E): 3.35699155
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=0.2............. Loss: -2.44260530, mean(E): -11.78625766+0.00943137j, var(E): 3.63728199
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=0.2............. Loss: -3.71360577, mean(E): -11.78856643-0.10502300j, var(E): 3.82446765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=0.2............. Loss: -3.42857346, mean(E): -11.61671271+0.03745563j, var(E): 3.41125413
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=0.2............. Loss: -3.13515624, mean(E): -11.63025248+0.09970115j, var(E): 3.15733701
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=0.2............. Loss: -0.53490544, mean(E): -11.89136154+0.02987243j, var(E): 4.17618061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=0.2............. Loss: -3.01984772, mean(E): -11.71928713-0.03992612j, var(E): 3.06367517
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=0.2............. Loss: -2.73233237, mean(E): -11.75877276-0.02086478j, var(E): 2.39023993
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=0.2............. Loss: -3.47663114, mean(E): -11.47129347-0.04565667j, var(E): 4.73645261
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=0.2............. Loss: -3.68400022, mean(E): -11.74787470+0.05538341j, var(E): 3.90059737
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=0.2............. Loss: -0.72355995, mean(E): -11.92863220+0.03096911j, var(E): 3.03684737
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=0.2............. Loss: -2.74723128, mean(E): -11.83602746-0.17783777j, var(E): 3.67505108
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=0.2............. Loss: -2.54309430, mean(E): -11.74402110+0.03511622j, var(E): 2.99211228
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=0.2............. Loss: -3.73134470, mean(E): -11.70483277+0.04731362j, var(E): 3.90375685
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=0.2............. Loss: -2.79560309, mean(E): -11.85321283-0.09329207j, var(E): 3.86940440
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=0.2............. Loss: -4.22729805, mean(E): -11.52298800-0.05918992j, var(E): 5.08862767
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=0.2............. Loss: -1.98303698, mean(E): -11.86665044+0.00542627j, var(E): 2.83611400
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=0.2............. Loss: -2.32388417, mean(E): -11.97123935-0.03386485j, var(E): 2.10286477
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=0.2............. Loss: -0.90950366, mean(E): -11.80692967+0.05623631j, var(E): 3.03340078
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=0.2............. Loss: -3.17894649, mean(E): -11.60003902+0.05800052j, var(E): 3.53626907
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=0.2............. Loss: -0.27216076, mean(E): -11.74089539+0.00430051j, var(E): 3.58005786
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=0.2............. Loss: -0.81102900, mean(E): -11.84649930+0.06201688j, var(E): 5.28258896
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=0.2............. Loss: -3.17451386, mean(E): -11.46490488-0.06921746j, var(E): 3.81246148
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=0.2............. Loss: -3.84583221, mean(E): -11.59029483-0.07039056j, var(E): 3.85137232
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=0.2............. Loss: -1.97528246, mean(E): -11.71660304+0.01858942j, var(E): 3.51399630
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=0.2............. Loss: -3.45819273, mean(E): -11.62103843+0.05221141j, var(E): 3.62791824
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=0.2............. Loss: -3.68006209, mean(E): -11.58293937+0.04100062j, var(E): 3.91537506
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=0.2............. Loss: -2.44223827, mean(E): -11.91020766-0.09708046j, var(E): 2.96542977
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=0.2............. Loss: -3.30342875, mean(E): -11.71554260+0.00506491j, var(E): 2.66959237
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=0.2............. Loss: -3.34081802, mean(E): -11.64600498-0.02309258j, var(E): 3.62974521
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=0.2............. Loss: -1.17075365, mean(E): -11.55499075+0.03562899j, var(E): 4.06550329
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=0.2............. Loss: 2.62073756, mean(E): -11.92449285+0.16651412j, var(E): 7.99862131
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=0.2............. Loss: -3.27916098, mean(E): -11.90909295-0.08791281j, var(E): 3.19553643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=0.2............. Loss: -2.85624171, mean(E): -11.81112398-0.04887012j, var(E): 4.08593977
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=0.2............. Loss: -3.94898504, mean(E): -11.75922783+0.02840652j, var(E): 2.70211751
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=0.2............. Loss: -2.13229225, mean(E): -11.89868235+0.02566503j, var(E): 2.94188898
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=0.2............. Loss: -2.48685072, mean(E): -11.79948443+0.08162798j, var(E): 3.55770128
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=0.2............. Loss: -1.63151135, mean(E): -11.67097539-0.05914288j, var(E): 2.88757726
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=0.2............. Loss: -1.36745716, mean(E): -11.53231101+0.05536055j, var(E): 3.80558130
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=0.2............. Loss: -1.72291648, mean(E): -11.81823605+0.02968145j, var(E): 2.88122208
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=0.2............. Loss: -0.89015215, mean(E): -11.88065964+0.01470672j, var(E): 2.33091894
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=0.2............. Loss: -2.10793342, mean(E): -11.85631700-0.02117172j, var(E): 2.56704730
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=0.2............. Loss: -1.84701264, mean(E): -11.63552865+0.02111509j, var(E): 3.40476163
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=0.2............. Loss: -2.60996288, mean(E): -11.62730432+0.03744730j, var(E): 3.38625326
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=0.2............. Loss: -3.05215844, mean(E): -11.72348695+0.05911899j, var(E): 3.25861214
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=0.2............. Loss: -1.90692091, mean(E): -12.03354001-0.00713387j, var(E): 1.69402351
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=0.2............. Loss: -3.34067434, mean(E): -11.52696372+0.06290857j, var(E): 4.11229444
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=0.2............. Loss: -0.91095216, mean(E): -11.77969332+0.04182707j, var(E): 2.68848925
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=0.2............. Loss: -2.01154934, mean(E): -11.52543917+0.08196465j, var(E): 4.49823442
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=0.2............. Loss: -2.37406574, mean(E): -11.78386308-0.05988908j, var(E): 4.18793404
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=0.2............. Loss: -3.79867548, mean(E): -11.95513125-0.01317961j, var(E): 3.60254581
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=0.2............. Loss: -0.77431324, mean(E): -11.66995949-0.03496166j, var(E): 4.48862319
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=0.2............. Loss: -4.44188273, mean(E): -11.50621726-0.02077864j, var(E): 3.56685593
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=0.2............. Loss: -0.38988832, mean(E): -11.80358157+0.04848236j, var(E): 4.20081092
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=0.2............. Loss: -3.40392240, mean(E): -11.57077635-0.06943216j, var(E): 5.76356956
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=0.2............. Loss: -3.57603348, mean(E): -11.72308780+0.03169789j, var(E): 3.57090736
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=0.2............. Loss: -2.87188821, mean(E): -11.71497331+0.05121582j, var(E): 3.98834384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=0.2............. Loss: -2.25827711, mean(E): -11.71494743-0.07912156j, var(E): 3.76118877
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=0.2............. Loss: -3.96084443, mean(E): -11.71233041+0.03473701j, var(E): 3.19463139
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=0.2............. Loss: -3.78384496, mean(E): -11.56124610+0.01208896j, var(E): 3.87386270
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=0.2............. Loss: -0.27634256, mean(E): -11.86660000+0.08103019j, var(E): 2.97339104
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=0.2............. Loss: -2.89037016, mean(E): -11.76666839-0.03243926j, var(E): 3.96886517
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=0.2............. Loss: -1.04017396, mean(E): -11.64388255-0.05507329j, var(E): 4.11359372
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=0.2............. Loss: -2.50498509, mean(E): -11.74724914+0.02785301j, var(E): 2.70987105
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=0.2............. Loss: -2.17392314, mean(E): -11.79818585+0.00733110j, var(E): 2.94876757
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=0.2............. Loss: -0.39651237, mean(E): -11.68610519+0.06259376j, var(E): 3.34441802
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=0.2............. Loss: -1.73879050, mean(E): -11.88322007-0.00847790j, var(E): 4.54021612
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=0.2............. Loss: -2.96147950, mean(E): -11.75143747-0.01902116j, var(E): 2.67982818
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=0.2............. Loss: -0.56922058, mean(E): -11.87319838+0.04230595j, var(E): 2.38549558
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=0.2............. Loss: -4.89143761, mean(E): -11.70736737-0.01840332j, var(E): 4.25596516
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=0.2............. Loss: -1.90865782, mean(E): -11.90432820+0.02497963j, var(E): 2.71003765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=0.2............. Loss: -1.32928107, mean(E): -11.62422422-0.01370380j, var(E): 3.61497444
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=0.2............. Loss: -3.86498526, mean(E): -11.45219614+0.03856135j, var(E): 7.36103384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=0.2............. Loss: -2.08616336, mean(E): -11.65016760+0.05789868j, var(E): 3.63661439
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=0.2............. Loss: -1.28031375, mean(E): -11.60177833+0.04147028j, var(E): 4.40495400
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=0.2............. Loss: -2.99990064, mean(E): -11.76922656-0.00457343j, var(E): 3.25281057
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=0.21............. Loss: -0.71345495, mean(E): -11.79131906-0.02460588j, var(E): 6.49958025
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=0.2............. Loss: -3.97693219, mean(E): -11.79583226-0.04314785j, var(E): 3.48461331
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=0.2............. Loss: -3.40424391, mean(E): -11.79539894-0.05554681j, var(E): 3.36592885
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=0.2............. Loss: -2.54671818, mean(E): -11.61845996-0.00343901j, var(E): 3.48560657
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=0.2............. Loss: -3.25768545, mean(E): -11.54627107+0.04995026j, var(E): 4.37366075
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=0.21............. Loss: -1.72255788, mean(E): -11.77471122+0.01393643j, var(E): 3.11485535
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=0.2............. Loss: -0.01663576, mean(E): -11.63163933+0.01031968j, var(E): 4.56608922
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=0.2............. Loss: -0.90213024, mean(E): -11.85014693-0.02561112j, var(E): 2.78711521
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=0.2............. Loss: -1.67611582, mean(E): -11.88540745+0.01015755j, var(E): 2.09872113
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=0.2............. Loss: -2.63199886, mean(E): -11.77650019-0.00121463j, var(E): 2.55106144
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=0.21............. Loss: -1.82155635, mean(E): -11.86039404+0.01296855j, var(E): 2.52587454
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=0.2............. Loss: -3.34333478, mean(E): -11.71052980-0.01190917j, var(E): 2.83239930
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=0.2............. Loss: -3.08841036, mean(E): -11.69323684+0.04089900j, var(E): 3.57032066
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=0.2............. Loss: -1.04878397, mean(E): -11.80376179+0.00528472j, var(E): 2.74223423
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=0.2............. Loss: -0.93215781, mean(E): -11.60538744+0.01975980j, var(E): 4.09434224
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=0.21............. Loss: -0.95203299, mean(E): -11.83660294+0.11293884j, var(E): 3.27503795
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=0.2............. Loss: 2.21874825, mean(E): -11.59355006+0.16308487j, var(E): 7.01172488
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=0.2............. Loss: -2.53945577, mean(E): -11.65777630+0.05441808j, var(E): 3.95802614
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=0.2............. Loss: -1.71496831, mean(E): -11.68122850-0.06941870j, var(E): 3.43246692
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=0.2............. Loss: -0.93211012, mean(E): -11.83781413+0.05484049j, var(E): 2.41019097
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=0.21............. Loss: -1.15164996, mean(E): -11.94259554+0.08024892j, var(E): 3.23667636
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=0.2............. Loss: 0.81227894, mean(E): -11.99416769+0.08835782j, var(E): 5.83036840
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=0.2............. Loss: 1.73139169, mean(E): -11.57527261+0.13200391j, var(E): 6.15497272
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=0.2............. Loss: -1.89953451, mean(E): -11.77514433+0.01400252j, var(E): 3.41283871
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=0.2............. Loss: -0.84239122, mean(E): -12.03536979+0.02934753j, var(E): 2.10189601
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=0.21............. Loss: -1.50522173, mean(E): -11.81717632+0.11219255j, var(E): 4.19771033
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=0.2............. Loss: -2.20551694, mean(E): -11.74563267-0.00967067j, var(E): 3.07775317
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=0.2............. Loss: -3.94269669, mean(E): -11.85461548+0.02848596j, var(E): 3.37999865
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=0.2............. Loss: -1.41416745, mean(E): -11.77318654+0.09322447j, var(E): 2.86792238
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=0.2............. Loss: -0.65781380, mean(E): -11.68931848+0.05220719j, var(E): 3.53630476
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=0.21............. Loss: -1.53425096, mean(E): -11.88547563-0.02223266j, var(E): 3.06742947
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=0.2............. Loss: -1.87827036, mean(E): -11.93720699+0.05010892j, var(E): 3.12584112
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=0.2............. Loss: -4.67479453, mean(E): -11.49052467-0.10439104j, var(E): 5.02363176
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=0.2............. Loss: -3.73121099, mean(E): -11.76895144-0.03228648j, var(E): 3.60234022
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=0.2............. Loss: 5.37073039, mean(E): -11.66065120+0.21726418j, var(E): 20.56515386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=0.21............. Loss: 2.34854552, mean(E): -11.69250015+0.20332788j, var(E): 14.75713061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=0.2............. Loss: -1.87406984, mean(E): -11.91226534-0.01691764j, var(E): 5.02678168
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=0.2............. Loss: 0.85604090, mean(E): -11.80819118+0.02496578j, var(E): 2.90499574
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=0.2............. Loss: -1.75912878, mean(E): -11.60517509-0.04522092j, var(E): 3.58937035
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=0.2............. Loss: -3.62613125, mean(E): -11.61575598-0.04012067j, var(E): 3.19135028
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=0.21............. Loss: 1.37476875, mean(E): -11.78529770+0.12445734j, var(E): 5.17946530
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=0.2............. Loss: -2.27422018, mean(E): -11.65099284-0.02285119j, var(E): 3.56473520
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=0.2............. Loss: -2.24341449, mean(E): -11.99932248+0.01540507j, var(E): 2.46858857
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=0.2............. Loss: -1.88052204, mean(E): -11.59974891+0.05826633j, var(E): 3.30550299
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=0.2............. Loss: -2.29026177, mean(E): -11.66971656-0.01863203j, var(E): 4.02064021
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=0.2............. Loss: 2.57452617, mean(E): -11.85959080+0.15321052j, var(E): 5.65489355
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=0.2............. Loss: -2.23879469, mean(E): -11.80344355+0.06468368j, var(E): 3.06556890
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=0.2............. Loss: -0.75200281, mean(E): -11.91818655+0.02437930j, var(E): 2.86923976
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=0.2............. Loss: -3.72495874, mean(E): -11.66822162-0.03132576j, var(E): 3.65796784
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=0.2............. Loss: 0.11298825, mean(E): -11.88826025+0.01681001j, var(E): 2.68050889
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=0.21............. Loss: 0.51488466, mean(E): -11.80115169+0.00368512j, var(E): 3.67903221
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=0.2............. Loss: -0.39820127, mean(E): -11.67336860+0.03096784j, var(E): 6.92213490
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=0.2............. Loss: -4.42122587, mean(E): -11.62574240-0.03967972j, var(E): 3.70963384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=0.2............. Loss: 1.91630687, mean(E): -11.81952812+0.11137697j, var(E): 4.93125143
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=0.2............. Loss: -2.56148711, mean(E): -11.77027200+0.02988491j, var(E): 3.01627623
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=0.21............. Loss: -2.53858584, mean(E): -11.61321782-0.02165773j, var(E): 3.44401129
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=0.2............. Loss: 0.78590657, mean(E): -11.99891411+0.08111277j, var(E): 5.04735514
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=0.2............. Loss: -1.80255394, mean(E): -11.91622135+0.02376293j, var(E): 2.38408121
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=0.2............. Loss: -1.69446532, mean(E): -11.99148469-0.01223396j, var(E): 2.64078540
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=0.2............. Loss: -3.01865641, mean(E): -11.90381451-0.03592322j, var(E): 2.60177680
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=0.21............. Loss: -2.34183138, mean(E): -11.94314999+0.03429369j, var(E): 2.57288249
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=0.2............. Loss: -2.24752141, mean(E): -11.81740591-0.08915657j, var(E): 3.71269714
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=0.2............. Loss: -4.26394765, mean(E): -11.70202694-0.03612453j, var(E): 3.88264419
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=0.2............. Loss: -3.28692742, mean(E): -11.63443884+0.01305702j, var(E): 4.54085991
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=0.2............. Loss: -1.65051551, mean(E): -11.74013536+0.00044301j, var(E): 2.98701294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=0.21............. Loss: -1.91053631, mean(E): -11.88358205+0.02040417j, var(E): 3.75581843
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=0.2............. Loss: -2.37054560, mean(E): -11.75405970+0.08443388j, var(E): 4.14877115
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=0.2............. Loss: -1.62039273, mean(E): -11.85429032-0.00935875j, var(E): 2.36821100
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=0.2............. Loss: 4.56036420, mean(E): -11.79855662-0.14649901j, var(E): 8.40130389
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=0.21............. Loss: -1.85186936, mean(E): -11.89362332-0.00877454j, var(E): 2.74099165
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=0.2............. Loss: -3.55330334, mean(E): -11.81495822-0.02473996j, var(E): 3.55583950
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=0.2............. Loss: -2.45597281, mean(E): -11.81643184+0.02712201j, var(E): 2.33802961
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=0.2............. Loss: -2.58100620, mean(E): -11.89324545+0.01105014j, var(E): 2.52745073
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=0.2............. Loss: -3.33909381, mean(E): -12.00570907-0.01392732j, var(E): 2.46998072
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=0.2............. Loss: -2.70117906, mean(E): -11.80014256-0.01527759j, var(E): 3.95243757
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=0.2............. Loss: -2.16532657, mean(E): -11.75459498-0.00372769j, var(E): 3.84303335
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=0.2............. Loss: -1.76063644, mean(E): -11.64888287+0.03263534j, var(E): 4.14499183
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=0.2............. Loss: -1.27155235, mean(E): -11.82342281+0.01273844j, var(E): 3.44331244
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=0.2............. Loss: -0.23775616, mean(E): -11.75594111+0.04386085j, var(E): 3.48030008
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=0.2............. Loss: -3.68005863, mean(E): -11.74306579+0.04251898j, var(E): 3.28727869
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=0.2............. Loss: -0.00720359, mean(E): -11.91254547+0.08431348j, var(E): 3.21173094
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=0.2............. Loss: -1.33707131, mean(E): -11.81996939-0.03131429j, var(E): 2.86192956
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=0.2............. Loss: -0.19066724, mean(E): -11.77906714+0.00186487j, var(E): 4.47282897
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=0.2............. Loss: -3.35208716, mean(E): -11.85232562+0.02327255j, var(E): 2.64065363
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=0.2............. Loss: -2.25300504, mean(E): -11.67859259-0.10767642j, var(E): 4.14266705
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=0.2............. Loss: -4.46970842, mean(E): -11.91380895-0.02491720j, var(E): 3.80422876
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=0.2............. Loss: -2.29066435, mean(E): -11.72358615-0.01728773j, var(E): 4.12890464
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=0.2............. Loss: -2.03796482, mean(E): -11.88414281+0.03199889j, var(E): 2.60881872
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=0.2............. Loss: -2.41256927, mean(E): -11.88026739-0.00390158j, var(E): 5.23808113
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=0.2............. Loss: -2.05846201, mean(E): -11.81634229+0.05446687j, var(E): 2.68734044
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=0.2............. Loss: -2.23449876, mean(E): -11.85722646-0.02799511j, var(E): 2.36567627
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=0.2............. Loss: -4.70389168, mean(E): -11.89951828-0.09086993j, var(E): 6.15108386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=0.2............. Loss: -2.00724111, mean(E): -11.82353899+0.00120039j, var(E): 2.52465835
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=0.2............. Loss: -2.23646552, mean(E): -11.80261205-0.02171632j, var(E): 2.52115592
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=0.2............. Loss: -3.89344543, mean(E): -11.70587904-0.03981974j, var(E): 3.12438887
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=0.2............. Loss: -3.05016933, mean(E): -11.74232620+0.09386266j, var(E): 3.34338522
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=0.2............. Loss: -3.46319986, mean(E): -11.82882430-0.10793212j, var(E): 7.07431664
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=0.2............. Loss: -1.57360086, mean(E): -11.88761938+0.03396694j, var(E): 2.52757711
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=0.2............. Loss: -2.26692618, mean(E): -11.73364129-0.02234425j, var(E): 4.32229150
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=0.2............. Loss: -2.53249577, mean(E): -11.94511235-0.06424280j, var(E): 2.65068503
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=0.2............. Loss: -1.90379027, mean(E): -11.84087766+0.02094772j, var(E): 3.12862925
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=0.2............. Loss: -2.94675665, mean(E): -11.79332364+0.02615150j, var(E): 2.48066521
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=0.2............. Loss: -1.85048357, mean(E): -11.69968735+0.02090956j, var(E): 2.80789260
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=0.2............. Loss: -4.72047810, mean(E): -11.66118698+0.01214763j, var(E): 3.59179239
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=0.2............. Loss: -1.07324464, mean(E): -11.90703237+0.00965777j, var(E): 2.77317220
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=0.2............. Loss: -2.27080522, mean(E): -11.77467378+0.06063191j, var(E): 3.60730506
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=0.2............. Loss: -1.93147011, mean(E): -11.95664405+0.00489647j, var(E): 2.27216267
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=0.2............. Loss: -1.94022350, mean(E): -11.81522917+0.02351621j, var(E): 2.83392359
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=0.2............. Loss: -2.78393803, mean(E): -11.77662957-0.01879618j, var(E): 4.67522292
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=0.2............. Loss: -2.83436625, mean(E): -11.78380555-0.07696244j, var(E): 3.71845205
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=0.2............. Loss: -0.40458558, mean(E): -11.83747935-0.07765709j, var(E): 2.74315778
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=0.2............. Loss: -1.17737184, mean(E): -11.86112745+0.02607443j, var(E): 3.05305399
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=0.2............. Loss: -4.13276447, mean(E): -11.86787570-0.02236045j, var(E): 3.55686397
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=0.2............. Loss: -0.71294457, mean(E): -11.72145966+0.04003356j, var(E): 4.04229509
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=0.21............. Loss: -1.46439027, mean(E): -11.79316923-0.00444022j, var(E): 2.99230809
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=0.21............. Loss: -2.24472085, mean(E): -11.63105595+0.01890083j, var(E): 4.00956593
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=0.21............. Loss: -3.17053622, mean(E): -11.99579384-0.03776010j, var(E): 5.00441167
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=0.21............. Loss: -1.24018090, mean(E): -11.87163797+0.00795465j, var(E): 3.31024879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=0.21............. Loss: -0.49934576, mean(E): -12.04743871+0.03254484j, var(E): 2.43177247
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=0.2............. Loss: 0.49416815, mean(E): -11.91509500-0.01075528j, var(E): 2.64742546
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=0.2............. Loss: -3.82417119, mean(E): -11.81524017-0.08403375j, var(E): 5.66218254
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=0.2............. Loss: -3.97076736, mean(E): -11.87333049-0.00489338j, var(E): 3.52686429
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=0.2............. Loss: -1.31749418, mean(E): -11.80917575+0.00539211j, var(E): 3.30525971
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=0.2............. Loss: -2.36310988, mean(E): -11.53280661+0.00368925j, var(E): 4.10253343
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=0.2............. Loss: -1.63277644, mean(E): -11.78667010+0.01702320j, var(E): 3.21759652
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=0.2............. Loss: -3.43249714, mean(E): -11.64994032+0.07402626j, var(E): 4.18233684
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=0.2............. Loss: -2.23728947, mean(E): -11.68571306+0.00500736j, var(E): 3.39920340
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=0.2............. Loss: -2.02815677, mean(E): -12.00827343-0.00023433j, var(E): 2.68495267
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=0.2............. Loss: -3.31880504, mean(E): -11.79743267-0.04680814j, var(E): 2.92369259
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=0.22............. Loss: -0.04995608, mean(E): -12.06494515+0.05826539j, var(E): 2.12411475
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=0.21............. Loss: -1.82489661, mean(E): -11.83259995+0.01053836j, var(E): 3.42280196
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=0.21............. Loss: -2.78438071, mean(E): -11.86322796-0.02596038j, var(E): 2.57504384
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=0.22............. Loss: 7.66965152, mean(E): -12.01275695-0.06988504j, var(E): 8.35541517
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=0.2............. Loss: -2.05313296, mean(E): -11.73526632+0.03296248j, var(E): 3.42822896
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=0.2............. Loss: -1.99677861, mean(E): -11.77066270+0.04565053j, var(E): 2.85123719
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=0.2............. Loss: -0.32387038, mean(E): -11.79617417+0.02363878j, var(E): 2.74611381
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=0.21............. Loss: -2.64344547, mean(E): -11.72161022+0.05831780j, var(E): 3.35994331
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=0.21............. Loss: -3.23178080, mean(E): -11.65705321+0.07063318j, var(E): 3.94248110
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=0.21............. Loss: -2.19563396, mean(E): -11.81168619-0.08000138j, var(E): 2.98824545
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=0.2............. Loss: -0.91338456, mean(E): -11.78599192+0.08615610j, var(E): 4.18985400
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=0.2............. Loss: -0.27008803, mean(E): -11.83171698+0.10984054j, var(E): 6.75917113
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=0.21............. Loss: -0.60196750, mean(E): -11.77188553+0.05312273j, var(E): 3.01772107
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=0.21............. Loss: -1.69356676, mean(E): -11.88661277-0.01286617j, var(E): 3.29356333
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=0.2............. Loss: -0.03455317, mean(E): -11.84706384+0.08075370j, var(E): 3.46715565
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=0.2............. Loss: -0.56130186, mean(E): -11.98762580-0.00601703j, var(E): 3.13811371
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=0.2............. Loss: -1.87377446, mean(E): -11.84211397+0.02356537j, var(E): 2.61057946
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=0.21............. Loss: -4.11168518, mean(E): -11.79822732-0.06266282j, var(E): 3.89390319
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=0.2............. Loss: -2.12143025, mean(E): -11.94222041-0.00102941j, var(E): 2.43696294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=0.2............. Loss: -5.84175940, mean(E): -11.81979693+0.02574449j, var(E): 13.48009731
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=0.2............. Loss: -1.16014868, mean(E): -11.87558306+0.00065495j, var(E): 3.07633797
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=0.2............. Loss: 1.30319278, mean(E): -11.71105941+0.08685911j, var(E): 6.37012241
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=0.2............. Loss: -4.69406056, mean(E): -11.68485451-0.12701409j, var(E): 4.08376146
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=0.21............. Loss: -0.50331925, mean(E): -12.05891279+0.00168744j, var(E): 1.81585427
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=0.21............. Loss: 0.71321407, mean(E): -11.87855111+0.10164296j, var(E): 6.83457470
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=0.2............. Loss: -4.50629876, mean(E): -11.82461619-0.08625598j, var(E): 4.25828367
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=0.21............. Loss: -2.32222349, mean(E): -11.80673748+0.08055995j, var(E): 3.09906769
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=0.2............. Loss: 0.10345319, mean(E): -11.72734493+0.04995803j, var(E): 6.45259548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=0.2............. Loss: 0.81663784, mean(E): -11.99939964+0.06355932j, var(E): 3.37018132
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=0.2............. Loss: 0.46539970, mean(E): -11.90415317+0.02148524j, var(E): 6.10724569
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=0.2............. Loss: -4.57638554, mean(E): -11.90586882-0.07766315j, var(E): 5.37689381
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=0.21............. Loss: -4.02924670, mean(E): -11.82118745+0.00771327j, var(E): 2.53531168
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=0.2............. Loss: -2.14626944, mean(E): -11.78158034+0.02542362j, var(E): 2.57576608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=0.2............. Loss: 0.66125248, mean(E): -11.91449028+0.08631621j, var(E): 6.73969713
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=0.21............. Loss: -2.42393823, mean(E): -11.83088074+0.02821964j, var(E): 3.06677700
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=0.2............. Loss: -0.86028179, mean(E): -11.98867063+0.00262944j, var(E): 1.93259838
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=0.21............. Loss: -3.04862916, mean(E): -11.89785037-0.01713766j, var(E): 2.84014672
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=0.2............. Loss: -2.88254674, mean(E): -11.89887615-0.00526946j, var(E): 2.57461709
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=0.2............. Loss: -2.76821239, mean(E): -11.78675968+0.01989624j, var(E): 3.58350071
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=0.2............. Loss: -2.42539988, mean(E): -12.04001204+0.01234262j, var(E): 4.06470584
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=0.21............. Loss: -3.06260853, mean(E): -11.93008146+0.07565017j, var(E): 3.09936847
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=0.21............. Loss: -3.08908506, mean(E): -11.76995619-0.00851107j, var(E): 3.07201395
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=0.2............. Loss: -1.69401178, mean(E): -12.21234002+0.02564144j, var(E): 2.04739522
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=0.2............. Loss: -1.04478563, mean(E): -12.06501963+0.02613537j, var(E): 3.09285197
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=0.22............. Loss: -3.05030790, mean(E): -11.89118125-0.01274432j, var(E): 2.02818300
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=0.22............. Loss: -1.76757356, mean(E): -11.90030811-0.02549320j, var(E): 3.59886115
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=0.21............. Loss: -3.12185032, mean(E): -11.66913591-0.02726821j, var(E): 3.76060936
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=0.21............. Loss: -3.57813468, mean(E): -11.47701258+0.01729777j, var(E): 4.24257811
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=0.2............. Loss: -2.28773485, mean(E): -11.78633174+0.02099502j, var(E): 3.32434496
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=0.2............. Loss: -2.33214760, mean(E): -11.83360089+0.04625778j, var(E): 3.86102927
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=0.2............. Loss: 4.79148141, mean(E): -11.83626167+0.27780202j, var(E): 14.36837520
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=0.2............. Loss: -0.15213828, mean(E): -11.85174660+0.02992466j, var(E): 2.79293124
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=0.2............. Loss: -1.84950865, mean(E): -11.85190471+0.05461497j, var(E): 3.45543843
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=0.2............. Loss: -0.96378706, mean(E): -12.01444520-0.04491869j, var(E): 2.32055475
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=0.2............. Loss: -1.89908883, mean(E): -11.93574575-0.00054011j, var(E): 2.96657005
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=0.2............. Loss: -2.67646218, mean(E): -11.77879355+0.07252606j, var(E): 3.50725714
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=0.2............. Loss: -1.78134563, mean(E): -11.94395850+0.03909682j, var(E): 3.48987515
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=0.2............. Loss: -1.54961282, mean(E): -11.95817462+0.02911531j, var(E): 2.60104294
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=0.2............. Loss: -1.76536754, mean(E): -11.89026363-0.00307227j, var(E): 4.06864838
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=0.2............. Loss: -0.78768946, mean(E): -11.65427095+0.02810261j, var(E): 3.93006183
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=0.2............. Loss: -1.90259180, mean(E): -11.93130564-0.00841470j, var(E): 2.20573780
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=0.2............. Loss: -1.19498445, mean(E): -11.78118162+0.07903737j, var(E): 3.58537461
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=0.2............. Loss: -2.83229081, mean(E): -11.61824947-0.01642228j, var(E): 3.94621794
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=0.2............. Loss: -2.47556989, mean(E): -11.87986397+0.04986092j, var(E): 3.45827951
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=0.2............. Loss: -1.36236646, mean(E): -11.89900905-0.00850351j, var(E): 2.62973879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=0.2............. Loss: -0.79509005, mean(E): -12.01116287-0.01368135j, var(E): 2.31583692
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=0.2............. Loss: -1.64508036, mean(E): -11.87175186+0.06297375j, var(E): 3.01870995
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=0.2............. Loss: -1.68150216, mean(E): -11.81586204-0.00900204j, var(E): 2.99577378
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=0.2............. Loss: -0.48804128, mean(E): -11.73865819+0.03847628j, var(E): 3.35932846
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=0.2............. Loss: -2.46160407, mean(E): -11.72974498+0.01119187j, var(E): 3.33560124
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=0.2............. Loss: -3.04628204, mean(E): -11.85877349-0.04584102j, var(E): 3.51384119
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=0.2............. Loss: -2.74723511, mean(E): -11.92973340-0.08696562j, var(E): 3.38193602
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=0.2............. Loss: -2.72551523, mean(E): -12.04942737-0.00214591j, var(E): 3.18894249
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=0.2............. Loss: 0.95561191, mean(E): -11.88534482+0.04108731j, var(E): 3.07669300
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=0.2............. Loss: 1.47096462, mean(E): -11.75716496-0.01217929j, var(E): 3.67296562
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=0.2............. Loss: -2.46361705, mean(E): -11.79682820+0.06413749j, var(E): 3.96702171
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=0.21............. Loss: -1.04601338, mean(E): -12.02421367-0.00890459j, var(E): 3.60404211
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=0.2............. Loss: -0.61887369, mean(E): -11.75829544+0.05457526j, var(E): 4.91575620
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=0.2............. Loss: -2.59152499, mean(E): -11.85902990+0.10911446j, var(E): 13.03160444
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=0.2............. Loss: -1.74264254, mean(E): -11.96925495+0.01254280j, var(E): 2.63962916
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=0.2............. Loss: -0.87138823, mean(E): -11.78693269+0.06452756j, var(E): 3.26538157
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=0.2............. Loss: -0.99364494, mean(E): -11.73361662+0.01618424j, var(E): 2.85830145
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=0.2............. Loss: -6.64262049, mean(E): -11.89480535-0.13603598j, var(E): 4.98310338
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=0.2............. Loss: -4.44234961, mean(E): -11.84955927-0.03185934j, var(E): 4.62743964
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=0.2............. Loss: -2.98287726, mean(E): -11.71288071+0.07981708j, var(E): 4.86449336
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=0.2............. Loss: -1.30772464, mean(E): -11.84118565+0.02534351j, var(E): 3.32312086
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=0.2............. Loss: -4.94312361, mean(E): -11.76743679+0.05059879j, var(E): 4.37548236
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=0.2............. Loss: -2.71195196, mean(E): -11.75270653+0.04365977j, var(E): 3.15688338
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=0.2............. Loss: -4.64838313, mean(E): -11.72562031+0.04661772j, var(E): 8.51624038
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=0.2............. Loss: -3.89951202, mean(E): -11.80562588+0.01907130j, var(E): 3.46869192
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=0.2............. Loss: -1.26749971, mean(E): -11.88035798-0.00060040j, var(E): 2.34377237
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=0.2............. Loss: -1.57609839, mean(E): -12.15392597+0.03074221j, var(E): 1.42516635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=0.2............. Loss: -2.54624006, mean(E): -11.84133583+0.13097759j, var(E): 3.55770370
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=0.2............. Loss: -1.46959952, mean(E): -11.84895019+0.02196861j, var(E): 3.00116057
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=0.2............. Loss: -1.77159035, mean(E): -11.91980025-0.01457584j, var(E): 2.32570808
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=0.2............. Loss: -1.10505731, mean(E): -11.88991856+0.04664200j, var(E): 3.09590617
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=0.2............. Loss: -4.72964107, mean(E): -12.06918378-0.08349180j, var(E): 3.99132232
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=0.2............. Loss: -2.38652913, mean(E): -11.68124193+0.03011107j, var(E): 3.41977949
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=0.2............. Loss: -1.12900665, mean(E): -11.84895623-0.00987230j, var(E): 2.93736476
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=0.2............. Loss: -0.72612113, mean(E): -11.96991318+0.02332938j, var(E): 3.65138747
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=0.2............. Loss: -2.58047701, mean(E): -11.95169905+0.07918778j, var(E): 3.50372467
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=0.2............. Loss: -0.87524888, mean(E): -11.85478130-0.02378405j, var(E): 4.56759120
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=0.2............. Loss: -2.81916051, mean(E): -11.69117101-0.01002513j, var(E): 3.21027464
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=0.2............. Loss: 1.70486425, mean(E): -11.95238131+0.01073232j, var(E): 5.65218888
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=0.2............. Loss: -2.56452017, mean(E): -11.65951888-0.01947841j, var(E): 3.42610721
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=0.2............. Loss: -2.27923455, mean(E): -11.97594084+0.02443693j, var(E): 2.81443986
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=0.2............. Loss: -0.63002227, mean(E): -11.78712873-0.01910275j, var(E): 3.25294512
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=0.2............. Loss: -2.89487262, mean(E): -11.90853003+0.00622714j, var(E): 3.15188514
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=0.2............. Loss: -0.79468679, mean(E): -11.99677036+0.04148708j, var(E): 3.09907224
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=0.2............. Loss: -1.15064964, mean(E): -11.87044962+0.04828074j, var(E): 2.73701481
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=0.2............. Loss: 0.85920729, mean(E): -12.03311739+0.04391602j, var(E): 3.27610411
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=0.2............. Loss: -0.19000494, mean(E): -12.17194483-0.00258361j, var(E): 3.03758015
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=0.2............. Loss: -2.89379633, mean(E): -11.87102729+0.03482518j, var(E): 2.47950468
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=0.2............. Loss: -1.65475340, mean(E): -11.81365835-0.00677921j, var(E): 4.00847299
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=0.2............. Loss: -0.38165747, mean(E): -11.85804906-0.01730362j, var(E): 3.31206658
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=0.2............. Loss: -0.12815590, mean(E): -11.94771574-0.01224443j, var(E): 3.10330203
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=0.2............. Loss: -0.50152329, mean(E): -12.03197246+0.00596236j, var(E): 1.85561168
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=0.2............. Loss: 0.00121684, mean(E): -11.86828720+0.08481087j, var(E): 3.78830285
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=0.2............. Loss: -0.28675388, mean(E): -11.88281218+0.16505576j, var(E): 6.63583617
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=0.2............. Loss: -3.32122443, mean(E): -11.81941158-0.01730866j, var(E): 3.65359376
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=0.2............. Loss: -1.92776189, mean(E): -12.07436251+0.01550908j, var(E): 2.06339401
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=0.2............. Loss: -2.69657741, mean(E): -11.95267317+0.01953959j, var(E): 3.32596116
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=0.2............. Loss: -1.91672429, mean(E): -12.04184877-0.01581889j, var(E): 1.60722993
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=0.2............. Loss: -3.39752835, mean(E): -11.80615434-0.06232788j, var(E): 2.95642874
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=0.2............. Loss: -1.40936639, mean(E): -11.87637494+0.06338168j, var(E): 3.58228323
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=0.21............. Loss: -5.33634733, mean(E): -11.84123502-0.02350000j, var(E): 4.19397190
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=0.2............. Loss: 0.13930407, mean(E): -12.05601835+0.03616883j, var(E): 2.50037091
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=0.2............. Loss: 3.61807751, mean(E): -11.94055651-0.09340532j, var(E): 6.55720532
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=0.2............. Loss: -2.77975130, mean(E): -11.88143660-0.00091388j, var(E): 3.03183013
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=0.2............. Loss: -3.50372718, mean(E): -11.84871774+0.07197483j, var(E): 2.89837685
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=0.2............. Loss: -1.16880214, mean(E): -11.84150590-0.01119117j, var(E): 2.90955904
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=0.2............. Loss: -0.57756310, mean(E): -12.01679326+0.00289366j, var(E): 2.29926794
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=0.2............. Loss: -1.99684714, mean(E): -11.99925719-0.02178590j, var(E): 3.36388623
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=0.2............. Loss: -2.46913304, mean(E): -11.88247061+0.06055188j, var(E): 2.90586362
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=0.2............. Loss: -4.22366828, mean(E): -11.90156966+0.00446680j, var(E): 3.14401401
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=0.2............. Loss: -2.04380746, mean(E): -11.89542304+0.04803442j, var(E): 3.04993670
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=0.2............. Loss: -2.87592896, mean(E): -11.89648546+0.00022328j, var(E): 3.06072986
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=0.2............. Loss: -0.90697208, mean(E): -11.96265537+0.03668394j, var(E): 2.92532882
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=0.2............. Loss: -2.95033111, mean(E): -11.82501406-0.00104085j, var(E): 3.31480899
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=0.2............. Loss: -1.89678168, mean(E): -11.73256508-0.01267829j, var(E): 3.59596166
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=0.2............. Loss: -0.93882791, mean(E): -12.04922342+0.04782847j, var(E): 2.84049191
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=0.2............. Loss: -1.35110728, mean(E): -11.81718481+0.00183579j, var(E): 3.81630962
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=0.2............. Loss: -3.18911357, mean(E): -11.78816696+0.00870031j, var(E): 2.85740700
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=0.2............. Loss: -0.74371767, mean(E): -11.87317829+0.04647669j, var(E): 3.34204729
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=0.21............. Loss: -2.14377924, mean(E): -11.95294431+0.01720337j, var(E): 2.74328805
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=0.2............. Loss: 0.83473602, mean(E): -11.84670387+0.06320973j, var(E): 3.91901879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=0.2............. Loss: -0.27440627, mean(E): -11.81608281+0.04434998j, var(E): 3.16807619
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=0.2............. Loss: -1.69222259, mean(E): -11.88712990-0.03494336j, var(E): 4.03694759
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=0.2............. Loss: -1.43761379, mean(E): -11.83122108+0.01694580j, var(E): 3.30104375
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=0.2............. Loss: -0.61672463, mean(E): -12.01339141+0.00439983j, var(E): 2.68507401
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=0.2............. Loss: -3.13994840, mean(E): -11.81869540-0.00125396j, var(E): 3.36938623
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=0.2............. Loss: -1.02511922, mean(E): -11.73907778-0.00499638j, var(E): 3.80164263
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=0.2............. Loss: -2.11135722, mean(E): -11.92209236+0.03169779j, var(E): 6.91853699
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=0.2............. Loss: -1.64248173, mean(E): -11.85618201+0.02813931j, var(E): 2.53405398
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=0.2............. Loss: -2.48683020, mean(E): -11.66969421-0.00449535j, var(E): 3.83041615
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=0.2............. Loss: -2.99591398, mean(E): -11.88169087-0.05633911j, var(E): 4.37441331
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=0.2............. Loss: -5.29240863, mean(E): -11.65891657+0.00255315j, var(E): 4.53401871
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=0.2............. Loss: -2.71985039, mean(E): -11.67850818+0.04964397j, var(E): 4.18664321
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=0.2............. Loss: -5.17048221, mean(E): -11.93143072-0.10072646j, var(E): 4.81769746
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=0.2............. Loss: -6.92528812, mean(E): -11.74466279+0.04202902j, var(E): 10.07638848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=0.2............. Loss: -0.79449373, mean(E): -11.72507538+0.04622190j, var(E): 3.93183117
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=0.2............. Loss: -2.24354492, mean(E): -11.89253723-0.05690222j, var(E): 4.86007432
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=0.2............. Loss: -1.53066745, mean(E): -11.90500869-0.04243224j, var(E): 2.92041133
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=0.2............. Loss: -3.89390918, mean(E): -12.09218055-0.07533038j, var(E): 4.32777727
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=0.2............. Loss: -1.97447044, mean(E): -11.78663230+0.03949446j, var(E): 3.20044548
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=0.2............. Loss: -2.08931350, mean(E): -11.93214456+0.02101023j, var(E): 3.28844226
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=0.2............. Loss: -2.54270867, mean(E): -11.84527519+0.04941262j, var(E): 2.87694945
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=0.2............. Loss: -0.75348053, mean(E): -12.02989967-0.00749244j, var(E): 2.39350491
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=0.2............. Loss: -1.72460505, mean(E): -11.92704995-0.03993295j, var(E): 2.38464292
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=0.2............. Loss: -2.92380320, mean(E): -11.68320947+0.05089810j, var(E): 3.78631492
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=0.2............. Loss: -1.08113619, mean(E): -11.91721141-0.01204819j, var(E): 3.54372900
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=0.2............. Loss: -1.29066014, mean(E): -12.00659545+0.05643598j, var(E): 3.18044217
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=0.2............. Loss: -2.64240414, mean(E): -11.81606432+0.01273267j, var(E): 2.91574137
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=0.2............. Loss: -2.98602950, mean(E): -11.70491802+0.07943312j, var(E): 4.95726879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=0.2............. Loss: -2.15982610, mean(E): -11.82912251+0.03073360j, var(E): 3.05133407
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=0.2............. Loss: -6.02881015, mean(E): -11.77017427-0.01539839j, var(E): 5.64896107
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=0.2............. Loss: -2.08449253, mean(E): -11.89884826+0.01704048j, var(E): 3.16100420
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=0.2............. Loss: -1.16660742, mean(E): -12.12973543-0.01518863j, var(E): 2.53380867
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=0.2............. Loss: -1.06838564, mean(E): -12.03070580+0.02229022j, var(E): 2.49556752
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=0.2............. Loss: -1.67153732, mean(E): -11.91989310+0.03301076j, var(E): 2.32818284
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=0.2............. Loss: 1.56179884, mean(E): -11.76321101-0.21707125j, var(E): 16.60388280
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=0.2............. Loss: -2.51899504, mean(E): -11.81069000-0.01051435j, var(E): 4.07697023
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=0.2............. Loss: -2.34838215, mean(E): -11.77376217+0.00102598j, var(E): 3.17146903
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=0.2............. Loss: -0.70056884, mean(E): -11.95343159-0.02245769j, var(E): 2.55798468
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=0.2............. Loss: -2.01620662, mean(E): -11.69533451-0.02203684j, var(E): 3.76868041
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=0.2............. Loss: -2.77454884, mean(E): -12.16028317-0.01921613j, var(E): 4.55911001
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=0.2............. Loss: -1.95257432, mean(E): -12.00655123-0.05773541j, var(E): 3.54075787
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=0.22............. Loss: -2.12957472, mean(E): -12.15704825+0.04997676j, var(E): 1.96852556
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=0.21............. Loss: -0.01446761, mean(E): -11.90007448-0.01135889j, var(E): 2.16731912
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=0.21............. Loss: -1.93601681, mean(E): -11.99057289+0.00943930j, var(E): 2.22898487
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=0.21............. Loss: -4.08640965, mean(E): -11.91690184-0.01069444j, var(E): 2.95947988
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=0.21............. Loss: -5.90837071, mean(E): -11.83587868+0.01762800j, var(E): 3.99161887
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=0.21............. Loss: 0.03117761, mean(E): -12.02277526+0.00888414j, var(E): 3.02693559
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=0.21............. Loss: -1.88977345, mean(E): -11.91578059+0.06560832j, var(E): 3.34462644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=0.21............. Loss: -1.29727083, mean(E): -11.97541399+0.06460162j, var(E): 2.39366322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=0.22............. Loss: -2.63649673, mean(E): -12.09127660+0.02426748j, var(E): 2.01786807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=0.21............. Loss: -1.90017224, mean(E): -11.74273867-0.00569289j, var(E): 3.19434467
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=0.22............. Loss: -2.23278354, mean(E): -12.10357080+0.02975228j, var(E): 2.48606053
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=0.21............. Loss: -1.27839965, mean(E): -11.91534016+0.01768124j, var(E): 3.60784646
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=0.21............. Loss: -1.75397666, mean(E): -12.03464556+0.04247499j, var(E): 3.21558061
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=0.21............. Loss: -2.71054112, mean(E): -11.75904710+0.01999025j, var(E): 3.51638614
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=0.21............. Loss: -1.27572927, mean(E): -11.99071511+0.01484980j, var(E): 2.54684892
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=0.21............. Loss: -2.45885908, mean(E): -11.84447984+0.01506734j, var(E): 3.72287933
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=0.21............. Loss: -0.93784895, mean(E): -12.02882637+0.03687878j, var(E): 2.39218619
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=0.21............. Loss: -1.51884539, mean(E): -11.99568721+0.02159282j, var(E): 3.14676264
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=0.21............. Loss: -5.36840349, mean(E): -12.14342457-0.13797059j, var(E): 4.28315699
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=0.21............. Loss: -3.21718087, mean(E): -11.81704793+0.03372605j, var(E): 3.71889325
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=0.21............. Loss: -3.86437018, mean(E): -11.91789289+0.01067057j, var(E): 3.13624107
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=0.21............. Loss: -2.02490236, mean(E): -11.89327285+0.02018078j, var(E): 2.76934216
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=0.21............. Loss: -2.89406798, mean(E): -11.99311289-0.00932397j, var(E): 3.50459243
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=0.21............. Loss: -0.85217549, mean(E): -12.10303120-0.01252239j, var(E): 2.67161865
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=0.21............. Loss: -3.10177733, mean(E): -12.05263127+0.02576405j, var(E): 2.61425122
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=0.21............. Loss: -1.63530034, mean(E): -11.86900277-0.00016485j, var(E): 2.93005350
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=0.21............. Loss: -1.49029673, mean(E): -11.97316642+0.00369039j, var(E): 2.98291764
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=0.21............. Loss: -2.75179432, mean(E): -11.70742581-0.01959773j, var(E): 3.31829113
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=0.21............. Loss: -1.84199943, mean(E): -11.92826979+0.04156748j, var(E): 2.80440207
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=0.21............. Loss: -2.80217402, mean(E): -11.95546440-0.02662458j, var(E): 3.48733749
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=0.21............. Loss: -0.05782982, mean(E): -11.96261449-0.04382952j, var(E): 4.94066357
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=0.21............. Loss: -3.29875046, mean(E): -11.80127929+0.01973387j, var(E): 3.63911007
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=0.21............. Loss: -3.17010672, mean(E): -11.76446156+0.03628814j, var(E): 3.18148014
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=0.21............. Loss: -2.81767789, mean(E): -11.99457273+0.01444312j, var(E): 2.63045828
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=0.21............. Loss: -0.78967681, mean(E): -11.86576002+0.04836389j, var(E): 3.85275710
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=0.21............. Loss: -2.43091195, mean(E): -11.90363536+0.00176979j, var(E): 2.77499501
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=0.21............. Loss: 0.82847987, mean(E): -12.10892757+0.06848743j, var(E): 3.22214495
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=0.21............. Loss: -1.84945947, mean(E): -11.96246112+0.00634319j, var(E): 2.43587091
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=0.21............. Loss: 3.48141094, mean(E): -11.96710646-0.12396334j, var(E): 5.95845466
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=0.21............. Loss: -2.12864837, mean(E): -11.91237080+0.06788331j, var(E): 3.10700444
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=0.21............. Loss: -0.36411349, mean(E): -12.10775087+0.06046702j, var(E): 3.51354660
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=0.21............. Loss: -4.65724139, mean(E): -11.87602922-0.08212094j, var(E): 6.79672485
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=0.21............. Loss: -2.11052315, mean(E): -11.91326279+0.06970929j, var(E): 2.85841495
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=0.21............. Loss: -0.69327386, mean(E): -11.91599030+0.01207169j, var(E): 2.93598581
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=0.21............. Loss: -2.00032526, mean(E): -11.88887873+0.01766405j, var(E): 3.23371291
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=0.21............. Loss: -1.74589712, mean(E): -12.01046378+0.04646975j, var(E): 2.48406653
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=0.21............. Loss: -0.30201334, mean(E): -11.87064339+0.00227517j, var(E): 3.46462858
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=0.21............. Loss: -1.56655517, mean(E): -11.87534590+0.10479661j, var(E): 3.59033880
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=0.21............. Loss: 0.08651344, mean(E): -12.02890525+0.00111416j, var(E): 3.32857112
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=0.22............. Loss: -2.10288369, mean(E): -12.02828820+0.02894122j, var(E): 2.61814781
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=0.21............. Loss: -2.45106912, mean(E): -11.76242385+0.01768790j, var(E): 3.68952359
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=0.21............. Loss: -0.43895583, mean(E): -12.11281100+0.04075662j, var(E): 3.49422393
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=0.21............. Loss: -1.30674464, mean(E): -11.86791378-0.02696571j, var(E): 2.85535518
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=0.21............. Loss: 2.67686245, mean(E): -11.83002876+0.16256161j, var(E): 7.76285249
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=0.21............. Loss: -0.79757296, mean(E): -12.01447638+0.01478919j, var(E): 2.34711955
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=0.21............. Loss: -5.68885935, mean(E): -11.58130332+0.08548233j, var(E): 14.77499315
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=0.21............. Loss: -2.72999103, mean(E): -11.63439037+0.03357484j, var(E): 4.92450895
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=0.21............. Loss: 1.30741811, mean(E): -11.93082570-0.12486752j, var(E): 5.23805619
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=0.21............. Loss: -2.10551482, mean(E): -11.85915052+0.01073266j, var(E): 3.06305256
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=0.21............. Loss: -2.90328843, mean(E): -11.94763981+0.01949676j, var(E): 3.35751011
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=0.22............. Loss: -2.51709173, mean(E): -11.79174484+0.10430896j, var(E): 12.35022610
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=0.21............. Loss: -4.63631891, mean(E): -12.08234929-0.08636289j, var(E): 4.65473832
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=0.21............. Loss: -2.95946424, mean(E): -11.93874870-0.02491604j, var(E): 2.53669132
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=0.21............. Loss: 2.07868463, mean(E): -11.81464511-0.12139404j, var(E): 5.68559902
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=0.21............. Loss: -3.04736089, mean(E): -12.07756348-0.02335064j, var(E): 3.38243149
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=0.21............. Loss: -0.21723533, mean(E): -11.97880560-0.02412510j, var(E): 2.89211761
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=0.21............. Loss: -0.15138125, mean(E): -11.91695837+0.03111506j, var(E): 3.90243289
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=0.27............. Loss: -1.56225884, mean(E): -11.98302712+0.03057426j, var(E): 2.88294904
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=0.21............. Loss: -1.61669787, mean(E): -11.99252110+0.03102060j, var(E): 2.65146684
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=0.22............. Loss: -2.34826577, mean(E): -11.89987117-0.06240155j, var(E): 3.55378848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=0.21............. Loss: -0.97178158, mean(E): -12.07962114+0.01197812j, var(E): 2.28889406
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=0.21............. Loss: -1.26149492, mean(E): -12.05385450-0.00329271j, var(E): 2.37761781
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=0.22............. Loss: -1.90511404, mean(E): -12.08054295-0.00162887j, var(E): 2.22793719
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=0.22............. Loss: -2.25721963, mean(E): -11.77116770+0.03080570j, var(E): 3.32424220
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=0.22............. Loss: -0.44298347, mean(E): -11.97075671+0.00267318j, var(E): 2.83468838
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=0.21............. Loss: -1.39565520, mean(E): -11.77532406+0.05089311j, var(E): 3.62231777
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=0.22............. Loss: -3.63309486, mean(E): -11.85426286-0.01859821j, var(E): 2.78299847
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=0.21............. Loss: -0.64641083, mean(E): -12.16697524+0.01998888j, var(E): 2.90698972
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=0.21............. Loss: -0.69982693, mean(E): -12.10557108+0.02743584j, var(E): 2.55155682
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=0.21............. Loss: -0.85076449, mean(E): -11.95048706+0.06406518j, var(E): 6.16543078
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=0.21............. Loss: -0.13473058, mean(E): -11.89160568+0.15510955j, var(E): 5.69388381
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=0.21............. Loss: -0.94474276, mean(E): -12.11721821+0.05863734j, var(E): 2.84035635
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=0.21............. Loss: -2.12387677, mean(E): -12.09703236-0.04248535j, var(E): 1.50544083
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=0.21............. Loss: 0.02082381, mean(E): -12.16451281+0.01036721j, var(E): 3.22434116
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=0.21............. Loss: -0.26611180, mean(E): -11.87005797+0.06251182j, var(E): 3.29322765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=0.22............. Loss: -5.85205672, mean(E): -11.59989333+0.12666933j, var(E): 15.20753571
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=0.21............. Loss: 0.45955582, mean(E): -12.05920775+0.04172501j, var(E): 3.67356934
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=0.21............. Loss: -1.94821624, mean(E): -11.85911477+0.02588573j, var(E): 3.53980844
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=0.21............. Loss: -2.38588388, mean(E): -11.88738098+0.01583426j, var(E): 2.94592386
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=0.21............. Loss: -0.86851952, mean(E): -12.02415349+0.00143349j, var(E): 2.34759507
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=0.21............. Loss: -1.39932515, mean(E): -11.89262155+0.02713846j, var(E): 2.77298330
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=0.21............. Loss: 0.94796986, mean(E): -12.03392579+0.01570088j, var(E): 3.76616879
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=0.21............. Loss: -0.63522222, mean(E): -12.02723115+0.03487519j, var(E): 3.00880519
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=0.21............. Loss: -6.32348530, mean(E): -11.81088363-0.06942662j, var(E): 5.68807833
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=0.21............. Loss: -1.30231669, mean(E): -11.76597536+0.01366021j, var(E): 3.74909083
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=0.21............. Loss: -1.75203868, mean(E): -11.97076687-0.00135129j, var(E): 2.62207623
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=0.21............. Loss: -0.49582552, mean(E): -11.77413389-0.05278622j, var(E): 4.19330800
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=0.21............. Loss: -1.02326622, mean(E): -12.03767488+0.00409708j, var(E): 2.75631098
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=0.21............. Loss: -1.86458850, mean(E): -12.14801297+0.00122201j, var(E): 2.56037856
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=0.21............. Loss: -2.69700319, mean(E): -11.79340150+0.01208838j, var(E): 2.68711547
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=0.21............. Loss: -2.63152924, mean(E): -11.98627491+0.06181547j, var(E): 2.68154764
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=0.21............. Loss: -2.19460675, mean(E): -11.81414836+0.05711622j, var(E): 3.56747829
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=0.21............. Loss: -2.50123618, mean(E): -11.93913499+0.00910739j, var(E): 3.19547772
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=0.21............. Loss: -1.49415217, mean(E): -12.08845227+0.02281396j, var(E): 2.01716134
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=0.21............. Loss: -2.35500768, mean(E): -11.90030625-0.03706203j, var(E): 3.26168472
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=0.21............. Loss: -5.46467711, mean(E): -11.95288175-0.06638732j, var(E): 8.19806254
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=0.21............. Loss: -3.31590016, mean(E): -11.97460587+0.05222770j, var(E): 4.68056783
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=0.21............. Loss: -0.18113869, mean(E): -12.11037037-0.04280934j, var(E): 3.39846281
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=0.21............. Loss: -0.00211885, mean(E): -12.27198829+0.03080853j, var(E): 3.22726785
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=0.21............. Loss: -2.10846574, mean(E): -11.97722184-0.01231884j, var(E): 3.32099272
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=0.21............. Loss: -0.35175839, mean(E): -12.03936561+0.03539978j, var(E): 1.73474408
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=0.21............. Loss: -1.80189573, mean(E): -11.81238788+0.06388473j, var(E): 3.29917389
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=0.21............. Loss: -1.91566425, mean(E): -12.15598462+0.04395747j, var(E): 1.96991391
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=0.21............. Loss: -2.37951081, mean(E): -11.85768022-0.05056795j, var(E): 3.18050641
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=0.21............. Loss: -0.93910139, mean(E): -12.00796078+0.04923624j, var(E): 2.57704005
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=0.21............. Loss: -1.66705969, mean(E): -11.98148647-0.00284136j, var(E): 2.73220848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=0.21............. Loss: -1.75975107, mean(E): -12.13389765-0.00015448j, var(E): 1.96940038
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=0.21............. Loss: -1.05085257, mean(E): -11.95409976+0.01854248j, var(E): 2.88069418
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=0.21............. Loss: -1.55318405, mean(E): -12.08653922-0.00867218j, var(E): 2.29303619
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=0.21............. Loss: 0.60440588, mean(E): -11.85501871+0.03331372j, var(E): 3.12437357
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=0.21............. Loss: -2.73732682, mean(E): -11.73085446+0.03899906j, var(E): 3.80804191
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=0.21............. Loss: -2.27280500, mean(E): -11.88725324+0.08182903j, var(E): 2.96866672
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=0.21............. Loss: -2.24578888, mean(E): -11.92690669+0.00917568j, var(E): 3.15312820
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=0.21............. Loss: -2.68567964, mean(E): -12.04464614-0.02566970j, var(E): 2.84324531
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=0.21............. Loss: -0.39223977, mean(E): -12.07471366+0.05367194j, var(E): 2.09677971
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=0.21............. Loss: -2.33735846, mean(E): -11.94028045-0.01201000j, var(E): 3.60166830
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=0.21............. Loss: -1.02356608, mean(E): -11.96678178+0.03801782j, var(E): 2.83820992
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=0.21............. Loss: -2.24885044, mean(E): -11.80673648-0.01123887j, var(E): 3.43869934
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=0.21............. Loss: -0.25210931, mean(E): -12.24765639-0.03060497j, var(E): 2.12838807
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=0.21............. Loss: -2.15918538, mean(E): -11.75684807-0.00911030j, var(E): 3.23910038
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=0.22............. Loss: -1.19043795, mean(E): -11.71755882+0.03081559j, var(E): 3.97397495
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=0.22............. Loss: -0.15131208, mean(E): -12.04459502+0.04901314j, var(E): 2.69245743
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=0.22............. Loss: -0.80329563, mean(E): -11.87210337+0.10560833j, var(E): 4.79032657
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=0.22............. Loss: -1.79418299, mean(E): -11.88073802+0.06323510j, var(E): 3.94053789
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=0.2............. Loss: -1.52571363, mean(E): -11.82755064-0.00389457j, var(E): 3.57650463
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=0.2............. Loss: -0.18725147, mean(E): -12.05315732+0.05431947j, var(E): 2.47006845
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=0.2............. Loss: -1.71256977, mean(E): -11.95576710+0.03892239j, var(E): 2.62580314
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=0.2............. Loss: -1.20038023, mean(E): -11.85619848+0.04744059j, var(E): 3.42828080
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=0.2............. Loss: -0.89788493, mean(E): -12.04698930+0.06700831j, var(E): 3.65931624
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=0.2............. Loss: -0.74105548, mean(E): -12.04516141-0.01577551j, var(E): 3.92415760
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=0.22............. Loss: -4.70191628, mean(E): -11.97519752-0.06882229j, var(E): 5.25250088
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=0.22............. Loss: -4.06683138, mean(E): -11.75648757-0.05052844j, var(E): 3.55850065
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=0.22............. Loss: -1.41539548, mean(E): -11.87947511-0.00338932j, var(E): 2.99600241
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=0.22............. Loss: -2.93759137, mean(E): -12.20849166-0.03170186j, var(E): 2.98656835
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=0.22............. Loss: -1.68452257, mean(E): -11.88244825+0.01479313j, var(E): 4.06519380
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=0.22............. Loss: -2.18930954, mean(E): -11.99147568+0.01030454j, var(E): 2.31584720
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=0.22............. Loss: -2.82169968, mean(E): -12.02625407+0.01413215j, var(E): 2.79228648
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=0.21............. Loss: -0.64033671, mean(E): -12.19047905-0.00196483j, var(E): 1.84509848
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=0.21............. Loss: 3.20234854, mean(E): -12.15602461-0.08117219j, var(E): 4.14498918
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=0.22............. Loss: -2.50888675, mean(E): -11.97324299+0.06249165j, var(E): 3.27182752
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(26.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=0.21............. Loss: -1.83004981, mean(E): -11.96616997+0.01383197j, var(E): 3.20006020
